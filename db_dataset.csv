id,title,abstract,authors,published_date,source,url,domain_task
1,Embed Any NeRF: Graph Meta-Networks for Neural Tasks on Arbitrary NeRF Architectures,"Neural Radiance Fields (NeRFs) have emerged as a groundbreaking paradigm for
representing 3D objects and scenes by encoding shape and appearance information
into the weights of a neural network. Recent works have shown how such weights
can be used as input to frameworks processing them to solve deep learning
tasks. Yet, these frameworks can only process NeRFs with a specific, predefined
architecture. In this paper, we present the first framework that can ingest
NeRFs with multiple architectures and perform inference on architectures unseen
at training time. We achieve this goal by training a Graph Meta-Network in a
representation learning framework. Moreover, we show how a contrastive
objective is conducive to obtaining an architecture-agnostic latent space. In
experiments on both MLP-based and tri-planar NeRFs, our approach demonstrates
robust performance in classification and retrieval tasks that either matches or
exceeds that of existing frameworks constrained to single architectures, thus
providing the first architecture-agnostic method to perform tasks on NeRFs by
processing their weights.","Francesco Ballerini, Pierluigi Zama Ramirez, Samuele Salti, Luigi Di Stefano",2025-02-13 18:59:50.000000,arXiv,http://arxiv.org/abs/2502.09623v1,Computer Vision
2,Theoretical Benefit and Limitation of Diffusion Language Model,"Diffusion language models have emerged as a promising approach for text
generation. One would naturally expect this method to be an efficient
replacement for autoregressive models since multiple tokens can be sampled in
parallel during each diffusion step. However, its efficiency-accuracy trade-off
is not yet well understood. In this paper, we present a rigorous theoretical
analysis of a widely used type of diffusion language model, the Masked
Diffusion Model (MDM), and find that its effectiveness heavily depends on the
target evaluation metric. Under mild conditions, we prove that when using
perplexity as the metric, MDMs can achieve near-optimal perplexity in sampling
steps regardless of sequence length, demonstrating that efficiency can be
achieved without sacrificing performance. However, when using the sequence
error rate--which is important for understanding the ""correctness"" of a
sequence, such as a reasoning chain--we show that the required sampling steps
must scale linearly with sequence length to obtain ""correct"" sequences, thereby
eliminating MDM's efficiency advantage over autoregressive models. Our analysis
establishes the first theoretical foundation for understanding the benefits and
limitations of MDMs. All theoretical findings are supported by empirical
studies.","Guhao Feng, Yihan Geng, Jian Guan, Wei Wu, Liwei Wang, Di He",2025-02-13 18:59:47.000000,arXiv,http://arxiv.org/abs/2502.09622v1,Machine Learning
3,"MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency","Answering questions with Chain-of-Thought (CoT) has significantly enhanced
the reasoning capabilities of Large Language Models (LLMs), yet its impact on
Large Multimodal Models (LMMs) still lacks a systematic assessment and in-depth
investigation. In this paper, we introduce MME-CoT, a specialized benchmark
evaluating the CoT reasoning performance of LMMs, spanning six domains: math,
science, OCR, logic, space-time, and general scenes. As the first comprehensive
study in this area, we propose a thorough evaluation suite incorporating three
novel metrics that assess the reasoning quality, robustness, and efficiency at
a fine-grained level. Leveraging curated high-quality data and a unique
evaluation strategy, we conduct an in-depth analysis of state-of-the-art LMMs,
uncovering several key insights: 1) Models with reflection mechanism
demonstrate a superior CoT quality, with Kimi k1.5 outperforming GPT-4o and
demonstrating the highest quality results; 2) CoT prompting often degrades LMM
performance on perception-heavy tasks, suggesting a potentially harmful
overthinking behavior; and 3) Although the CoT quality is high, LMMs with
reflection exhibit significant inefficiency in both normal response and
self-correction phases. We hope MME-CoT serves as a foundation for advancing
multimodal reasoning in LMMs. Project Page: https://mmecot.github.io/","Dongzhi Jiang, Renrui Zhang, Ziyu Guo, Yanwei Li, Yu Qi, Xinyan Chen, Liuhui Wang, Jianhan Jin, Claire Guo, Shen Yan, Bo Zhang, Chaoyou Fu, Peng Gao, Hongsheng Li",2025-02-13 18:59:46.000000,arXiv,http://arxiv.org/abs/2502.09621v1,Computer Vision
4,Exploring the Potential of Encoder-free Architectures in 3D LMMs,"Encoder-free architectures have been preliminarily explored in the 2D visual
domain, yet it remains an open question whether they can be effectively applied
to 3D understanding scenarios. In this paper, we present the first
comprehensive investigation into the potential of encoder-free architectures to
overcome the challenges of encoder-based 3D Large Multimodal Models (LMMs).
These challenges include the failure to adapt to varying point cloud
resolutions and the point features from the encoder not meeting the semantic
needs of Large Language Models (LLMs). We identify key aspects for 3D LMMs to
remove the encoder and enable the LLM to assume the role of the 3D encoder: 1)
We propose the LLM-embedded Semantic Encoding strategy in the pre-training
stage, exploring the effects of various point cloud self-supervised losses. And
we present the Hybrid Semantic Loss to extract high-level semantics. 2) We
introduce the Hierarchical Geometry Aggregation strategy in the instruction
tuning stage. This incorporates inductive bias into the LLM early layers to
focus on the local details of the point clouds. To the end, we present the
first Encoder-free 3D LMM, ENEL. Our 7B model rivals the current
state-of-the-art model, ShapeLLM-13B, achieving 55.0%, 50.92%, and 42.7% on the
classification, captioning, and VQA tasks, respectively. Our results
demonstrate that the encoder-free architecture is highly promising for
replacing encoder-based architectures in the field of 3D understanding. The
code is released at https://github.com/Ivan-Tang-3D/ENEL","Yiwen Tang, Zoey Guo, Zhuhao Wang, Ray Zhang, Qizhi Chen, Junli Liu, Delin Qu, Zhigang Wang, Dong Wang, Xuelong Li, Bin Zhao",2025-02-13 18:59:45.000000,arXiv,http://arxiv.org/abs/2502.09620v1,Computer Vision
5,Can this Model Also Recognize Dogs? Zero-Shot Model Search from Weights,"With the increasing numbers of publicly available models, there are probably
pretrained, online models for most tasks users require. However, current model
search methods are rudimentary, essentially a text-based search in the
documentation, thus users cannot find the relevant models. This paper presents
ProbeLog, a method for retrieving classification models that can recognize a
target concept, such as ""Dog"", without access to model metadata or training
data. Differently from previous probing methods, ProbeLog computes a descriptor
for each output dimension (logit) of each model, by observing its responses on
a fixed set of inputs (probes). Our method supports both logit-based retrieval
(""find more logits like this"") and zero-shot, text-based retrieval (""find all
logits corresponding to dogs""). As probing-based representations require
multiple costly feedforward passes through the model, we develop a method,
based on collaborative filtering, that reduces the cost of encoding
repositories by 3x. We demonstrate that ProbeLog achieves high retrieval
accuracy, both in real-world and fine-grained search tasks and is scalable to
full-size repositories.","Jonathan Kahana, Or Nathan, Eliahu Horwitz, Yedid Hoshen",2025-02-13 18:59:44.000000,arXiv,http://arxiv.org/abs/2502.09619v1,Machine Learning
6,LIFe-GoM: Generalizable Human Rendering with Learned Iterative Feedback Over Multi-Resolution Gaussians-on-Mesh,"Generalizable rendering of an animatable human avatar from sparse inputs
relies on data priors and inductive biases extracted from training on large
data to avoid scene-specific optimization and to enable fast reconstruction.
This raises two main challenges: First, unlike iterative gradient-based
adjustment in scene-specific optimization, generalizable methods must
reconstruct the human shape representation in a single pass at inference time.
Second, rendering is preferably computationally efficient yet of high
resolution. To address both challenges we augment the recently proposed dual
shape representation, which combines the benefits of a mesh and Gaussian
points, in two ways. To improve reconstruction, we propose an iterative
feedback update framework, which successively improves the canonical human
shape representation during reconstruction. To achieve computationally
efficient yet high-resolution rendering, we study a coupled-multi-resolution
Gaussians-on-Mesh representation. We evaluate the proposed approach on the
challenging THuman2.0, XHuman and AIST++ data. Our approach reconstructs an
animatable representation from sparse inputs in less than 1s, renders views
with 95.1FPS at $1024 \times 1024$, and achieves PSNR/LPIPS*/FID of
24.65/110.82/51.27 on THuman2.0, outperforming the state-of-the-art in
rendering quality.","Jing Wen, Alexander G. Schwing, Shenlong Wang",2025-02-13 18:59:19.000000,arXiv,http://arxiv.org/abs/2502.09617v1,Computer Vision
7,Variational Rectified Flow Matching,"We study Variational Rectified Flow Matching, a framework that enhances
classic rectified flow matching by modeling multi-modal velocity vector-fields.
At inference time, classic rectified flow matching 'moves' samples from a
source distribution to the target distribution by solving an ordinary
differential equation via integration along a velocity vector-field. At
training time, the velocity vector-field is learnt by linearly interpolating
between coupled samples one drawn from the source and one drawn from the target
distribution randomly. This leads to ''ground-truth'' velocity vector-fields
that point in different directions at the same location, i.e., the velocity
vector-fields are multi-modal/ambiguous. However, since training uses a
standard mean-squared-error loss, the learnt velocity vector-field averages
''ground-truth'' directions and isn't multi-modal. In contrast, variational
rectified flow matching learns and samples from multi-modal flow directions. We
show on synthetic data, MNIST, CIFAR-10, and ImageNet that variational
rectified flow matching leads to compelling results.","Pengsheng Guo, Alexander G. Schwing",2025-02-13 18:59:15.000000,arXiv,http://arxiv.org/abs/2502.09616v1,Machine Learning
8,DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References,"We address the challenge of developing a generalizable neural tracking
controller for dexterous manipulation from human references. This controller
aims to manage a dexterous robot hand to manipulate diverse objects for various
purposes defined by kinematic human-object interactions. Developing such a
controller is complicated by the intricate contact dynamics of dexterous
manipulation and the need for adaptivity, generalizability, and robustness.
Current reinforcement learning and trajectory optimization methods often fall
short due to their dependence on task-specific rewards or precise system
models. We introduce an approach that curates large-scale successful robot
tracking demonstrations, comprising pairs of human references and robot
actions, to train a neural controller. Utilizing a data flywheel, we
iteratively enhance the controller's performance, as well as the number and
quality of successful tracking demonstrations. We exploit available tracking
demonstrations and carefully integrate reinforcement learning and imitation
learning to boost the controller's performance in dynamic environments. At the
same time, to obtain high-quality tracking demonstrations, we individually
optimize per-trajectory tracking by leveraging the learned tracking controller
in a homotopy optimization method. The homotopy optimization, mimicking
chain-of-thought, aids in solving challenging trajectory tracking problems to
increase demonstration diversity. We showcase our success by training a
generalizable neural controller and evaluating it in both simulation and real
world. Our method achieves over a 10% improvement in success rates compared to
leading baselines. The project website with animated results is available at
https://meowuu7.github.io/DexTrack/.","Xueyi Liu, Jianibieke Adalibieke, Qianwei Han, Yuzhe Qin, Li Yi",2025-02-13 18:59:13.000000,arXiv,http://arxiv.org/abs/2502.09614v1,Robotics
9,RigAnything: Template-Free Autoregressive Rigging for Diverse 3D Assets,"We present RigAnything, a novel autoregressive transformer-based model, which
makes 3D assets rig-ready by probabilistically generating joints, skeleton
topologies, and assigning skinning weights in a template-free manner. Unlike
most existing auto-rigging methods, which rely on predefined skeleton template
and are limited to specific categories like humanoid, RigAnything approaches
the rigging problem in an autoregressive manner, iteratively predicting the
next joint based on the global input shape and the previous prediction. While
autoregressive models are typically used to generate sequential data,
RigAnything extends their application to effectively learn and represent
skeletons, which are inherently tree structures. To achieve this, we organize
the joints in a breadth-first search (BFS) order, enabling the skeleton to be
defined as a sequence of 3D locations and the parent index. Furthermore, our
model improves the accuracy of position prediction by leveraging diffusion
modeling, ensuring precise and consistent placement of joints within the
hierarchy. This formulation allows the autoregressive model to efficiently
capture both spatial and hierarchical relationships within the skeleton.
Trained end-to-end on both RigNet and Objaverse datasets, RigAnything
demonstrates state-of-the-art performance across diverse object types,
including humanoids, quadrupeds, marine creatures, insects, and many more,
surpassing prior methods in quality, robustness, generalizability, and
efficiency. Please check our website for more details:
https://www.liuisabella.com/RigAnything.","Isabella Liu, Zhan Xu, Wang Yifan, Hao Tan, Zexiang Xu, Xiaolong Wang, Hao Su, Zifan Shi",2025-02-13 18:59:13.000000,arXiv,http://arxiv.org/abs/2502.09615v1,Computer Vision
10,Latent Radiance Fields with 3D-aware 2D Representations,"Latent 3D reconstruction has shown great promise in empowering 3D semantic
understanding and 3D generation by distilling 2D features into the 3D space.
However, existing approaches struggle with the domain gap between 2D feature
space and 3D representations, resulting in degraded rendering performance. To
address this challenge, we propose a novel framework that integrates 3D
awareness into the 2D latent space. The framework consists of three stages: (1)
a correspondence-aware autoencoding method that enhances the 3D consistency of
2D latent representations, (2) a latent radiance field (LRF) that lifts these
3D-aware 2D representations into 3D space, and (3) a VAE-Radiance Field
(VAE-RF) alignment strategy that improves image decoding from the rendered 2D
representations. Extensive experiments demonstrate that our method outperforms
the state-of-the-art latent 3D reconstruction approaches in terms of synthesis
performance and cross-dataset generalizability across diverse indoor and
outdoor scenes. To our knowledge, this is the first work showing the radiance
field representations constructed from 2D latent representations can yield
photorealistic 3D reconstruction performance.","Chaoyi Zhou, Xi Liu, Feng Luo, Siyu Huang",2025-02-13 18:59:09.000000,arXiv,http://arxiv.org/abs/2502.09613v1,Computer Vision
11,Designing a Conditional Prior Distribution for Flow-Based Generative Models,"Flow-based generative models have recently shown impressive performance for
conditional generation tasks, such as text-to-image generation. However,
current methods transform a general unimodal noise distribution to a specific
mode of the target data distribution. As such, every point in the initial
source distribution can be mapped to every point in the target distribution,
resulting in long average paths. To this end, in this work, we tap into a
non-utilized property of conditional flow-based models: the ability to design a
non-trivial prior distribution. Given an input condition, such as a text
prompt, we first map it to a point lying in data space, representing an
``average"" data point with the minimal average distance to all data points of
the same conditional mode (e.g., class). We then utilize the flow matching
formulation to map samples from a parametric distribution centered around this
point to the conditional target distribution. Experimentally, our method
significantly improves training times and generation efficiency (FID, KID and
CLIP alignment scores) compared to baselines, producing high quality samples
using fewer sampling steps.","Noam Issachar, Mohammad Salama, Raanan Fattal, Sagie Benaim",2025-02-13 18:58:15.000000,arXiv,http://arxiv.org/abs/2502.09611v1,Machine Learning
12,Score-of-Mixture Training: Training One-Step Generative Models Made Simple,"We propose Score-of-Mixture Training (SMT), a novel framework for training
one-step generative models by minimizing a class of divergences called the
$\alpha$-skew Jensen-Shannon divergence. At its core, SMT estimates the score
of mixture distributions between real and fake samples across multiple noise
levels. Similar to consistency models, our approach supports both training from
scratch (SMT) and distillation using a pretrained diffusion model, which we
call Score-of-Mixture Distillation (SMD). It is simple to implement, requires
minimal hyperparameter tuning, and ensures stable training. Experiments on
CIFAR-10 and ImageNet 64x64 show that SMT/SMD are competitive with and can even
outperform existing methods.","Tejas Jayashankar, J. Jon Ryu, Gregory Wornell",2025-02-13 18:57:20.000000,arXiv,http://arxiv.org/abs/2502.09609v1,Machine Learning
13,Instance Segmentation of Scene Sketches Using Natural Image Priors,"Sketch segmentation involves grouping pixels within a sketch that belong to
the same object or instance. It serves as a valuable tool for sketch editing
tasks, such as moving, scaling, or removing specific components. While image
segmentation models have demonstrated remarkable capabilities in recent years,
sketches present unique challenges for these models due to their sparse nature
and wide variation in styles. We introduce SketchSeg, a method for instance
segmentation of raster scene sketches. Our approach adapts state-of-the-art
image segmentation and object detection models to the sketch domain by
employing class-agnostic fine-tuning and refining segmentation masks using
depth cues. Furthermore, our method organizes sketches into sorted layers,
where occluded instances are inpainted, enabling advanced sketch editing
applications. As existing datasets in this domain lack variation in sketch
styles, we construct a synthetic scene sketch segmentation dataset featuring
sketches with diverse brush strokes and varying levels of detail. We use this
dataset to demonstrate the robustness of our approach and will release it to
promote further research in the field.
  Project webpage: https://sketchseg.github.io/sketch-seg/","Mia Tang, Yael Vinker, Chuan Yan, Lvmin Zhang, Maneesh Agrawala",2025-02-13 18:56:05.000000,arXiv,http://arxiv.org/abs/2502.09608v1,Computer Vision
14,Human-LLM Coevolution: Evidence from Academic Writing,"With a statistical analysis of arXiv paper abstracts, we report a marked drop
in the frequency of several words previously identified as overused by ChatGPT,
such as ""delve"", starting soon after they were pointed out in early 2024. The
frequency of certain other words favored by ChatGPT, such as ""significant"", has
instead kept increasing. These phenomena suggest that some authors of academic
papers have adapted their use of large language models (LLMs), for example, by
selecting outputs or applying modifications to the LLM-generated content. Such
coevolution and cooperation of humans and LLMs thus introduce additional
challenges to the detection of machine-generated text in real-world scenarios.
Estimating the impact of LLMs on academic writing by examining word frequency
remains feasible, and more attention should be paid to words that were already
frequently employed, including those that have decreased in frequency.","Mingmeng Geng, Roberto Trotta",2025-02-13 18:55:56.000000,arXiv,http://arxiv.org/abs/2502.09606v1,Natural Language Processing
15,SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models,"We introduce SelfCite, a novel self-supervised approach that aligns LLMs to
generate high-quality, fine-grained, sentence-level citations for the
statements in their generated responses. Instead of only relying on costly and
labor-intensive annotations, SelfCite leverages a reward signal provided by the
LLM itself through context ablation: If a citation is necessary, removing the
cited text from the context should prevent the same response; if sufficient,
retaining the cited text alone should preserve the same response. This reward
can guide the inference-time best-of-N sampling strategy to improve citation
quality significantly, as well as be used in preference optimization to
directly fine-tune the models for generating better citations. The
effectiveness of SelfCite is demonstrated by increasing citation F1 up to 5.3
points on the LongBench-Cite benchmark across five long-form question answering
tasks.","Yung-Sung Chuang, Benjamin Cohen-Wang, Shannon Zejiang Shen, Zhaofeng Wu, Hu Xu, Xi Victoria Lin, James Glass, Shang-Wen Li, Wen-tau Yih",2025-02-13 18:55:13.000000,arXiv,http://arxiv.org/abs/2502.09604v1,Natural Language Processing
16,CoT-Valve: Length-Compressible Chain-of-Thought Tuning,"Chain-of-Thought significantly enhances a model's reasoning capability, but
it also comes with a considerable increase in inference costs due to long
chains. With the observation that the reasoning path can be easily compressed
under easy tasks but struggle on hard tasks, we explore the feasibility of
elastically controlling the length of reasoning paths with only one model,
thereby reducing the inference overhead of reasoning models dynamically based
on task difficulty. We introduce a new tuning and inference strategy named
CoT-Valve, designed to allow models to generate reasoning chains of varying
lengths. To achieve this, we propose to identify a direction in the parameter
space that, when manipulated, can effectively control the length of generated
CoT. Moreover, we show that this property is valuable for compressing the
reasoning chain. We construct datasets with chains from long to short for the
same questions and explore two enhanced strategies for CoT-Valve: (1) a precise
length-compressible CoT tuning method, and (2) a progressive chain length
compression approach. Our experiments show that CoT-Valve successfully enables
controllability and compressibility of the chain and shows better performance
than the prompt-based control. We applied this method to QwQ-32B-Preview,
reducing reasoning chains on GSM8K from 741 to 225 tokens with a minor
performance drop (95.07% to 94.92%) and on AIME from 6827 to 4629 tokens, with
only one additional incorrect answer.","Xinyin Ma, Guangnian Wan, Runpeng Yu, Gongfan Fang, Xinchao Wang",2025-02-13 18:52:36.000000,arXiv,http://arxiv.org/abs/2502.09601v1,Artificial Intelligence
17,"GAIA: A Global, Multi-modal, Multi-scale Vision-Language Dataset for Remote Sensing Image Analysis","The continuous operation of Earth-orbiting satellites generates vast and
ever-growing archives of Remote Sensing (RS) images. Natural language presents
an intuitive interface for accessing, querying, and interpreting the data from
such archives. However, existing Vision-Language Models (VLMs) are
predominantly trained on web-scraped, noisy image-text data, exhibiting limited
exposure to the specialized domain of RS. This deficiency results in poor
performance on RS-specific tasks, as commonly used datasets often lack
detailed, scientifically accurate textual descriptions and instead emphasize
solely on attributes like date and location. To bridge this critical gap, we
introduce GAIA, a novel dataset designed for multi-scale, multi-sensor, and
multi-modal RS image analysis. GAIA comprises of 205,150 meticulously curated
RS image-text pairs, representing a diverse range of RS modalities associated
to different spatial resolutions. Unlike existing vision-language datasets in
RS, GAIA specifically focuses on capturing a diverse range of RS applications,
providing unique information about environmental changes, natural disasters,
and various other dynamic phenomena. The dataset provides a spatially and
temporally balanced distribution, spanning across the globe, covering the last
25 years with a balanced temporal distribution of observations. GAIA's
construction involved a two-stage process: (1) targeted web-scraping of images
and accompanying text from reputable RS-related sources, and (2) generation of
five high-quality, scientifically grounded synthetic captions for each image
using carefully crafted prompts that leverage the advanced vision-language
capabilities of GPT-4o. Our extensive experiments, including fine-tuning of
CLIP and BLIP2 models, demonstrate that GAIA significantly improves performance
on RS image classification, cross-modal retrieval and image captioning tasks.","Angelos Zavras, Dimitrios Michail, Xiao Xiang Zhu, Begüm Demir, Ioannis Papoutsis",2025-02-13 18:52:14.000000,arXiv,http://arxiv.org/abs/2502.09598v1,Computer Vision
18,Do LLMs Recognize Your Preferences? Evaluating Personalized Preference Following in LLMs,"Large Language Models (LLMs) are increasingly used as chatbots, yet their
ability to personalize responses to user preferences remains limited. We
introduce PrefEval, a benchmark for evaluating LLMs' ability to infer, memorize
and adhere to user preferences in a long-context conversational setting.
PrefEval comprises 3,000 manually curated user preference and query pairs
spanning 20 topics. PrefEval contains user personalization or preference
information in both explicit and implicit forms, and evaluates LLM performance
using a generation and a classification task. With PrefEval, we evaluated the
aforementioned preference following capabilities of 10 open-source and
proprietary LLMs in multi-session conversations with varying context lengths up
to 100k tokens. We benchmark with various prompting, iterative feedback, and
retrieval-augmented generation methods. Our benchmarking effort reveals that
state-of-the-art LLMs face significant challenges in proactively following
users' preferences during conversations. In particular, in zero-shot settings,
preference following accuracy falls below 10% at merely 10 turns (~3k tokens)
across most evaluated models. Even with advanced prompting and retrieval
methods, preference following still deteriorates in long-context conversations.
Furthermore, we show that fine-tuning on PrefEval significantly improves
performance. We believe PrefEval serves as a valuable resource for measuring,
understanding, and enhancing LLMs' preference following abilities, paving the
way for personalized conversational agents. Our code and dataset are available
at https://prefeval.github.io/.","Siyan Zhao, Mingyi Hong, Yang Liu, Devamanyu Hazarika, Kaixiang Lin",2025-02-13 18:52:03.000000,arXiv,http://arxiv.org/abs/2502.09597v1,Machine Learning
19,KIMAs: A Configurable Knowledge Integrated Multi-Agent System,"Knowledge-intensive conversations supported by large language models (LLMs)
have become one of the most popular and helpful applications that can assist
people in different aspects. Many current knowledge-intensive applications are
centered on retrieval-augmented generation (RAG) techniques. While many
open-source RAG frameworks facilitate the development of RAG-based
applications, they often fall short in handling practical scenarios complicated
by heterogeneous data in topics and formats, conversational context management,
and the requirement of low-latency response times. This technical report
presents a configurable knowledge integrated multi-agent system, KIMAs, to
address these challenges. KIMAs features a flexible and configurable system for
integrating diverse knowledge sources with 1) context management and query
rewrite mechanisms to improve retrieval accuracy and multi-turn conversational
coherency, 2) efficient knowledge routing and retrieval, 3) simple but
effective filter and reference generation mechanisms, and 4) optimized
parallelizable multi-agent pipeline execution. Our work provides a scalable
framework for advancing the deployment of LLMs in real-world settings. To show
how KIMAs can help developers build knowledge-intensive applications with
different scales and emphases, we demonstrate how we configure the system to
three applications already running in practice with reliable performance.","Zitao Li, Fei Wei, Yuexiang Xie, Dawei Gao, Weirui Kuang, Zhijian Ma, Bingchen Qian, Yaliang Li, Bolin Ding",2025-02-13 18:51:12.000000,arXiv,http://arxiv.org/abs/2502.09596v1,Artificial Intelligence
20,Censor Dependent Variational Inference,"This paper provides a comprehensive analysis of variational inference in
latent variable models for survival analysis, emphasizing the distinctive
challenges associated with applying variational methods to survival data. We
identify a critical weakness in the existing methodology, demonstrating how a
poorly designed variational distribution may hinder the objective of survival
analysis tasks--modeling time-to-event distributions. We prove that the optimal
variational distribution, which perfectly bounds the log-likelihood, may depend
on the censoring mechanism. To address this issue, we propose censor-dependent
variational inference (CDVI), tailored for latent variable models in survival
analysis. More practically, we introduce CD-CVAE, a V-structure Variational
Autoencoder (VAE) designed for the scalable implementation of CDVI. Further
discussion extends some existing theories and training techniques to survival
analysis. Extensive experiments validate our analysis and demonstrate
significant improvements in the estimation of individual survival
distributions.","Chuanhui Liu, Xiao Wang",2025-02-13 18:48:04.000000,arXiv,http://arxiv.org/abs/2502.09591v1,Machine Learning
21,Logical forms complement probability in understanding language model (and human) performance,"With the increasing interest in using large language models (LLMs) for
planning in natural language, understanding their behaviors becomes an
important research question. This work conducts a systematic investigation of
LLMs' ability to perform logical reasoning in natural language. We introduce a
controlled dataset of hypothetical and disjunctive syllogisms in propositional
and modal logic and use it as the testbed for understanding LLM performance.
Our results lead to novel insights in predicting LLM behaviors: in addition to
the probability of input (Gonen et al., 2023; McCoy et al., 2024), logical
forms should be considered as orthogonal factors. In addition, we show
similarities and differences between the logical reasoning performances of
humans and LLMs by comparing LLM and human behavioral results.","Yixuan Wang, Freda Shi",2025-02-13 18:46:44.000000,arXiv,http://arxiv.org/abs/2502.09589v1,Natural Language Processing
22,Rolling Ahead Diffusion for Traffic Scene Simulation,"Realistic driving simulation requires that NPCs not only mimic natural
driving behaviors but also react to the behavior of other simulated agents.
Recent developments in diffusion-based scenario generation focus on creating
diverse and realistic traffic scenarios by jointly modelling the motion of all
the agents in the scene. However, these traffic scenarios do not react when the
motion of agents deviates from their modelled trajectories. For example, the
ego-agent can be controlled by a stand along motion planner. To produce
reactive scenarios with joint scenario models, the model must regenerate the
scenario at each timestep based on new observations in a Model Predictive
Control (MPC) fashion. Although reactive, this method is time-consuming, as one
complete possible future for all NPCs is generated per simulation step.
Alternatively, one can utilize an autoregressive model (AR) to predict only the
immediate next-step future for all NPCs. Although faster, this method lacks the
capability for advanced planning. We present a rolling diffusion based traffic
scene generation model which mixes the benefits of both methods by predicting
the next step future and simultaneously predicting partially noised further
future steps at the same time. We show that such model is efficient compared to
diffusion model based AR, achieving a beneficial compromise between reactivity
and computational efficiency.","Yunpeng Liu, Matthew Niedoba, William Harvey, Adam Scibior, Berend Zwartsenberg, Frank Wood",2025-02-13 18:45:56.000000,arXiv,http://arxiv.org/abs/2502.09587v1,Machine Learning
23,Learning to Coordinate with Experts,"When deployed in dynamic environments, AI agents will inevitably encounter
challenges that exceed their individual capabilities. Leveraging assistance
from expert agents-whether human or AI-can significantly enhance safety and
performance in such situations. However, querying experts is often costly,
necessitating the development of agents that can efficiently request and
utilize expert guidance. In this paper, we introduce a fundamental coordination
problem called Learning to Yield and Request Control (YRC), where the objective
is to learn a strategy that determines when to act autonomously and when to
seek expert assistance. We consider a challenging practical setting in which an
agent does not interact with experts during training but must adapt to novel
environmental changes and expert interventions at test time. To facilitate
empirical research, we introduce YRC-Bench, an open-source benchmark featuring
diverse domains. YRC-Bench provides a standardized Gym-like API, simulated
experts, evaluation pipeline, and implementation of competitive baselines.
Towards tackling the YRC problem, we propose a novel validation approach and
investigate the performance of various learning methods across diverse
environments, yielding insights that can guide future research.","Mohamad H. Danesh, Tu Trinh, Benjamin Plaut, Nguyen X. Khanh",2025-02-13 18:41:55.000000,arXiv,http://arxiv.org/abs/2502.09583v1,Machine Learning
24,Optimizing GPT for Video Understanding: Zero-Shot Performance and Prompt Engineering,"In this study, we tackle industry challenges in video content classification
by exploring and optimizing GPT-based models for zero-shot classification
across seven critical categories of video quality. We contribute a novel
approach to improving GPT's performance through prompt optimization and policy
refinement, demonstrating that simplifying complex policies significantly
reduces false negatives. Additionally, we introduce a new
decomposition-aggregation-based prompt engineering technique, which outperforms
traditional single-prompt methods. These experiments, conducted on real
industry problems, show that thoughtful prompt design can substantially enhance
GPT's performance without additional finetuning, offering an effective and
scalable solution for improving video classification systems across various
domains in industry.","Mark Beliaev, Victor Yang, Madhura Raju, Jiachen Sun, Xinghai Hu",2025-02-13 18:31:17.000000,arXiv,http://arxiv.org/abs/2502.09573v1,Computer Vision
25,DiffMS: Diffusion Generation of Molecules Conditioned on Mass Spectra,"Mass spectrometry plays a fundamental role in elucidating the structures of
unknown molecules and subsequent scientific discoveries. One formulation of the
structure elucidation task is the conditional $\textit{de novo}$ generation of
molecular structure given a mass spectrum. Toward a more accurate and efficient
scientific discovery pipeline for small molecules, we present DiffMS, a
formula-restricted encoder-decoder generative network that achieves
state-of-the-art performance on this task. The encoder utilizes a transformer
architecture and models mass spectra domain knowledge such as peak formulae and
neutral losses, and the decoder is a discrete graph diffusion model restricted
by the heavy-atom composition of a known chemical formula. To develop a robust
decoder that bridges latent embeddings and molecular structures, we pretrain
the diffusion decoder with fingerprint-structure pairs, which are available in
virtually infinite quantities, compared to structure-spectrum pairs that number
in the tens of thousands. Extensive experiments on established benchmarks show
that DiffMS outperforms existing models on $\textit{de novo}$ molecule
generation. We provide several ablations to demonstrate the effectiveness of
our diffusion and pretraining approaches and show consistent performance
scaling with increasing pretraining dataset size. DiffMS code is publicly
available at https://github.com/coleygroup/DiffMS.","Montgomery Bohde, Mrunali Manjrekar, Runzhong Wang, Shuiwang Ji, Connor W. Coley",2025-02-13 18:29:48.000000,arXiv,http://arxiv.org/abs/2502.09571v1,Machine Learning
26,Enhancing the Utility of Higher-Order Information in Relational Learning,"Higher-order information is crucial for relational learning in many domains
where relationships extend beyond pairwise interactions. Hypergraphs provide a
natural framework for modeling such relationships, which has motivated recent
extensions of graph neural net- work architectures to hypergraphs. However,
comparisons between hypergraph architectures and standard graph-level models
remain limited. In this work, we systematically evaluate a selection of
hypergraph-level and graph-level architectures, to determine their
effectiveness in leveraging higher-order information in relational learning.
Our results show that graph-level architectures applied to hypergraph
expansions often outperform hypergraph- level ones, even on inputs that are
naturally parametrized as hypergraphs. As an alternative approach for
leveraging higher-order information, we propose hypergraph-level encodings
based on classical hypergraph characteristics. While these encodings do not
significantly improve hypergraph architectures, they yield substantial
performance gains when combined with graph-level models. Our theoretical
analysis shows that hypergraph-level encodings provably increase the
representational power of message-passing graph neural networks beyond that of
their graph-level counterparts.","Raphael Pellegrin, Lukas Fesser, Melanie Weber",2025-02-13 18:28:17.000000,arXiv,http://arxiv.org/abs/2502.09570v1,Machine Learning
27,MorphNLI: A Stepwise Approach to Natural Language Inference Using Text Morphing,"We introduce MorphNLI, a modular step-by-step approach to natural language
inference (NLI). When classifying the premise-hypothesis pairs into
{entailment, contradiction, neutral}, we use a language model to generate the
necessary edits to incrementally transform (i.e., morph) the premise into the
hypothesis. Then, using an off-the-shelf NLI model we track how the entailment
progresses with these atomic changes, aggregating these intermediate labels
into a final output. We demonstrate the advantages of our proposed method
particularly in realistic cross-domain settings, where our method always
outperforms strong baselines with improvements up to 12.6% (relative). Further,
our proposed approach is explainable as the atomic edits can be used to
understand the overall NLI label.","Vlad Andrei Negru, Robert Vacareanu, Camelia Lemnaru, Mihai Surdeanu, Rodica Potolea",2025-02-13 18:22:31.000000,arXiv,http://arxiv.org/abs/2502.09567v1,Natural Language Processing
28,Zero-shot generation of synthetic neurosurgical data with large language models,"Clinical data is fundamental to advance neurosurgical research, but access is
often constrained by data availability, small sample sizes, privacy
regulations, and resource-intensive preprocessing and de-identification
procedures. Synthetic data offers a potential solution to challenges associated
with accessing and using real-world data (RWD). This study aims to evaluate the
capability of zero-shot generation of synthetic neurosurgical data with a large
language model (LLM), GPT-4o, by benchmarking with the conditional tabular
generative adversarial network (CTGAN). Synthetic datasets were compared to
real-world neurosurgical data to assess fidelity (means, proportions,
distributions, and bivariate correlations), utility (ML classifier performance
on RWD), and privacy (duplication of records from RWD). The GPT-4o-generated
datasets matched or exceeded CTGAN performance, despite no fine-tuning or
access to RWD for pre-training. Datasets demonstrated high univariate and
bivariate fidelity to RWD without directly exposing any real patient records,
even at amplified sample size. Training an ML classifier on GPT-4o-generated
data and testing on RWD for a binary prediction task showed an F1 score (0.706)
with comparable performance to training on the CTGAN data (0.705) for
predicting postoperative functional status deterioration. GPT-4o demonstrated a
promising ability to generate high-fidelity synthetic neurosurgical data. These
findings also indicate that data synthesized with GPT-4o can effectively
augment clinical data with small sample sizes, and train ML models for
prediction of neurosurgical outcomes. Further investigation is necessary to
improve the preservation of distributional characteristics and boost classifier
performance.","Austin A. Barr, Eddie Guo, Emre Sezgin",2025-02-13 18:21:15.000000,arXiv,http://arxiv.org/abs/2502.09566v1,Natural Language Processing
29,MDCrow: Automating Molecular Dynamics Workflows with Large Language Models,"Molecular dynamics (MD) simulations are essential for understanding
biomolecular systems but remain challenging to automate. Recent advances in
large language models (LLM) have demonstrated success in automating complex
scientific tasks using LLM-based agents. In this paper, we introduce MDCrow, an
agentic LLM assistant capable of automating MD workflows. MDCrow uses
chain-of-thought over 40 expert-designed tools for handling and processing
files, setting up simulations, analyzing the simulation outputs, and retrieving
relevant information from literature and databases. We assess MDCrow's
performance across 25 tasks of varying required subtasks and difficulty, and we
evaluate the agent's robustness to both difficulty and prompt style.
\texttt{gpt-4o} is able to complete complex tasks with low variance, followed
closely by \texttt{llama3-405b}, a compelling open-source model. While prompt
style does not influence the best models' performance, it has significant
effects on smaller models.","Quintina Campbell, Sam Cox, Jorge Medina, Brittany Watterson, Andrew D. White",2025-02-13 18:19:20.000000,arXiv,http://arxiv.org/abs/2502.09565v1,Artificial Intelligence
30,Diffusing DeBias: a Recipe for Turning a Bug into a Feature,"Deep learning model effectiveness in classification tasks is often challenged
by the quality and quantity of training data which, whenever containing strong
spurious correlations between specific attributes and target labels, can result
in unrecoverable biases in model predictions. Tackling these biases is crucial
in improving model generalization and trust, especially in real-world
scenarios. This paper presents Diffusing DeBias (DDB), a novel approach acting
as a plug-in for common methods in model debiasing while exploiting the
inherent bias-learning tendency of diffusion models. Our approach leverages
conditional diffusion models to generate synthetic bias-aligned images, used to
train a bias amplifier model, to be further employed as an auxiliary method in
different unsupervised debiasing approaches. Our proposed method, which also
tackles the common issue of training set memorization typical of this type of
tech- niques, beats current state-of-the-art in multiple benchmark datasets by
significant margins, demonstrating its potential as a versatile and effective
tool for tackling dataset bias in deep learning applications.","Massimiliano Ciranni, Vito Paolo Pastore, Roberto Di Via, Enzo Tartaglione, Francesca Odone, Vittorio Murino",2025-02-13 18:17:03.000000,arXiv,http://arxiv.org/abs/2502.09564v1,Machine Learning
31,Self-Calibrating Gaussian Splatting for Large Field of View Reconstruction,"In this paper, we present a self-calibrating framework that jointly optimizes
camera parameters, lens distortion and 3D Gaussian representations, enabling
accurate and efficient scene reconstruction. In particular, our technique
enables high-quality scene reconstruction from Large field-of-view (FOV)
imagery taken with wide-angle lenses, allowing the scene to be modeled from a
smaller number of images. Our approach introduces a novel method for modeling
complex lens distortions using a hybrid network that combines invertible
residual networks with explicit grids. This design effectively regularizes the
optimization process, achieving greater accuracy than conventional camera
models. Additionally, we propose a cubemap-based resampling strategy to support
large FOV images without sacrificing resolution or introducing distortion
artifacts. Our method is compatible with the fast rasterization of Gaussian
Splatting, adaptable to a wide variety of camera lens distortion, and
demonstrates state-of-the-art performance on both synthetic and real-world
datasets.","Youming Deng, Wenqi Xian, Guandao Yang, Leonidas Guibas, Gordon Wetzstein, Steve Marschner, Paul Debevec",2025-02-13 18:15:10.000000,arXiv,http://arxiv.org/abs/2502.09563v1,Computer Vision
32,EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents,"Leveraging Multi-modal Large Language Models (MLLMs) to create embodied
agents offers a promising avenue for tackling real-world tasks. While
language-centric embodied agents have garnered substantial attention,
MLLM-based embodied agents remain underexplored due to the lack of
comprehensive evaluation frameworks. To bridge this gap, we introduce
EmbodiedBench, an extensive benchmark designed to evaluate vision-driven
embodied agents. EmbodiedBench features: (1) a diverse set of 1,128 testing
tasks across four environments, ranging from high-level semantic tasks (e.g.,
household) to low-level tasks involving atomic actions (e.g., navigation and
manipulation); and (2) six meticulously curated subsets evaluating essential
agent capabilities like commonsense reasoning, complex instruction
understanding, spatial awareness, visual perception, and long-term planning.
Through extensive experiments, we evaluated 13 leading proprietary and
open-source MLLMs within EmbodiedBench. Our findings reveal that: MLLMs excel
at high-level tasks but struggle with low-level manipulation, with the best
model, GPT-4o, scoring only 28.9% on average. EmbodiedBench provides a
multifaceted standardized evaluation platform that not only highlights existing
challenges but also offers valuable insights to advance MLLM-based embodied
agents. Our code is available at https://embodiedbench.github.io.","Rui Yang, Hanyang Chen, Junyu Zhang, Mark Zhao, Cheng Qian, Kangrui Wang, Qineng Wang, Teja Venkat Koripella, Marziyeh Movahedi, Manling Li, Heng Ji, Huan Zhang, Tong Zhang",2025-02-13 18:11:34.000000,arXiv,http://arxiv.org/abs/2502.09560v1,Artificial Intelligence
33,Real-Time Fast Marching Tree for Mobile Robot Motion Planning in Dynamic Environments,"This paper proposes the Real-Time Fast Marching Tree (RT-FMT), a real-time
planning algorithm that features local and global path generation,
multiple-query planning, and dynamic obstacle avoidance. During the search,
RT-FMT quickly looks for the global solution and, in the meantime, generates
local paths that can be used by the robot to start execution faster. In
addition, our algorithm constantly rewires the tree to keep branches from
forming inside the dynamic obstacles and to maintain the tree root near the
robot, which allows the tree to be reused multiple times for different goals.
Our algorithm is based on the planners Fast Marching Tree (FMT*) and Real-time
Rapidly-Exploring Random Tree (RT-RRT*). We show via simulations that RT-FMT
outperforms RT- RRT* in both execution cost and arrival time, in most cases.
Moreover, we also demonstrate via simulation that it is worthwhile taking the
local path before the global path is available in order to reduce arrival time,
even though there is a small possibility of taking an inferior path.","Jefferson Silveira, Kleber Cabral, Sidney Givigi, Joshua A. Marshall",2025-02-13 18:08:17.000000,arXiv,http://arxiv.org/abs/2502.09556v1,Robotics
34,SyntheticPop: Attacking Speaker Verification Systems With Synthetic VoicePops,"Voice Authentication (VA), also known as Automatic Speaker Verification
(ASV), is a widely adopted authentication method, particularly in automated
systems like banking services, where it serves as a secondary layer of user
authentication. Despite its popularity, VA systems are vulnerable to various
attacks, including replay, impersonation, and the emerging threat of deepfake
audio that mimics the voice of legitimate users. To mitigate these risks,
several defense mechanisms have been proposed. One such solution, Voice Pops,
aims to distinguish an individual's unique phoneme pronunciations during the
enrollment process. While promising, the effectiveness of VA+VoicePop against a
broader range of attacks, particularly logical or adversarial attacks, remains
insufficiently explored. We propose a novel attack method, which we refer to as
SyntheticPop, designed to target the phoneme recognition capabilities of the
VA+VoicePop system. The SyntheticPop attack involves embedding synthetic ""pop""
noises into spoofed audio samples, significantly degrading the model's
performance. We achieve an attack success rate of over 95% while poisoning 20%
of the training dataset. Our experiments demonstrate that VA+VoicePop achieves
69% accuracy under normal conditions, 37% accuracy when subjected to a baseline
label flipping attack, and just 14% accuracy under our proposed SyntheticPop
attack, emphasizing the effectiveness of our method.","Eshaq Jamdar, Amith Kamath Belman",2025-02-13 18:05:12.000000,arXiv,http://arxiv.org/abs/2502.09553v1,Other
35,Fast Tensor Completion via Approximate Richardson Iteration,"We study tensor completion (TC) through the lens of low-rank tensor
decomposition (TD). Many TD algorithms use fast alternating minimization
methods, which solve highly structured linear regression problems at each step
(e.g., for CP, Tucker, and tensor-train decompositions). However, such
algebraic structure is lost in TC regression problems, making direct extensions
unclear. To address this, we propose a lifting approach that approximately
solves TC regression problems using structured TD regression algorithms as
blackbox subroutines, enabling sublinear-time methods. We theoretically analyze
the convergence rate of our approximate Richardson iteration based algorithm,
and we demonstrate on real-world tensors that its running time can be 100x
faster than direct methods for CP completion.","Mehrdad Ghadiri, Matthew Fahrbach, Yunbum Kook, Ali Jadbabaie",2025-02-13 17:50:27.000000,arXiv,http://arxiv.org/abs/2502.09534v1,Other
36,Long-Term TalkingFace Generation via Motion-Prior Conditional Diffusion Model,"Recent advances in conditional diffusion models have shown promise for
generating realistic TalkingFace videos, yet challenges persist in achieving
consistent head movement, synchronized facial expressions, and accurate lip
synchronization over extended generations. To address these, we introduce the
\textbf{M}otion-priors \textbf{C}onditional \textbf{D}iffusion \textbf{M}odel
(\textbf{MCDM}), which utilizes both archived and current clip motion priors to
enhance motion prediction and ensure temporal consistency. The model consists
of three key elements: (1) an archived-clip motion-prior that incorporates
historical frames and a reference frame to preserve identity and context; (2) a
present-clip motion-prior diffusion model that captures multimodal causality
for accurate predictions of head movements, lip sync, and expressions; and (3)
a memory-efficient temporal attention mechanism that mitigates error
accumulation by dynamically storing and updating motion features. We also
release the \textbf{TalkingFace-Wild} dataset, a multilingual collection of
over 200 hours of footage across 10 languages. Experimental results demonstrate
the effectiveness of MCDM in maintaining identity and motion continuity for
long-term TalkingFace generation. Code, models, and datasets will be publicly
available.","Fei Shen, Cong Wang, Junyao Gao, Qin Guo, Jisheng Dang, Jinhui Tang, Tat-Seng Chua",2025-02-13 17:50:23.000000,arXiv,http://arxiv.org/abs/2502.09533v1,Computer Vision
37,Mind the Gap! Choice Independence in Using Multilingual LLMs for Persuasive Co-Writing Tasks in Different Languages,"Recent advances in generative AI have precipitated a proliferation of novel
writing assistants. These systems typically rely on multilingual large language
models (LLMs), providing globalized workers the ability to revise or create
diverse forms of content in different languages. However, there is substantial
evidence indicating that the performance of multilingual LLMs varies between
languages. Users who employ writing assistance for multiple languages are
therefore susceptible to disparate output quality. Importantly, recent research
has shown that people tend to generalize algorithmic errors across independent
tasks, violating the behavioral axiom of choice independence. In this paper, we
analyze whether user utilization of novel writing assistants in a charity
advertisement writing task is affected by the AI's performance in a second
language. Furthermore, we quantify the extent to which these patterns translate
into the persuasiveness of generated charity advertisements, as well as the
role of peoples' beliefs about LLM utilization in their donation choices. Our
results provide evidence that writers who engage with an LLM-based writing
assistant violate choice independence, as prior exposure to a Spanish LLM
reduces subsequent utilization of an English LLM. While these patterns do not
affect the aggregate persuasiveness of the generated advertisements, people's
beliefs about the source of an advertisement (human versus AI) do. In
particular, Spanish-speaking female participants who believed that they read an
AI-generated advertisement strongly adjusted their donation behavior downwards.
Furthermore, people are generally not able to adequately differentiate between
human-generated and LLM-generated ads. Our work has important implications for
the design, development, integration, and adoption of multilingual LLMs as
assistive agents -- particularly in writing tasks.","Shreyan Biswas, Alexander Erlei, Ujwal Gadiraju",2025-02-13 17:49:30.000000,arXiv,http://arxiv.org/abs/2502.09532v1,Natural Language Processing
38,Exact Leader Estimation: A New Approach for Distributed Differentiation,"A novel strategy aimed at cooperatively differentiating a signal among
multiple interacting agents is introduced, where none of the agents needs to
know which agent is the leader, i.e. the one producing the signal to be
differentiated. Every agent communicates only a scalar variable to its
neighbors; except for the leader, all agents execute the same algorithm. The
proposed strategy can effectively obtain derivatives up to arbitrary $m$-th
order in a finite time under the assumption that the $(m+1)$-th derivative is
bounded. The strategy borrows some of its structure from the celebrated
homogeneous robust exact differentiator by A. Levant, inheriting its exact
differentiation capability and robustness to measurement noise. Hence, the
proposed strategy can be said to perform robust exact distributed
differentiation. In addition, and for the first time in the distributed
leader-observer literature, sampled-data communication and bounded measurement
noise are considered, and corresponding steady-state worst-case accuracy bounds
are derived. The effectiveness of the proposed strategy is verified numerically
for second- and fourth-order systems, i.e., for estimating derivatives of up to
first and third order, respectively.","Rodrigo Aldana-Lopez, David Gomez-Gutierrez, Elio Usai, Hernan Haimovich",2025-02-13 17:39:37.000000,arXiv,http://arxiv.org/abs/2502.09529v1,Other
39,SteROI-D: System Design and Mapping for Stereo Depth Inference on Regions of Interest,"Machine learning algorithms have enabled high quality stereo depth estimation
to run on Augmented and Virtual Reality (AR/VR) devices. However, high energy
consumption across the full image processing stack prevents stereo depth
algorithms from running effectively on battery-limited devices. This paper
introduces SteROI-D, a full stereo depth system paired with a mapping
methodology. SteROI-D exploits Region-of-Interest (ROI) and temporal sparsity
at the system level to save energy. SteROI-D's flexible and heterogeneous
compute fabric supports diverse ROIs. Importantly, we introduce a systematic
mapping methodology to effectively handle dynamic ROIs, thereby maximizing
energy savings. Using these techniques, our 28nm prototype SteROI-D design
achieves up to 4.35x reduction in total system energy compared to a baseline
ASIC.","Jack Erhardt, Ziang Li, Reid Pinkham, Andrew Berkovich, Zhengya Zhang",2025-02-13 17:39:28.000000,arXiv,http://arxiv.org/abs/2502.09528v1,Computer Vision
40,Robust Learning of Multi-index Models via Iterative Subspace Approximation,"We study the task of learning Multi-Index Models (MIMs) with label noise
under the Gaussian distribution. A $K$-MIM is any function $f$ that only
depends on a $K$-dimensional subspace. We focus on well-behaved MIMs with
finite ranges that satisfy certain regularity properties. Our main contribution
is a general robust learner that is qualitatively optimal in the Statistical
Query (SQ) model. Our algorithm iteratively constructs better approximations to
the defining subspace by computing low-degree moments conditional on the
projection to the subspace computed thus far, and adding directions with
relatively large empirical moments. This procedure efficiently finds a subspace
$V$ so that $f(\mathbf{x})$ is close to a function of the projection of
$\mathbf{x}$ onto $V$. Conversely, for functions for which these conditional
moments do not help, we prove an SQ lower bound suggesting that no efficient
learner exists.
  As applications, we provide faster robust learners for the following concept
classes:
  * {\bf Multiclass Linear Classifiers} We give a constant-factor approximate
agnostic learner with sample complexity $N = O(d)
2^{\mathrm{poly}(K/\epsilon)}$ and computational complexity $\mathrm{poly}(N
,d)$. This is the first constant-factor agnostic learner for this class whose
complexity is a fixed-degree polynomial in $d$.
  * {\bf Intersections of Halfspaces} We give an approximate agnostic learner
for this class achieving 0-1 error $K \tilde{O}(\mathrm{OPT}) + \epsilon$ with
sample complexity $N=O(d^2) 2^{\mathrm{poly}(K/\epsilon)}$ and computational
complexity $\mathrm{poly}(N ,d)$. This is the first agnostic learner for this
class with near-linear error dependence and complexity a fixed-degree
polynomial in $d$.
  Furthermore, we show that in the presence of random classification noise, the
complexity of our algorithm scales polynomially with $1/\epsilon$.","Ilias Diakonikolas, Giannis Iakovidis, Daniel M. Kane, Nikos Zarifis",2025-02-13 17:37:42.000000,arXiv,http://arxiv.org/abs/2502.09525v1,Machine Learning
41,SQ-GAN: Semantic Image Communications Using Masked Vector Quantization,"This work introduces Semantically Masked VQ-GAN (SQ-GAN), a novel approach
integrating generative models to optimize image compression for
semantic/task-oriented communications. SQ-GAN employs off-the-shelf semantic
semantic segmentation and a new specifically developed semantic-conditioned
adaptive mask module (SAMM) to selectively encode semantically significant
features of the images. SQ-GAN outperforms state-of-the-art image compression
schemes such as JPEG2000 and BPG across multiple metrics, including perceptual
quality and semantic segmentation accuracy on the post-decoding reconstructed
image, at extreme low compression rates expressed in bits per pixel.","Francesco Pezone, Sergio Barbarossa, Giuseppe Caire",2025-02-13 17:35:57.000000,arXiv,http://arxiv.org/abs/2502.09520v1,Computer Vision
42,Diffusion Models for Molecules: A Survey of Methods and Tasks,"Generative tasks about molecules, including but not limited to molecule
generation, are crucial for drug discovery and material design, and have
consistently attracted significant attention. In recent years, diffusion models
have emerged as an impressive class of deep generative models, sparking
extensive research and leading to numerous studies on their application to
molecular generative tasks. Despite the proliferation of related work, there
remains a notable lack of up-to-date and systematic surveys in this area.
Particularly, due to the diversity of diffusion model formulations, molecular
data modalities, and generative task types, the research landscape is
challenging to navigate, hindering understanding and limiting the area's
growth. To address this, this paper conducts a comprehensive survey of
diffusion model-based molecular generative methods. We systematically review
the research from the perspectives of methodological formulations, data
modalities, and task types, offering a novel taxonomy. This survey aims to
facilitate understanding and further flourishing development in this area. The
relevant papers are summarized at:
https://github.com/AzureLeon1/awesome-molecular-diffusion-models.","Liang Wang, Chao Song, Zhiyuan Liu, Yu Rong, Qiang Liu, Shu Wu, Liang Wang",2025-02-13 17:22:50.000000,arXiv,http://arxiv.org/abs/2502.09511v1,Machine Learning
43,EQ-VAE: Equivariance Regularized Latent Space for Improved Generative Image Modeling,"Latent generative models have emerged as a leading approach for high-quality
image synthesis. These models rely on an autoencoder to compress images into a
latent space, followed by a generative model to learn the latent distribution.
We identify that existing autoencoders lack equivariance to semantic-preserving
transformations like scaling and rotation, resulting in complex latent spaces
that hinder generative performance. To address this, we propose EQ-VAE, a
simple regularization approach that enforces equivariance in the latent space,
reducing its complexity without degrading reconstruction quality. By finetuning
pre-trained autoencoders with EQ-VAE, we enhance the performance of several
state-of-the-art generative models, including DiT, SiT, REPA and MaskGIT,
achieving a 7 speedup on DiT-XL/2 with only five epochs of SD-VAE fine-tuning.
EQ-VAE is compatible with both continuous and discrete autoencoders, thus
offering a versatile enhancement for a wide range of latent generative models.
Project page and code: https://eq-vae.github.io/.","Theodoros Kouzelis, Ioannis Kakogeorgiou, Spyros Gidaris, Nikos Komodakis",2025-02-13 17:21:51.000000,arXiv,http://arxiv.org/abs/2502.09509v1,Machine Learning
44,When and How Does CLIP Enable Domain and Compositional Generalization?,"The remarkable generalization performance of contrastive vision-language
models like CLIP is often attributed to the diversity of their training
distributions. However, key questions remain unanswered: Can CLIP generalize to
an entirely unseen domain when trained on a diverse mixture of domains (domain
generalization)? Can it generalize to unseen classes within partially seen
domains (compositional generalization)? What factors affect such
generalization? To answer these questions, we trained CLIP models on
systematically constructed training distributions with controlled domain
diversity and object class exposure. Our experiments show that domain diversity
is essential for both domain and compositional generalization, yet
compositional generalization can be surprisingly weaker than domain
generalization when the training distribution contains a suboptimal subset of
the test domain. Through data-centric and mechanistic analyses, we find that
successful generalization requires learning of shared representations already
in intermediate layers and shared circuitry.","Elias Kempf, Simon Schrodi, Max Argus, Thomas Brox",2025-02-13 17:21:37.000000,arXiv,http://arxiv.org/abs/2502.09507v1,Machine Learning
45,AttentionSmithy: A Modular Framework for Rapid Transformer Development and Customization,"Transformer architectures have transformed AI applications but remain complex
to customize for domain experts lacking low-level implementation expertise. We
introduce AttentionSmithy, a modular software package that simplifies
transformer innovation by breaking down key components into reusable building
blocks: attention modules, feed-forward networks, normalization layers, and
positional encodings. Users can rapidly prototype and evaluate transformer
variants without extensive coding. Our framework supports four positional
encoding strategies and integrates with neural architecture search for
automated design. We validate AttentionSmithy by replicating the original
transformer under resource constraints and optimizing translation performance
by combining positional encodings. Additionally, we demonstrate its
adaptability in gene-specific modeling, achieving over 95% accuracy in cell
type classification. These case studies highlight AttentionSmithy's potential
to accelerate research across diverse fields by removing framework
implementation barriers.","Caleb Cranney, Jesse G. Meyer",2025-02-13 17:15:26.000000,arXiv,http://arxiv.org/abs/2502.09503v1,Machine Learning
46,Scalable First-order Method for Certifying Optimal k-Sparse GLMs,"This paper investigates the problem of certifying optimality for sparse
generalized linear models (GLMs), where sparsity is enforced through an
$\ell_0$ cardinality constraint. While branch-and-bound (BnB) frameworks can
certify optimality by pruning nodes using dual bounds, existing methods for
computing these bounds are either computationally intensive or exhibit slow
convergence, limiting their scalability to large-scale problems. To address
this challenge, we propose a first-order proximal gradient algorithm designed
to solve the perspective relaxation of the problem within a BnB framework.
Specifically, we formulate the relaxed problem as a composite optimization
problem and demonstrate that the proximal operator of the non-smooth component
can be computed exactly in log-linear time complexity, eliminating the need to
solve a computationally expensive second-order cone program. Furthermore, we
introduce a simple restart strategy that enhances convergence speed while
maintaining low per-iteration complexity. Extensive experiments on synthetic
and real-world datasets show that our approach significantly accelerates dual
bound computations and is highly effective in providing optimality certificates
for large-scale problems.","Jiachang Liu, Soroosh Shafiee, Andrea Lodi",2025-02-13 17:14:18.000000,arXiv,http://arxiv.org/abs/2502.09502v1,Machine Learning
47,Prior-Constrained Association Learning for Fine-Grained Generalized Category Discovery,"This paper addresses generalized category discovery (GCD), the task of
clustering unlabeled data from potentially known or unknown categories with the
help of labeled instances from each known category. Compared to traditional
semi-supervised learning, GCD is more challenging because unlabeled data could
be from novel categories not appearing in labeled data. Current
state-of-the-art methods typically learn a parametric classifier assisted by
self-distillation. While being effective, these methods do not make use of
cross-instance similarity to discover class-specific semantics which are
essential for representation learning and category discovery. In this paper, we
revisit the association-based paradigm and propose a Prior-constrained
Association Learning method to capture and learn the semantic relations within
data. In particular, the labeled data from known categories provides a unique
prior for the association of unlabeled data. Unlike previous methods that only
adopts the prior as a pre or post-clustering refinement, we fully incorporate
the prior into the association process, and let it constrain the association
towards a reliable grouping outcome. The estimated semantic groups are utilized
through non-parametric prototypical contrast to enhance the representation
learning. A further combination of both parametric and non-parametric
classification complements each other and leads to a model that outperforms
existing methods by a significant margin. On multiple GCD benchmarks, we
perform extensive experiments and validate the effectiveness of our proposed
method.","Menglin Wang, Zhun Zhong, Xiaojin Gong",2025-02-13 17:13:46.000000,arXiv,http://arxiv.org/abs/2502.09501v1,Computer Vision
48,Eidetic Learning: an Efficient and Provable Solution to Catastrophic Forgetting,"Catastrophic forgetting -- the phenomenon of a neural network learning a task
t1 and losing the ability to perform it after being trained on some other task
t2 -- is a long-standing problem for neural networks [McCloskey and Cohen,
1989]. We present a method, Eidetic Learning, that provably solves catastrophic
forgetting. A network trained with Eidetic Learning -- here, an EideticNet --
requires no rehearsal or replay. We consider successive discrete tasks and show
how at inference time an EideticNet automatically routes new instances without
auxiliary task information. An EideticNet bears a family resemblance to the
sparsely-gated Mixture-of-Experts layer Shazeer et al. [2016] in that network
capacity is partitioned across tasks and the network itself performs
data-conditional routing. An EideticNet is easy to implement and train, is
efficient, and has time and space complexity linear in the number of
parameters. The guarantee of our method holds for normalization layers of
modern neural networks during both pre-training and fine-tuning. We show with a
variety of network architectures and sets of tasks that EideticNets are immune
to forgetting. While the practical benefits of EideticNets are substantial, we
believe they can be benefit practitioners and theorists alike. The code for
training EideticNets is available at
\href{https://github.com/amazon-science/eideticnet-training}{this https URL}.","Nicholas Dronen, Randall Balestriero",2025-02-13 17:10:43.000000,arXiv,http://arxiv.org/abs/2502.09500v1,Machine Learning
49,Improve LLM-based Automatic Essay Scoring with Linguistic Features,"Automatic Essay Scoring (AES) assigns scores to student essays, reducing the
grading workload for instructors. Developing a scoring system capable of
handling essays across diverse prompts is challenging due to the flexibility
and diverse nature of the writing task. Existing methods typically fall into
two categories: supervised feature-based approaches and large language model
(LLM)-based methods. Supervised feature-based approaches often achieve higher
performance but require resource-intensive training. In contrast, LLM-based
methods are computationally efficient during inference but tend to suffer from
lower performance. This paper combines these approaches by incorporating
linguistic features into LLM-based scoring. Experimental results show that this
hybrid method outperforms baseline models for both in-domain and out-of-domain
writing prompts.","Zhaoyi Joey Hou, Alejandro Ciuba, Xiang Lorraine Li",2025-02-13 17:09:52.000000,arXiv,http://arxiv.org/abs/2502.09497v1,Natural Language Processing
50,On Agnostic PAC Learning in the Small Error Regime,"Binary classification in the classic PAC model exhibits a curious phenomenon:
Empirical Risk Minimization (ERM) learners are suboptimal in the realizable
case yet optimal in the agnostic case. Roughly speaking, this owes itself to
the fact that non-realizable distributions $\mathcal{D}$ are simply more
difficult to learn than realizable distributions -- even when one discounts a
learner's error by $\mathrm{err}(h^*_{\mathcal{D}})$, the error of the best
hypothesis in $\mathcal{H}$ for $\mathcal{D}$. Thus, optimal agnostic learners
are permitted to incur excess error on (easier-to-learn) distributions
$\mathcal{D}$ for which $\tau = \mathrm{err}(h^*_{\mathcal{D}})$ is small.
  Recent work of Hanneke, Larsen, and Zhivotovskiy (FOCS `24) addresses this
shortcoming by including $\tau$ itself as a parameter in the agnostic error
term. In this more fine-grained model, they demonstrate tightness of the error
lower bound $\tau + \Omega \left(\sqrt{\frac{\tau (d + \log(1 / \delta))}{m}} +
\frac{d + \log(1 / \delta)}{m} \right)$ in a regime where $\tau > d/m$, and
leave open the question of whether there may be a higher lower bound when $\tau
\approx d/m$, with $d$ denoting $\mathrm{VC}(\mathcal{H})$. In this work, we
resolve this question by exhibiting a learner which achieves error $c \cdot
\tau + O \left(\sqrt{\frac{\tau (d + \log(1 / \delta))}{m}} + \frac{d + \log(1
/ \delta)}{m} \right)$ for a constant $c \leq 2.1$, thus matching the lower
bound when $\tau \approx d/m$. Further, our learner is computationally
efficient and is based upon careful aggregations of ERM classifiers, making
progress on two other questions of Hanneke, Larsen, and Zhivotovskiy (FOCS
`24). We leave open the interesting question of whether our approach can be
refined to lower the constant from 2.1 to 1, which would completely settle the
complexity of agnostic learning.","Julian Asilis, Mikael Møller Høgsgaard, Grigoris Velegkas",2025-02-13 17:03:03.000000,arXiv,http://arxiv.org/abs/2502.09496v1,Machine Learning
51,Cracking the Code: Enhancing Development finance understanding with artificial intelligence,"Analyzing development projects is crucial for understanding donors aid
strategies, recipients priorities, and to assess development finance capacity
to adress development issues by on-the-ground actions. In this area, the
Organisation for Economic Co-operation and Developments (OECD) Creditor
Reporting System (CRS) dataset is a reference data source. This dataset
provides a vast collection of project narratives from various sectors
(approximately 5 million projects). While the OECD CRS provides a rich source
of information on development strategies, it falls short in informing project
purposes due to its reporting process based on donors self-declared main
objectives and pre-defined industrial sectors. This research employs a novel
approach that combines Machine Learning (ML) techniques, specifically Natural
Language Processing (NLP), an innovative Python topic modeling technique called
BERTopic, to categorise (cluster) and label development projects based on their
narrative descriptions. By revealing existing yet hidden topics of development
finance, this application of artificial intelligence enables a better
understanding of donor priorities and overall development funding and provides
methods to analyse public and private projects narratives.",Pierre Beaucoral,2025-02-13 17:01:45.000000,arXiv,http://arxiv.org/abs/2502.09495v1,Other
52,Communicating Likelihoods with Normalising Flows,"We present a machine-learning-based workflow to model an unbinned likelihood
from its samples. A key advancement over existing approaches is the validation
of the learned likelihood using rigorous statistical tests of the joint
distribution, such as the Kolmogorov-Smirnov test of the joint distribution.
Our method enables the reliable communication of experimental and
phenomenological likelihoods for subsequent analyses. We demonstrate its
effectiveness through three case studies in high-energy physics. To support
broader adoption, we provide an open-source reference implementation, nabu.","Jack Y. Araz, Anja Beck, Méril Reboud, Michael Spannowsky, Danny van Dyk",2025-02-13 17:00:11.000000,arXiv,http://arxiv.org/abs/2502.09494v1,Other
53,Inverse Design with Dynamic Mode Decomposition,"We introduce a computationally efficient method for the automation of inverse
design in science and engineering. Based on simple least-square regression, the
underlying dynamic mode decomposition algorithm can be used to construct a
low-rank subspace spanning multiple experiments in parameter space. The
proposed inverse design dynamic mode composition (ID-DMD) algorithm leverages
the computed low-dimensional subspace to enable fast digital design and
optimization on laptop-level computing, including the potential to prescribe
the dynamics themselves. Moreover, the method is robust to noise, physically
interpretable, and can provide uncertainty quantification metrics. The
architecture can also efficiently scale to large-scale design problems using
randomized algorithms in the ID-DMD. The simplicity of the method and its
implementation are highly attractive in practice, and the ID-DMD has been
demonstrated to be an order of magnitude more accurate than competing methods
while simultaneously being 3-5 orders faster on challenging engineering design
problems ranging from structural vibrations to fluid dynamics. Due to its
speed, robustness, interpretability, and ease-of-use, ID-DMD in comparison with
other leading machine learning methods represents a significant advancement in
data-driven methods for inverse design and optimization, promising a paradigm
shift in how to approach inverse design in practice.","Yunpeng Zhu, Liangliang Cheng, Anping Jing, Hanyu Huo, Ziqiang Lang, Bo Zhang, J. Nathan Kutz",2025-02-13 16:57:07.000000,arXiv,http://arxiv.org/abs/2502.09490v1,Machine Learning
54,Objective quantification of mood states using large language models,"Emotional states influence human behaviour and cognition, leading to diverse
thought trajectories. Similarly, Large Language Models (LLMs) showcase an
excellent level of response consistency across wide-ranging contexts (prompts).
We leverage these parallels to establish a framework for quantifying mental
states. Our approach utilises self-report questionnaires that reliably assess
these states due to their inherent sensitivity to patterns of co-occurring
responses. Specifically, we recruited a large sample of participants (N=422) to
investigate how well an LLM (Mistral-7B-OpenOrca) quantifies a heterogenous set
of depressive mood states measured with participants' open-ended responses to a
depression questionnaire. We show LLM responses to held-out multiple-choice
questions, given participants' open-ended answers, correlate strongly (r:
0.52-0.84) with true questionnaire scores, demonstrating LLM's generalisation
from mood representations. We explore a link between these representations and
factor analysis. Using ridge regression, we find depression-related subspaces
within LLM hidden states. We show these subspaces to be predictive of
participants' ""Depression"" and ""Somatic & Emotional Distress"" factor scores, as
well as suicidality severity. Overall, LLMs can provide quantitative measures
of mental states. The reliability of these hinges upon how informative the
questions we ask participants are. Used correctly, this approach could
supplement mental state assessment in a variety of settings.","Jakub Onysk, Quentin Huys",2025-02-13 16:52:06.000000,arXiv,http://arxiv.org/abs/2502.09487v1,Natural Language Processing
55,PenTest++: Elevating Ethical Hacking with AI and Automation,"Traditional ethical hacking relies on skilled professionals and
time-intensive command management, which limits its scalability and efficiency.
To address these challenges, we introduce PenTest++, an AI-augmented system
that integrates automation with generative AI (GenAI) to optimise ethical
hacking workflows. Developed in a controlled virtual environment, PenTest++
streamlines critical penetration testing tasks, including reconnaissance,
scanning, enumeration, exploitation, and documentation, while maintaining a
modular and adaptable design. The system balances automation with human
oversight, ensuring informed decision-making at key stages, and offers
significant benefits such as enhanced efficiency, scalability, and
adaptability. However, it also raises ethical considerations, including privacy
concerns and the risks of AI-generated inaccuracies (hallucinations). This
research underscores the potential of AI-driven systems like PenTest++ to
complement human expertise in cybersecurity by automating routine tasks,
enabling professionals to focus on strategic decision-making. By incorporating
robust ethical safeguards and promoting ongoing refinement, PenTest++
demonstrates how AI can be responsibly harnessed to address operational and
ethical challenges in the evolving cybersecurity landscape.","Haitham S. Al-Sinani, Chris J. Mitchell",2025-02-13 16:46:23.000000,arXiv,http://arxiv.org/abs/2502.09484v1,Other
56,Standardisation of Convex Ultrasound Data Through Geometric Analysis and Augmentation,"The application of ultrasound in healthcare has seen increased diversity and
importance. Unlike other medical imaging modalities, ultrasound research and
development has historically lagged, particularly in the case of applications
with data-driven algorithms. A significant issue with ultrasound is the extreme
variability of the images, due to the number of different machines available
and the possible combination of parameter settings. One outcome of this is the
lack of standardised and benchmarking ultrasound datasets. The method proposed
in this article is an approach to alleviating this issue of disorganisation.
For this purpose, the issue of ultrasound data sparsity is examined and a novel
perspective, approach, and solution is proposed; involving the extraction of
the underlying ultrasound plane within the image and representing it using
annulus sector geometry. An application of this methodology is proposed, which
is the extraction of scan lines and the linearisation of convex planes.
Validation of the robustness of the proposed method is performed on both
private and public data. The impact of deformation and the invertibility of
augmentation using the estimated annulus sector parameters is also studied.
Keywords: Ultrasound, Annulus Sector, Augmentation, Linearisation.","Alistair Weld, Giovanni Faoro, Luke Dixon, Sophie Camp, Arianna Menciassi, Stamatia Giannarou",2025-02-13 16:45:39.000000,arXiv,http://arxiv.org/abs/2502.09482v1,Computer Vision
57,Assessing Generative AI value in a public sector context: evidence from a field experiment,"The emergence of Generative AI (Gen AI) has motivated an interest in
understanding how it could be used to enhance productivity across various
tasks. We add to research results for the performance impact of Gen AI on
complex knowledge-based tasks in a public sector setting. In a pre-registered
experiment, after establishing a baseline level of performance, we find mixed
evidence for two types of composite tasks related to document understanding and
data analysis. For the Documents task, the treatment group using Gen AI had a
17% improvement in answer quality scores (as judged by human evaluators) and a
34% improvement in task completion time compared to a control group. For the
Data task, we find the Gen AI treatment group experienced a 12% reduction in
quality scores and no significant difference in mean completion time compared
to the control group. These results suggest that the benefits of Gen AI may be
task and potentially respondent dependent. We also discuss field notes and
lessons learned, as well as supplementary insights from a post-trial survey and
feedback workshop with participants.","Trevor Fitzpatrick, Seamus Kelly, Patrick Carey, David Walsh, Ruairi Nugent",2025-02-13 16:43:32.000000,arXiv,http://arxiv.org/abs/2502.09479v1,Other
58,DiffRenderGAN: Addressing Training Data Scarcity in Deep Segmentation Networks for Quantitative Nanomaterial Analysis through Differentiable Rendering and Generative Modelling,"Nanomaterials exhibit distinctive properties governed by parameters such as
size, shape, and surface characteristics, which critically influence their
applications and interactions across technological, biological, and
environmental contexts. Accurate quantification and understanding of these
materials are essential for advancing research and innovation. In this regard,
deep learning segmentation networks have emerged as powerful tools that enable
automated insights and replace subjective methods with precise quantitative
analysis. However, their efficacy depends on representative annotated datasets,
which are challenging to obtain due to the costly imaging of nanoparticles and
the labor-intensive nature of manual annotations. To overcome these
limitations, we introduce DiffRenderGAN, a novel generative model designed to
produce annotated synthetic data. By integrating a differentiable renderer into
a Generative Adversarial Network (GAN) framework, DiffRenderGAN optimizes
textural rendering parameters to generate realistic, annotated nanoparticle
images from non-annotated real microscopy images. This approach reduces the
need for manual intervention and enhances segmentation performance compared to
existing synthetic data methods by generating diverse and realistic data.
Tested on multiple ion and electron microscopy cases, including titanium
dioxide (TiO$_2$), silicon dioxide (SiO$_2$)), and silver nanowires (AgNW),
DiffRenderGAN bridges the gap between synthetic and real data, advancing the
quantification and understanding of complex nanomaterial systems.","Dennis Possart, Leonid Mill, Florian Vollnhals, Tor Hildebrand, Peter Suter, Mathis Hoffmann, Jonas Utz, Daniel Augsburger, Mareike Thies, Mingxuan Wu, Fabian Wagner, George Sarau, Silke Christiansen, Katharina Breininger",2025-02-13 16:41:44.000000,arXiv,http://arxiv.org/abs/2502.09477v1,Other
59,Learning to Predict Global Atrial Fibrillation Dynamics from Sparse Measurements,"Catheter ablation of Atrial Fibrillation (AF) consists of a one-size-fits-all
treatment with limited success in persistent AF. This may be due to our
inability to map the dynamics of AF with the limited resolution and coverage
provided by sequential contact mapping catheters, preventing effective patient
phenotyping for personalised, targeted ablation. Here we introduce FibMap, a
graph recurrent neural network model that reconstructs global AF dynamics from
sparse measurements. Trained and validated on 51 non-contact whole atria
recordings, FibMap reconstructs whole atria dynamics from 10% surface coverage,
achieving a 210% lower mean absolute error and an order of magnitude higher
performance in tracking phase singularities compared to baseline methods.
Clinical utility of FibMap is demonstrated on real-world contact mapping
recordings, achieving reconstruction fidelity comparable to non-contact
mapping. FibMap's state-spaces and patient-specific parameters offer insights
for electrophenotyping AF. Integrating FibMap into clinical practice could
enable personalised AF care and improve outcomes.","Alexander Jenkins, Andrea Cini, Joseph Barker, Alexander Sharp, Arunashis Sau, Varun Valentine, Srushti Valasang, Xinyang Li, Tom Wong, Timothy Betts, Danilo Mandic, Cesare Alippi, Fu Siong Ng",2025-02-13 16:36:25.000000,arXiv,http://arxiv.org/abs/2502.09473v1,Machine Learning
60,Wholly-WOOD: Wholly Leveraging Diversified-quality Labels for Weakly-supervised Oriented Object Detection,"Accurately estimating the orientation of visual objects with compact rotated
bounding boxes (RBoxes) has become a prominent demand, which challenges
existing object detection paradigms that only use horizontal bounding boxes
(HBoxes). To equip the detectors with orientation awareness, supervised
regression/classification modules have been introduced at the high cost of
rotation annotation. Meanwhile, some existing datasets with oriented objects
are already annotated with horizontal boxes or even single points. It becomes
attractive yet remains open for effectively utilizing weaker single point and
horizontal annotations to train an oriented object detector (OOD). We develop
Wholly-WOOD, a weakly-supervised OOD framework, capable of wholly leveraging
various labeling forms (Points, HBoxes, RBoxes, and their combination) in a
unified fashion. By only using HBox for training, our Wholly-WOOD achieves
performance very close to that of the RBox-trained counterpart on remote
sensing and other areas, significantly reducing the tedious efforts on
labor-intensive annotation for oriented objects. The source codes are available
at https://github.com/VisionXLab/whollywood (PyTorch-based) and
https://github.com/VisionXLab/whollywood-jittor (Jittor-based).","Yi Yu, Xue Yang, Yansheng Li, Zhenjun Han, Feipeng Da, Junchi Yan",2025-02-13 16:34:59.000000,arXiv,http://arxiv.org/abs/2502.09471v1,Computer Vision
61,Metamorphic Testing for Pose Estimation Systems,"Pose estimation systems are used in a variety of fields, from sports
analytics to livestock care. Given their potential impact, it is paramount to
systematically test their behaviour and potential for failure. This is a
complex task due to the oracle problem and the high cost of manual labelling
necessary to build ground truth keypoints. This problem is exacerbated by the
fact that different applications require systems to focus on different subjects
(e.g., human versus animal) or landmarks (e.g., only extremities versus whole
body and face), which makes labelled test data rarely reusable. To combat these
problems we propose MET-POSE, a metamorphic testing framework for pose
estimation systems that bypasses the need for manual annotation while assessing
the performance of these systems under different circumstances. MET-POSE thus
allows users of pose estimation systems to assess the systems in conditions
that more closely relate to their application without having to label an ad-hoc
test dataset or rely only on available datasets, which may not be adapted to
their application domain. While we define MET-POSE in general terms, we also
present a non-exhaustive list of metamorphic rules that represent common
challenges in computer vision applications, as well as a specific way to
evaluate these rules. We then experimentally show the effectiveness of MET-POSE
by applying it to Mediapipe Holistic, a state of the art human pose estimation
system, with the FLIC and PHOENIX datasets. With these experiments, we outline
numerous ways in which the outputs of MET-POSE can uncover faults in pose
estimation systems at a similar or higher rate than classic testing using hand
labelled data, and show that users can tailor the rule set they use to the
faults and level of accuracy relevant to their application.","Matias Duran, Thomas Laurent, Ellen Rushe, Anthony Ventresque",2025-02-13 16:27:23.000000,arXiv,http://arxiv.org/abs/2502.09460v1,Other
62,The Multilingual Mind : A Survey of Multilingual Reasoning in Language Models,"While reasoning and multilingual capabilities in Language Models (LMs) have
achieved remarkable progress in recent years, their integration into a unified
paradigm, multilingual reasoning, is at a nascent stage. Multilingual reasoning
requires language models to handle logical reasoning across languages while
addressing misalignment, biases, and challenges in low-resource settings. This
survey provides the first in-depth review of multilingual reasoning in LMs. In
this survey, we provide a systematic overview of existing methods that leverage
LMs for multilingual reasoning, specifically outlining the challenges,
motivations, and foundational aspects of applying language models to reason
across diverse languages. We provide an overview of the standard data resources
used for training multilingual reasoning in LMs and the evaluation benchmarks
employed to assess their multilingual capabilities. Next, we analyze various
state-of-the-art methods and their performance on these benchmarks. Finally, we
explore future research opportunities to improve multilingual reasoning in LMs,
focusing on enhancing their ability to handle diverse languages and complex
reasoning tasks.","Akash Ghosh, Debayan Datta, Sriparna Saha, Chirag Agarwal",2025-02-13 16:25:16.000000,arXiv,http://arxiv.org/abs/2502.09457v1,Natural Language Processing
63,Spiking Neural Networks for Temporal Processing: Status Quo and Future Prospects,"Temporal processing is fundamental for both biological and artificial
intelligence systems, as it enables the comprehension of dynamic environments
and facilitates timely responses. Spiking Neural Networks (SNNs) excel in
handling such data with high efficiency, owing to their rich neuronal dynamics
and sparse activity patterns. Given the recent surge in the development of
SNNs, there is an urgent need for a comprehensive evaluation of their temporal
processing capabilities. In this paper, we first conduct an in-depth assessment
of commonly used neuromorphic benchmarks, revealing critical limitations in
their ability to evaluate the temporal processing capabilities of SNNs. To
bridge this gap, we further introduce a benchmark suite consisting of three
temporal processing tasks characterized by rich temporal dynamics across
multiple timescales. Utilizing this benchmark suite, we perform a thorough
evaluation of recently introduced SNN approaches to elucidate the current
status of SNNs in temporal processing. Our findings indicate significant
advancements in recently developed spiking neuron models and neural
architectures regarding their temporal processing capabilities, while also
highlighting a performance gap in handling long-range dependencies when
compared to state-of-the-art non-spiking models. Finally, we discuss the key
challenges and outline potential avenues for future research.","Chenxiang Ma, Xinyi Chen, Yanchen Li, Qu Yang, Yujie Wu, Guoqi Li, Gang Pan, Huajin Tang, Kay Chen Tan, Jibin Wu",2025-02-13 16:17:57.000000,arXiv,http://arxiv.org/abs/2502.09449v1,Neural Networks
64,Pixel-Level Reasoning Segmentation via Multi-turn Conversations,"Existing visual perception systems focus on region-level segmentation in
single-turn dialogues, relying on complex and explicit query instructions. Such
systems cannot reason at the pixel level and comprehend dynamic user intent
that changes over interaction. Our work tackles this issue by introducing a
novel task, Pixel-level Reasoning Segmentation (Pixel-level RS) based on
multi-turn conversations, tracking evolving user intent via multi-turn
interactions for fine-grained segmentation. To establish a benchmark for this
novel task, we build a Pixel-level ReasonIng Segmentation Dataset Based on
Multi-Turn Conversations (PRIST), comprising 24k utterances from 8.3k
multi-turn conversational scenarios with segmentation targets. Building on
PRIST, we further propose MIRAS, a Multi-turn Interactive ReAsoning
Segmentation framework, integrates pixel-level segmentation with robust
multi-turn conversation understanding, generating pixel-grounded explanations
aligned with user intent. The PRIST dataset and MIRSA framework fill the gap in
pixel-level reasoning segmentation. Experimental results on the PRIST dataset
demonstrate that our method outperforms current segmentation-specific baselines
in terms of segmentation and LLM-based reasoning metrics. The code and data are
available at: https://github.com/ccccai239/PixelRIST.","Dexian Cai, Xiaocui Yang, Yongkang Liu, Daling Wang, Shi Feng, Yifei Zhang, Soujanya Poria",2025-02-13 16:16:54.000000,arXiv,http://arxiv.org/abs/2502.09447v1,Computer Vision
65,A Differentiable Rank-Based Objective For Better Feature Learning,"In this paper, we leverage existing statistical methods to better understand
feature learning from data. We tackle this by modifying the model-free variable
selection method, Feature Ordering by Conditional Independence (FOCI), which is
introduced in \cite{azadkia2021simple}. While FOCI is based on a non-parametric
coefficient of conditional dependence, we introduce its parametric,
differentiable approximation. With this approximate coefficient of correlation,
we present a new algorithm called difFOCI, which is applicable to a wider range
of machine learning problems thanks to its differentiable nature and learnable
parameters. We present difFOCI in three contexts: (1) as a variable selection
method with baseline comparisons to FOCI, (2) as a trainable model parametrized
with a neural network, and (3) as a generic, widely applicable neural network
regularizer, one that improves feature learning with better management of
spurious correlations. We evaluate difFOCI on increasingly complex problems
ranging from basic variable selection in toy examples to saliency map
comparisons in convolutional networks. We then show how difFOCI can be
incorporated in the context of fairness to facilitate classifications without
relying on sensitive data.","Krunoslav Lehman Pavasovic, David Lopez-Paz, Giulio Biroli, Levent Sagun",2025-02-13 16:15:43.000000,arXiv,http://arxiv.org/abs/2502.09445v1,Statistical Machine Learning
66,Relational Conformal Prediction for Correlated Time Series,"We address the problem of uncertainty quantification in time series
forecasting by exploiting observations at correlated sequences. Relational deep
learning methods leveraging graph representations are among the most effective
tools for obtaining point estimates from spatiotemporal data and correlated
time series. However, the problem of exploiting relational structures to
estimate the uncertainty of such predictions has been largely overlooked in the
same context. To this end, we propose a novel distribution-free approach based
on the conformal prediction framework and quantile regression. Despite the
recent applications of conformal prediction to sequential data, existing
methods operate independently on each target time series and do not account for
relationships among them when constructing the prediction interval. We fill
this void by introducing a novel conformal prediction method based on graph
deep learning operators. Our method, named Conformal Relational Prediction
(CoRel), does not require the relational structure (graph) to be known as a
prior and can be applied on top of any pre-trained time series predictor.
Additionally, CoRel includes an adaptive component to handle non-exchangeable
data and changes in the input time series. Our approach provides accurate
coverage and archives state-of-the-art uncertainty quantification in relevant
benchmarks.","Andrea Cini, Alexander Jenkins, Danilo Mandic, Cesare Alippi, Filippo Maria Bianchi",2025-02-13 16:12:17.000000,arXiv,http://arxiv.org/abs/2502.09443v1,Machine Learning
67,Variable Stiffness for Robust Locomotion through Reinforcement Learning,"Reinforcement-learned locomotion enables legged robots to perform highly
dynamic motions but often accompanies time-consuming manual tuning of joint
stiffness. This paper introduces a novel control paradigm that integrates
variable stiffness into the action space alongside joint positions, enabling
grouped stiffness control such as per-joint stiffness (PJS), per-leg stiffness
(PLS) and hybrid joint-leg stiffness (HJLS). We show that variable stiffness
policies, with grouping in per-leg stiffness (PLS), outperform position-based
control in velocity tracking and push recovery. In contrast, HJLS excels in
energy efficiency. Furthermore, our method showcases robust walking behaviour
on diverse outdoor terrains by sim-to-real transfer, although the policy is
sorely trained on a flat floor. Our approach simplifies design by eliminating
per-joint stiffness tuning while keeping competitive results with various
metrics.","Dario Spoljaric, Yashuai Yan, Dongheui Lee",2025-02-13 16:00:46.000000,arXiv,http://arxiv.org/abs/2502.09436v1,Robotics
68,Redistribute Ensemble Training for Mitigating Memorization in Diffusion Models,"Diffusion models, known for their tremendous ability to generate high-quality
samples, have recently raised concerns due to their data memorization behavior,
which poses privacy risks. Recent methods for memory mitigation have primarily
addressed the issue within the context of the text modality in cross-modal
generation tasks, restricting their applicability to specific conditions. In
this paper, we propose a novel method for diffusion models from the perspective
of visual modality, which is more generic and fundamental for mitigating
memorization. Directly exposing visual data to the model increases memorization
risk, so we design a framework where models learn through proxy model
parameters instead. Specially, the training dataset is divided into multiple
shards, with each shard training a proxy model, then aggregated to form the
final model. Additionally, practical analysis of training losses illustrates
that the losses for easily memorable images tend to be obviously lower. Thus,
we skip the samples with abnormally low loss values from the current mini-batch
to avoid memorizing. However, balancing the need to skip memorization-prone
samples while maintaining sufficient training data for high-quality image
generation presents a key challenge. Thus, we propose IET-AGC+, which
redistributes highly memorizable samples between shards, to mitigate these
samples from over-skipping. Furthermore, we dynamically augment samples based
on their loss values to further reduce memorization. Extensive experiments and
analysis on four datasets show that our method successfully reduces memory
capacity while maintaining performance. Moreover, we fine-tune the pre-trained
diffusion models, e.g., Stable Diffusion, and decrease the memorization score
by 46.7\%, demonstrating the effectiveness of our method. Code is available in:
https://github.com/liuxiao-guan/IET_AGC.","Xiaoliu Guan, Yu Wu, Huayang Huang, Xiao Liu, Jiaxu Miao, Yi Yang",2025-02-13 15:56:44.000000,arXiv,http://arxiv.org/abs/2502.09434v1,Computer Vision
69,Dual Formulation for Non-Rectangular Lp Robust Markov Decision Processes,"We study robust Markov decision processes (RMDPs) with non-rectangular
uncertainty sets, which capture interdependencies across states unlike
traditional rectangular models. While non-rectangular robust policy evaluation
is generally NP-hard, even in approximation, we identify a powerful class of
$L_p$-bounded uncertainty sets that avoid these complexity barriers due to
their structural simplicity. We further show that this class can be decomposed
into infinitely many \texttt{sa}-rectangular $L_p$-bounded sets and leverage
its structural properties to derive a novel dual formulation for $L_p$ RMDPs.
This formulation provides key insights into the adversary's strategy and
enables the development of the first robust policy evaluation algorithms for
non-rectangular RMDPs. Empirical results demonstrate that our approach
significantly outperforms brute-force methods, establishing a promising
foundation for future investigation into non-rectangular robust MDPs.","Navdeep Kumar, Adarsh Gupta, Maxence Mohamed Elfatihi, Giorgia Ramponi, Kfir Yehuda Levy, Shie Mannor",2025-02-13 15:55:00.000000,arXiv,http://arxiv.org/abs/2502.09432v1,Artificial Intelligence
70,A 3D Facial Reconstruction Evaluation Methodology: Comparing Smartphone Scans with Deep Learning Based Methods Using Geometry and Morphometry Criteria,"Three-dimensional (3D) facial shape analysis has gained interest due to its
potential clinical applications. However, the high cost of advanced 3D facial
acquisition systems limits their widespread use, driving the development of
low-cost acquisition and reconstruction methods. This study introduces a novel
evaluation methodology that goes beyond traditional geometry-based benchmarks
by integrating morphometric shape analysis techniques, providing a statistical
framework for assessing facial morphology preservation. As a case study, we
compare smartphone-based 3D scans with state-of-the-art deep learning
reconstruction methods from 2D images, using high-end stereophotogrammetry
models as ground truth. This methodology enables a quantitative assessment of
global and local shape differences, offering a biologically meaningful
validation approach for low-cost 3D facial acquisition and reconstruction
techniques.","Álvaro Heredia-Lidón, Alejandro Moñux-Bernal, Alejandro González, Luis M. Echeverry-Quiceno, Max Rubert, Aroa Casado, María Esther Esteban, Mireia Andreu-Montoriol, Susanna Gallardo, Cristina Ruffo, Neus Martínez-Abadías, Xavier Sevillano",2025-02-13 15:47:45.000000,arXiv,http://arxiv.org/abs/2502.09425v1,Computer Vision
71,Transformer-Enhanced Variational Autoencoder for Crystal Structure Prediction,"Crystal structure forms the foundation for understanding the physical and
chemical properties of materials. Generative models have emerged as a new
paradigm in crystal structure prediction(CSP), however, accurately capturing
key characteristics of crystal structures, such as periodicity and symmetry,
remains a significant challenge. In this paper, we propose a
Transformer-Enhanced Variational Autoencoder for Crystal Structure Prediction
(TransVAE-CSP), who learns the characteristic distribution space of stable
materials, enabling both the reconstruction and generation of crystal
structures. TransVAE-CSP integrates adaptive distance expansion with
irreducible representation to effectively capture the periodicity and symmetry
of crystal structures, and the encoder is a transformer network based on an
equivariant dot product attention mechanism. Experimental results on the
carbon_24, perov_5, and mp_20 datasets demonstrate that TransVAE-CSP
outperforms existing methods in structure reconstruction and generation tasks
under various modeling metrics, offering a powerful tool for crystal structure
design and optimization.","Ziyi Chen, Yang Yuan, Siming Zheng, Jialong Guo, Sihan Liang, Yangang Wang, Zongguo Wang",2025-02-13 15:45:36.000000,arXiv,http://arxiv.org/abs/2502.09423v1,Other
72,On multi-token prediction for efficient LLM inference,"We systematically investigate multi-token prediction (MTP) capabilities
within LLMs pre-trained for next-token prediction (NTP). We first show that
such models inherently possess MTP capabilities via numerical marginalization
over intermediate token probabilities, though performance is data-dependent and
improves with model scale. Furthermore, we explore the challenges of
integrating MTP heads into frozen LLMs and find that their hidden layers are
strongly specialized for NTP, making adaptation non-trivial. Finally, we show
that while joint training of MTP heads with the backbone improves performance,
it cannot fully overcome this barrier, prompting further research in this
direction. Our findings provide a deeper understanding of MTP applied to
pretrained LLMs, informing strategies for accelerating inference through
parallel token prediction.","Somesh Mehra, Javier Alonso Garcia, Lukas Mauch",2025-02-13 15:42:44.000000,arXiv,http://arxiv.org/abs/2502.09419v1,Natural Language Processing
73,A Survey of Reinforcement Learning for Optimization in Automation,"Reinforcement Learning (RL) has become a critical tool for optimization
challenges within automation, leading to significant advancements in several
areas. This review article examines the current landscape of RL within
automation, with a particular focus on its roles in manufacturing, energy
systems, and robotics. It discusses state-of-the-art methods, major challenges,
and upcoming avenues of research within each sector, highlighting RL's capacity
to solve intricate optimization challenges. The paper reviews the advantages
and constraints of RL-driven optimization methods in automation. It points out
prevalent challenges encountered in RL optimization, including issues related
to sample efficiency and scalability; safety and robustness; interpretability
and trustworthiness; transfer learning and meta-learning; and real-world
deployment and integration. It further explores prospective strategies and
future research pathways to navigate these challenges. Additionally, the survey
includes a comprehensive list of relevant research papers, making it an
indispensable guide for scholars and practitioners keen on exploring this
domain.","Ahmad Farooq, Kamran Iqbal",2025-02-13 15:40:39.000000,arXiv,http://arxiv.org/abs/2502.09417v1,Machine Learning
74,Rethinking Evaluation Metrics for Grammatical Error Correction: Why Use a Different Evaluation Process than Human?,"One of the goals of automatic evaluation metrics in grammatical error
correction (GEC) is to rank GEC systems such that it matches human preferences.
However, current automatic evaluations are based on procedures that diverge
from human evaluation. Specifically, human evaluation derives rankings by
aggregating sentence-level relative evaluation results, e.g., pairwise
comparisons, using a rating algorithm, whereas automatic evaluation averages
sentence-level absolute scores to obtain corpus-level scores, which are then
sorted to determine rankings. In this study, we propose an aggregation method
for existing automatic evaluation metrics which aligns with human evaluation
methods to bridge this gap. We conducted experiments using various metrics,
including edit-based metrics, $n$-gram based metrics, and sentence-level
metrics, and show that resolving the gap improves results for the most of
metrics on the SEEDA benchmark. We also found that even BERT-based metrics
sometimes outperform the metrics of GPT-4. We publish our unified
implementation of the metrics and meta-evaluations.","Takumi Goto, Yusuke Sakai, Taro Watanabe",2025-02-13 15:39:07.000000,arXiv,http://arxiv.org/abs/2502.09416v1,Natural Language Processing
75,ImageRAG: Dynamic Image Retrieval for Reference-Guided Image Generation,"Diffusion models enable high-quality and diverse visual content synthesis.
However, they struggle to generate rare or unseen concepts. To address this
challenge, we explore the usage of Retrieval-Augmented Generation (RAG) with
image generation models. We propose ImageRAG, a method that dynamically
retrieves relevant images based on a given text prompt, and uses them as
context to guide the generation process. Prior approaches that used retrieved
images to improve generation, trained models specifically for retrieval-based
generation. In contrast, ImageRAG leverages the capabilities of existing image
conditioning models, and does not require RAG-specific training. Our approach
is highly adaptable and can be applied across different model types, showing
significant improvement in generating rare and fine-grained concepts using
different base models.
  Our project page is available at: https://rotem-shalev.github.io/ImageRAG","Rotem Shalev-Arkushin, Rinon Gal, Amit H. Bermano, Ohad Fried",2025-02-13 15:36:12.000000,arXiv,http://arxiv.org/abs/2502.09411v1,Computer Vision
76,A hierarchical approach for assessing the vulnerability of tree-based classification models to membership inference attack,"Machine learning models can inadvertently expose confidential properties of
their training data, making them vulnerable to membership inference attacks
(MIA). While numerous evaluation methods exist, many require computationally
expensive processes, such as training multiple shadow models. This article
presents two new complementary approaches for efficiently identifying
vulnerable tree-based models: an ante-hoc analysis of hyperparameter choices
and a post-hoc examination of trained model structure. While these new methods
cannot certify whether a model is safe from MIA, they provide practitioners
with a means to significantly reduce the number of models that need to undergo
expensive MIA assessment through a hierarchical filtering approach.
  More specifically, it is shown that the rank order of disclosure risk for
different hyperparameter combinations remains consistent across datasets,
enabling the development of simple, human-interpretable rules for identifying
relatively high-risk models before training. While this ante-hoc analysis
cannot determine absolute safety since this also depends on the specific
dataset, it allows the elimination of unnecessarily risky configurations during
hyperparameter tuning. Additionally, computationally inexpensive structural
metrics serve as indicators of MIA vulnerability, providing a second filtering
stage to identify risky models after training but before conducting expensive
attacks. Empirical results show that hyperparameter-based risk prediction rules
can achieve high accuracy in predicting the most at risk combinations of
hyperparameters across different tree-based model types, while requiring no
model training. Moreover, target model accuracy is not seen to correlate with
privacy risk, suggesting opportunities to optimise model configurations for
both performance and privacy.","Richard J. Preen, Jim Smith",2025-02-13 15:16:53.000000,arXiv,http://arxiv.org/abs/2502.09396v1,Machine Learning
77,Robot Pouring: Identifying Causes of Spillage and Selecting Alternative Action Parameters Using Probabilistic Actual Causation,"In everyday life, we perform tasks (e.g., cooking or cleaning) that involve a
large variety of objects and goals. When confronted with an unexpected or
unwanted outcome, we take corrective actions and try again until achieving the
desired result. The reasoning performed to identify a cause of the observed
outcome and to select an appropriate corrective action is a crucial aspect of
human reasoning for successful task execution. Central to this reasoning is the
assumption that a factor is responsible for producing the observed outcome. In
this paper, we investigate the use of probabilistic actual causation to
determine whether a factor is the cause of an observed undesired outcome.
Furthermore, we show how the actual causation probabilities can be used to find
alternative actions to change the outcome. We apply the probabilistic actual
causation analysis to a robot pouring task. When spillage occurs, the analysis
indicates whether a task parameter is the cause and how it should be changed to
avoid spillage. The analysis requires a causal graph of the task and the
corresponding conditional probability distributions. To fulfill these
requirements, we perform a complete causal modeling procedure (i.e., task
analysis, definition of variables, determination of the causal graph structure,
and estimation of conditional probability distributions) using data from a
realistic simulation of the robot pouring task, covering a large combinatorial
space of task parameters. Based on the results, we discuss the implications of
the variables' representation and how the alternative actions suggested by the
actual causation analysis would compare to the alternative solutions proposed
by a human observer. The practical use of the analysis of probabilistic actual
causation to select alternative action parameters is demonstrated.","Jaime Maldonado, Jonas Krumme, Christoph Zetzsche, Vanessa Didelez, Kerstin Schill",2025-02-13 15:16:52.000000,arXiv,http://arxiv.org/abs/2502.09395v1,Robotics
78,Generalizable Reinforcement Learning with Biologically Inspired Hyperdimensional Occupancy Grid Maps for Exploration and Goal-Directed Path Planning,"Real-time autonomous systems utilize multi-layer computational frameworks to
perform critical tasks such as perception, goal finding, and path planning.
Traditional methods implement perception using occupancy grid mapping (OGM),
segmenting the environment into discretized cells with probabilistic
information. This classical approach is well-established and provides a
structured input for downstream processes like goal finding and path planning
algorithms. Recent approaches leverage a biologically inspired mathematical
framework known as vector symbolic architectures (VSA), commonly known as
hyperdimensional computing, to perform probabilistic OGM in hyperdimensional
space. This approach, VSA-OGM, provides native compatibility with spiking
neural networks, positioning VSA-OGM as a potential neuromorphic alternative to
conventional OGM. However, for large-scale integration, it is essential to
assess the performance implications of VSA-OGM on downstream tasks compared to
established OGM methods. This study examines the efficacy of VSA-OGM against a
traditional OGM approach, Bayesian Hilbert Maps (BHM), within reinforcement
learning based goal finding and path planning frameworks, across a controlled
exploration environment and an autonomous driving scenario inspired by the
F1-Tenth challenge. Our results demonstrate that VSA-OGM maintains comparable
learning performance across single and multi-scenario training configurations
while improving performance on unseen environments by approximately 47%. These
findings highlight the increased generalizability of policy networks trained
with VSA-OGM over BHM, reinforcing its potential for real-world deployment in
diverse environments.","Shay Snyder, Ryan Shea, Andrew Capodieci, David Gorsich, Maryam Parsa",2025-02-13 15:10:45.000000,arXiv,http://arxiv.org/abs/2502.09393v1,Robotics
79,SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models,"In the rapidly evolving field of Natural Language Processing, Large Language
Models (LLMs) are tasked with increasingly complex reasoning challenges.
Traditional methods like chain-of-thought prompting have shown promise but
often fall short in fully leveraging a model's reasoning capabilities. This
paper introduces SQuARE (Sequential Question Answering Reasoning Engine), a
novel prompting technique designed to improve reasoning through a
self-interrogation paradigm. Building upon CoT frameworks, SQuARE prompts
models to generate and resolve multiple auxiliary questions before tackling the
main query, promoting a more thorough exploration of various aspects of a
topic. Our expansive evaluations, conducted with Llama 3 and GPT-4o models
across multiple question-answering datasets, demonstrate that SQuARE
significantly surpasses traditional CoT prompts and existing
rephrase-and-respond methods. By systematically decomposing queries, SQuARE
advances LLM capabilities in reasoning tasks. The code is publicly available at
https://github.com/IntelLabs/RAG-FiT/tree/square.","Daniel Fleischer, Moshe Berchansky, Gad Markovits, Moshe Wasserblat",2025-02-13 15:07:20.000000,arXiv,http://arxiv.org/abs/2502.09390v1,Natural Language Processing
80,S$^2$-Diffusion: Generalizing from Instance-level to Category-level Skills in Robot Manipulation,"Recent advances in skill learning has propelled robot manipulation to new
heights by enabling it to learn complex manipulation tasks from a practical
number of demonstrations. However, these skills are often limited to the
particular action, object, and environment \textit{instances} that are shown in
the training data, and have trouble transferring to other instances of the same
category. In this work we present an open-vocabulary Spatial-Semantic Diffusion
policy (S$^2$-Diffusion) which enables generalization from instance-level
training data to category-level, enabling skills to be transferable between
instances of the same category. We show that functional aspects of skills can
be captured via a promptable semantic module combined with a spatial
representation. We further propose leveraging depth estimation networks to
allow the use of only a single RGB camera. Our approach is evaluated and
compared on a diverse number of robot manipulation tasks, both in simulation
and in the real world. Our results show that S$^2$-Diffusion is invariant to
changes in category-irrelevant factors as well as enables satisfying
performance on other instances within the same category, even if it was not
trained on that specific instance. Full videos of all real-world experiments
are available in the supplementary material.","Quantao Yang, Michael C. Welle, Danica Kragic, Olov Andersson",2025-02-13 15:06:42.000000,arXiv,http://arxiv.org/abs/2502.09389v1,Robotics
81,Truth Knows No Language: Evaluating Truthfulness Beyond English,"We introduce a professionally translated extension of the TruthfulQA
benchmark designed to evaluate truthfulness in Basque, Catalan, Galician, and
Spanish. Truthfulness evaluations of large language models (LLMs) have
primarily been conducted in English. However, the ability of LLMs to maintain
truthfulness across languages remains under-explored. Our study evaluates 12
state-of-the-art open LLMs, comparing base and instruction-tuned models using
human evaluation, multiple-choice metrics, and LLM-as-a-Judge scoring. Our
findings reveal that, while LLMs perform best in English and worst in Basque
(the lowest-resourced language), overall truthfulness discrepancies across
languages are smaller than anticipated. Furthermore, we show that
LLM-as-a-Judge correlates more closely with human judgments than
multiple-choice metrics, and that informativeness plays a critical role in
truthfulness assessment. Our results also indicate that machine translation
provides a viable approach for extending truthfulness benchmarks to additional
languages, offering a scalable alternative to professional translation.
Finally, we observe that universal knowledge questions are better handled
across languages than context- and time-dependent ones, highlighting the need
for truthfulness evaluations that account for cultural and temporal
variability. Dataset and code are publicly available under open licenses.","Blanca Calvo Figueras, Eneko Sagarzazu, Julen Etxaniz, Jeremy Barnes, Pablo Gamallo, Iria De Dios Flores, Rodrigo Agerri",2025-02-13 15:04:53.000000,arXiv,http://arxiv.org/abs/2502.09387v1,Natural Language Processing
82,TRIFFID: Autonomous Robotic Aid For Increasing First Responders Efficiency,"The increasing complexity of natural disaster incidents demands innovative
technological solutions to support first responders in their efforts. This
paper introduces the TRIFFID system, a comprehensive technical framework that
integrates unmanned ground and aerial vehicles with advanced artificial
intelligence functionalities to enhance disaster response capabilities across
wildfires, urban floods, and post-earthquake search and rescue missions. By
leveraging state-of-the-art autonomous navigation, semantic perception, and
human-robot interaction technologies, TRIFFID provides a sophisticated system
com- posed of the following key components: hybrid robotic platform,
centralized ground station, custom communication infrastructure, and smartphone
application. The defined research and development activities demonstrate how
deep neural networks, knowledge graphs, and multimodal information fusion can
enable robots to autonomously navigate and analyze disaster environ- ments,
reducing personnel risks and accelerating response times. The proposed system
enhances emergency response teams by providing advanced mission planning,
safety monitoring, and adaptive task execution capabilities. Moreover, it
ensures real- time situational awareness and operational support in complex and
risky situations, facilitating rapid and precise information collection and
coordinated actions.","Jorgen Cani, Panagiotis Koletsis, Konstantinos Foteinos, Ioannis Kefaloukos, Lampros Argyriou, Manolis Falelakis, Iván Del Pino, Angel Santamaria-Navarro, Martin Čech, Ondřej Severa, Alessandro Umbrico, Francesca Fracasso, AndreA Orlandini, Dimitrios Drakoulis, Evangelos Markakis, Georgios Th. Papadopoulos",2025-02-13 14:46:40.000000,arXiv,http://arxiv.org/abs/2502.09379v1,Robotics
83,A Deep Inverse-Mapping Model for a Flapping Robotic Wing,"In systems control, the dynamics of a system are governed by modulating its
inputs to achieve a desired outcome. For example, to control the thrust of a
quad-copter propeller the controller modulates its rotation rate, relying on a
straightforward mapping between the input rotation rate and the resulting
thrust. This mapping can be inverted to determine the rotation rate needed to
generate a desired thrust. However, in complex systems, such as flapping-wing
robots where intricate fluid motions are involved, mapping inputs (wing
kinematics) to outcomes (aerodynamic forces) is nontrivial and inverting this
mapping for real-time control is computationally impractical. Here, we report a
machine-learning solution for the inverse mapping of a flapping-wing system
based on data from an experimental system we have developed. Our model learns
the input wing motion required to generate a desired aerodynamic force outcome.
We used a sequence-to-sequence model tailored for time-series data and
augmented it with a novel adaptive-spectrum layer that implements
representation learning in the frequency domain. To train our model, we
developed a flapping wing system that simultaneously measures the wing's
aerodynamic force and its 3D motion using high-speed cameras. We demonstrate
the performance of our system on an additional open-source dataset of a
flapping wing in a different flow regime. Results show superior performance
compared with more complex state-of-the-art transformer-based models, with 11%
improvement on the test datasets median loss. Moreover, our model shows
superior inference time, making it practical for onboard robotic control. Our
open-source data and framework may improve modeling and real-time control of
systems governed by complex dynamics, from biomimetic robots to biomedical
devices.","Hadar Sharvit, Raz Karl, Tsevi Beatus",2025-02-13 14:46:04.000000,arXiv,http://arxiv.org/abs/2502.09378v1,Artificial Intelligence
84,LoRA Training Provably Converges to a Low-Rank Global Minimum or It Fails Loudly (But it Probably Won't Fail),"Low-rank adaptation (LoRA) has become a standard approach for fine-tuning
large foundation models. However, our theoretical understanding of LoRA remains
limited as prior analyses of LoRA's training dynamics either rely on
linearization arguments or consider highly simplified setups. In this work, we
analyze the LoRA loss landscape without such restrictive assumptions. We define
two regimes: a ``special regime'', which includes idealized setups where
linearization arguments hold, and a ``generic regime'' representing more
realistic setups where linearization arguments do not hold. In the generic
regime, we show that LoRA training converges to a global minimizer with low
rank and small magnitude, or a qualitatively distinct solution with high rank
and large magnitude. Finally, we argue that the zero-initialization and weight
decay in LoRA training induce an implicit bias toward the low-rank,
small-magnitude region of the parameter space -- where global minima lie --
thus shedding light on why LoRA training usually succeeds in finding global
minima.","Junsu Kim, Jaeyeon Kim, Ernest K. Ryu",2025-02-13 14:45:11.000000,arXiv,http://arxiv.org/abs/2502.09376v1,Machine Learning
85,FARM: Frequency-Aware Model for Cross-Domain Live-Streaming Recommendation,"Live-streaming services have attracted widespread popularity due to their
real-time interactivity and entertainment value. Users can engage with
live-streaming authors by participating in live chats, posting likes, or
sending virtual gifts to convey their preferences and support. However, the
live-streaming services faces serious data-sparsity problem, which can be
attributed to the following two points: (1) User's valuable behaviors are
usually sparse, e.g., like, comment and gift, which are easily overlooked by
the model, making it difficult to describe user's personalized preference. (2)
The main exposure content on our platform is short-video, which is 9 times
higher than the exposed live-streaming, leading to the inability of
live-streaming content to fully model user preference. To this end, we propose
a Frequency-Aware Model for Cross-Domain Live-Streaming Recommendation, termed
as FARM. Specifically, we first present the intra-domain frequency aware module
to enable our model to perceive user's sparse yet valuable behaviors, i.e.,
high-frequency information, supported by the Discrete Fourier Transform (DFT).
To transfer user preference across the short-video and live-streaming domains,
we propose a novel preference align before fuse strategy, which consists of two
parts: the cross-domain preference align module to align user preference in
both domains with contrastive learning, and the cross-domain preference fuse
module to further fuse user preference in both domains using a serious of
tailor-designed attention mechanisms. Extensive offline experiments and online
A/B testing on Kuaishou live-streaming services demonstrate the effectiveness
and superiority of FARM. Our FARM has been deployed in online live-streaming
services and currently serves hundreds of millions of users on Kuaishou.","Xiaodong Li, Ruochen Yang, Shuang Wen, Shen Wang, Yueyang Liu, Guoquan Wang, Weisong Hu, Qiang Luo, Jiawei Sheng, Tingwen Liu, Jiangxia Cao, Shuang Yang, Zhaojie Liu",2025-02-13 14:44:15.000000,arXiv,http://arxiv.org/abs/2502.09375v1,Information Retrieval
86,Mitigating multiple single-event upsets during deep neural network inference using fault-aware training,"Deep neural networks (DNNs) are increasingly used in safety-critical
applications. Reliable fault analysis and mitigation are essential to ensure
their functionality in harsh environments that contain high radiation levels.
This study analyses the impact of multiple single-bit single-event upsets in
DNNs by performing fault injection at the level of a DNN model. Additionally, a
fault aware training (FAT) methodology is proposed that improves the DNNs'
robustness to faults without any modification to the hardware. Experimental
results show that the FAT methodology improves the tolerance to faults up to a
factor 3.","Toon Vinck, Naïn Jonckers, Gert Dekkers, Jeffrey Prinzie, Peter Karsmakers",2025-02-13 14:43:22.000000,arXiv,http://arxiv.org/abs/2502.09374v1,Machine Learning
87,Language Agents as Digital Representatives in Collective Decision-Making,"Consider the process of collective decision-making, in which a group of
individuals interactively select a preferred outcome from among a universe of
alternatives. In this context, ""representation"" is the activity of making an
individual's preferences present in the process via participation by a proxy
agent -- i.e. their ""representative"". To this end, learned models of human
behavior have the potential to fill this role, with practical implications for
multi-agent scenario studies and mechanism design. In this work, we investigate
the possibility of training \textit{language agents} to behave in the capacity
of representatives of human agents, appropriately expressing the preferences of
those individuals whom they stand for. First, we formalize the setting of
\textit{collective decision-making} -- as the episodic process of interaction
between a group of agents and a decision mechanism. On this basis, we then
formalize the problem of \textit{digital representation} -- as the simulation
of an agent's behavior to yield equivalent outcomes from the mechanism.
Finally, we conduct an empirical case study in the setting of
\textit{consensus-finding} among diverse humans, and demonstrate the
feasibility of fine-tuning large language models to act as digital
representatives.","Daniel Jarrett, Miruna Pîslar, Michiel A. Bakker, Michael Henry Tessler, Raphael Köster, Jan Balaguer, Romuald Elie, Christopher Summerfield, Andrea Tacchetti",2025-02-13 14:35:40.000000,arXiv,http://arxiv.org/abs/2502.09369v1,Machine Learning
88,Simple Path Structural Encoding for Graph Transformers,"Graph transformers extend global self-attention to graph-structured data,
achieving notable success in graph learning. Recently, random walk structural
encoding (RWSE) has been found to further enhance their predictive power by
encoding both structural and positional information into the edge
representation. However, RWSE cannot always distinguish between edges that
belong to different local graph patterns, which reduces its ability to capture
the full structural complexity of graphs. This work introduces Simple Path
Structural Encoding (SPSE), a novel method that utilizes simple path counts for
edge encoding. We show theoretically and experimentally that SPSE overcomes the
limitations of RWSE, providing a richer representation of graph structures,
particularly for capturing local cyclic patterns. To make SPSE computationally
tractable, we propose an efficient approximate algorithm for simple path
counting. SPSE demonstrates significant performance improvements over RWSE on
various benchmarks, including molecular and long-range graph datasets,
achieving statistically significant gains in discriminative tasks. These
results pose SPSE as a powerful edge encoding alternative for enhancing the
expressivity of graph transformers.","Louis Airale, Antonio Longa, Mattia Rigon, Andrea Passerini, Roberto Passerone",2025-02-13 14:33:02.000000,arXiv,http://arxiv.org/abs/2502.09365v1,Machine Learning
89,The Accuracy Cost of Weakness: A Theoretical Analysis of Fixed-Segment Weak Labeling for Events in Time,"Accurate labels are critical for deriving robust machine learning models.
Labels are used to train supervised learning models and to evaluate most
machine learning paradigms. In this paper, we model the accuracy and cost of a
common weak labeling process where annotators assign presence or absence labels
to fixed-length data segments for a given event class. The annotator labels a
segment as ""present"" if it sufficiently covers an event from that class, e.g.,
a birdsong sound event in audio data. We analyze how the segment length affects
the label accuracy and the required number of annotations, and compare this
fixed-length labeling approach with an oracle method that uses the true event
activations to construct the segments. Furthermore, we quantify the gap between
these methods and verify that in most realistic scenarios the oracle method is
better than the fixed-length labeling method in both accuracy and cost. Our
findings provide a theoretical justification for adaptive weak labeling
strategies that mimic the oracle process, and a foundation for optimizing weak
labeling processes in sequence labeling tasks.","John Martinsson, Olof Mogren, Tuomas Virtanen, Maria Sandsten",2025-02-13 14:31:49.000000,arXiv,http://arxiv.org/abs/2502.09363v1,Machine Learning
90,Galileo: Learning Global and Local Features in Pretrained Remote Sensing Models,"From crop mapping to flood detection, machine learning in remote sensing has
a wide range of societally beneficial applications. The commonalities between
remote sensing data in these applications present an opportunity for pretrained
machine learning models tailored to remote sensing to reduce the labeled data
and effort required to solve individual tasks. However, such models must be:
(i) flexible enough to ingest input data of varying sensor modalities and
shapes (i.e., of varying spatial and temporal dimensions), and (ii) able to
model Earth surface phenomena of varying scales and types. To solve this gap,
we present Galileo, a family of pretrained remote sensing models designed to
flexibly process multimodal remote sensing data. We also introduce a novel and
highly effective self-supervised learning approach to learn both large- and
small-scale features, a challenge not addressed by previous models. Our Galileo
models obtain state-of-the-art results across diverse remote sensing tasks.","Gabriel Tseng, Anthony Fuller, Marlena Reil, Henry Herzog, Patrick Beukema, Favyen Bastani, James R. Green, Evan Shelhamer, Hannah Kerner, David Rolnick",2025-02-13 14:21:03.000000,arXiv,http://arxiv.org/abs/2502.09356v1,Computer Vision
91,Wasserstein distributional adversarial training for deep neural networks,"Design of adversarial attacks for deep neural networks, as well as methods of
adversarial training against them, are subject of intense research. In this
paper, we propose methods to train against distributional attack threats,
extending the TRADES method used for pointwise attacks. Our approach leverages
recent contributions and relies on sensitivity analysis for Wasserstein
distributionally robust optimization problems. We introduce an efficient
fine-tuning method which can be deployed on a previously trained model. We test
our methods on a range of pre-trained models on RobustBench. These experimental
results demonstrate the additional training enhances Wasserstein distributional
robustness, while maintaining original levels of pointwise robustness, even for
already very successful networks. The improvements are less marked for models
pre-trained using huge synthetic datasets of 20-100M images. However,
remarkably, sometimes our methods are still able to improve their performance
even when trained using only the original training dataset (50k images).","Xingjian Bai, Guangyi He, Yifan Jiang, Jan Obloj",2025-02-13 14:18:41.000000,arXiv,http://arxiv.org/abs/2502.09352v1,Machine Learning
92,Machine learning for modelling unstructured grid data in computational physics: a review,"Unstructured grid data are essential for modelling complex geometries and
dynamics in computational physics. Yet, their inherent irregularity presents
significant challenges for conventional machine learning (ML) techniques. This
paper provides a comprehensive review of advanced ML methodologies designed to
handle unstructured grid data in high-dimensional dynamical systems. Key
approaches discussed include graph neural networks, transformer models with
spatial attention mechanisms, interpolation-integrated ML methods, and meshless
techniques such as physics-informed neural networks. These methodologies have
proven effective across diverse fields, including fluid dynamics and
environmental simulations. This review is intended as a guidebook for
computational scientists seeking to apply ML approaches to unstructured grid
data in their domains, as well as for ML researchers looking to address
challenges in computational physics. It places special focus on how ML methods
can overcome the inherent limitations of traditional numerical techniques and,
conversely, how insights from computational physics can inform ML development.
To support benchmarking, this review also provides a summary of open-access
datasets of unstructured grid data in computational physics. Finally, emerging
directions such as generative models with unstructured data, reinforcement
learning for mesh generation, and hybrid physics-data-driven paradigms are
discussed to inspire future advancements in this evolving field.","Sibo Cheng, Marc Bocquet, Weiping Ding, Tobias Sebastian Finn, Rui Fu, Jinlong Fu, Yike Guo, Eleda Johnson, Siyi Li, Che Liu, Eric Newton Moro, Jie Pan, Matthew Piggott, Cesar Quilodran, Prakhar Sharma, Kun Wang, Dunhui Xiao, Xiao Xue, Yong Zeng, Mingrui Zhang, Hao Zhou, Kewei Zhu, Rossella Arcucci",2025-02-13 14:11:33.000000,arXiv,http://arxiv.org/abs/2502.09346v1,Machine Learning
93,Neural Spatiotemporal Point Processes: Trends and Challenges,"Spatiotemporal point processes (STPPs) are probabilistic models for events
occurring in continuous space and time. Real-world event data often exhibit
intricate dependencies and heterogeneous dynamics. By incorporating modern deep
learning techniques, STPPs can model these complexities more effectively than
traditional approaches. Consequently, the fusion of neural methods with STPPs
has become an active and rapidly evolving research area. In this review, we
categorize existing approaches, unify key design choices, and explain the
challenges of working with this data modality. We further highlight emerging
trends and diverse application domains. Finally, we identify open challenges
and gaps in the literature.","Sumantrak Mukherjee, Mouad Elhamdi, George Mohler, David A. Selby, Yao Xie, Sebastian Vollmer, Gerrit Grossmann",2025-02-13 14:01:15.000000,arXiv,http://arxiv.org/abs/2502.09341v1,Machine Learning
94,This looks like what? Challenges and Future Research Directions for Part-Prototype Models,"The growing interest in eXplainable Artificial Intelligence (XAI) has
prompted research into models with built-in interpretability, the most
prominent of which are part-prototype models. Part-Prototype Models (PPMs) make
decisions by comparing an input image to a set of learned prototypes, providing
human-understandable explanations in the form of ``this looks like that''.
Despite their inherent interpretability, PPMS are not yet considered a valuable
alternative to post-hoc models. In this survey, we investigate the reasons for
this and provide directions for future research. We analyze papers from 2019 to
2024, and derive a taxonomy of the challenges that current PPMS face. Our
analysis shows that the open challenges are quite diverse. The main concern is
the quality and quantity of prototypes. Other concerns are the lack of
generalization to a variety of tasks and contexts, and general methodological
issues, including non-standardized evaluation. We provide ideas for future
research in five broad directions: improving predictive performance, developing
novel architectures grounded in theory, establishing frameworks for human-AI
collaboration, aligning models with humans, and establishing metrics and
benchmarks for evaluation. We hope that this survey will stimulate research and
promote intrinsically interpretable models for application domains. Our list of
surveyed papers is available at https://github.com/aix-group/ppm-survey.","Khawla Elhadri, Tomasz Michalski, Adam Wróbel, Jörg Schlötterer, Bartosz Zieliński, Christin Seifert",2025-02-13 14:00:55.000000,arXiv,http://arxiv.org/abs/2502.09340v1,Machine Learning
95,Graph Diffusion Network for Drug-Gene Prediction,"Predicting drug-gene associations is crucial for drug development and disease
treatment. While graph neural networks (GNN) have shown effectiveness in this
task, they face challenges with data sparsity and efficient contrastive
learning implementation. We introduce a graph diffusion network for drug-gene
prediction (GDNDGP), a framework that addresses these limitations through two
key innovations. First, it employs meta-path-based homogeneous graph learning
to capture drug-drug and gene-gene relationships, ensuring similar entities
share embedding spaces. Second, it incorporates a parallel diffusion network
that generates hard negative samples during training, eliminating the need for
exhaustive negative sample retrieval. Our model achieves superior performance
on the DGIdb 4.0 dataset and demonstrates strong generalization capability on
tripartite drug-gene-disease networks. Results show significant improvements
over existing methods in drug-gene prediction tasks, particularly in handling
complex heterogeneous relationships. The source code is publicly available at
https://github.com/csjywu1/GDNDGP.","Jiayang Wu, Wensheng Gan, Philip S. Yu",2025-02-13 13:54:58.000000,arXiv,http://arxiv.org/abs/2502.09335v1,Machine Learning
96,Full Swap Regret and Discretized Calibration,"We study the problem of minimizing swap regret in structured normal-form
games. Players have a very large (potentially infinite) number of pure actions,
but each action has an embedding into $d$-dimensional space and payoffs are
given by bilinear functions of these embeddings. We provide an efficient
learning algorithm for this setting that incurs at most
$\tilde{O}(T^{(d+1)/(d+3)})$ swap regret after $T$ rounds.
  To achieve this, we introduce a new online learning problem we call
\emph{full swap regret minimization}. In this problem, a learner repeatedly
takes a (randomized) action in a bounded convex $d$-dimensional action set
$\mathcal{K}$ and then receives a loss from the adversary, with the goal of
minimizing their regret with respect to the \emph{worst-case} swap function
mapping $\mathcal{K}$ to $\mathcal{K}$. For varied assumptions about the
convexity and smoothness of the loss functions, we design algorithms with full
swap regret bounds ranging from $O(T^{d/(d+2)})$ to $O(T^{(d+1)/(d+2)})$.
  Finally, we apply these tools to the problem of online forecasting to
minimize calibration error, showing that several notions of calibration can be
viewed as specific instances of full swap regret. In particular, we design
efficient algorithms for online forecasting that guarantee at most $O(T^{1/3})$
$\ell_2$-calibration error and $O(\max(\sqrt{\epsilon T}, T^{1/3}))$
\emph{discretized-calibration} error (when the forecaster is restricted to
predicting multiples of $\epsilon$).","Maxwell Fishelson, Robert Kleinberg, Princewill Okoroafor, Renato Paes Leme, Jon Schneider, Yifeng Teng",2025-02-13 13:49:52.000000,arXiv,http://arxiv.org/abs/2502.09332v1,Machine Learning
97,Beyond English: The Impact of Prompt Translation Strategies across Languages and Tasks in Multilingual LLMs,"Despite advances in the multilingual capabilities of Large Language Models
(LLMs) across diverse tasks, English remains the dominant language for LLM
research and development. So, when working with a different language, this has
led to the widespread practice of pre-translation, i.e., translating the task
prompt into English before inference. Selective pre-translation, a more
surgical approach, focuses on translating specific prompt components. However,
its current use is sporagic and lacks a systematic research foundation.
Consequently, the optimal pre-translation strategy for various multilingual
settings and tasks remains unclear. In this work, we aim to uncover the optimal
setup for pre-translation by systematically assessing its use. Specifically, we
view the prompt as a modular entity, composed of four functional parts:
instruction, context, examples, and output, either of which could be translated
or not. We evaluate pre-translation strategies across 35 languages covering
both low and high-resource languages, on various tasks including Question
Answering (QA), Natural Language Inference (NLI), Named Entity Recognition
(NER), and Abstractive Summarization. Our experiments show the impact of
factors as similarity to English, translation quality and the size of
pre-trained data, on the model performance with pre-translation. We suggest
practical guidelines for choosing optimal strategies in various multilingual
settings.","Itai Mondshine, Tzuf Paz-Argaman, Reut Tsarfaty",2025-02-13 13:49:30.000000,arXiv,http://arxiv.org/abs/2502.09331v1,Natural Language Processing
98,Bayesian Optimization for Simultaneous Selection of Machine Learning Algorithms and Hyperparameters on Shared Latent Space,"Selecting the optimal combination of a machine learning (ML) algorithm and
its hyper-parameters is crucial for the development of high-performance ML
systems. However, since the combination of ML algorithms and hyper-parameters
is enormous, the exhaustive validation requires a significant amount of time.
Many existing studies use Bayesian optimization (BO) for accelerating the
search. On the other hand, a significant difficulty is that, in general, there
exists a different hyper-parameter space for each one of candidate ML
algorithms. BO-based approaches typically build a surrogate model independently
for each hyper-parameter space, by which sufficient observations are required
for all candidate ML algorithms. In this study, our proposed method embeds
different hyper-parameter spaces into a shared latent space, in which a
surrogate multi-task model for BO is estimated. This approach can share
information of observations from different ML algorithms by which efficient
optimization is expected with a smaller number of total observations. We
further propose the pre-training of the latent space embedding with an
adversarial regularization, and a ranking model for selecting an effective
pre-trained embedding for a given target dataset. Our empirical study
demonstrates effectiveness of the proposed method through datasets from OpenML.","Kazuki Ishikawa, Ryota Ozaki, Yohei Kanzaki, Ichiro Takeuchi, Masayuki Karasuyama",2025-02-13 13:43:52.000000,arXiv,http://arxiv.org/abs/2502.09329v1,Machine Learning
99,A Benchmark for Crime Surveillance Video Analysis with Large Models,"Anomaly analysis in surveillance videos is a crucial topic in computer
vision. In recent years, multimodal large language models (MLLMs) have
outperformed task-specific models in various domains. Although MLLMs are
particularly versatile, their abilities to understand anomalous concepts and
details are insufficiently studied because of the outdated benchmarks of this
field not providing MLLM-style QAs and efficient algorithms to assess the
model's open-ended text responses. To fill this gap, we propose a benchmark for
crime surveillance video analysis with large models denoted as UCVL, including
1,829 videos and reorganized annotations from the UCF-Crime and UCF-Crime
Annotation datasets. We design six types of questions and generate diverse QA
pairs. Then we develop detailed instructions and use OpenAI's GPT-4o for
accurate assessment. We benchmark eight prevailing MLLMs ranging from 0.5B to
40B parameters, and the results demonstrate the reliability of this bench.
Moreover, we finetune LLaVA-OneVision on UCVL's training set. The improvement
validates our data's high quality for video anomaly analysis.","Haoran Chen, Dong Yi, Moyan Cao, Chensen Huang, Guibo Zhu, Jinqiao Wang",2025-02-13 13:38:17.000000,arXiv,http://arxiv.org/abs/2502.09325v1,Computer Vision
100,Depth-Bounds for Neural Networks via the Braid Arrangement,"We contribute towards resolving the open question of how many hidden layers
are required in ReLU networks for exactly representing all continuous and
piecewise linear functions on $\mathbb{R}^d$. While the question has been
resolved in special cases, the best known lower bound in general is still 2. We
focus on neural networks that are compatible with certain polyhedral complexes,
more precisely with the braid fan. For such neural networks, we prove a
non-constant lower bound of $\Omega(\log\log d)$ hidden layers required to
exactly represent the maximum of $d$ numbers. Additionally, under our
assumption, we provide a combinatorial proof that 3 hidden layers are necessary
to compute the maximum of 5 numbers; this had only been verified with an
excessive computation so far. Finally, we show that a natural generalization of
the best known upper bound to maxout networks is not tight, by demonstrating
that a rank-3 maxout layer followed by a rank-2 maxout layer is sufficient to
represent the maximum of 7 numbers.","Moritz Grillo, Christoph Hertrich, Georg Loho",2025-02-13 13:37:52.000000,arXiv,http://arxiv.org/abs/2502.09324v1,Machine Learning
101,Bridging Jensen Gap for Max-Min Group Fairness Optimization in Recommendation,"Group max-min fairness (MMF) is commonly used in fairness-aware recommender
systems (RS) as an optimization objective, as it aims to protect marginalized
item groups and ensures a fair competition platform. However, our theoretical
analysis indicates that integrating MMF constraint violates the assumption of
sample independence during optimization, causing the loss function to deviate
from linear additivity. Such nonlinearity property introduces the Jensen gap
between the model's convergence point and the optimal point if mini-batch
sampling is applied. Both theoretical and empirical studies show that as the
mini-batch size decreases and the group size increases, the Jensen gap will
widen accordingly. Some methods using heuristic re-weighting or debiasing
strategies have the potential to bridge the Jensen gap. However, they either
lack theoretical guarantees or suffer from heavy computational costs. To
overcome these limitations, we first theoretically demonstrate that the
MMF-constrained objective can be essentially reformulated as a group-weighted
optimization objective. Then we present an efficient and effective algorithm
named FairDual, which utilizes a dual optimization technique to minimize the
Jensen gap. Our theoretical analysis demonstrates that FairDual can achieve a
sub-linear convergence rate to the globally optimal solution and the Jensen gap
can be well bounded under a mini-batch sampling strategy with random shuffle.
Extensive experiments conducted using six large-scale RS backbone models on
three publicly available datasets demonstrate that FairDual outperforms all
baselines in terms of both accuracy and fairness. Our data and codes are shared
at https://github.com/XuChen0427/FairDual.","Chen Xu, Yuxin Li, Wenjie Wang, Liang Pang, Jun Xu, Tat-Seng Chua",2025-02-13 13:33:45.000000,arXiv,http://arxiv.org/abs/2502.09319v1,Information Retrieval
102,SigGate: Enhancing Recurrent Neural Networks with Signature-Based Gating Mechanisms,"In this paper, we propose a novel approach that enhances recurrent neural
networks (RNNs) by incorporating path signatures into their gating mechanisms.
Our method modifies both Long Short-Term Memory (LSTM) and Gated Recurrent Unit
(GRU) architectures by replacing their forget and reset gates, respectively,
with learnable path signatures. These signatures, which capture the geometric
features of the entire path history, provide a richer context for controlling
information flow through the network's memory. This modification allows the
networks to make memory decisions based on the full historical context rather
than just the current input and state. Through experimental studies, we
demonstrate that our Signature-LSTM (SigLSTM) and Signature-GRU (SigGRU) models
outperform their traditional counterparts across various sequential learning
tasks. By leveraging path signatures in recurrent architectures, this method
offers new opportunities to enhance performance in time series analysis and
forecasting applications.","Rémi Genet, Hugo Inzirillo",2025-02-13 13:33:35.000000,arXiv,http://arxiv.org/abs/2502.09318v1,Machine Learning
103,A Judge-free LLM Open-ended Generation Benchmark Based on the Distributional Hypothesis,"Evaluating the open-ended text generation of large language models (LLMs) is
challenging because of the lack of a clear ground truth and the high cost of
human or LLM-based assessments. We propose a novel benchmark that evaluates
LLMs using n-gram statistics and rules, without relying on human judgement or
LLM-as-a-judge approaches. Using 50 question and reference answer sets, we
introduce three new metrics based on n-grams and rules: Fluency, Truthfulness,
and Helpfulness. Our benchmark strongly correlates with GPT-4o-based
evaluations while requiring significantly fewer computational resources,
demonstrating its effectiveness as a scalable alternative for assessing LLMs'
open-ended generation capabilities.","Kentaro Imajo, Masanori Hirano, Shuji Suzuki, Hiroaki Mikami",2025-02-13 13:30:54.000000,arXiv,http://arxiv.org/abs/2502.09316v1,Natural Language Processing
104,Mitigating the Impact of Prominent Position Shift in Drone-based RGBT Object Detection,"Drone-based RGBT object detection plays a crucial role in many
around-the-clock applications. However, real-world drone-viewed RGBT data
suffers from the prominent position shift problem, i.e., the position of a tiny
object differs greatly in different modalities. For instance, a slight
deviation of a tiny object in the thermal modality will induce it to drift from
the main body of itself in the RGB modality. Considering RGBT data are usually
labeled on one modality (reference), this will cause the unlabeled modality
(sensed) to lack accurate supervision signals and prevent the detector from
learning a good representation. Moreover, the mismatch of the corresponding
feature point between the modalities will make the fused features confusing for
the detection head. In this paper, we propose to cast the cross-modality box
shift issue as the label noise problem and address it on the fly via a novel
Mean Teacher-based Cross-modality Box Correction head ensemble (CBC). In this
way, the network can learn more informative representations for both
modalities. Furthermore, to alleviate the feature map mismatch problem in RGBT
fusion, we devise a Shifted Window-Based Cascaded Alignment (SWCA) module. SWCA
mines long-range dependencies between the spatially unaligned features inside
shifted windows and cascaded aligns the sensed features with the reference
ones. Extensive experiments on two drone-based RGBT object detection datasets
demonstrate that the correction results are both visually and quantitatively
favorable, thereby improving the detection performance. In particular, our CBC
module boosts the precision of the sensed modality ground truth by 25.52 aSim
points. Overall, the proposed detector achieves an mAP_50 of 43.55 points on
RGBTDronePerson and surpasses a state-of-the-art method by 8.6 mAP50 on a shift
subset of DroneVehicle dataset. The code and data will be made publicly
available.","Yan Zhang, Wen Yang, Chang Xu, Qian Hu, Fang Xu, Gui-Song Xia",2025-02-13 13:25:13.000000,arXiv,http://arxiv.org/abs/2502.09311v1,Computer Vision
105,When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models,"Modern Large Language Models (LLMs) have shown human-like abilities in many
language tasks, sparking interest in comparing LLMs' and humans' language
processing. In this paper, we conduct a detailed comparison of the two on a
sentence comprehension task using garden-path constructions, which are
notoriously challenging for humans. Based on psycholinguistic research, we
formulate hypotheses on why garden-path sentences are hard, and test these
hypotheses on human participants and a large suite of LLMs using comprehension
questions. Our findings reveal that both LLMs and humans struggle with specific
syntactic complexities, with some models showing high correlation with human
comprehension. To complement our findings, we test LLM comprehension of
garden-path constructions with paraphrasing and text-to-image generation tasks,
and find that the results mirror the sentence comprehension question results,
further validating our findings on LLM understanding of these constructions.","Samuel Joseph Amouyal, Aya Meltzer-Asscher, Jonathan Berant",2025-02-13 13:19:33.000000,arXiv,http://arxiv.org/abs/2502.09307v1,Natural Language Processing
106,Non-asymptotic Analysis of Diffusion Annealed Langevin Monte Carlo for Generative Modelling,"We investigate the theoretical properties of general diffusion
(interpolation) paths and their Langevin Monte Carlo implementation, referred
to as diffusion annealed Langevin Monte Carlo (DALMC), under weak conditions on
the data distribution. Specifically, we analyse and provide non-asymptotic
error bounds for the annealed Langevin dynamics where the path of distributions
is defined as Gaussian convolutions of the data distribution as in diffusion
models. We then extend our results to recently proposed heavy-tailed (Student's
t) diffusion paths, demonstrating their theoretical properties for heavy-tailed
data distributions for the first time. Our analysis provides theoretical
guarantees for a class of score-based generative models that interpolate
between a simple distribution (Gaussian or Student's t) and the data
distribution in finite time. This approach offers a broader perspective
compared to standard score-based diffusion approaches, which are typically
based on a forward Ornstein-Uhlenbeck (OU) noising process.","Paula Cordero-Encinar, O. Deniz Akyildiz, Andrew B. Duncan",2025-02-13 13:18:30.000000,arXiv,http://arxiv.org/abs/2502.09306v1,Statistical Machine Learning
107,Predicting Drive Test Results in Mobile Networks Using Optimization Techniques,"Mobile network operators constantly optimize their networks to ensure
superior service quality and coverage. This optimization is crucial for
maintaining an optimal user experience and requires extensive data collection
and analysis. One of the primary methods for gathering this data is through
drive tests, where technical teams use specialized equipment to collect signal
information across various regions. However, drive tests are both costly and
time-consuming, and they face challenges such as traffic conditions,
environmental factors, and limited access to certain areas. These constraints
make it difficult to replicate drive tests under similar conditions. In this
study, we propose a method that enables operators to predict received signal
strength at specific locations using data from other drive test points. By
reducing the need for widespread drive tests, this approach allows operators to
save time and resources while still obtaining the necessary data to optimize
their networks and mitigate the challenges associated with traditional drive
tests.","MohammadJava Taheri, Abolfazl Diyanat, MortezaAli Ahmadi, Ali Nazari",2025-02-13 13:17:31.000000,arXiv,http://arxiv.org/abs/2502.09305v1,Other
108,KET-RAG: A Cost-Efficient Multi-Granular Indexing Framework for Graph-RAG,"Graph-RAG constructs a knowledge graph from text chunks to improve retrieval
in Large Language Model (LLM)-based question answering. It is particularly
useful in domains such as biomedicine, law, and political science, where
retrieval often requires multi-hop reasoning over proprietary documents. Some
existing Graph-RAG systems construct KNN graphs based on text chunk relevance,
but this coarse-grained approach fails to capture entity relationships within
texts, leading to sub-par retrieval and generation quality. To address this,
recent solutions leverage LLMs to extract entities and relationships from text
chunks, constructing triplet-based knowledge graphs. However, this approach
incurs significant indexing costs, especially for large document collections.
  To ensure a good result accuracy while reducing the indexing cost, we propose
KET-RAG, a multi-granular indexing framework. KET-RAG first identifies a small
set of key text chunks and leverages an LLM to construct a knowledge graph
skeleton. It then builds a text-keyword bipartite graph from all text chunks,
serving as a lightweight alternative to a full knowledge graph. During
retrieval, KET-RAG searches both structures: it follows the local search
strategy of existing Graph-RAG systems on the skeleton while mimicking this
search on the bipartite graph to improve retrieval quality. We evaluate eight
solutions on two real-world datasets, demonstrating that KET-RAG outperforms
all competitors in indexing cost, retrieval effectiveness, and generation
quality. Notably, it achieves comparable or superior retrieval quality to
Microsoft's Graph-RAG while reducing indexing costs by over an order of
magnitude. Additionally, it improves the generation quality by up to 32.4%
while lowering indexing costs by around 20%.","Yiqian Huang, Shiqi Zhang, Xiaokui Xiao",2025-02-13 13:16:16.000000,arXiv,http://arxiv.org/abs/2502.09304v1,Information Retrieval
109,Towards Seamless Hierarchical Federated Learning under Intermittent Client Participation: A Stagewise Decision-Making Methodology,"Federated Learning (FL) offers a pioneering distributed learning paradigm
that enables devices/clients to build a shared global model. This global model
is obtained through frequent model transmissions between clients and a central
server, which may cause high latency, energy consumption, and congestion over
backhaul links. To overcome these drawbacks, Hierarchical Federated Learning
(HFL) has emerged, which organizes clients into multiple clusters and utilizes
edge nodes (e.g., edge servers) for intermediate model aggregations between
clients and the central server. Current research on HFL mainly focus on
enhancing model accuracy, latency, and energy consumption in scenarios with a
stable/fixed set of clients. However, addressing the dynamic availability of
clients -- a critical aspect of real-world scenarios -- remains underexplored.
This study delves into optimizing client selection and client-to-edge
associations in HFL under intermittent client participation so as to minimize
overall system costs (i.e., delay and energy), while achieving fast model
convergence. We unveil that achieving this goal involves solving a complex
NP-hard problem. To tackle this, we propose a stagewise methodology that splits
the solution into two stages, referred to as Plan A and Plan B. Plan A focuses
on identifying long-term clients with high chance of participation in
subsequent model training rounds. Plan B serves as a backup, selecting
alternative clients when long-term clients are unavailable during model
training rounds. This stagewise methodology offers a fresh perspective on
client selection that can enhance both HFL and conventional FL via enabling
low-overhead decision-making processes. Through evaluations on MNIST and
CIFAR-10 datasets, we show that our methodology outperforms existing benchmarks
in terms of model accuracy and system costs.","Minghong Wu, Minghui Liwang, Yuhan Su, Li Li, Seyyedali Hosseinalipour, Xianbin Wang, Huaiyu Dai, Zhenzhen Jiao",2025-02-13 13:16:10.000000,arXiv,http://arxiv.org/abs/2502.09303v1,Machine Learning
110,Moving Matter: Efficient Reconfiguration of Tile Arrangements by a Single Active Robot,"We consider the problem of reconfiguring a two-dimensional connected grid
arrangement of passive building blocks from a start configuration to a goal
configuration, using a single active robot that can move on the tiles, remove
individual tiles from a given location and physically move them to a new
position by walking on the remaining configuration. The objective is to
determine a reconfiguration schedule that minimizes the overall makespan, while
ensuring that the tile configuration remains connected. We provide both
negative and positive results. (1) We present a generalized version of the
problem, parameterized by weighted costs for moving with or without tiles, and
show that this is NP-complete. (2) We give a polynomial-time constant-factor
approximation algorithm for the case of disjoint start and target bounding
boxes. In addition, our approach yields optimal carry distance for 2-scaled
instances.","Aaron T. Becker, Sándor P. Fekete, Jonas Friemel, Ramin Kosfeld, Peter Kramer, Harm Kube, Christian Rieck, Christian Scheffer, Arne Schmidt",2025-02-13 13:13:44.000000,arXiv,http://arxiv.org/abs/2502.09299v1,Other
111,Convex Is Back: Solving Belief MDPs With Convexity-Informed Deep Reinforcement Learning,"We present a novel method for Deep Reinforcement Learning (DRL),
incorporating the convex property of the value function over the belief space
in Partially Observable Markov Decision Processes (POMDPs). We introduce hard-
and soft-enforced convexity as two different approaches, and compare their
performance against standard DRL on two well-known POMDP environments, namely
the Tiger and FieldVisionRockSample problems. Our findings show that including
the convexity feature can substantially increase performance of the agents, as
well as increase robustness over the hyperparameter space, especially when
testing on out-of-distribution domains. The source code for this work can be
found at https://github.com/Dakout/Convex_DRL.","Daniel Koutas, Daniel Hettegger, Kostas G. Papakonstantinou, Daniel Straub",2025-02-13 13:12:16.000000,arXiv,http://arxiv.org/abs/2502.09298v1,Machine Learning
112,When do neural networks learn world models?,"Humans develop world models that capture the underlying generation process of
data. Whether neural networks can learn similar world models remains an open
problem. In this work, we provide the first theoretical results for this
problem, showing that in a multi-task setting, models with a low-degree bias
provably recover latent data-generating variables under mild assumptions --
even if proxy tasks involve complex, non-linear functions of the latents.
However, such recovery is also sensitive to model architecture. Our analysis
leverages Boolean models of task solutions via the Fourier-Walsh transform and
introduces new techniques for analyzing invertible Boolean transforms, which
may be of independent interest. We illustrate the algorithmic implications of
our results and connect them to related research areas, including
self-supervised learning, out-of-distribution generalization, and the linear
representation hypothesis in large language models.","Tianren Zhang, Guanyu Chen, Feng Chen",2025-02-13 13:11:54.000000,arXiv,http://arxiv.org/abs/2502.09297v1,Machine Learning
113,A Physics-Informed Deep Learning Model for MRI Brain Motion Correction,"Background: MRI is crucial for brain imaging but is highly susceptible to
motion artifacts due to long acquisition times. This study introduces
PI-MoCoNet, a physics-informed motion correction network that integrates
spatial and k-space information to remove motion artifacts without explicit
motion parameter estimation, enhancing image fidelity and diagnostic
reliability. Materials and Methods: PI-MoCoNet consists of a motion detection
network (U-net with spatial averaging) to identify corrupted k-space lines and
a motion correction network (U-net with Swin Transformer blocks) to reconstruct
motion-free images. The correction is guided by three loss functions:
reconstruction (L1), perceptual (LPIPS), and data consistency (Ldc). Motion
artifacts were simulated via rigid phase encoding perturbations and evaluated
on IXI and MR-ART datasets against Pix2Pix, CycleGAN, and U-net using PSNR,
SSIM, and NMSE. Results: PI-MoCoNet significantly improved image quality. On
IXI, for minor artifacts, PSNR increased from 34.15 dB to 45.95 dB, SSIM from
0.87 to 1.00, and NMSE reduced from 0.55% to 0.04%. For moderate artifacts,
PSNR improved from 30.23 dB to 42.16 dB, SSIM from 0.80 to 0.99, and NMSE from
1.32% to 0.09%. For heavy artifacts, PSNR rose from 27.99 dB to 36.01 dB, SSIM
from 0.75 to 0.97, and NMSE decreased from 2.21% to 0.36%. On MR-ART,
PI-MoCoNet achieved PSNR gains of ~10 dB and SSIM improvements of up to 0.20,
with NMSE reductions of ~6%. Ablation studies confirmed the importance of data
consistency and perceptual losses, yielding a 1 dB PSNR gain and 0.17% NMSE
reduction. Conclusions: PI-MoCoNet effectively mitigates motion artifacts in
brain MRI, outperforming existing methods. Its ability to integrate spatial and
k-space information makes it a promising tool for clinical use in motion-prone
settings. Code: https://github.com/mosaf/PI-MoCoNet.git.","Mojtaba Safari, Shansong Wang, Zach Eidex, Richard Qiu, Chih-Wei Chang, David S. Yu, Xiaofeng Yang",2025-02-13 13:09:55.000000,arXiv,http://arxiv.org/abs/2502.09296v1,Computer Vision
114,Indeterminacy in Affective Computing: Considering Meaning and Context in Data Collection Practices,"Automatic Affect Prediction (AAP) uses computational analysis of input data
such as text, speech, images, and physiological signals to predict various
affective phenomena (e.g., emotions or moods). These models are typically
constructed using supervised machine-learning algorithms, which rely heavily on
labeled training datasets. In this position paper, we posit that all AAP
training data are derived from human Affective Interpretation Processes,
resulting in a form of Affective Meaning. Research on human affect indicates a
form of complexity that is fundamental to such meaning: it can possess what we
refer to here broadly as Qualities of Indeterminacy (QIs) - encompassing
Subjectivity (meaning depends on who is interpreting), Uncertainty (lack of
confidence regarding meanings' correctness), Ambiguity (meaning contains
mutually exclusive concepts) and Vagueness (meaning is situated at different
levels in a nested hierarchy). Failing to appropriately consider QIs leads to
results incapable of meaningful and reliable predictions. Based on this
premise, we argue that a crucial step in adequately addressing indeterminacy in
AAP is the development of data collection practices for modeling corpora that
involve the systematic consideration of 1) a relevant set of QIs and 2) context
for the associated interpretation processes. To this end, we are 1) outlining a
conceptual model of AIPs and the QIs associated with the meaning these produce
and a conceptual structure of relevant context, supporting understanding of its
role. Finally, we use our framework for 2) discussing examples of
context-sensitivity-related challenges for addressing QIs in data collection
setups. We believe our efforts can stimulate a structured discussion of both
the role of aspects of indeterminacy and context in research on AAP, informing
the development of better practices for data collection and analysis.","Bernd Dudzik, Tiffany Matej Hrkalovic, Chenxu Hao, Chirag Raman, Masha Tsfasman",2025-02-13 13:08:42.000000,arXiv,http://arxiv.org/abs/2502.09294v1,Artificial Intelligence
115,Joint Attention Mechanism Learning to Facilitate Opto-physiological Monitoring during Physical Activity,"Opto-physiological monitoring is a non-contact technique for measuring
cardiac signals, i.e., photoplethysmography (PPG). Quality PPG signals directly
lead to reliable physiological readings. However, PPG signal acquisition
procedures are often accompanied by spurious motion artefacts (MAs), especially
during low-to-high-intensity physical activity. This study proposes a practical
adversarial learning approach for opto-physiological monitoring by using a
generative adversarial network with an attention mechanism (AM-GAN) to model
motion noise and to allow MA removal. The AM-GAN learns an MA-resistant mapping
from raw and noisy signals to clear PPG signals in an adversarial manner,
guided by an attention mechanism to directly translate the motion reference of
triaxial acceleration to the MAs appearing in the raw signal. The AM-GAN was
experimented with three various protocols engaged with 39 subjects in various
physical activities. The average absolute error for heart rate (HR) derived
from the MA-free PPG signal via the AM-GAN, is 1.81 beats/min for the IEEE-SPC
dataset and 3.86 beats/min for the PPGDalia dataset. The same procedure applied
to an in-house LU dataset resulted in average absolute errors for HR and
respiratory rate (RR) of less than 1.37 beats/min and 2.49 breaths/min,
respectively. The study demonstrates the robustness and resilience of AM-GAN,
particularly during low-to-high-intensity physical activities.","Xiaoyu Zheng, Sijung Hu, Vincent Dwyer, Mahsa Derakhshani, Laura Barrett",2025-02-13 13:08:11.000000,arXiv,http://arxiv.org/abs/2502.09291v1,Other
116,Dynamic Rolling Horizon Optimization for Network-Constrained V2X Value Stacking of Electric Vehicles Under Uncertainties,"Electric vehicle (EV) coordination can provide significant benefits through
vehicle-to-everything (V2X) by interacting with the grid, buildings, and other
EVs. This work aims to develop a V2X value-stacking framework, including
vehicle-to-building (V2B), vehicle-to-grid (V2G), and energy trading, to
maximize economic benefits for residential communities while maintaining
distribution voltage. This work also seeks to quantify the impact of prediction
errors related to building load, renewable energy, and EV arrivals. A dynamic
rolling-horizon optimization (RHO) method is employed to leverage multiple
revenue streams and maximize the potential of EV coordination. To address
energy uncertainties, including hourly local building load, local photovoltaic
(PV) generation, and EV arrivals, this work develops a Transformer-based
forecasting model named Gated Recurrent Units-Encoder-Temporal Fusion Decoder
(GRU-EN-TFD). The simulation results, using real data from Australia's National
Electricity Market, and the Independent System Operators in New England and New
York in the US, reveal that V2X value stacking can significantly reduce energy
costs. The proposed GRU-EN-TFD model outperforms the benchmark forecast model.
Uncertainties in EV arrivals have a more substantial impact on value-stacking
performance, highlighting the significance of its accurate forecast. This work
provides new insights into the dynamic interactions among residential
communities, unlocking the full potential of EV batteries.","Canchen Jiang, Ariel Liebman, Bo Jie, Hao Wang",2025-02-13 13:06:56.000000,arXiv,http://arxiv.org/abs/2502.09290v1,Other
117,An Uncertainty Principle for Linear Recurrent Neural Networks,"We consider linear recurrent neural networks, which have become a key
building block of sequence modeling due to their ability for stable and
effective long-range modeling. In this paper, we aim at characterizing this
ability on a simple but core copy task, whose goal is to build a linear filter
of order $S$ that approximates the filter that looks $K$ time steps in the past
(which we refer to as the shift-$K$ filter), where $K$ is larger than $S$.
Using classical signal models and quadratic cost, we fully characterize the
problem by providing lower bounds of approximation, as well as explicit filters
that achieve this lower bound up to constants. The optimal performance
highlights an uncertainty principle: the optimal filter has to average values
around the $K$-th time step in the past with a range~(width) that is
proportional to $K/S$.","Alexandre François, Antonio Orvieto, Francis Bach",2025-02-13 13:01:46.000000,arXiv,http://arxiv.org/abs/2502.09287v1,Machine Learning
118,EmoAssist: Emotional Assistant for Visual Impairment Community,"The rapid advancement of large multi-modality models (LMMs) has significantly
propelled the integration of artificial intelligence into practical
applications. Visual Question Answering (VQA) systems, which can process
multi-modal data including vision, text, and audio, hold great potential for
assisting the Visual Impairment (VI) community in navigating complex and
dynamic real-world environments. However, existing VI assistive LMMs overlook
the emotional needs of VI individuals, and current benchmarks lack emotional
evaluation of these LMMs. To address these gaps, this paper introduces the
EmoAssist Benchmark, a comprehensive benchmark designed to evaluate the
assistive performance of LMMs for the VI community. To the best of our
knowledge, this is the first benchmark that incorporates emotional intelligence
as a key consideration. Furthermore, we propose the EmoAssist Model, an
Emotion-Assistive LMM specifically designed for the VI community. The EmoAssist
Model utilizes Direct Preference Optimization (DPO) to align outputs with human
emotional preferences. Experiment results demonstrate that the EmoAssist Model
significantly enhances the recognition of implicit emotions and intentions of
VI users, delivers empathetic responses, and provides actionable guidance.
Specifically, it shows respective improvements of 147.8% and 89.7% in the
Empathy and Suggestion metrics on the EmoAssist Benchmark, compared to the
pre-tuning LMM, and even outperforms state-of-the-art LLMs such as GPT-4o.","Xingyu Qi, He Li, Linjie Li, Zhenyu Wu",2025-02-13 13:00:33.000000,arXiv,http://arxiv.org/abs/2502.09285v1,Computer Vision
119,SparQLe: Speech Queries to Text Translation Through LLMs,"With the growing influence of Large Language Models (LLMs), there is
increasing interest in integrating speech representations with them to enable
more seamless multi-modal processing and speech understanding. This study
introduces a novel approach that leverages self-supervised speech
representations in combination with instruction-tuned LLMs for speech-to-text
translation. The proposed approach leverages a modality adapter to align
extracted speech features with instruction-tuned LLMs using English-language
data. Our experiments demonstrate that this method effectively preserves the
semantic content of the input speech and serves as an effective bridge between
self-supervised speech models and instruction-tuned LLMs, offering a promising
solution for various speech understanding applications.","Amirbek Djanibekov, Hanan Aldarmaki",2025-02-13 12:57:15.000000,arXiv,http://arxiv.org/abs/2502.09284v1,Natural Language Processing
120,FE-LWS: Refined Image-Text Representations via Decoder Stacking and Fused Encodings for Remote Sensing Image Captioning,"Remote sensing image captioning aims to generate descriptive text from remote
sensing images, typically employing an encoder-decoder framework. In this
setup, a convolutional neural network (CNN) extracts feature representations
from the input image, which then guide the decoder in a sequence-to-sequence
caption generation process. Although much research has focused on refining the
decoder, the quality of image representations from the encoder remains crucial
for accurate captioning. This paper introduces a novel approach that integrates
features from two distinct CNN based encoders, capturing complementary
information to enhance caption generation. Additionally, we propose a weighted
averaging technique to combine the outputs of all GRUs in the stacked decoder.
Furthermore, a comparison-based beam search strategy is incorporated to refine
caption selection. The results demonstrate that our fusion-based approach,
along with the enhanced stacked decoder, significantly outperforms both the
transformer-based state-of-the-art model and other LSTM-based baselines.","Swadhin Das, Raksha Sharma",2025-02-13 12:54:13.000000,arXiv,http://arxiv.org/abs/2502.09282v1,Computer Vision
121,Adaptive Multi-Objective Bayesian Optimization for Capacity Planning of Hybrid Heat Sources in Electric-Heat Coupling Systems of Cold Regions,"The traditional heat-load generation pattern of combined heat and power
generators has become a problem leading to renewable energy source (RES) power
curtailment in cold regions, motivating the proposal of a planning model for
alternative heat sources. The model aims to identify non-dominant capacity
allocation schemes for heat pumps, thermal energy storage, electric boilers,
and combined storage heaters to construct a Pareto front, considering both
economic and sustainable objectives. The integration of various heat sources
from both generation and consumption sides enhances flexibility in utilization.
The study introduces a novel optimization algorithm, the adaptive
multi-objective Bayesian optimization (AMBO). Compared to other widely used
multi-objective optimization algorithms, AMBO eliminates predefined parameters
that may introduce subjectivity from planners. Beyond the algorithm, the
proposed model incorporates a noise term to account for inevitable simulation
deviations, enabling the identification of better-performing planning results
that meet the unique requirements of cold regions. What's more, the
characteristics of electric-thermal coupling scenarios are captured and
reflected in the operation simulation model to make sure the simulation is
close to reality. Numerical simulation verifies the superiority of the proposed
approach in generating a more diverse and evenly distributed Pareto front in a
sample-efficient manner, providing comprehensive and objective planning
choices.","Ruizhe Yang, Zhongkai Yi, Ying Xu, Guiyu Chen, Haojie Yang, Rong Yi, Tongqing Li, Miaozhe ShenJin Li, Haoxiang Gao, Hongyu Duan",2025-02-13 12:50:43.000000,arXiv,http://arxiv.org/abs/2502.09280v1,Other
122,ConsistentDreamer: View-Consistent Meshes Through Balanced Multi-View Gaussian Optimization,"Recent advances in diffusion models have significantly improved 3D
generation, enabling the use of assets generated from an image for embodied AI
simulations. However, the one-to-many nature of the image-to-3D problem limits
their use due to inconsistent content and quality across views. Previous models
optimize a 3D model by sampling views from a view-conditioned diffusion prior,
but diffusion models cannot guarantee view consistency. Instead, we present
ConsistentDreamer, where we first generate a set of fixed multi-view prior
images and sample random views between them with another diffusion model
through a score distillation sampling (SDS) loss. Thereby, we limit the
discrepancies between the views guided by the SDS loss and ensure a consistent
rough shape. In each iteration, we also use our generated multi-view prior
images for fine-detail reconstruction. To balance between the rough shape and
the fine-detail optimizations, we introduce dynamic task-dependent weights
based on homoscedastic uncertainty, updated automatically in each iteration.
Additionally, we employ opacity, depth distortion, and normal alignment losses
to refine the surface for mesh extraction. Our method ensures better view
consistency and visual quality compared to the state-of-the-art.","Onat Şahin, Mohammad Altillawi, George Eskandar, Carlos Carbone, Ziyuan Liu",2025-02-13 12:49:25.000000,arXiv,http://arxiv.org/abs/2502.09278v1,Computer Vision
123,FLARES: Fast and Accurate LiDAR Multi-Range Semantic Segmentation,"3D scene understanding is a critical yet challenging task in autonomous
driving, primarily due to the irregularity and sparsity of LiDAR data, as well
as the computational demands of processing large-scale point clouds. Recent
methods leverage the range-view representation to improve processing
efficiency. To mitigate the performance drop caused by information loss
inherent to the ""many-to-one"" problem, where multiple nearby 3D points are
mapped to the same 2D grids and only the closest is retained, prior works tend
to choose a higher azimuth resolution for range-view projection. However, this
can bring the drawback of reducing the proportion of pixels that carry
information and heavier computation within the network. We argue that it is not
the optimal solution and show that, in contrast, decreasing the resolution is
more advantageous in both efficiency and accuracy. In this work, we present a
comprehensive re-design of the workflow for range-view-based LiDAR semantic
segmentation. Our approach addresses data representation, augmentation, and
post-processing methods for improvements. Through extensive experiments on two
public datasets, we demonstrate that our pipeline significantly enhances the
performance of various network architectures over their baselines, paving the
way for more effective LiDAR-based perception in autonomous systems.","Bin Yang, Alexandru Paul Condurache",2025-02-13 12:39:26.000000,arXiv,http://arxiv.org/abs/2502.09274v1,Computer Vision
124,LiSA: Leveraging Link Recommender to Attack Graph Neural Networks via Subgraph Injection,"Graph Neural Networks (GNNs) have demonstrated remarkable proficiency in
modeling data with graph structures, yet recent research reveals their
susceptibility to adversarial attacks. Traditional attack methodologies, which
rely on manipulating the original graph or adding links to artificially created
nodes, often prove impractical in real-world settings. This paper introduces a
novel adversarial scenario involving the injection of an isolated subgraph to
deceive both the link recommender and the node classifier within a GNN system.
Specifically, the link recommender is mislead to propose links between targeted
victim nodes and the subgraph, encouraging users to unintentionally establish
connections and that would degrade the node classification accuracy, thereby
facilitating a successful attack. To address this, we present the LiSA
framework, which employs a dual surrogate model and bi-level optimization to
simultaneously meet two adversarial objectives. Extensive experiments on
real-world datasets demonstrate the effectiveness of our method.","Wenlun Zhang, Enyan Dai, Kentaro Yoshioka",2025-02-13 12:33:39.000000,arXiv,http://arxiv.org/abs/2502.09271v1,Machine Learning
125,Memory-based Ensemble Learning in CMR Semantic Segmentation,"Existing models typically segment either the entire 3D frame or 2D slices
independently to derive clinical functional metrics from ventricular
segmentation in cardiac cine sequences. While performing well overall, they
struggle at the end slices. To address this, we leverage spatial continuity to
extract global uncertainty from segmentation variance and use it as memory in
our ensemble learning method, Streaming, for classifier weighting, balancing
overall and end-slice performance. Additionally, we introduce the End
Coefficient (EC) to quantify end-slice accuracy. Experiments on ACDC and M\&Ms
datasets show that our framework achieves near-state-of-the-art Dice Similarity
Coefficient (DSC) and outperforms all models on end-slice performance,
improving patient-specific segmentation accuracy.","Yiwei Liu, Ziyi Wu, Liang Zhong, Linyi Wen, Yuankai Wu",2025-02-13 12:31:09.000000,arXiv,http://arxiv.org/abs/2502.09269v1,Computer Vision
126,GEVRM: Goal-Expressive Video Generation Model For Robust Visual Manipulation,"With the rapid development of embodied artificial intelligence, significant
progress has been made in vision-language-action (VLA) models for general robot
decision-making. However, the majority of existing VLAs fail to account for the
inevitable external perturbations encountered during deployment. These
perturbations introduce unforeseen state information to the VLA, resulting in
inaccurate actions and consequently, a significant decline in generalization
performance. The classic internal model control (IMC) principle demonstrates
that a closed-loop system with an internal model that includes external input
signals can accurately track the reference input and effectively offset the
disturbance. We propose a novel closed-loop VLA method GEVRM that integrates
the IMC principle to enhance the robustness of robot visual manipulation. The
text-guided video generation model in GEVRM can generate highly expressive
future visual planning goals. Simultaneously, we evaluate perturbations by
simulating responses, which are called internal embeddings and optimized
through prototype contrastive learning. This allows the model to implicitly
infer and distinguish perturbations from the external environment. The proposed
GEVRM achieves state-of-the-art performance on both standard and perturbed
CALVIN benchmarks and shows significant improvements in realistic robot tasks.","Hongyin Zhang, Pengxiang Ding, Shangke Lyu, Ying Peng, Donglin Wang",2025-02-13 12:29:50.000000,arXiv,http://arxiv.org/abs/2502.09268v1,Robotics
127,Unlocking the Potential of Classic GNNs for Graph-level Tasks: Simple Architectures Meet Excellence,"Message-passing Graph Neural Networks (GNNs) are often criticized for their
limited expressiveness, issues like over-smoothing and over-squashing, and
challenges in capturing long-range dependencies, while Graph Transformers (GTs)
are considered superior due to their global attention mechanisms. Literature
frequently suggests that GTs outperform GNNs, particularly in graph-level tasks
such as graph classification and regression. In this study, we explore the
untapped potential of GNNs through an enhanced framework, GNN+, which
integrates six widely used techniques: edge feature integration, normalization,
dropout, residual connections, feed-forward networks, and positional encoding,
to effectively tackle graph-level tasks. We conduct a systematic evaluation of
three classic GNNs, namely GCN, GIN, and GatedGCN, enhanced by the GNN+
framework across 14 well-known graph-level datasets. Our results show that,
contrary to the prevailing belief, classic GNNs excel in graph-level tasks,
securing top three rankings across all datasets and achieving first place in
eight, while also demonstrating greater efficiency than GTs. This highlights
the potential of simple GNN architectures, challenging the belief that complex
mechanisms in GTs are essential for superior graph-level performance.","Yuankai Luo, Lei Shi, Xiao-Ming Wu",2025-02-13 12:24:23.000000,arXiv,http://arxiv.org/abs/2502.09263v1,Machine Learning
128,Bandit Multiclass List Classification,"We study the problem of multiclass list classification with (semi-)bandit
feedback, where input examples are mapped into subsets of size $m$ of a
collection of $K$ possible labels, and the feedback consists of the predicted
labels which lie in the set of true labels of the given example. Our main
result is for the $(\varepsilon,\delta)$-PAC variant of the problem for which
we design an algorithm that returns an $\varepsilon$-optimal hypothesis with
high probability using a sample complexity of $O \big( (\mathrm{poly}(K/m) + sm
/ \varepsilon^2) \log (|H|/\delta) \big)$ where $H$ is the underlying (finite)
hypothesis class and $s$ is an upper bound on the number of true labels for a
given example. This bound improves upon known bounds for combinatorial
semi-bandits whenever $s \ll K$. Moreover, in the regime where $s = O(1)$ the
leading terms in our bound match the corresponding full-information rates,
implying that bandit feedback essentially comes at no cost. Our PAC learning
algorithm is also computationally efficient given access to an ERM oracle for
$H$. Additionally, we consider the regret minimization setting where data can
be generated adversarially, and establish a regret bound of $\widetilde O(|H| +
\sqrt{smT \log |H|})$. Our results generalize and extend those of Erez et al.
(2024) who consider the simpler single-label setting corresponding to $s=m=1$,
and in fact hold for the more general contextual combinatorial semi-bandit
problem with $s$-sparse rewards.","Liad Erez, Tomer Koren",2025-02-13 12:13:25.000000,arXiv,http://arxiv.org/abs/2502.09257v1,Machine Learning
129,DynSegNet:Dynamic Architecture Adjustment for Adversarial Learning in Segmenting Hemorrhagic Lesions from Fundus Images,"The hemorrhagic lesion segmentation plays a critical role in ophthalmic
diagnosis, directly influencing early disease detection, treatment planning,
and therapeutic efficacy evaluation. However, the task faces significant
challenges due to lesion morphological variability, indistinct boundaries, and
low contrast with background tissues. To improve diagnostic accuracy and
treatment outcomes, developing advanced segmentation techniques remains
imperative. This paper proposes an adversarial learning-based dynamic
architecture adjustment approach that integrates hierarchical U-shaped
encoder-decoder, residual blocks, attention mechanisms, and ASPP modules. By
dynamically optimizing feature fusion, our method enhances segmentation
performance. Experimental results demonstrate a Dice coefficient of 0.6802, IoU
of 0.5602, Recall of 0.766, Precision of 0.6525, and Accuracy of 0.9955,
effectively addressing the challenges in fundus image hemorrhage
segmentation.[* Corresponding author.]","Zesheng Li, Minwen Liao, Haoran Chen, Yan Su, Chengchang Pan, Honggang Qi",2025-02-13 12:11:58.000000,arXiv,http://arxiv.org/abs/2502.09256v1,Computer Vision
130,AnomalyGFM: Graph Foundation Model for Zero/Few-shot Anomaly Detection,"Graph anomaly detection (GAD) aims to identify abnormal nodes that differ
from the majority of the nodes in a graph, which has been attracting
significant attention in recent years. Existing generalist graph models have
achieved remarkable success in different graph tasks but struggle to generalize
to the GAD task. This limitation arises from their difficulty in learning
generalized knowledge for capturing the inherently infrequent, irregular and
heterogeneous abnormality patterns in graphs from different domains. To address
this challenge, we propose AnomalyGFM, a GAD-oriented graph foundation model
that supports zero-shot inference and few-shot prompt tuning for GAD in diverse
graph datasets. One key insight is that graph-agnostic representations for
normal and abnormal classes are required to support effective zero/few-shot GAD
across different graphs. Motivated by this, AnomalyGFM is pre-trained to align
data-independent, learnable normal and abnormal class prototypes with node
representation residuals (i.e., representation deviation of a node from its
neighbors). The residual features essentially project the node information into
a unified feature space where we can effectively measure the abnormality of
nodes from different graphs in a consistent way. This provides a driving force
for the learning of graph-agnostic, discriminative prototypes for the normal
and abnormal classes, which can be used to enable zero-shot GAD on new graphs,
including very large-scale graphs. If there are few-shot labeled normal nodes
available in the new graphs, AnomalyGFM can further support prompt tuning to
leverage these nodes for better adaptation. Comprehensive experiments on 11
widely-used GAD datasets with real anomalies, demonstrate that AnomalyGFM
significantly outperforms state-of-the-art competing methods under both zero-
and few-shot GAD settings.","Hezhe Qiao, Chaoxi Niu, Ling Chen, Guansong Pang",2025-02-13 12:10:05.000000,arXiv,http://arxiv.org/abs/2502.09254v1,Machine Learning
131,On the Importance of Embedding Norms in Self-Supervised Learning,"Self-supervised learning (SSL) allows training data representations without a
supervised signal and has become an important paradigm in machine learning.
Most SSL methods employ the cosine similarity between embedding vectors and
hence effectively embed data on a hypersphere. While this seemingly implies
that embedding norms cannot play any role in SSL, a few recent works have
suggested that embedding norms have properties related to network convergence
and confidence. In this paper, we resolve this apparent contradiction and
systematically establish the embedding norm's role in SSL training. Using
theoretical analysis, simulations, and experiments, we show that embedding
norms (i) govern SSL convergence rates and (ii) encode network confidence, with
smaller norms corresponding to unexpected samples. Additionally, we show that
manipulating embedding norms can have large effects on convergence speed. Our
findings demonstrate that SSL embedding norms are integral to understanding and
optimizing network behavior.","Andrew Draganov, Sharvaree Vadgama, Sebastian Damrich, Jan Niklas Böhm, Lucas Maes, Dmitry Kobak, Erik Bekkers",2025-02-13 12:09:17.000000,arXiv,http://arxiv.org/abs/2502.09252v1,Machine Learning
132,The Joint Entity-Relation Extraction Model Based on Span and Interactive Fusion Representation for Chinese Medical Texts with Complex Semantics,"Joint entity-relation extraction is a critical task in transforming
unstructured or semi-structured text into triplets, facilitating the
construction of large-scale knowledge graphs, and supporting various downstream
applications. Despite its importance, research on Chinese text, particularly
with complex semantics in specialized domains like medicine, remains limited.
To address this gap, we introduce the CH-DDI, a Chinese drug-drug interactions
dataset designed to capture the intricacies of medical text. Leveraging the
strengths of attention mechanisms in capturing long-range dependencies, we
propose the SEA module, which enhances the extraction of complex contextual
semantic information, thereby improving entity recognition and relation
extraction. Additionally, to address the inefficiencies of existing methods in
facilitating information exchange between entity recognition and relation
extraction, we present an interactive fusion representation module. This module
employs Cross Attention for bidirectional information exchange between the
tasks and further refines feature extraction through BiLSTM. Experimental
results on both our CH-DDI dataset and public CoNLL04 dataset demonstrate that
our model exhibits strong generalization capabilities. On the CH-DDI dataset,
our model achieves an F1-score of 96.73% for entity recognition and 78.43% for
relation extraction. On the CoNLL04 dataset, it attains an entity recognition
precision of 89.54% and a relation extraction accuracy of 71.64%.","Danni Feng, Runzhi Li, Jing Wang, Siyu Yan, Lihong Ma, Yunli Xing",2025-02-13 12:03:36.000000,arXiv,http://arxiv.org/abs/2502.09247v1,Natural Language Processing
133,You Do Not Fully Utilize Transformer's Representation Capacity,"In contrast to RNNs, which compress previous tokens into a single hidden
state, Transformers can attend to all previous tokens directly. However,
standard Transformers only use representations from the immediately preceding
layer. In this paper, we show that this design choice causes representation
collapse and leads to suboptimal performance. To address this issue, we
introduce Layer-Integrated Memory (LIMe), a simple yet powerful approach that
preserves the model's overall memory footprint while expanding its
representational capacity by allowing access to hidden states from earlier
layers. Through extensive experiments across various architectures and
different lookup mechanisms, we demonstrate consistent performance improvements
on a wide range of tasks. Moreover, our analysis of the learned representation
dynamics and our exploration of depthwise circuits reveal how LIMe integrates
information across layers, pointing to promising directions for future
research.","Gleb Gerasimov, Yaroslav Aksenov, Nikita Balagansky, Viacheslav Sinii, Daniil Gavrilov",2025-02-13 12:00:50.000000,arXiv,http://arxiv.org/abs/2502.09245v1,Machine Learning
134,From large language models to multimodal AI: A scoping review on the potential of generative AI in medicine,"Generative artificial intelligence (AI) models, such as diffusion models and
OpenAI's ChatGPT, are transforming medicine by enhancing diagnostic accuracy
and automating clinical workflows. The field has advanced rapidly, evolving
from text-only large language models for tasks such as clinical documentation
and decision support to multimodal AI systems capable of integrating diverse
data modalities, including imaging, text, and structured data, within a single
model. The diverse landscape of these technologies, along with rising interest,
highlights the need for a comprehensive review of their applications and
potential. This scoping review explores the evolution of multimodal AI,
highlighting its methods, applications, datasets, and evaluation in clinical
settings. Adhering to PRISMA-ScR guidelines, we systematically queried PubMed,
IEEE Xplore, and Web of Science, prioritizing recent studies published up to
the end of 2024. After rigorous screening, 144 papers were included, revealing
key trends and challenges in this dynamic field. Our findings underscore a
shift from unimodal to multimodal approaches, driving innovations in diagnostic
support, medical report generation, drug discovery, and conversational AI.
However, critical challenges remain, including the integration of heterogeneous
data types, improving model interpretability, addressing ethical concerns, and
validating AI systems in real-world clinical settings. This review summarizes
the current state of the art, identifies critical gaps, and provides insights
to guide the development of scalable, trustworthy, and clinically impactful
multimodal AI solutions in healthcare.","Lukas Buess, Matthias Keicher, Nassir Navab, Andreas Maier, Soroosh Tayebi Arasteh",2025-02-13 11:57:51.000000,arXiv,http://arxiv.org/abs/2502.09242v1,Artificial Intelligence
135,Safety Evaluation of Human Arm Operations Using IMU Sensors with a Spring-Damper-Mass Predictive Model,"This paper presents a novel approach to real-time safety monitoring in
human-robot collaborative manufacturing environments through a wrist-mounted
Inertial Measurement Unit (IMU) system integrated with a Predictive Safety
Model (PSM). The proposed system extends previous PSM implementations through
the adaptation of a spring-damper-mass model specifically optimized for wrist
motions, employing probabilistic safety assessment through impedance-based
computations. We analyze our proposed impedance-based safety approach with
frequency domain methods, establishing quantitative safety thresholds through
comprehensive comparative analysis. Experimental validation across three
manufacturing tasks - tool manipulation, visual inspection, and pick-and-place
operations. Results show robust performance across diverse manufacturing
scenarios while maintaining computational efficiency through optimized
parameter selection. This work establishes a foundation for future developments
in adaptive risk assessment in real-time for human-robot collaborative
manufacturing environments.","Musab Zubair Inamdar, Seyed Amir Tafrishi",2025-02-13 11:57:07.000000,arXiv,http://arxiv.org/abs/2502.09241v1,Robotics
136,OpenBench: A New Benchmark and Baseline for Semantic Navigation in Smart Logistics,"The increasing demand for efficient last-mile delivery in smart logistics
underscores the role of autonomous robots in enhancing operational efficiency
and reducing costs. Traditional navigation methods, which depend on
high-precision maps, are resource-intensive, while learning-based approaches
often struggle with generalization in real-world scenarios. To address these
challenges, this work proposes the Openstreetmap-enhanced oPen-air sEmantic
Navigation (OPEN) system that combines foundation models with classic
algorithms for scalable outdoor navigation. The system uses off-the-shelf
OpenStreetMap (OSM) for flexible map representation, thereby eliminating the
need for extensive pre-mapping efforts. It also employs Large Language Models
(LLMs) to comprehend delivery instructions and Vision-Language Models (VLMs)
for global localization, map updates, and house number recognition. To
compensate the limitations of existing benchmarks that are inadequate for
assessing last-mile delivery, this work introduces a new benchmark specifically
designed for outdoor navigation in residential areas, reflecting the real-world
challenges faced by autonomous delivery systems. Extensive experiments in
simulated and real-world environments demonstrate the proposed system's
efficacy in enhancing navigation efficiency and reliability. To facilitate
further research, our code and benchmark are publicly available.","Junhui Wang, Dongjie Huo, Zehui Xu, Yongliang Shi, Yimin Yan, Yuanxin Wang, Chao Gao, Yan Qiao, Guyue Zhou",2025-02-13 11:55:33.000000,arXiv,http://arxiv.org/abs/2502.09238v1,Robotics
137,Reliable Conversational Agents under ASP Control that Understand Natural Language,"Efforts have been made to make machines converse like humans in the past few
decades. The recent techniques of Large Language Models (LLMs) make it possible
to have human-like conversations with machines, but LLM's flaws of lacking
understanding and reliability are well documented. We believe that the best way
to eliminate this problem is to use LLMs only as parsers to translate text to
knowledge and vice versa and carry out the conversation by reasoning over this
knowledge using the answer set programming. I have been developing a framework
based on LLMs and ASP to realize reliable chatbots that ""understand"" human
conversation. This framework has been used to develop task-specific chatbots as
well as socialbots. My future research is focused on making these chatbots
scalable and trainable.",Yankai Zeng,2025-02-13 11:54:28.000000,arXiv,http://arxiv.org/abs/2502.09237v1,Other
138,Hybrid Answer Set Programming: Foundations and Applications,"Answer Set Programming (ASP) is a powerful tool for solving real-world
problems. However, many problems involve numeric values and complex constraints
beyond the capabilities of standard ASP solvers. Hybrid solvers like CLINGCON
and CLINGO[DL] address this by using specialized methods for specific
constraints. However, these solvers lack a strong theoretical foundation.
  This issue has first been addressed by introducing the Logic of
Here-and-There with constraints (HT_c) as an extension of the Logic of
Here-and-There (HT) and its non-monotone extension Equilibrium Logic. Nowadays,
HT serves as a logical foundation for ASP and has facilitated a broader
understanding of this paradigm. The idea is that HTC (and other extensions)
play an analogous role for hybrid ASP.
  There remain many open questions about these logics regarding their
fundamental characteristics as well as their practical use in solvers, ie. how
they can guide the implementation.
  Having a formal understanding of these hybrid logics is also needed to better
understand the inherent structure of the (real-world) problems they are applied
to and to improve their representations in ASP. As an example of an application
of ASP we use product configuration.",Nicolas Rühling,2025-02-13 11:53:57.000000,arXiv,http://arxiv.org/abs/2502.09235v1,Artificial Intelligence
139,Commonsense Reasoning-Aided Autonomous Vehicle Systems,"Autonomous Vehicle (AV) systems have been developed with a strong reliance on
machine learning techniques. While machine learning approaches, such as deep
learning, are extremely effective at tasks that involve observation and
classification, they struggle when it comes to performing higher level
reasoning about situations on the road. This research involves incorporating
commonsense reasoning models that use image data to improve AV systems. This
will allow AV systems to perform more accurate reasoning while also making them
more adjustable, explainable, and ethical. This paper will discuss the findings
so far and motivate its direction going forward.",Keegan Kimbrell,2025-02-13 11:53:25.000000,arXiv,http://arxiv.org/abs/2502.09233v1,Artificial Intelligence
140,Logical foundations of Smart Contracts,"Nowadays, sophisticated domains are emerging which require appropriate
formalisms to be specified accurately in order to reason about them. One such
domain is constituted of smart contracts that have emerged in cyber physical
systems as a way of enforcing formal agreements between components of these
systems. Smart contracts self-execute to run and share business processes
through blockchain, in decentralized systems, with many different participants.
Legal contracts are in many cases complex documents, with a number of
exceptions, and many subcontracts. The implementation of smart contracts based
on legal contracts is a long and laborious task, that needs to include all
actions, procedures, and the effects of actions related to the execution of the
contract. An ongoing open problem in this area is to formally account for smart
contracts using a uniform and somewhat universal formalism. This thesis
proposes logical foundations to smart contracts using the Situation Calculus, a
logic for reasoning about actions. Situation Calculus is one of the prominent
logic-based artificial intelligence approaches that provides enough logical
mechanism to specify and implement dynamic and complex systems such as
contracts. Situation Calculus is suitable to show how worlds dynamically
change. Smart contracts are going to be implement with Golog (written en
Prolog), a Situation Calculus-based programming language for modeling complex
and dynamic behaviors.",Kalonji Kalala,2025-02-13 11:53:10.000000,arXiv,http://arxiv.org/abs/2502.09232v1,Other
141,Answer Set Counting and its Applications,"We have focused on Answer Set Programming (ASP), more specifically, answer
set counting, exploring both exact and approximate methodologies. We developed
an exact ASP counter, sharpASP, which utilizes a compact encoding for
propositional formulas, significantly enhancing efficiency compared to existing
methods that often struggle with inefficient encodings. Our evaluations
indicate that sharpASP outperforms current ASP counters on several benchmarks.
In addition, we proposed an approximate ASP counter, named ApproxASP, a
hashing-based counter integrating Gauss-Jordan elimination within the ASP
solver, clingo. As a practical application, we employed ApproxASP for network
reliability estimation, demonstrating superior performance over both
traditional reliability estimators and #SAT-based methods.",Mohimenul Kabir,2025-02-13 11:52:55.000000,arXiv,http://arxiv.org/abs/2502.09231v1,Natural Language Processing
142,Relating Answer Set Programming and Many-sorted Logics for Formal Verification,"Answer Set Programming (ASP) is an important logic programming paradigm
within the field of Knowledge Representation and Reasoning. As a concise,
human-readable, declarative language, ASP is an excellent tool for developing
trustworthy (especially, artificially intelligent) software systems. However,
formally verifying ASP programs offers some unique challenges, such as
  1. a lack of modularity (the meanings of rules are difficult to define in
isolation from the enclosing program),
  2. the ground-and-solve semantics (the meanings of rules are dependent on the
input data with which the program is grounded), and
  3. limitations of existing tools.
  My research agenda has been focused on addressing these three issues with the
intention of making ASP verification an accessible, routine task that is
regularly performed alongside program development. In this vein, I have
investigated alternative semantics for ASP based on translations into the logic
of here-and-there and many-sorted first-order logic. These semantics promote a
modular understanding of logic programs, bypass grounding, and enable us to use
automated theorem provers to automatically verify properties of programs.",Zachary Hansen,2025-02-13 11:52:40.000000,arXiv,http://arxiv.org/abs/2502.09230v1,Other
143,Computational methods for Dynamic Answer Set Programming,"In our daily lives and industrial settings, we often encounter dynamic
problems that require reasoning over time and metric constraints. These include
tasks such as scheduling, routing, and production sequencing. Dynamic logics
have traditionally addressed these needs but often lack the flexibility and
integration required for comprehensive problem modeling. This research aims to
extend Answer Set Programming (ASP), a powerful declarative problem-solving
approach, to handle dynamic domains effectively. By integrating concepts from
dynamic, temporal, and metric logics into ASP, we seek to develop robust
systems capable of modeling complex dynamic problems and performing efficient
reasoning tasks, thereby enhancing ASPs applicability in industrial contexts.",Susana Hahn,2025-02-13 11:52:25.000000,arXiv,http://arxiv.org/abs/2502.09228v1,Artificial Intelligence
144,Generating Causally Compliant Counterfactual Explanations using ASP,"This research is focused on generating achievable counterfactual
explanations. Given a negative outcome computed by a machine learning model or
a decision system, the novel CoGS approach generates (i) a counterfactual
solution that represents a positive outcome and (ii) a path that will take us
from the negative outcome to the positive one, where each node in the path
represents a change in an attribute (feature) value. CoGS computes paths that
respect the causal constraints among features. Thus, the counterfactuals
computed by CoGS are realistic. CoGS utilizes rule-based machine learning
algorithms to model causal dependencies between features. The paper discusses
the current status of the research and the preliminary results obtained.",Sopam Dasgupta,2025-02-13 11:51:53.000000,arXiv,http://arxiv.org/abs/2502.09226v1,Artificial Intelligence
145,Order-Sorted Intensional Logic: Expressing Subtyping Polymorphism with Typing Assertions and Quantification over Concepts,"Subtyping, also known as subtype polymorphism, is a concept extensively
studied in programming language theory, delineating the substitutability
relation among datatypes. This property ensures that programs designed for
supertype objects remain compatible with their subtypes.
  In this paper, we explore the capability of order-sorted logic for utilizing
these ideas in the context of Knowledge Representation. We recognize two
fundamental limitations: First, the inability of this logic to address the
concept rather than the value of non-logical symbols, and second, the lack of
language constructs for constraining the type of terms. Consequently, we
propose guarded order-sorted intensional logic, where guards are language
constructs for annotating typing information and intensional logic provides
support for quantification over concepts.","Đorđe Marković, Marc Denecker",2025-02-13 11:51:22.000000,arXiv,http://arxiv.org/abs/2502.09224v1,Artificial Intelligence
146,ASP-driven User-interaction with Clinguin,"We present clinguin, a system for ASP-driven user interface design. Clinguin
streamlines the development of user interfaces for ASP developers by letting
them build interactive prototypes directly in ASP, eliminating the need for
separate frontend languages. To this end, clinguin uses a few dedicated
predicates to define user interfaces and the treatment of user-triggered
events. This simple design greatly facilitates the specification of user
interactions with an ASP system, in our case clingo.","Alexander Beiser, Susana Hahn, Torsten Schaub",2025-02-13 11:50:51.000000,arXiv,http://arxiv.org/abs/2502.09222v1,Artificial Intelligence
147,Pearce's Characterisation in an Epistemic Domain,"Answer-set programming (ASP) is a successful problem-solving approach in
logic-based AI. In ASP, problems are represented as declarative logic programs,
and solutions are identified through their answer sets. Equilibrium logic (EL)
is a general-purpose nonmonotonic reasoning formalism, based on a monotonic
logic called here-and-there logic. EL was basically proposed by Pearce as a
foundational framework of ASP. Epistemic specifications (ES) are extensions of
ASP-programs with subjective literals. These new modal constructs in the
ASP-language make it possible to check whether a regular literal of ASP is true
in every (or some) answer-set of a program. ES-programs are interpreted by
world-views, which are essentially collections of answer-sets. (Reflexive)
autoepistemic logic is a nonmonotonic formalism, modeling self-belief
(knowledge) of ideally rational agents. A relatively new semantics for ES is
based on a combination of EL and (reflexive) autoepistemic logic. In this
paper, we first propose an overarching framework in the epistemic ASP domain.
We then establish a correspondence between existing (reflexive) (auto)epistemic
equilibrium logics and our easily-adaptable comprehensive framework, building
on Pearce's characterisation of answer-sets as equilibrium models. We achieve
this by extending Ferraris' work on answer sets for propositional theories to
the epistemic case and reveal the relationship between some ES-semantic
proposals.",Ezgi Iraz Su,2025-02-13 11:50:36.000000,arXiv,http://arxiv.org/abs/2502.09221v1,Artificial Intelligence
148,"Graphical Conditions for the Existence, Unicity and Number of Regular Models","The regular models of a normal logic program are a particular type of partial
(i.e. 3-valued) models which correspond to stable partial models with minimal
undefinedness. In this paper, we explore graphical conditions on the dependency
graph of a finite ground normal logic program to analyze the existence, unicity
and number of regular models for the program. We show three main results: 1) a
necessary condition for the existence of non-trivial (i.e. non-2-valued)
regular models, 2) a sufficient condition for the unicity of regular models,
and 3) two upper bounds for the number of regular models based on positive
feedback vertex sets. The first two conditions generalize the finite cases of
the two existing results obtained by You and Yuan (1994) for normal logic
programs with well-founded stratification. The third result is also new to the
best of our knowledge. Key to our proofs is a connection that we establish
between finite ground normal logic programs and Boolean network theory.","Van-Giang Trinh, Belaid Benhamou, Sylvain Soliman, François Fages",2025-02-13 11:50:20.000000,arXiv,http://arxiv.org/abs/2502.09220v1,Other
149,Abduction of Domain Relationships from Data for VQA,"In this paper, we study the problem of visual question answering (VQA) where
the image and query are represented by ASP programs that lack domain data. We
provide an approach that is orthogonal and complementary to existing knowledge
augmentation techniques where we abduce domain relationships of image
constructs from past examples. After framing the abduction problem, we provide
a baseline approach, and an implementation that significantly improves the
accuracy of query answering yet requires few examples.","Al Mehdi Saadat Chowdhury, Paulo Shakarian, Gerardo I. Simari",2025-02-13 11:50:04.000000,arXiv,http://arxiv.org/abs/2502.09219v1,Other
150,Data2Concept2Text: An Explainable Multilingual Framework for Data Analysis Narration,"This paper presents a complete explainable system that interprets a set of
data, abstracts the underlying features and describes them in a natural
language of choice. The system relies on two crucial stages: (i) identifying
emerging properties from data and transforming them into abstract concepts, and
(ii) converting these concepts into natural language. Despite the impressive
natural language generation capabilities demonstrated by Large Language Models,
their statistical nature and the intricacy of their internal mechanism still
force us to employ these techniques as black boxes, forgoing trustworthiness.
Developing an explainable pipeline for data interpretation would allow
facilitating its use in safety-critical environments like processing medical
information and allowing non-experts and visually impaired people to access
narrated information. To this end, we believe that the fields of knowledge
representation and automated reasoning research could present a valid
alternative. Expanding on prior research that tackled the first stage (i), we
focus on the second stage, named Concept2Text. Being explainable, data
translation is easily modeled through logic-based rules, once again emphasizing
the role of declarative programming in achieving AI explainability. This paper
explores a Prolog/CLP-based rewriting system to interpret concepts-articulated
in terms of classes and relations, plus common knowledge-derived from a generic
ontology, generating natural language text. Its main features include
hierarchical tree rewritings, modular multilingual generation, support for
equivalent variants across semantic, grammar, and lexical levels, and a
transparent rule-based system. We outline the architecture and demonstrate its
flexibility through some examples capable of generating numerous diverse and
equivalent rewritings based on the input concept.","Flavio Bertini, Alessandro Dal Palù, Federica Zaglio, Francesco Fabiano, Andrea Formisano",2025-02-13 11:49:48.000000,arXiv,http://arxiv.org/abs/2502.09218v1,Other
151,"Mind the Gaps: Logical English, Prolog, and Multi-agent Systems for Autonomous Vehicles","In this paper, we present a modular system for representing and reasoning
with legal aspects of traffic rules for autonomous vehicles. We focus on a
subset of the United Kingdom's Highway Code (HC) related to junctions. As human
drivers and automated vehicles (AVs) will interact on the roads, especially in
urban environments, we claim that an accessible, unitary, high-level
computational model should exist and be applicable to both users. Autonomous
vehicles introduce a shift in liability that should not bring disadvantages or
increased burden on human drivers. We develop a system ""in silico"" of the
model. The proposed system is built of three main components: a natural
language interface, using Logical English, which encodes the rules; an internal
representation of the rules in Prolog; and an multi-agent-based simulation
environment, built in NetLogo. The three components interact: Logical English
is translated into and out of Prolog (along with some support code); Prolog and
NetLogo interface via predicates. Such a modular approach enables the different
components to carry different ""burdens"" in the overall system; it also allows
swapping of modules. Given NetLogo, we can visualize the effect of the modeled
rules as well as validate the system with a simple dynamic running scenario.
Designated agents monitor the behaviour of the vehicles for compliance and
record potential violations where they occur. The information on potential
violations is then utilized by Validators, to determine whether the violation
is punishable, differentiating between exceptions and cases.","Galileo Sartor, Adam Wyner, Giuseppe Contissa",2025-02-13 11:49:17.000000,arXiv,http://arxiv.org/abs/2502.09216v1,Artificial Intelligence
152,Architecture for Simulating Behavior Mode Changes in Norm-Aware Autonomous Agents,"This paper presents an architecture for simulating the actions of a
norm-aware intelligent agent whose behavior with respect to norm compliance is
set, and can later be changed, by a human controller. Updating an agent's
behavior mode from a norm-abiding to a riskier one may be relevant when the
agent is involved in time-sensitive rescue operations, for example. We base our
work on the Authorization and Obligation Policy Language AOPL designed by
Gelfond and Lobo for the specification of norms. We introduce an architecture
and a prototype software system that can be used to simulate an agent's plans
under different behavior modes that can later be changed by the controller. We
envision such software to be useful to policy makers, as they can more readily
understand how agents may act in certain situations based on the agents'
attitudes towards norm-compliance. Policy makers may then refine their policies
if simulations show unwanted consequences.","Sean Glaze, Daniela Inclezan",2025-02-13 11:49:02.000000,arXiv,http://arxiv.org/abs/2502.09215v1,Other
153,Neuro-Symbolic Contrastive Learning for Cross-domain Inference,"Pre-trained language models (PLMs) have made significant advances in natural
language inference (NLI) tasks, however their sensitivity to textual
perturbations and dependence on large datasets indicate an over-reliance on
shallow heuristics. In contrast, inductive logic programming (ILP) excels at
inferring logical relationships across diverse, sparse and limited datasets,
but its discrete nature requires the inputs to be precisely specified, which
limits their application. This paper proposes a bridge between the two
approaches: neuro-symbolic contrastive learning. This allows for smooth and
differentiable optimisation that improves logical accuracy across an otherwise
discrete, noisy, and sparse topological space of logical functions. We show
that abstract logical relationships can be effectively embedded within a
neuro-symbolic paradigm, by representing data as logic programs and sets of
logic rules. The embedding space captures highly varied textual information
with similar semantic logical relations, but can also separate similar textual
relations that have dissimilar logical relations. Experimental results
demonstrate that our approach significantly improves the inference capabilities
of the models in terms of generalisation and reasoning.","Mingyue Liu, Ryo Ueda, Zhen Wan, Katsumi Inoue, Chris G. Willcocks",2025-02-13 11:48:46.000000,arXiv,http://arxiv.org/abs/2502.09213v1,Machine Learning
154,LP-LM: No Hallucinations in Question Answering with Logic Programming,"Large language models (LLMs) are able to generate human-like responses to
user queries. However, LLMs exhibit inherent limitations, especially because
they hallucinate. This paper introduces LP-LM, a system that grounds answers to
questions in known facts contained in a knowledge base (KB), facilitated
through semantic parsing in Prolog, and always produces answers that are
reliable.
  LP-LM generates a most probable constituency parse tree along with a
corresponding Prolog term for an input question via Prolog definite clause
grammar (DCG) parsing. The term is then executed against a KB of natural
language sentences also represented as Prolog terms for question answering. By
leveraging DCG and tabling, LP-LM runs in linear time in the size of input
sentences for sufficiently many grammar rules. Performing experiments comparing
LP-LM with current well-known LLMs in accuracy, we show that LLMs hallucinate
on even simple questions, unlike LP-LM.","Katherine Wu, Yanhong A. Liu",2025-02-13 11:48:31.000000,arXiv,http://arxiv.org/abs/2502.09212v1,Artificial Intelligence
155,Visual Graph Question Answering with ASP and LLMs for Language Parsing,"Visual Question Answering (VQA) is a challenging problem that requires to
process multimodal input. Answer-Set Programming (ASP) has shown great
potential in this regard to add interpretability and explainability to modular
VQA architectures. In this work, we address the problem of how to integrate ASP
with modules for vision and natural language processing to solve a new and
demanding VQA variant that is concerned with images of graphs (not graphs in
symbolic form). Images containing graph-based structures are an ubiquitous and
popular form of visualisation. Here, we deal with the particular problem of
graphs inspired by transit networks, and we introduce a novel dataset that
amends an existing one by adding images of graphs that resemble metro lines.
Our modular neuro-symbolic approach combines optical graph recognition for
graph parsing, a pretrained optical character recognition neural network for
parsing labels, Large Language Models (LLMs) for language processing, and ASP
for reasoning. This method serves as a first baseline and achieves an overall
average accuracy of 73% on the dataset. Our evaluation provides further
evidence of the potential of modular neuro-symbolic systems, in particular with
pretrained models that do not involve any further training and logic
programming for reasoning, to solve complex VQA tasks.","Jakob Johannes Bauer, Thomas Eiter, Nelson Higuera Ruiz, Johannes Oetsch",2025-02-13 11:47:59.000000,arXiv,http://arxiv.org/abs/2502.09211v1,Artificial Intelligence
156,On LLM-generated Logic Programs and their Inference Execution Methods,"Large Language Models (LLMs) trained on petabytes of data are highly
compressed repositories of a significant proportion of the knowledge
accumulated and distilled so far. In this paper we study techniques to elicit
this knowledge in the form of several classes of logic programs, including
propositional Horn clauses, Dual Horn clauses, relational triplets and Definite
Clause Grammars. Exposing this knowledge as logic programs enables sound
reasoning methods that can verify alignment of LLM outputs to their intended
uses and extend their inference capabilities. We study new execution methods
for the generated programs, including soft-unification of abducible facts
against LLM-generated content stored in a vector database as well as GPU-based
acceleration of minimal model computation that supports inference with large
LLM-generated programs.",Paul Tarau,2025-02-13 11:47:44.000000,arXiv,http://arxiv.org/abs/2502.09209v1,Artificial Intelligence
157,Efficient OWL2QL Meta-reasoning Using ASP-based Hybrid Knowledge Bases,"Metamodeling refers to scenarios in ontologies in which classes and roles can
be members of classes or occur in roles. This is a desirable modelling feature
in several applications, but allowing it without restrictions is problematic
for several reasons, mainly because it causes undecidability. Therefore,
practical languages either forbid metamodeling explicitly or treat occurrences
of classes as instances to be semantically different from other occurrences,
thereby not allowing metamodeling semantically. Several extensions have been
proposed to provide metamodeling to some extent. Building on earlier work that
reduces metamodeling query answering to Datalog query answering, recently
reductions to query answering over hybrid knowledge bases were proposed with
the aim of using the Datalog transformation only where necessary. Preliminary
work showed that the approach works, but the hoped-for performance improvements
were not observed yet. In this work we expand on this body of work by improving
the theoretical basis of the reductions and by using alternative tools that
show competitive performance.","Haya Majid Qureshi, Wolfgang Faber",2025-02-13 11:46:10.000000,arXiv,http://arxiv.org/abs/2502.09206v1,Other
158,Counterfactual Explanations as Plans,"There has been considerable recent interest in explainability in AI,
especially with black-box machine learning models. As correctly observed by the
planning community, when the application at hand is not a single-shot decision
or prediction, but a sequence of actions that depend on observations, a richer
notion of explanations are desirable.
  In this paper, we look to provide a formal account of ``counterfactual
explanations,"" based in terms of action sequences. We then show that this
naturally leads to an account of model reconciliation, which might take the
form of the user correcting the agent's model, or suggesting actions to the
agent's plan. For this, we will need to articulate what is true versus what is
known, and we appeal to a modal fragment of the situation calculus to formalise
these intuitions. We consider various settings: the agent knowing partial
truths, weakened truths and having false beliefs, and show that our definitions
easily generalize to these different settings.",Vaishak Belle,2025-02-13 11:45:54.000000,arXiv,http://arxiv.org/abs/2502.09205v1,Artificial Intelligence
159,Logical Lease Litigation: Prolog and LLMs for Rental Law Compliance in New York,"Legal cases require careful logical reasoning following the laws, whereas
interactions with non- technical users must be in natural language. As an
application combining logical reasoning using Prolog and natural language
processing using large language models (LLMs), this paper presents a novel
approach and system, LogicLease, to automate the analysis of landlord-tenant
legal cases in the state of New York. LogicLease determines compliance with
relevant legal requirements by analyzing case descriptions and citing all
relevant laws. It leverages LLMs for information extraction and Prolog for
legal reasoning. By separating information extraction from legal reasoning,
LogicLease achieves greater transparency and control over the legal logic
applied to each case. We evaluate the accuracy, efficiency, and robustness of
LogicLease through a series of tests, achieving 100% accuracy and an average
processing time of 2.57 seconds. LogicLease presents advantages over
state-of-the-art LLM- based legal analysis systems by providing clear,
step-by-step reasoning, citing specific laws, and distinguishing itself by its
ability to avoid hallucinations - a common issue in LLMs.","Sanskar Sehgal, Yanhong A. Liu",2025-02-13 11:45:38.000000,arXiv,http://arxiv.org/abs/2502.09204v1,Artificial Intelligence
160,Revisiting Euclidean Alignment for Transfer Learning in EEG-Based Brain-Computer Interfaces,"Due to the non-stationarity and large individual differences of EEG signals,
EEG-based brain-computer interfaces (BCIs) usually need subject-specific
calibration to tailor the decoding algorithm for each new subject, which is
time-consuming and user-unfriendly, hindering their real-world applications.
Transfer learning (TL) has been extensively used to expedite the calibration,
by making use of EEG data from other subjects/sessions. An important
consideration in TL for EEG-based BCIs is to reduce the data distribution
discrepancies among different subjects/session, to avoid negative transfer.
Euclidean alignment (EA) was proposed in 2020 to address this challenge.
Numerous experiments from 10 different BCI paradigms demonstrated its
effectiveness and efficiency. This paper revisits the EA, explaining its
procedure and correct usage, introducing its applications and extensions, and
pointing out potential new research directions. It should be very helpful to
BCI researchers, especially those who are working on EEG signal decoding.",Dongrui Wu,2025-02-13 11:43:43.000000,arXiv,http://arxiv.org/abs/2502.09203v1,Other
161,"Faster than real-time detection of shot boundaries, sampling structure and dynamic keyframes in video","The detection of shot boundaries (hardcuts and short dissolves), sampling
structure (progressive / interlaced / pulldown) and dynamic keyframes in a
video are fundamental video analysis tasks which have to be done before any
further high-level analysis tasks. We present a novel algorithm which does all
these analysis tasks in an unified way, by utilizing a combination of
inter-frame and intra-frame measures derived from the motion field and
normalized cross correlation. The algorithm runs four times faster than
real-time due to sparse and selective calculation of these measures. An initial
evaluation furthermore shows that the proposed algorithm is extremely robust
even for challenging content showing large camera or object motion,
flashlights, flicker or low contrast / noise.",Hannes Fassold,2025-02-13 11:40:46.000000,arXiv,http://arxiv.org/abs/2502.09202v1,Computer Vision
162,Understanding High-Dimensional Bayesian Optimization,"Recent work reported that simple Bayesian optimization methods perform well
for high-dimensional real-world tasks, seemingly contradicting prior work and
tribal knowledge. This paper investigates the 'why'. We identify fundamental
challenges that arise in high-dimensional Bayesian optimization and explain why
recent methods succeed. Our analysis shows that vanishing gradients caused by
Gaussian process initialization schemes play a major role in the failures of
high-dimensional Bayesian optimization and that methods that promote local
search behaviors are better suited for the task. We find that maximum
likelihood estimation of Gaussian process length scales suffices for
state-of-the-art performance. Based on this, we propose a simple variant of
maximum likelihood estimation called MSR that leverages these findings to
achieve state-of-the-art performance on a comprehensive set of real-world
applications. We also present targeted experiments to illustrate and confirm
our findings.","Leonard Papenmeier, Matthias Poloczek, Luigi Nardi",2025-02-13 11:37:55.000000,arXiv,http://arxiv.org/abs/2502.09198v1,Machine Learning
163,Generalizability through Explainability: Countering Overfitting with Counterfactual Examples,"Overfitting is a well-known issue in machine learning that occurs when a
model struggles to generalize its predictions to new, unseen data beyond the
scope of its training set. Traditional techniques to mitigate overfitting
include early stopping, data augmentation, and regularization. In this work, we
demonstrate that the degree of overfitting of a trained model is correlated
with the ability to generate counterfactual examples. The higher the
overfitting, the easier it will be to find a valid counterfactual example for a
randomly chosen input data point. Therefore, we introduce CF-Reg, a novel
regularization term in the training loss that controls overfitting by ensuring
enough margin between each instance and its corresponding counterfactual.
Experiments conducted across multiple datasets and models show that our
counterfactual regularizer generally outperforms existing regularization
techniques.","Flavio Giorgi, Fabiano Veglianti, Fabrizio Silvestri, Gabriele Tolomei",2025-02-13 11:33:17.000000,arXiv,http://arxiv.org/abs/2502.09193v1,Machine Learning
164,Thinking beyond the anthropomorphic paradigm benefits LLM research,"Anthropomorphism, or the attribution of human traits to technology, is an
automatic and unconscious response that occurs even in those with advanced
technical expertise. In this position paper, we analyze hundreds of thousands
of computer science research articles from the past decade and present
empirical evidence of the prevalence and growth of anthropomorphic terminology
in research on large language models (LLMs). This terminology reflects deeper
anthropomorphic conceptualizations which shape how we think about and conduct
LLM research. We argue these conceptualizations may be limiting, and that
challenging them opens up new pathways for understanding and improving LLMs
beyond human analogies. To illustrate this, we identify and analyze five core
anthropomorphic assumptions shaping prominent methodologies across the LLM
development lifecycle, from the assumption that models must use natural
language for reasoning tasks to the assumption that model capabilities should
be evaluated through human-centric benchmarks. For each assumption, we
demonstrate how non-anthropomorphic alternatives can open new directions for
research and development.","Lujain Ibrahim, Myra Cheng",2025-02-13 11:32:09.000000,arXiv,http://arxiv.org/abs/2502.09192v1,Natural Language Processing
165,Matina: A Large-Scale 73B Token Persian Text Corpus,"Text corpora are essential for training models used in tasks like
summarization, translation, and large language models (LLMs). While various
efforts have been made to collect monolingual and multilingual datasets in many
languages, Persian has often been underrepresented due to limited resources for
data collection and preprocessing. Existing Persian datasets are typically
small and lack content diversity, consisting mainly of weblogs and news
articles. This shortage of high-quality, varied data has slowed the development
of NLP models and open-source LLMs for Persian. Since model performance depends
heavily on the quality of training data, we address this gap by introducing the
Matina corpus, a new Persian dataset of 72.9B tokens, carefully preprocessed
and deduplicated to ensure high data quality. We further assess its
effectiveness by training and evaluating transformer-based models on key NLP
tasks. Both the dataset and preprocessing codes are publicly available,
enabling researchers to build on and improve this resource for future Persian
NLP advancements.","Sara Bourbour Hosseinbeigi, Fatemeh Taherinezhad, Heshaam Faili, Hamed Baghbani, Fatemeh Nadi, Mostafa Amiri",2025-02-13 11:22:19.000000,arXiv,http://arxiv.org/abs/2502.09188v1,Natural Language Processing
166,RefineCoder: Iterative Improving of Large Language Models via Adaptive Critique Refinement for Code Generation,"Code generation has attracted increasing attention with the rise of Large
Language Models (LLMs). Many studies have developed powerful code LLMs by
synthesizing code-related instruction data and applying supervised fine-tuning.
However, these methods are limited by teacher model distillation and ignore the
potential of iterative refinement by self-generated code. In this paper, we
propose Adaptive Critique Refinement (ACR), which enables the model to refine
itself by self-generated code and external critique, rather than directly
imitating the code responses of the teacher model. Concretely, ACR includes a
composite scoring system with LLM-as-a-Judge to evaluate the quality of code
responses and a selective critique strategy with LLM-as-a-Critic to critique
self-generated low-quality code responses. We develop the RefineCoder series by
iteratively applying ACR, achieving continuous performance improvement on
multiple code generation benchmarks. Compared to the baselines of the same
size, our proposed RefineCoder series can achieve comparable or even superior
performance using less data.","Changzhi Zhou, Xinyu Zhang, Dandan Song, Xiancai Chen, Wanli Gu, Huipeng Ma, Yuhang Tian, Mengdi Zhang, Linmei Hu",2025-02-13 11:17:53.000000,arXiv,http://arxiv.org/abs/2502.09183v1,Natural Language Processing
167,A Machine Learning Approach to Sensor Substitution for Non-Prehensile Manipulation,"Mobile manipulators are increasingly deployed in complex environments,
requiring diverse sensors to perceive and interact with their surroundings.
However, equipping every robot with every possible sensor is often impractical
due to cost and physical constraints. A critical challenge arises when robots
with differing sensor capabilities need to collaborate or perform similar
tasks. For example, consider a scenario where a mobile manipulator equipped
with high-resolution tactile skin is skilled at non-prehensile manipulation
tasks like pushing. If this robot needs to be replaced or augmented by a robot
lacking such tactile sensing, the learned manipulation policies become
inapplicable. This paper addresses the problem of sensor substitution in
non-prehensile manipulation. We propose a novel machine learning-based
framework that enables a robot with a limited sensor set (e.g., LiDAR or RGB-D
camera) to effectively perform tasks previously reliant on a richer sensor
suite (e.g., tactile skin). Our approach learns a mapping between the available
sensor data and the information provided by the substituted sensor, effectively
synthesizing the missing sensory input. Specifically, we demonstrate the
efficacy of our framework by training a model to substitute tactile skin data
for the task of non-prehensile pushing using a mobile manipulator. We show that
a manipulator equipped only with LiDAR or RGB-D can, after training, achieve
comparable and sometimes even better pushing performance to a mobile base
utilizing direct tactile feedback.","Idil Ozdamar, Doganay Sirintuna, Arash Ajoudani",2025-02-13 11:15:37.000000,arXiv,http://arxiv.org/abs/2502.09180v1,Robotics
168,FLAME: Flexible LLM-Assisted Moderation Engine,"The rapid advancement of Large Language Models (LLMs) has introduced
significant challenges in moderating user-model interactions. While LLMs
demonstrate remarkable capabilities, they remain vulnerable to adversarial
attacks, particularly ``jailbreaking'' techniques that bypass content safety
measures. Current content moderation systems, which primarily rely on input
prompt filtering, have proven insufficient, with techniques like Best-of-N
(BoN) jailbreaking achieving success rates of 80% or more against popular LLMs.
In this paper, we introduce Flexible LLM-Assisted Moderation Engine (FLAME): a
new approach that shifts the focus from input filtering to output moderation.
Unlike traditional circuit-breaking methods that analyze user queries, FLAME
evaluates model responses, offering several key advantages: (1) computational
efficiency in both training and inference, (2) enhanced resistance to BoN
jailbreaking attacks, and (3) flexibility in defining and updating safety
criteria through customizable topic filtering. Our experiments demonstrate that
FLAME significantly outperforms current moderation systems. For example, FLAME
reduces attack success rate in GPT-4o-mini and DeepSeek-v3 by a factor of ~9,
while maintaining low computational overhead. We provide comprehensive
evaluation on various LLMs and analyze the engine's efficiency against the
state-of-the-art jailbreaking. This work contributes to the development of more
robust and adaptable content moderation systems for LLMs.","Ivan Bakulin, Ilia Kopanichuk, Iaroslav Bespalov, Nikita Radchenko, Vladimir Shaposhnikov, Dmitry Dylov, Ivan Oseledets",2025-02-13 11:05:55.000000,arXiv,http://arxiv.org/abs/2502.09175v1,Other
169,Two-Stage Representation Learning for Analyzing Movement Behavior Dynamics in People Living with Dementia,"In remote healthcare monitoring, time series representation learning reveals
critical patient behavior patterns from high-frequency data. This study
analyzes home activity data from individuals living with dementia by proposing
a two-stage, self-supervised learning approach tailored to uncover low-rank
structures. The first stage converts time-series activities into text sequences
encoded by a pre-trained language model, providing a rich, high-dimensional
latent state space using a PageRank-based method. This PageRank vector captures
latent state transitions, effectively compressing complex behaviour data into a
succinct form that enhances interpretability. This low-rank representation not
only enhances model interpretability but also facilitates clustering and
transition analysis, revealing key behavioral patterns correlated with
clinicalmetrics such as MMSE and ADAS-COG scores. Our findings demonstrate the
framework's potential in supporting cognitive status prediction, personalized
care interventions, and large-scale health monitoring.","Jin Cui, Alexander Capstick, Payam Barnaghi, Gregory Scott",2025-02-13 10:57:25.000000,arXiv,http://arxiv.org/abs/2502.09173v1,Machine Learning
170,LOB-Bench: Benchmarking Generative AI for Finance - an Application to Limit Order Book Data,"While financial data presents one of the most challenging and interesting
sequence modelling tasks due to high noise, heavy tails, and strategic
interactions, progress in this area has been hindered by the lack of consensus
on quantitative evaluation paradigms. To address this, we present LOB-Bench, a
benchmark, implemented in python, designed to evaluate the quality and realism
of generative message-by-order data for limit order books (LOB) in the LOBSTER
format. Our framework measures distributional differences in conditional and
unconditional statistics between generated and real LOB data, supporting
flexible multivariate statistical evaluation. The benchmark also includes
features commonly used LOB statistics such as spread, order book volumes, order
imbalance, and message inter-arrival times, along with scores from a trained
discriminator network. Lastly, LOB-Bench contains ""market impact metrics"", i.e.
the cross-correlations and price response functions for specific events in the
data. We benchmark generative autoregressive state-space models, a (C)GAN, as
well as a parametric LOB model and find that the autoregressive GenAI approach
beats traditional model classes.","Peer Nagy, Sascha Frey, Kang Li, Bidipta Sarkar, Svitlana Vyetrenko, Stefan Zohren, Ani Calinescu, Jakob Foerster",2025-02-13 10:56:58.000000,arXiv,http://arxiv.org/abs/2502.09172v1,Machine Learning
171,LimSim Series: An Autonomous Driving Simulation Platform for Validation and Enhancement,"Closed-loop simulation environments play a crucial role in the validation and
enhancement of autonomous driving systems (ADS). However, certain challenges
warrant significant attention, including balancing simulation accuracy with
duration, reconciling functionality with practicality, and establishing
comprehensive evaluation mechanisms. This paper addresses these challenges by
introducing the LimSim Series, a comprehensive simulation platform designed to
support the rapid deployment and efficient iteration of ADS. The LimSim Series
integrates multi-type information from road networks, employs human-like
decision-making and planning algorithms for background vehicles, and introduces
the concept of the Area of Interest (AoI) to optimize computational resources.
The platform offers a variety of baseline algorithms and user-friendly
interfaces, facilitating flexible validation of multiple technical pipelines.
Additionally, the LimSim Series incorporates multi-dimensional evaluation
metrics, delivering thorough insights into system performance, thus enabling
researchers to promptly identify issues for further improvements. Experiments
demonstrate that the LimSim Series is compatible with modular, end-to-end, and
VLM-based knowledge-driven systems. It can assist in the iteration and updating
of ADS by evaluating performance across various scenarios. The code of the
LimSim Series is released at: https://github.com/PJLab-ADG/LimSim.","Daocheng Fu, Naiting Zhong, Xu Han, Pinlong Cai, Licheng Wen, Song Mao, Botian Shi, Yu Qiao",2025-02-13 10:53:38.000000,arXiv,http://arxiv.org/abs/2502.09170v1,Robotics
172,Musical Heritage Historical Entity Linking,"Linking named entities occurring in text to their corresponding entity in a
Knowledge Base (KB) is challenging, especially when dealing with historical
texts. In this work, we introduce Musical Heritage named Entities Recognition,
Classification and Linking (MHERCL), a novel benchmark consisting of manually
annotated sentences extrapolated from historical periodicals of the music
domain. MHERCL contains named entities under-represented or absent in the most
famous KBs. We experiment with several State-of-the-Art models on the Entity
Linking (EL) task and show that MHERCL is a challenging dataset for all of
them. We propose a novel unsupervised EL model and a method to extend
supervised entity linkers by using Knowledge Graphs (KGs) to tackle the main
difficulties posed by historical documents. Our experiments reveal that relying
on unsupervised techniques and improving models with logical constraints based
on KGs and heuristics to predict NIL entities (entities not represented in the
KB of reference) results in better EL performance on historical documents.","Arianna Graciotti, Nicolas Lazzari, Valentina Presutti, Rocco Tripodi",2025-02-13 10:51:40.000000,arXiv,http://arxiv.org/abs/2502.09168v1,Natural Language Processing
173,E-MD3C: Taming Masked Diffusion Transformers for Efficient Zero-Shot Object Customization,"We propose E-MD3C ($\underline{E}$fficient $\underline{M}$asked
$\underline{D}$iffusion Transformer with Disentangled $\underline{C}$onditions
and $\underline{C}$ompact $\underline{C}$ollector), a highly efficient
framework for zero-shot object image customization. Unlike prior works reliant
on resource-intensive Unet architectures, our approach employs lightweight
masked diffusion transformers operating on latent patches, offering
significantly improved computational efficiency. The framework integrates three
core components: (1) an efficient masked diffusion transformer for processing
autoencoder latents, (2) a disentangled condition design that ensures
compactness while preserving background alignment and fine details, and (3) a
learnable Conditions Collector that consolidates multiple inputs into a compact
representation for efficient denoising and learning. E-MD3C outperforms the
existing approach on the VITON-HD dataset across metrics such as PSNR, FID,
SSIM, and LPIPS, demonstrating clear advantages in parameters, memory
efficiency, and inference speed. With only $\frac{1}{4}$ of the parameters, our
Transformer-based 468M model delivers $2.5\times$ faster inference and uses
$\frac{2}{3}$ of the GPU memory compared to an 1720M Unet-based latent
diffusion model.","Trung X. Pham, Zhang Kang, Ji Woo Hong, Xuran Zheng, Chang D. Yoo",2025-02-13 10:48:11.000000,arXiv,http://arxiv.org/abs/2502.09164v1,Computer Vision
174,Improving TCM Question Answering through Tree-Organized Self-Reflective Retrieval with LLMs,"Objectives: Large language models (LLMs) can harness medical knowledge for
intelligent question answering (Q&A), promising support for auxiliary diagnosis
and medical talent cultivation. However, there is a deficiency of highly
efficient retrieval-augmented generation (RAG) frameworks within the domain of
Traditional Chinese Medicine (TCM). Our purpose is to observe the effect of the
Tree-Organized Self-Reflective Retrieval (TOSRR) framework on LLMs in TCM Q&A
tasks.
  Materials and Methods: We introduce the novel approach of knowledge
organization, constructing a tree structure knowledge base with hierarchy. At
inference time, our self-reflection framework retrieves from this knowledge
base, integrating information across chapters. Questions from the TCM Medical
Licensing Examination (MLE) and the college Classics Course Exam (CCE) were
randomly selected as benchmark datasets.
  Results: By coupling with GPT-4, the framework can improve the best
performance on the TCM MLE benchmark by 19.85% in absolute accuracy, and
improve recall accuracy from 27% to 38% on CCE datasets. In manual evaluation,
the framework improves a total of 18.52 points across dimensions of safety,
consistency, explainability, compliance, and coherence.
  Conclusion: The TOSRR framework can effectively improve LLM's capability in
Q&A tasks of TCM.","Chang Liu, Ying Chang, Jianmin Li, Yiqian Qu, Yu Li, Lingyong Cao, Shuyuan Lin",2025-02-13 10:36:18.000000,arXiv,http://arxiv.org/abs/2502.09156v1,Natural Language Processing
175,Use of Air Quality Sensor Network Data for Real-time Pollution-Aware POI Suggestion,"This demo paper presents AirSense-R, a privacy-preserving mobile application
that provides real-time, pollution-aware recommendations for points of interest
(POIs) in urban environments. By combining real-time air quality monitoring
data with user preferences, the proposed system aims to help users make
health-conscious decisions about the locations they visit. The application
utilizes collaborative filtering for personalized suggestions, and federated
learning for privacy protection, and integrates air pollutant readings from
AirSENCE sensor networks in cities such as Bari, Italy, and Cork, Ireland.
Additionally, the AirSENCE prediction engine can be employed to detect anomaly
readings and interpolate for air quality readings in areas with sparse sensor
coverage. This system offers a promising, health-oriented POI recommendation
solution that adapts dynamically to current urban air quality conditions while
safeguarding user privacy. The code of AirTOWN and a demonstration video is
made available at the following repo:
https://github.com/AirtownApp/Airtown-Application.git.","Giuseppe Fasano, Yashar Deldjoo, Tommaso di Noia, Bianca Lau, Sina Adham-Khiabani, Eric Morris, Xia Liu, Ganga Chinna Rao Devarapu, Liam O'Faolain",2025-02-13 10:36:17.000000,arXiv,http://arxiv.org/abs/2502.09155v1,Information Retrieval
176,Vertical Federated Continual Learning via Evolving Prototype Knowledge,"Vertical Federated Learning (VFL) has garnered significant attention as a
privacy-preserving machine learning framework for sample-aligned feature
federation. However, traditional VFL approaches do not address the challenges
of class and feature continual learning, resulting in catastrophic forgetting
of knowledge from previous tasks. To address the above challenge, we propose a
novel vertical federated continual learning method, named Vertical Federated
Continual Learning via Evolving Prototype Knowledge (V-LETO), which primarily
facilitates the transfer of knowledge from previous tasks through the evolution
of prototypes. Specifically, we propose an evolving prototype knowledge method,
enabling the global model to retain both previous and current task knowledge.
Furthermore, we introduce a model optimization technique that mitigates the
forgetting of previous task knowledge by restricting updates to specific
parameters of the local model, thereby enhancing overall performance. Extensive
experiments conducted in both CIL and FIL settings demonstrate that our method,
V-LETO, outperforms the other state-of-the-art methods. For example, our method
outperforms the state-of-the-art method by 10.39% and 35.15% for CIL and FIL
tasks, respectively. Our code is available at
https://anonymous.4open.science/r/V-LETO-0108/README.md.","Shuo Wang, Keke Gai, Jing Yu, Liehuang Zhu, Qi Wu",2025-02-13 10:29:31.000000,arXiv,http://arxiv.org/abs/2502.09152v1,Machine Learning
177,Regularization can make diffusion models more efficient,"Diffusion models are one of the key architectures of generative AI. Their
main drawback, however, is the computational costs. This study indicates that
the concept of sparsity, well known especially in statistics, can provide a
pathway to more efficient diffusion pipelines. Our mathematical guarantees
prove that sparsity can reduce the input dimension's influence on the
computational complexity to that of a much smaller intrinsic dimension of the
data. Our empirical findings confirm that inducing sparsity can indeed lead to
better samples at a lower cost.","Mahsa Taheri, Johannes Lederer",2025-02-13 10:27:30.000000,arXiv,http://arxiv.org/abs/2502.09151v1,Machine Learning
178,Shortcut Learning Susceptibility in Vision Classifiers,"Shortcut learning, where machine learning models exploit spurious
correlations in data instead of capturing meaningful features, poses a
significant challenge to building robust and generalizable models. This
phenomenon is prevalent across various machine learning applications, including
vision, natural language processing, and speech recognition, where models may
find unintended cues that minimize training loss but fail to capture the
underlying structure of the data. Vision classifiers such as Convolutional
Neural Networks (CNNs), Multi-Layer Perceptrons (MLPs), and Vision Transformers
(ViTs) leverage distinct architectural principles to process spatial and
structural information, making them differently susceptible to shortcut
learning. In this study, we systematically evaluate these architectures by
introducing deliberate shortcuts into the dataset that are positionally
correlated with class labels, creating a controlled setup to assess whether
models rely on these artificial cues or learn actual distinguishing features.
We perform both quantitative evaluation by training on the shortcut-modified
dataset and testing them on two different test sets -- one containing the same
shortcuts and another without them -- to determine the extent of reliance on
shortcuts. Additionally, qualitative evaluation is performed by using network
inversion-based reconstruction techniques to analyze what the models
internalize in their weights, aiming to reconstruct the training data as
perceived by the classifiers. We evaluate shortcut learning behavior across
multiple benchmark datasets, including MNIST, Fashion-MNIST, SVHN, and
CIFAR-10, to compare the susceptibility of different vision classifier
architectures to shortcut reliance and assess their varying degrees of
sensitivity to spurious correlations.","Pirzada Suhail, Amit Sethi",2025-02-13 10:25:52.000000,arXiv,http://arxiv.org/abs/2502.09150v1,Machine Learning
179,Multimodal HIE Lesion Segmentation in Neonates: A Comparative Study of Loss Functions,"Segmentation of Hypoxic-Ischemic Encephalopathy (HIE) lesions in neonatal MRI
is a crucial but challenging task due to diffuse multifocal lesions with
varying volumes and the limited availability of annotated HIE lesion datasets.
Using the BONBID-HIE dataset, we implemented a 3D U-Net with optimized
preprocessing, augmentation, and training strategies to overcome data
constraints. The goal of this study is to identify the optimal loss function
specifically for the HIE lesion segmentation task. To this end, we evaluated
various loss functions, including Dice, Dice-Focal, Tversky, Hausdorff Distance
(HausdorffDT) Loss, and two proposed compound losses -- Dice-Focal-HausdorffDT
and Tversky-HausdorffDT -- to enhance segmentation performance. The results
show that different loss functions predict distinct segmentation masks, with
compound losses outperforming standalone losses. Tversky-HausdorffDT Loss
achieves the highest Dice and Normalized Surface Dice scores, while
Dice-Focal-HausdorffDT Loss minimizes Mean Surface Distance. This work
underscores the significance of task-specific loss function optimization,
demonstrating that combining region-based and boundary-aware losses leads to
more accurate HIE lesion segmentation, even with limited training data.","Annayah Usman, Abdul Haseeb, Tahir Syed",2025-02-13 10:23:45.000000,arXiv,http://arxiv.org/abs/2502.09148v1,Computer Vision
180,Feature-based Graph Attention Networks Improve Online Continual Learning,"Online continual learning for image classification is crucial for models to
adapt to new data while retaining knowledge of previously learned tasks. This
capability is essential to address real-world challenges involving dynamic
environments and evolving data distributions. Traditional approaches
predominantly employ Convolutional Neural Networks, which are limited to
processing images as grids and primarily capture local patterns rather than
relational information. Although the emergence of transformer architectures has
improved the ability to capture relationships, these models often require
significantly larger resources. In this paper, we present a novel online
continual learning framework based on Graph Attention Networks (GATs), which
effectively capture contextual relationships and dynamically update the
task-specific representation via learned attention weights. Our approach
utilizes a pre-trained feature extractor to convert images into graphs using
hierarchical feature maps, representing information at varying levels of
granularity. These graphs are then processed by a GAT and incorporate an
enhanced global pooling strategy to improve classification performance for
continual learning. In addition, we propose the rehearsal memory duplication
technique that improves the representation of the previous tasks while
maintaining the memory budget. Comprehensive evaluations on benchmark datasets,
including SVHN, CIFAR10, CIFAR100, and MiniImageNet, demonstrate the
superiority of our method compared to the state-of-the-art methods.","Adjovi Sim, Zhengkui Wang, Aik Beng Ng, Shalini De Mello, Simon See, Wonmin Byeon",2025-02-13 10:18:44.000000,arXiv,http://arxiv.org/abs/2502.09143v1,Computer Vision
181,LLM-Driven Augmented Reality Puppeteer: Controller-Free Voice-Commanded Robot Teleoperation,"The integration of robotics and augmented reality (AR) presents
transformative opportunities for advancing human-robot interaction (HRI) by
improving usability, intuitiveness, and accessibility. This work introduces a
controller-free, LLM-driven voice-commanded AR puppeteering system, enabling
users to teleoperate a robot by manipulating its virtual counterpart in real
time. By leveraging natural language processing (NLP) and AR technologies, our
system -- prototyped using Meta Quest 3 -- eliminates the need for physical
controllers, enhancing ease of use while minimizing potential safety risks
associated with direct robot operation. A preliminary user demonstration
successfully validated the system's functionality, demonstrating its potential
for safer, more intuitive, and immersive robotic control.","Yuchong Zhang, Bastian Orthmann, Michael C. Welle, Jonne Van Haastregt, Danica Kragic",2025-02-13 10:17:12.000000,arXiv,http://arxiv.org/abs/2502.09142v1,Other
182,Replay-free Online Continual Learning with Self-Supervised MultiPatches,"Online Continual Learning (OCL) methods train a model on a non-stationary
data stream where only a few examples are available at a time, often leveraging
replay strategies. However, usage of replay is sometimes forbidden, especially
in applications with strict privacy regulations. Therefore, we propose
Continual MultiPatches (CMP), an effective plug-in for existing OCL
self-supervised learning strategies that avoids the use of replay samples. CMP
generates multiple patches from a single example and projects them into a
shared feature space, where patches coming from the same example are pushed
together without collapsing into a single point. CMP surpasses replay and other
SSL-based strategies on OCL streams, challenging the role of replay as a go-to
solution for self-supervised OCL.","Giacomo Cignoni, Andrea Cossu, Alex Gomez-Villa, Joost van de Weijer, Antonio Carta",2025-02-13 10:15:16.000000,arXiv,http://arxiv.org/abs/2502.09140v1,Machine Learning
183,"Trust Me, I Know the Way: Predictive Uncertainty in the Presence of Shortcut Learning","The correct way to quantify predictive uncertainty in neural networks remains
a topic of active discussion. In particular, it is unclear whether the
state-of-the art entropy decomposition leads to a meaningful representation of
model, or epistemic, uncertainty (EU) in the light of a debate that pits
ignorance against disagreement perspectives. We aim to reconcile the
conflicting viewpoints by arguing that both are valid but arise from different
learning situations. Notably, we show that the presence of shortcuts is
decisive for EU manifesting as disagreement.","Lisa Wimmer, Bernd Bischl, Ludwig Bothmann",2025-02-13 10:13:20.000000,arXiv,http://arxiv.org/abs/2502.09137v1,Machine Learning
184,Interpreting and Steering Protein Language Models through Sparse Autoencoders,"The rapid advancements in transformer-based language models have
revolutionized natural language processing, yet understanding the internal
mechanisms of these models remains a significant challenge. This paper explores
the application of sparse autoencoders (SAE) to interpret the internal
representations of protein language models, specifically focusing on the ESM-2
8M parameter model. By performing a statistical analysis on each latent
component's relevance to distinct protein annotations, we identify potential
interpretations linked to various protein characteristics, including
transmembrane regions, binding sites, and specialized motifs.
  We then leverage these insights to guide sequence generation, shortlisting
the relevant latent components that can steer the model towards desired targets
such as zinc finger domains. This work contributes to the emerging field of
mechanistic interpretability in biological sequence models, offering new
perspectives on model steering for sequence design.","Edith Natalia Villegas Garcia, Alessio Ansuini",2025-02-13 10:11:36.000000,arXiv,http://arxiv.org/abs/2502.09135v1,Machine Learning
185,Finite-Time Analysis of Discrete-Time Stochastic Interpolants,"The stochastic interpolant framework offers a powerful approach for
constructing generative models based on ordinary differential equations (ODEs)
or stochastic differential equations (SDEs) to transform arbitrary data
distributions. However, prior analyses of this framework have primarily focused
on the continuous-time setting, assuming a perfect solution of the underlying
equations. In this work, we present the first discrete-time analysis of the
stochastic interpolant framework, where we introduce an innovative
discrete-time sampler and derive a finite-time upper bound on its distribution
estimation error. Our result provides a novel quantification of how different
factors, including the distance between source and target distributions and
estimation accuracy, affect the convergence rate and also offers a new
principled way to design efficient schedules for convergence acceleration.
Finally, numerical experiments are conducted on the discrete-time sampler to
corroborate our theoretical findings.","Yuhao Liu, Yu Chen, Rui Hu, Longbo Huang",2025-02-13 10:07:35.000000,arXiv,http://arxiv.org/abs/2502.09130v1,Machine Learning
186,A Novel Dialect-Aware Framework for the Classification of Arabic Dialects and Emotions,"Arabic is one of the oldest languages still in use today. As a result,
several Arabic-speaking regions have developed dialects that are unique to
them. Dialect and emotion recognition have various uses in Arabic text
analysis, such as determining an online customer's origin based on their
comments. Furthermore, intelligent chatbots that are aware of a user's emotions
can respond appropriately to the user. Current research in emotion detection in
the Arabic language lacks awareness of how emotions are exhibited in different
dialects, which motivates the work found in this study. This research addresses
the problems of dialect and emotion classification in Arabic. Specifically,
this is achieved by building a novel framework that can identify and predict
Arabic dialects and emotions from a given text. The framework consists of three
modules: A text-preprocessing module, a classification module, and a clustering
module with the novel capability of building new dialect-aware emotion
lexicons. The proposed framework generated a new emotional lexicon for
different dialects. It achieved an accuracy of 88.9% in classifying Arabic
dialects, which outperforms the state-of-the-art results by 6.45 percentage
points. Furthermore, the framework achieved 89.1-79% accuracy in detecting
emotions in the Egyptian and Gulf dialects, respectively.",Nasser A Alsadhan,2025-02-13 10:05:44.000000,arXiv,http://arxiv.org/abs/2502.09128v1,Natural Language Processing
187,Automatic Pruning via Structured Lasso with Class-wise Information,"Most pruning methods concentrate on unimportant filters of neural networks.
However, they face the loss of statistical information due to a lack of
consideration for class-wise data. In this paper, from the perspective of
leveraging precise class-wise information for model pruning, we utilize
structured lasso with guidance from Information Bottleneck theory. Our approach
ensures that statistical information is retained during the pruning process.
With these techniques, we introduce two innovative adaptive network pruning
schemes: sparse graph-structured lasso pruning with Information Bottleneck
(\textbf{sGLP-IB}) and sparse tree-guided lasso pruning with Information
Bottleneck (\textbf{sTLP-IB}). The key aspect is pruning model filters using
sGLP-IB and sTLP-IB to better capture class-wise relatedness. Compared to
multiple state-of-the-art methods, our approaches demonstrate superior
performance across three datasets and six model architectures in extensive
experiments. For instance, using the VGG16 model on the CIFAR-10 dataset, we
achieve a parameter reduction of 85%, a decrease in FLOPs by 61%, and maintain
an accuracy of 94.10% (0.14% higher than the original model); we reduce the
parameters by 55% with the accuracy at 76.12% using the ResNet architecture on
ImageNet (only drops 0.03%). In summary, we successfully reduce model size and
computational resource usage while maintaining accuracy. Our codes are at
https://anonymous.4open.science/r/IJCAI-8104.","Xiang Liu, Mingchen Li, Xia Li, Leigang Qu, Zifan Peng, Yijun Song, Zemin Liu, Linshan Jiang, Jialin Li",2025-02-13 10:03:29.000000,arXiv,http://arxiv.org/abs/2502.09125v1,Computer Vision
188,Improving Deep Regression with Tightness,"For deep regression, preserving the ordinality of the targets with respect to
the feature representation improves performance across various tasks. However,
a theoretical explanation for the benefits of ordinality is still lacking. This
work reveals that preserving ordinality reduces the conditional entropy
$H(Z|Y)$ of representation $Z$ conditional on the target $Y$. However, our
findings reveal that typical regression losses do little to reduce $H(Z|Y)$,
even though it is vital for generalization performance. With this motivation,
we introduce an optimal transport-based regularizer to preserve the similarity
relationships of targets in the feature space to reduce $H(Z|Y)$. Additionally,
we introduce a simple yet efficient strategy of duplicating the regressor
targets, also with the aim of reducing $H(Z|Y)$. Experiments on three
real-world regression tasks verify the effectiveness of our strategies to
improve deep regression. Code:
https://github.com/needylove/Regression_tightness.","Shihao Zhang, Yuguang Yan, Angela Yao",2025-02-13 09:57:25.000000,arXiv,http://arxiv.org/abs/2502.09122v1,Machine Learning
189,The influence of visual and linguistic cues on ignorance inference in Vision-Language Models (VLMs),"This study explored how Vision-Language Models (VLMs) process ignorance
implicatures with visual and linguistic cues. Particularly, we focused on the
effects of contexts (precise and approximate contexts) and modifier types (bare
numerals, superlative, and comparative modifiers), which were considered
pragmatic and semantic factors respectively. Methodologically, we conducted a
truth-value judgment task in visually grounded settings using GPT-4o and Gemini
1.5 Pro. The results indicate that while both models exhibited sensitivity to
linguistic cues (modifier), they failed to process ignorance implicatures with
visual cues (context) as humans do. Specifically, the influence of context was
weaker and inconsistent across models, indicating challenges in pragmatic
reasoning for VLMs. On the other hand, superlative modifiers were more strongly
associated with ignorance implicatures as compared to comparative modifiers,
supporting the semantic view. These findings highlight the need for further
advancements in VLMs to process language-vision information in a
context-dependent way to achieve human-like pragmatic inference.","Ye-eun Cho, Yunho Maeng",2025-02-13 09:55:48.000000,arXiv,http://arxiv.org/abs/2502.09120v1,Natural Language Processing
190,DenseSplat: Densifying Gaussian Splatting SLAM with Neural Radiance Prior,"Gaussian SLAM systems excel in real-time rendering and fine-grained
reconstruction compared to NeRF-based systems. However, their reliance on
extensive keyframes is impractical for deployment in real-world robotic
systems, which typically operate under sparse-view conditions that can result
in substantial holes in the map. To address these challenges, we introduce
DenseSplat, the first SLAM system that effectively combines the advantages of
NeRF and 3DGS. DenseSplat utilizes sparse keyframes and NeRF priors for
initializing primitives that densely populate maps and seamlessly fill gaps. It
also implements geometry-aware primitive sampling and pruning strategies to
manage granularity and enhance rendering efficiency. Moreover, DenseSplat
integrates loop closure and bundle adjustment, significantly enhancing
frame-to-frame tracking accuracy. Extensive experiments on multiple large-scale
datasets demonstrate that DenseSplat achieves superior performance in tracking
and mapping compared to current state-of-the-art methods.","Mingrui Li, Shuhong Liu, Tianchen Deng, Hongyu Wang",2025-02-13 09:41:08.000000,arXiv,http://arxiv.org/abs/2502.09111v1,Computer Vision
191,Pulling Back the Curtain: Unsupervised Adversarial Detection via Contrastive Auxiliary Networks,"Deep learning models are widely employed in safety-critical applications yet
remain susceptible to adversarial attacks -- imperceptible perturbations that
can significantly degrade model performance. Conventional defense mechanisms
predominantly focus on either enhancing model robustness or detecting
adversarial inputs independently. In this work, we propose an Unsupervised
adversarial detection via Contrastive Auxiliary Networks (U-CAN) to uncover
adversarial behavior within auxiliary feature representations, without the need
for adversarial examples. U-CAN is embedded within selected intermediate layers
of the target model. These auxiliary networks, comprising projection layers and
ArcFace-based linear layers, refine feature representations to more effectively
distinguish between benign and adversarial inputs. Comprehensive experiments
across multiple datasets (CIFAR-10, Mammals, and a subset of ImageNet) and
architectures (ResNet-50, VGG-16, and ViT) demonstrate that our method
surpasses existing unsupervised adversarial detection techniques, achieving
superior F1 scores against four distinct attack methods. The proposed framework
provides a scalable and effective solution for enhancing the security and
reliability of deep learning systems.","Eylon Mizrahi, Raz Lapid, Moshe Sipper",2025-02-13 09:40:26.000000,arXiv,http://arxiv.org/abs/2502.09110v1,Computer Vision
192,Scaling Law for Stochastic Gradient Descent in Quadratically Parameterized Linear Regression,"In machine learning, the scaling law describes how the model performance
improves with the model and data size scaling up. From a learning theory
perspective, this class of results establishes upper and lower generalization
bounds for a specific learning algorithm. Here, the exact algorithm running
using a specific model parameterization often offers a crucial implicit
regularization effect, leading to good generalization. To characterize the
scaling law, previous theoretical studies mainly focus on linear models,
whereas, feature learning, a notable process that contributes to the remarkable
empirical success of neural networks, is regretfully vacant. This paper studies
the scaling law over a linear regression with the model being quadratically
parameterized. We consider infinitely dimensional data and slope ground truth,
both signals exhibiting certain power-law decay rates. We study convergence
rates for Stochastic Gradient Descent and demonstrate the learning rates for
variables will automatically adapt to the ground truth. As a result, in the
canonical linear regression, we provide explicit separations for generalization
curves between SGD with and without feature learning, and the
information-theoretical lower bound that is agnostic to parametrization method
and the algorithm. Our analysis for decaying ground truth provides a new
characterization for the learning dynamic of the model.","Shihong Ding, Haihan Zhang, Hanzhen Zhao, Cong Fang",2025-02-13 09:29:04.000000,arXiv,http://arxiv.org/abs/2502.09106v1,Machine Learning
193,One-shot Federated Learning Methods: A Practical Guide,"One-shot Federated Learning (OFL) is a distributed machine learning paradigm
that constrains client-server communication to a single round, addressing
privacy and communication overhead issues associated with multiple rounds of
data exchange in traditional Federated Learning (FL). OFL demonstrates the
practical potential for integration with future approaches that require
collaborative training models, such as large language models (LLMs). However,
current OFL methods face two major challenges: data heterogeneity and model
heterogeneity, which result in subpar performance compared to conventional FL
methods. Worse still, despite numerous studies addressing these limitations, a
comprehensive summary is still lacking. To address these gaps, this paper
presents a systematic analysis of the challenges faced by OFL and thoroughly
reviews the current methods. We also offer an innovative categorization method
and analyze the trade-offs of various techniques. Additionally, we discuss the
most promising future directions and the technologies that should be integrated
into the OFL field. This work aims to provide guidance and insights for future
research.","Xiang Liu, Zhenheng Tang, Xia Li, Yijun Song, Sijie Ji, Zemin Liu, Bo Han, Linshan Jiang, Jialin Li",2025-02-13 09:26:44.000000,arXiv,http://arxiv.org/abs/2502.09104v1,Machine Learning
194,Logical Reasoning in Large Language Models: A Survey,"With the emergence of advanced reasoning models like OpenAI o3 and
DeepSeek-R1, large language models (LLMs) have demonstrated remarkable
reasoning capabilities. However, their ability to perform rigorous logical
reasoning remains an open question. This survey synthesizes recent advancements
in logical reasoning within LLMs, a critical area of AI research. It outlines
the scope of logical reasoning in LLMs, its theoretical foundations, and the
benchmarks used to evaluate reasoning proficiency. We analyze existing
capabilities across different reasoning paradigms - deductive, inductive,
abductive, and analogical - and assess strategies to enhance reasoning
performance, including data-centric tuning, reinforcement learning, decoding
strategies, and neuro-symbolic approaches. The review concludes with future
directions, emphasizing the need for further exploration to strengthen logical
reasoning in AI systems.","Hanmeng Liu, Zhizhang Fu, Mengru Ding, Ruoxi Ning, Chaoli Zhang, Xiaozhang Liu, Yue Zhang",2025-02-13 09:19:14.000000,arXiv,http://arxiv.org/abs/2502.09100v1,Artificial Intelligence
195,A Hybrid Transformer Model for Fake News Detection: Leveraging Bayesian Optimization and Bidirectional Recurrent Unit,"In this paper, we propose an optimized Transformer model that integrates
Bayesian algorithms with a Bidirectional Gated Recurrent Unit (BiGRU), and
apply it to fake news classification for the first time. First, we employ the
TF-IDF method to extract features from news texts and transform them into
numeric representations to facilitate subsequent machine learning tasks. Two
sets of experiments are then conducted for fake news detection and
classification: one using a Transformer model optimized only with BiGRU, and
the other incorporating Bayesian algorithms into the BiGRU-based Transformer.
Experimental results show that the BiGRU-optimized Transformer achieves 100%
accuracy on the training set and 99.67% on the test set, while the addition of
the Bayesian algorithm maintains 100% accuracy on the training set and slightly
improves test-set accuracy to 99.73%. This indicates that the Bayesian
algorithm boosts model accuracy by 0.06%, further enhancing the detection
capability for fake news. Moreover, the proposed algorithm converges rapidly at
around the 10th training epoch with accuracy nearing 100%, demonstrating both
its effectiveness and its fast classification ability. Overall, the optimized
Transformer model, enhanced by the Bayesian algorithm and BiGRU, exhibits
excellent continuous learning and detection performance, offering a robust
technical means to combat the spread of fake news in the current era of
information overload.","Tianyi Huang, Zeqiu Xu, Peiyang Yu, Jingyuan Yi, Xiaochuan Xu",2025-02-13 09:13:23.000000,arXiv,http://arxiv.org/abs/2502.09097v1,Natural Language Processing
196,From Visuals to Vocabulary: Establishing Equivalence Between Image and Text Token Through Autoregressive Pre-training in MLLMs,"While MLLMs perform well on perceptual tasks, they lack precise multimodal
alignment, limiting performance. To address this challenge, we propose Vision
Dynamic Embedding-Guided Pretraining (VDEP), a hybrid autoregressive training
paradigm for MLLMs. Utilizing dynamic embeddings from the MLP following the
visual encoder, this approach supervises image hidden states and integrates
image tokens into autoregressive training. Existing MLLMs primarily focused on
recovering information from textual inputs, often neglecting the effective
processing of image data. In contrast, the key improvement of this work is the
reinterpretation of multimodal alignment as a process of recovering information
from input data, with particular emphasis on reconstructing detailed visual
features.The proposed method seamlessly integrates into standard models without
architectural changes. Experiments on 13 benchmarks show VDEP outperforms
baselines, surpassing existing methods.","Mingxiao Li, Fang Qu, Zhanpeng Chen, Na Su, Zhizhou Zhong, Ziyang Chen, Nan Du, Xiaolong Li",2025-02-13 09:04:28.000000,arXiv,http://arxiv.org/abs/2502.09093v1,Computer Vision
197,Semantic Ads Retrieval at Walmart eCommerce with Language Models Progressively Trained on Multiple Knowledge Domains,"Sponsored search in e-commerce poses several unique and complex challenges.
These challenges stem from factors such as the asymmetric language structure
between search queries and product names, the inherent ambiguity in user search
intent, and the vast volume of sparse and imbalanced search corpus data. The
role of the retrieval component within a sponsored search system is pivotal,
serving as the initial step that directly affects the subsequent ranking and
bidding systems. In this paper, we present an end-to-end solution tailored to
optimize the ads retrieval system on Walmart.com. Our approach is to pretrain
the BERT-like classification model with product category information, enhancing
the model's understanding of Walmart product semantics. Second, we design a
two-tower Siamese Network structure for embedding structures to augment
training efficiency. Third, we introduce a Human-in-the-loop Progressive Fusion
Training method to ensure robust model performance. Our results demonstrate the
effectiveness of this pipeline. It enhances the search relevance metric by up
to 16% compared to a baseline DSSM-based model. Moreover, our large-scale
online A/B testing demonstrates that our approach surpasses the ad revenue of
the existing production model.","Zhaodong Wang, Weizhi Du, Md Omar Faruk Rokon, Pooshpendu Adhikary, Yanbing Xue, Jiaxuan Xu, Jianghong Zhou, Kuang-chih Lee, Musen Wen",2025-02-13 09:01:34.000000,arXiv,http://arxiv.org/abs/2502.09089v1,Information Retrieval
198,Unsupervised Anomaly Detection on Implicit Shape representations for Sarcopenia Detection,"Sarcopenia is an age-related progressive loss of muscle mass and strength
that significantly impacts daily life. A commonly studied criterion for
characterizing the muscle mass has been the combination of 3D imaging and
manual segmentations. In this paper, we instead study the muscles' shape. We
rely on an implicit neural representation (INR) to model normal muscle shapes.
We then introduce an unsupervised anomaly detection method to identify
sarcopenic muscles based on the reconstruction error of the implicit model.
Relying on a conditional INR with an auto-decoding strategy, we also learn a
latent representation of the muscles that clearly separates normal from
abnormal muscles in an unsupervised fashion. Experimental results on a dataset
of 103 segmented volumes indicate that our double anomaly detection strategy
effectively discriminates sarcopenic and non-sarcopenic muscles.","Louise Piecuch, Jeremie Huet, Antoine Frouin, Antoine Nordez, Anne-Sophie Boureau, Diana Mateus",2025-02-13 09:01:00.000000,arXiv,http://arxiv.org/abs/2502.09088v1,Computer Vision
199,A Hybrid Model for Few-Shot Text Classification Using Transfer and Meta-Learning,"With the continuous development of natural language processing (NLP)
technology, text classification tasks have been widely used in multiple
application fields. However, obtaining labeled data is often expensive and
difficult, especially in few-shot learning scenarios. To solve this problem,
this paper proposes a few-shot text classification model based on transfer
learning and meta-learning. The model uses the knowledge of the pre-trained
model for transfer and optimizes the model's rapid adaptability in few-sample
tasks through a meta-learning mechanism. Through a series of comparative
experiments and ablation experiments, we verified the effectiveness of the
proposed method. The experimental results show that under the conditions of few
samples and medium samples, the model based on transfer learning and
meta-learning significantly outperforms traditional machine learning and deep
learning methods. In addition, ablation experiments further analyzed the
contribution of each component to the model performance and confirmed the key
role of transfer learning and meta-learning in improving model accuracy.
Finally, this paper discusses future research directions and looks forward to
the potential of this method in practical applications.","Jia Gao, Shuangquan Lyu, Guiran Liu, Binrong Zhu, Hongye Zheng, Xiaoxuan Liao",2025-02-13 09:00:32.000000,arXiv,http://arxiv.org/abs/2502.09086v1,Natural Language Processing
200,Application of Tabular Transformer Architectures for Operating System Fingerprinting,"Operating System (OS) fingerprinting is essential for network management and
cybersecurity, enabling accurate device identification based on network traffic
analysis. Traditional rule-based tools such as Nmap and p0f face challenges in
dynamic environments due to frequent OS updates and obfuscation techniques.
While Machine Learning (ML) approaches have been explored, Deep Learning (DL)
models, particularly Transformer architectures, remain unexploited in this
domain. This study investigates the application of Tabular Transformer
architectures-specifically TabTransformer and FT-Transformer-for OS
fingerprinting, leveraging structured network data from three publicly
available datasets. Our experiments demonstrate that FT-Transformer generally
outperforms traditional ML models, previous approaches and TabTransformer
across multiple classification levels (OS family, major, and minor versions).
The results establish a strong foundation for DL-based OS fingerprinting,
improving accuracy and adaptability in complex network environments.
Furthermore, we ensure the reproducibility of our research by providing an
open-source implementation.","Rubén Pérez-Jove, Cristian R. Munteanu, Alejandro Pazos, Jose Vázquez-Naya",2025-02-13 08:59:04.000000,arXiv,http://arxiv.org/abs/2502.09084v1,Other
201,Show Me the Work: Fact-Checkers' Requirements for Explainable Automated Fact-Checking,"The pervasiveness of large language models and generative AI in online media
has amplified the need for effective automated fact-checking to assist
fact-checkers in tackling the increasing volume and sophistication of
misinformation. The complex nature of fact-checking demands that automated
fact-checking systems provide explanations that enable fact-checkers to
scrutinise their outputs. However, it is unclear how these explanations should
align with the decision-making and reasoning processes of fact-checkers to be
effectively integrated into their workflows. Through semi-structured interviews
with fact-checking professionals, we bridge this gap by: (i) providing an
account of how fact-checkers assess evidence, make decisions, and explain their
processes; (ii) examining how fact-checkers use automated tools in practice;
and (iii) identifying fact-checker explanation requirements for automated
fact-checking tools. The findings show unmet explanation needs and identify
important criteria for replicable fact-checking explanations that trace the
model's reasoning path, reference specific evidence, and highlight uncertainty
and information gaps.","Greta Warren, Irina Shklovski, Isabelle Augenstein",2025-02-13 08:56:25.000000,arXiv,http://arxiv.org/abs/2502.09083v1,Other
202,CoSER: Coordinating LLM-Based Persona Simulation of Established Roles,"Role-playing language agents (RPLAs) have emerged as promising applications
of large language models (LLMs). However, simulating established characters
presents a challenging task for RPLAs, due to the lack of authentic character
datasets and nuanced evaluation methods using such data. In this paper, we
present CoSER, a collection of a high-quality dataset, open models, and an
evaluation protocol towards effective RPLAs of established characters. The
CoSER dataset covers 17,966 characters from 771 renowned books. It provides
authentic dialogues with real-world intricacies, as well as diverse data types
such as conversation setups, character experiences and internal thoughts.
Drawing from acting methodology, we introduce given-circumstance acting for
training and evaluating role-playing LLMs, where LLMs sequentially portray
multiple characters in book scenes. Using our dataset, we develop CoSER 8B and
CoSER 70B, i.e., advanced open role-playing LLMs built on LLaMA-3.1 models.
Extensive experiments demonstrate the value of the CoSER dataset for RPLA
training, evaluation and retrieval. Moreover, CoSER 70B exhibits
state-of-the-art performance surpassing or matching GPT-4o on our evaluation
and three existing benchmarks, i.e., achieving 75.80% and 93.47% accuracy on
the InCharacter and LifeChoice benchmarks respectively.","Xintao Wang, Heng Wang, Yifei Zhang, Xinfeng Yuan, Rui Xu, Jen-tse Huang, Siyu Yuan, Haoran Guo, Jiangjie Chen, Wei Wang, Yanghua Xiao, Shuchang Zhou",2025-02-13 08:55:24.000000,arXiv,http://arxiv.org/abs/2502.09082v1,Natural Language Processing
203,BevSplat: Resolving Height Ambiguity via Feature-Based Gaussian Primitives for Weakly-Supervised Cross-View Localization,"This paper addresses the problem of weakly supervised cross-view
localization, where the goal is to estimate the pose of a ground camera
relative to a satellite image with noisy ground truth annotations. A common
approach to bridge the cross-view domain gap for pose estimation is Bird's-Eye
View (BEV) synthesis. However, existing methods struggle with height ambiguity
due to the lack of depth information in ground images and satellite height
maps. Previous solutions either assume a flat ground plane or rely on complex
models, such as cross-view transformers. We propose BevSplat, a novel method
that resolves height ambiguity by using feature-based Gaussian primitives. Each
pixel in the ground image is represented by a 3D Gaussian with semantic and
spatial features, which are synthesized into a BEV feature map for relative
pose estimation. Additionally, to address challenges with panoramic query
images, we introduce an icosphere-based supervision strategy for the Gaussian
primitives. We validate our method on the widely used KITTI and VIGOR datasets,
which include both pinhole and panoramic query images. Experimental results
show that BevSplat significantly improves localization accuracy over prior
approaches.","Qiwei Wang, Shaoxun Wu, Yujiao Shi",2025-02-13 08:54:04.000000,arXiv,http://arxiv.org/abs/2502.09080v1,Computer Vision
204,Quantifying Cryptocurrency Unpredictability: A Comprehensive Study of Complexity and Forecasting,"This paper offers a thorough examination of the univariate predictability in
cryptocurrency time-series. By exploiting a combination of complexity measure
and model predictions we explore the cryptocurrencies time-series forecasting
task focusing on the exchange rate in USD of Litecoin, Binance Coin, Bitcoin,
Ethereum, and XRP. On one hand, to assess the complexity and the randomness of
these time-series, a comparative analysis has been performed using Brownian and
colored noises as a benchmark. The results obtained from the Complexity-Entropy
causality plane and power density spectrum analysis reveal that cryptocurrency
time-series exhibit characteristics closely resembling those of Brownian noise
when analyzed in a univariate context. On the other hand, the application of a
wide range of statistical, machine and deep learning models for time-series
forecasting demonstrates the low predictability of cryptocurrencies. Notably,
our analysis reveals that simpler models such as Naive models consistently
outperform the more complex machine and deep learning ones in terms of
forecasting accuracy across different forecast horizons and time windows. The
combined study of complexity and forecasting accuracies highlights the
difficulty of predicting the cryptocurrency market. These findings provide
valuable insights into the inherent characteristics of the cryptocurrency data
and highlight the need to reassess the challenges associated with predicting
cryptocurrency's price movements.","Francesco Puoti, Fabrizio Pittorino, Manuel Roveri",2025-02-13 08:53:13.000000,arXiv,http://arxiv.org/abs/2502.09079v1,Other
205,PTZ-Calib: Robust Pan-Tilt-Zoom Camera Calibration,"In this paper, we present PTZ-Calib, a robust two-stage PTZ camera
calibration method, that efficiently and accurately estimates camera parameters
for arbitrary viewpoints. Our method includes an offline and an online stage.
In the offline stage, we first uniformly select a set of reference images that
sufficiently overlap to encompass a complete 360{\deg} view. We then utilize
the novel PTZ-IBA (PTZ Incremental Bundle Adjustment) algorithm to
automatically calibrate the cameras within a local coordinate system.
Additionally, for practical application, we can further optimize camera
parameters and align them with the geographic coordinate system using extra
global reference 3D information. In the online stage, we formulate the
calibration of any new viewpoints as a relocalization problem. Our approach
balances the accuracy and computational efficiency to meet real-world demands.
Extensive evaluations demonstrate our robustness and superior performance over
state-of-the-art methods on various real and synthetic datasets. Datasets and
source code can be accessed online at https://github.com/gjgjh/PTZ-Calib","Jinhui Guo, Lubin Fan, Bojian Wu, Jiaqi Gu, Shen Cao, Jieping Ye",2025-02-13 08:45:43.000000,arXiv,http://arxiv.org/abs/2502.09075v1,Computer Vision
206,Enhancing RAG with Active Learning on Conversation Records: Reject Incapables and Answer Capables,"Retrieval-augmented generation (RAG) is a key technique for leveraging
external knowledge and reducing hallucinations in large language models (LLMs).
However, RAG still struggles to fully prevent hallucinated responses. To
address this, it is essential to identify samples prone to hallucination or
guide LLMs toward correct responses, which experts then annotate to develop
high-quality datasets for refining LLMs. However, the growing scarcity of such
datasets makes their creation challenging. This paper proposes using the vast
amount of conversations from widespread LLM usage to build these datasets,
training LLMs to avoid hallucination-prone questions while accurately
responding to manageable ones. Given the impracticality of expert-annotating
all conversation records, the paper introduces AL4RAG, which uses active
learning to select the most suitable conversation samples for annotation,
optimizing performance within an annotation budget. Additionally, recognizing
that traditional active learning methods are not fully compatible with RAG due
to unsuitable distance metrics, we develop a novel sample distance measurement
for RAG active learning. Extensive experiments show that our method
consistently outperforms baselines across multiple metrics.","Xuzhao Geng, Haozhao Wang, Jun Wang, Wei Liu, Ruixuan Li",2025-02-13 08:42:29.000000,arXiv,http://arxiv.org/abs/2502.09073v1,Natural Language Processing
207,FlowAR: une plateforme uniformisée pour la reconnaissance des activités humaines à partir de capteurs binaires,"This demo showcases a platform for developing human activity recognition (AR)
systems, focusing on daily activities using sensor data, like binary sensors.
With a data-driven approach, this platform, named FlowAR, features a three-step
pipeline (flow): data cleaning, segmentation, and personalized classification.
Its modularity allows flexibility to test methods, datasets, and ensure
rigorous evaluations. A concrete use case demonstrates its effectiveness.","Ali Ncibi, Luc Bouganim, Philippe Pucheral",2025-02-13 08:32:24.000000,arXiv,http://arxiv.org/abs/2502.09067v1,Machine Learning
208,StyleBlend: Enhancing Style-Specific Content Creation in Text-to-Image Diffusion Models,"Synthesizing visually impressive images that seamlessly align both text
prompts and specific artistic styles remains a significant challenge in
Text-to-Image (T2I) diffusion models. This paper introduces StyleBlend, a
method designed to learn and apply style representations from a limited set of
reference images, enabling content synthesis of both text-aligned and
stylistically coherent. Our approach uniquely decomposes style into two
components, composition and texture, each learned through different strategies.
We then leverage two synthesis branches, each focusing on a corresponding style
component, to facilitate effective style blending through shared features
without affecting content generation. StyleBlend addresses the common issues of
text misalignment and weak style representation that previous methods have
struggled with. Extensive qualitative and quantitative comparisons demonstrate
the superiority of our approach.","Zichong Chen, Shijin Wang, Yang Zhou",2025-02-13 08:26:54.000000,arXiv,http://arxiv.org/abs/2502.09064v1,Computer Vision
209,CRANE: Reasoning with constrained LLM generation,"Code generation, symbolic math reasoning, and other tasks require LLMs to
produce outputs that are both syntactically and semantically correct.
Constrained LLM generation is a promising direction to enforce adherence to
formal grammar, but prior works have empirically observed that strict
enforcement of formal constraints often diminishes the reasoning capabilities
of LLMs. In this work, we first provide a theoretical explanation for why
constraining LLM outputs to very restrictive grammars that only allow
syntactically valid final answers reduces the reasoning capabilities of the
model. Second, we demonstrate that by augmenting the output grammar with
carefully designed additional rules, it is always possible to preserve the
reasoning capabilities of the LLM while ensuring syntactic and semantic
correctness in its outputs. Building on these theoretical insights, we propose
a reasoning-augmented constrained decoding algorithm, CRANE, which effectively
balances the correctness of constrained generation with the flexibility of
unconstrained generation. Experiments on multiple open-source LLMs and
benchmarks show that CRANE significantly outperforms both state-of-the-art
constrained decoding strategies and standard unconstrained decoding, showing up
to 10% points accuracy improvement over baselines on challenging symbolic
reasoning benchmarks GSM-symbolic and FOLIO.","Debangshu Banerjee, Tarun Suresh, Shubham Ugare, Sasa Misailovic, Gagandeep Singh",2025-02-13 08:23:42.000000,arXiv,http://arxiv.org/abs/2502.09061v1,Other
210,Unleashing the Power of Large Language Model for Denoising Recommendation,"Recommender systems are crucial for personalizing user experiences but often
depend on implicit feedback data, which can be noisy and misleading. Existing
denoising studies involve incorporating auxiliary information or learning
strategies from interaction data. However, they struggle with the inherent
limitations of external knowledge and interaction data, as well as the
non-universality of certain predefined assumptions, hindering accurate noise
identification. Recently, large language models (LLMs) have gained attention
for their extensive world knowledge and reasoning abilities, yet their
potential in enhancing denoising in recommendations remains underexplored. In
this paper, we introduce LLaRD, a framework leveraging LLMs to improve
denoising in recommender systems, thereby boosting overall recommendation
performance. Specifically, LLaRD generates denoising-related knowledge by first
enriching semantic insights from observational data via LLMs and inferring
user-item preference knowledge. It then employs a novel Chain-of-Thought (CoT)
technique over user-item interaction graphs to reveal relation knowledge for
denoising. Finally, it applies the Information Bottleneck (IB) principle to
align LLM-generated denoising knowledge with recommendation targets, filtering
out noise and irrelevant LLM knowledge. Empirical results demonstrate LLaRD's
effectiveness in enhancing denoising and recommendation accuracy.","Shuyao Wang, Zhi Zheng, Yongduo Sui, Hui Xiong",2025-02-13 08:19:45.000000,arXiv,http://arxiv.org/abs/2502.09058v1,Information Retrieval
211,Vision-Language In-Context Learning Driven Few-Shot Visual Inspection Model,"We propose general visual inspection model using Vision-Language Model~(VLM)
with few-shot images of non-defective or defective products, along with
explanatory texts that serve as inspection criteria. Although existing VLM
exhibit high performance across various tasks, they are not trained on specific
tasks such as visual inspection. Thus, we construct a dataset consisting of
diverse images of non-defective and defective products collected from the web,
along with unified formatted output text, and fine-tune VLM. For new products,
our method employs In-Context Learning, which allows the model to perform
inspections with an example of non-defective or defective image and the
corresponding explanatory texts with visual prompts. This approach eliminates
the need to collect a large number of training samples and re-train the model
for each product. The experimental results show that our method achieves high
performance, with MCC of 0.804 and F1-score of 0.950 on MVTec AD in a one-shot
manner. Our code is available
at~https://github.com/ia-gu/Vision-Language-In-Context-Learning-Driven-Few-Shot-Visual-Inspection-Model.","Shiryu Ueno, Yoshikazu Hayashi, Shunsuke Nakatsuka, Yusei Yamada, Hiroaki Aizawa, Kunihito Kato",2025-02-13 08:11:10.000000,arXiv,http://arxiv.org/abs/2502.09057v1,Computer Vision
212,An Open Recipe: Adapting Language-Specific LLMs to a Reasoning Model in One Day via Model Merging,"This paper investigates data selection and model merging methodologies aimed
at incorporating advanced reasoning capabilities such as those of DeepSeek R1
into language-specific large language models (LLMs), with a particular focus on
the Thai LLM. Our goal is to enhance the reasoning capabilities of
language-specific LLMs while maintaining their target language abilities.
DeepSeek R1 excels in reasoning but primarily benefits high-resource languages
such as English and Chinese. However, low-resource languages remain underserved
due to the dominance of English-centric training data and model optimizations,
which limit performance in these languages. This limitation results in
unreliable code-switching and diminished effectiveness on tasks in low-resource
languages. Meanwhile, local and regional LLM initiatives have attempted to
bridge this gap by developing language-specific LLMs that focus on improving
local linguistic fidelity. We demonstrate that, with only publicly available
datasets and a computational budget of $120, it is possible to enhance the
reasoning capabilities of language-specific LLMs to match the level of DeepSeek
R1, without compromising their performance on target language tasks.","Kunat Pipatanakul, Pittawat Taveekitworachai, Potsawee Manakul, Kasima Tharnpipitchai",2025-02-13 08:10:45.000000,arXiv,http://arxiv.org/abs/2502.09056v1,Natural Language Processing
213,Exploring the Needs of Practising Musicians in Co-Creative AI Through Co-Design,"Recent advances in generative AI music have resulted in new technologies that
are being framed as co-creative tools for musicians with early work
demonstrating their potential to add to music practice. While the field has
seen many valuable contributions, work that involves practising musicians in
the design and development of these tools is limited, with the majority of work
including them only once a tool has been developed. In this paper, we present a
case study that explores the needs of practising musicians through the
co-design of a musical variation system, highlighting the importance of
involving a diverse range of musicians throughout the design process and
uncovering various design insights. This was achieved through two workshops and
a two week ecological evaluation, where musicians from different musical
backgrounds offered valuable insights not only on a musical system's design but
also on how a musical AI could be integrated into their musical practices.","Stephen James Krol, Maria Teresa Llano Rodriguez, Miguel Loor Paredes",2025-02-13 08:10:07.000000,arXiv,http://arxiv.org/abs/2502.09055v1,Other
214,Cost-Saving LLM Cascades with Early Abstention,"LLM cascades are based on the idea that processing all queries with the
largest and most expensive LLMs is inefficient. Instead, cascades deploy small
LLMs to answer the majority of queries, limiting the use of large and expensive
LLMs to only the most difficult queries. This approach can significantly reduce
costs without impacting performance. However, risk-sensitive domains such as
finance or medicine place an additional premium on avoiding model errors.
Recognizing that even the most expensive models may make mistakes, applications
in these domains benefit from allowing LLM systems to completely abstain from
answering a query when the chance of making a mistake is significant. However,
giving a cascade the ability to abstain poses an immediate design question for
LLM cascades: should abstention only be allowed at the final model or also at
earlier models? Since the error patterns of small and large models are
correlated, the latter strategy may further reduce inference costs by letting
inexpensive models anticipate abstention decisions by expensive models, thereby
obviating the need to run the expensive models. We investigate the benefits of
""early abstention"" in LLM cascades and find that it reduces the overall test
loss by 2.2% on average across six benchmarks (GSM8K, MedMCQA, MMLU, TriviaQA,
TruthfulQA, and XSum). These gains result from a more effective use of
abstention, which trades a 4.1% average increase in the overall abstention rate
for a 13.0% reduction in cost and a 5.0% reduction in error rate. Our findings
demonstrate that it is possible to leverage correlations between the error
patterns of different language models to drive performance improvements for LLM
systems with abstention.","Michael J. Zellinger, Rex Liu, Matt Thomson",2025-02-13 08:08:39.000000,arXiv,http://arxiv.org/abs/2502.09054v1,Artificial Intelligence
215,Game Theory Meets Large Language Models: A Systematic Survey,"Game theory establishes a fundamental framework for analyzing strategic
interactions among rational decision-makers. The rapid advancement of large
language models (LLMs) has sparked extensive research exploring the
intersection of these two fields. Specifically, game-theoretic methods are
being applied to evaluate and enhance LLM capabilities, while LLMs themselves
are reshaping classic game models. This paper presents a comprehensive survey
of the intersection of these fields, exploring a bidirectional relationship
from three perspectives: (1) Establishing standardized game-based benchmarks
for evaluating LLM behavior; (2) Leveraging game-theoretic methods to improve
LLM performance through algorithmic innovations; (3) Characterizing the
societal impacts of LLMs through game modeling. Among these three aspects, we
also highlight how the equilibrium analysis for traditional game models is
impacted by LLMs' advanced language understanding, which in turn extends the
study of game theory. Finally, we identify key challenges and future research
directions, assessing their feasibility based on the current state of the
field. By bridging theoretical rigor with emerging AI capabilities, this survey
aims to foster interdisciplinary collaboration and drive progress in this
evolving research area.","Haoran Sun, Yusen Wu, Yukun Cheng, Xu Chu",2025-02-13 08:08:27.000000,arXiv,http://arxiv.org/abs/2502.09053v1,Artificial Intelligence
216,AIDE: Agentically Improve Visual Language Model with Domain Experts,"The enhancement of Visual Language Models (VLMs) has traditionally relied on
knowledge distillation from larger, more capable models. This dependence
creates a fundamental bottleneck for improving state-of-the-art systems,
particularly when no superior models exist. We introduce AIDE (Agentic
Improvement through Domain Experts), a novel framework that enables VLMs to
autonomously enhance their capabilities by leveraging specialized domain expert
models. AIDE operates through a four-stage process: (1) identifying instances
for refinement, (2) engaging domain experts for targeted analysis, (3)
synthesizing expert outputs with existing data, and (4) integrating enhanced
instances into the training pipeline. Experiments on multiple benchmarks,
including MMMU, MME, MMBench, etc., demonstrate AIDE's ability to achieve
notable performance gains without relying on larger VLMs nor human supervision.
Our framework provides a scalable, resource-efficient approach to continuous
VLM improvement, addressing critical limitations in current methodologies,
particularly valuable when larger models are unavailable to access.","Ming-Chang Chiu, Fuxiao Liu, Karan Sapra, Andrew Tao, Yaser Jacoob, Xuezhe Ma, Zhiding Yu, Guilin Liu",2025-02-13 08:05:44.000000,arXiv,http://arxiv.org/abs/2502.09051v1,Computer Vision
217,Leveraging Member-Group Relations via Multi-View Graph Filtering for Effective Group Recommendation,"Group recommendation aims at providing optimized recommendations tailored to
diverse groups, enabling groups to enjoy appropriate items. On the other hand,
most existing group recommendation methods are built upon deep neural network
(DNN) architectures designed to capture the intricate relationships between
member-level and group-level interactions. While these DNN-based approaches
have proven their effectiveness, they require complex and expensive training
procedures to incorporate group-level interactions in addition to member-level
interactions. To overcome such limitations, we introduce Group-GF, a new
approach for extremely fast recommendations of items to each group via
multi-view graph filtering (GF) that offers a holistic view of complex
member-group dynamics, without the need for costly model training.
Specifically, in Group-GF, we first construct three item similarity graphs
manifesting different viewpoints for GF. Then, we discover a distinct
polynomial graph filter for each similarity graph and judiciously aggregate the
three graph filters. Extensive experiments demonstrate the effectiveness of
Group-GF in terms of significantly reducing runtime and achieving
state-of-the-art recommendation accuracy.","Chae-Hyun Kim, Yoon-Ryung Choi, Jin-Duk Park, Won-Yong Shin",2025-02-13 08:05:14.000000,arXiv,http://arxiv.org/abs/2502.09050v1,Information Retrieval
218,Optimal Algorithms in Linear Regression under Covariate Shift: On the Importance of Precondition,"A common pursuit in modern statistical learning is to attain satisfactory
generalization out of the source data distribution (OOD). In theory, the
challenge remains unsolved even under the canonical setting of covariate shift
for the linear model. This paper studies the foundational (high-dimensional)
linear regression where the ground truth variables are confined to an
ellipse-shape constraint and addresses two fundamental questions in this
regime: (i) given the target covariate matrix, what is the min-max
\emph{optimal} algorithm under covariate shift? (ii) for what kinds of target
classes, the commonly-used SGD-type algorithms achieve optimality? Our analysis
starts with establishing a tight lower generalization bound via a Bayesian
Cramer-Rao inequality. For (i), we prove that the optimal estimator can be
simply a certain linear transformation of the best estimator for the source
distribution. Given the source and target matrices, we show that the
transformation can be efficiently computed via a convex program. The min-max
optimal analysis for SGD leverages the idea that we recognize both the
accumulated updates of the applied algorithms and the ideal transformation as
preconditions on the learning variables. We provide sufficient conditions when
SGD with its acceleration variants attain optimality.","Yuanshi Liu, Haihan Zhang, Qian Chen, Cong Fang",2025-02-13 08:02:15.000000,arXiv,http://arxiv.org/abs/2502.09047v1,Statistical Machine Learning
219,Criteria-Aware Graph Filtering: Extremely Fast Yet Accurate Multi-Criteria Recommendation,"Multi-criteria (MC) recommender systems, which utilize MC rating information
for recommendation, are increasingly widespread in various e-commerce domains.
However, the MC recommendation using training-based collaborative filtering,
requiring consideration of multiple ratings compared to single-criterion
counterparts, often poses practical challenges in achieving state-of-the-art
performance along with scalable model training. To solve this problem, we
propose CA-GF, a training-free MC recommendation method, which is built upon
criteria-aware graph filtering for efficient yet accurate MC recommendations.
Specifically, first, we construct an item-item similarity graph using an MC
user-expansion graph. Next, we design CA-GF composed of the following key
components, including 1) criterion-specific graph filtering where the optimal
filter for each criterion is found using various types of polynomial low-pass
filters and 2) criteria preference-infused aggregation where the smoothed
signals from each criterion are aggregated. We demonstrate that CA-GF is (a)
efficient: providing the computational efficiency, offering the extremely fast
runtime of less than 0.2 seconds even on the largest benchmark dataset, (b)
accurate: outperforming benchmark MC recommendation methods, achieving
substantial accuracy gains up to 24% compared to the best competitor, and (c)
interpretable: providing interpretations for the contribution of each criterion
to the model prediction based on visualizations.","Jin-Duk Park, Jaemin Yoo, Won-Yong Shin",2025-02-13 08:01:38.000000,arXiv,http://arxiv.org/abs/2502.09046v1,Information Retrieval
220,Evolution of Data-driven Single- and Multi-Hazard Susceptibility Mapping and Emergence of Deep Learning Methods,"Data-driven susceptibility mapping of natural hazards has harnessed the
advances in classification methods used on heterogeneous sources represented as
raster images. Susceptibility mapping is an important step towards risk
assessment for any natural hazard. Increasingly, multiple hazards co-occur
spatially, temporally, or both, which calls for an in-depth study on
multi-hazard susceptibility mapping. In recent years, single-hazard
susceptibility mapping algorithms have become well-established and have been
extended to multi-hazard susceptibility mapping. Deep learning is also emerging
as a promising method for single-hazard susceptibility mapping. Here, we
discuss the evolution of methods for a single hazard, their extensions to
multi-hazard maps as a late fusion of decisions, and the use of deep learning
methods in susceptibility mapping. We finally propose a vision for adapting
data fusion strategies in multimodal deep learning to multi-hazard
susceptibility mapping. From the background study of susceptibility methods, we
demonstrate that deep learning models are promising, untapped methods for
multi-hazard susceptibility mapping. Data fusion strategies provide a larger
space of deep learning models applicable to multi-hazard susceptibility
mapping.","Jaya Sreevalsan-Nair, Aswathi Mundayatt",2025-02-13 08:01:29.000000,arXiv,http://arxiv.org/abs/2502.09045v1,Computer Vision
221,Typhoon T1: An Open Thai Reasoning Model,"This paper introduces Typhoon T1, an open effort to develop an open Thai
reasoning model. A reasoning model is a relatively new type of generative model
built on top of large language models (LLMs). A reasoning model generates a
long chain of thought before arriving at a final answer, an approach found to
improve performance on complex tasks. However, details on developing such a
model are limited, especially for reasoning models that can generate traces in
a low-resource language. Typhoon T1 presents an open effort that dives into the
details of developing a reasoning model in a more cost-effective way by
leveraging supervised fine-tuning using open datasets, instead of reinforcement
learning. This paper shares the details about synthetic data generation and
training, as well as our dataset and model weights. Additionally, we provide
insights gained from developing a reasoning model that generalizes across
domains and is capable of generating reasoning traces in a low-resource
language, using Thai as an example. We hope this open effort provides a
foundation for further research in this field.","Pittawat Taveekitworachai, Potsawee Manakul, Kasima Tharnpipitchai, Kunat Pipatanakul",2025-02-13 07:55:54.000000,arXiv,http://arxiv.org/abs/2502.09042v1,Natural Language Processing
222,Large Images are Gaussians: High-Quality Large Image Representation with Levels of 2D Gaussian Splatting,"While Implicit Neural Representations (INRs) have demonstrated significant
success in image representation, they are often hindered by large training
memory and slow decoding speed. Recently, Gaussian Splatting (GS) has emerged
as a promising solution in 3D reconstruction due to its high-quality novel view
synthesis and rapid rendering capabilities, positioning it as a valuable tool
for a broad spectrum of applications. In particular, a GS-based representation,
2DGS, has shown potential for image fitting. In our work, we present
\textbf{L}arge \textbf{I}mages are \textbf{G}aussians (\textbf{LIG}), which
delves deeper into the application of 2DGS for image representations,
addressing the challenge of fitting large images with 2DGS in the situation of
numerous Gaussian points, through two distinct modifications: 1) we adopt a
variant of representation and optimization strategy, facilitating the fitting
of a large number of Gaussian points; 2) we propose a Level-of-Gaussian
approach for reconstructing both coarse low-frequency initialization and fine
high-frequency details. Consequently, we successfully represent large images as
Gaussian points and achieve high-quality large image representation,
demonstrating its efficacy across various types of large images. Code is
available at
{\href{https://github.com/HKU-MedAI/LIG}{https://github.com/HKU-MedAI/LIG}}.","Lingting Zhu, Guying Lin, Jinnan Chen, Xinjie Zhang, Zhenchao Jin, Zhao Wang, Lequan Yu",2025-02-13 07:48:56.000000,arXiv,http://arxiv.org/abs/2502.09039v1,Computer Vision
223,AoI-Sensitive Data Forwarding with Distributed Beamforming in UAV-Assisted IoT,"This paper proposes a UAV-assisted forwarding system based on distributed
beamforming to enhance age of information (AoI) in Internet of Things (IoT).
Specifically, UAVs collect and relay data between sensor nodes (SNs) and the
remote base station (BS). However, flight delays increase the AoI and degrade
the network performance. To mitigate this, we adopt distributed beamforming to
extend the communication range, reduce the flight frequency and ensure the
continuous data relay and efficient energy utilization. Then, we formulate an
optimization problem to minimize AoI and UAV energy consumption, by jointly
optimizing the UAV trajectories and communication schedules. The problem is
non-convex and with high dynamic, and thus we propose a deep reinforcement
learning (DRL)-based algorithm to solve the problem, thereby enhancing the
stability and accelerate convergence speed. Simulation results show that the
proposed algorithm effectively addresses the problem and outperforms other
benchmark algorithms.","Zifan Lang, Guixia Liu, Geng Sun, Jiahui Li, Zemin Sun, Jiacheng Wang, Victor C. M. Leung",2025-02-13 07:48:36.000000,arXiv,http://arxiv.org/abs/2502.09038v1,Artificial Intelligence
224,MTDP: Modulated Transformer Diffusion Policy Model,"Recent research on robot manipulation based on Behavior Cloning (BC) has made
significant progress. By combining diffusion models with BC, diffusion policiy
has been proposed, enabling robots to quickly learn manipulation tasks with
high success rates. However, integrating diffusion policy with high-capacity
Transformer presents challenges, traditional Transformer architectures struggle
to effectively integrate guiding conditions, resulting in poor performance in
manipulation tasks when using Transformer-based models. In this paper, we
investigate key architectural designs of Transformers and improve the
traditional Transformer architecture by proposing the Modulated Transformer
Diffusion Policy (MTDP) model for diffusion policy. The core of this model is
the Modulated Attention module we proposed, which more effectively integrates
the guiding conditions with the main input, improving the generative model's
output quality and, consequently, increasing the robot's task success rate. In
six experimental tasks, MTDP outperformed existing Transformer model
architectures, particularly in the Toolhang experiment, where the success rate
increased by 12\%. To verify the generality of Modulated Attention, we applied
it to the UNet architecture to construct Modulated UNet Diffusion Policy model
(MUDP), which also achieved higher success rates than existing UNet
architectures across all six experiments. The Diffusion Policy uses Denoising
Diffusion Probabilistic Models (DDPM) as the diffusion model. Building on this,
we also explored Denoising Diffusion Implicit Models (DDIM) as the diffusion
model, constructing the MTDP-I and MUDP-I model, which nearly doubled the
generation speed while maintaining performance.","Qianhao Wang, Yinqian Sun, Enmeng Lu, Qian Zhang, Yi Zeng",2025-02-13 07:35:03.000000,arXiv,http://arxiv.org/abs/2502.09029v1,Robotics
225,A Contextual-Aware Position Encoding for Sequential Recommendation,"Sequential recommendation (SR), which encodes user activity to predict the
next action, has emerged as a widely adopted strategy in developing commercial
personalized recommendation systems. A critical component of modern SR models
is the attention mechanism, which synthesizes users' historical activities.
This mechanism is typically order-invariant and generally relies on position
encoding (PE). Conventional SR models simply assign a learnable vector to each
position, resulting in only modest gains compared to traditional recommendation
models. Moreover, limited research has been conducted on position encoding
tailored for sequential recommendation, leaving a significant gap in addressing
its unique requirements. To bridge this gap, we propose a novel
Contextual-Aware Position Encoding method for sequential recommendation,
abbreviated as CAPE. To the best of our knowledge, CAPE is the first PE method
specifically designed for sequential recommendation. Comprehensive experiments
conducted on benchmark SR datasets demonstrate that CAPE consistently enhances
multiple mainstream backbone models and achieves state-of-the-art performance,
across small and large scale model size. Furthermore, we deployed CAPE in an
industrial setting on a real-world commercial platform, clearly showcasing the
effectiveness of our approach. Our source code is available at
https://github.com/yjdy/CAPE.","Jun Yuan, Guohao Cai, Zhenhua Dong",2025-02-13 07:31:34.000000,arXiv,http://arxiv.org/abs/2502.09027v1,Information Retrieval
226,Billet Number Recognition Based on Test-Time Adaptation,"During the steel billet production process, it is essential to recognize
machine-printed or manually written billet numbers on moving billets in
real-time. To address the issue of low recognition accuracy for existing scene
text recognition methods, caused by factors such as image distortions and
distribution differences between training and test data, we propose a billet
number recognition method that integrates test-time adaptation with prior
knowledge. First, we introduce a test-time adaptation method into a model that
uses the DB network for text detection and the SVTR network for text
recognition. By minimizing the model's entropy during the testing phase, the
model can adapt to the distribution of test data without the need for
supervised fine-tuning. Second, we leverage the billet number encoding rules as
prior knowledge to assess the validity of each recognition result. Invalid
results, which do not comply with the encoding rules, are replaced. Finally, we
introduce a validation mechanism into the CTC algorithm using prior knowledge
to address its limitations in recognizing damaged characters. Experimental
results on real datasets, including both machine-printed billet numbers and
handwritten billet numbers, show significant improvements in evaluation
metrics, validating the effectiveness of the proposed method.","Yuan Wei, Xiuzhuang Zhou",2025-02-13 07:31:03.000000,arXiv,http://arxiv.org/abs/2502.09026v1,Computer Vision
227,Mechanistic Unveiling of Transformer Circuits: Self-Influence as a Key to Model Reasoning,"Transformer-based language models have achieved notable success, yet their
internal reasoning mechanisms remain largely opaque due to complex non-linear
interactions and high-dimensional operations. While previous research suggests
that these models implicitly encode reasoning structures, it is still unclear
which specific multi-step thought processes they employ to solve complex tasks.
To address this gap, we propose a novel mechanistic interpretability framework,
SICAF, designed to trace and analyze the reasoning strategies that language
models use in multi-step inference tasks. By employing circuit analysis and
self-influence functions, we quantify the evolving importance of each token
throughout the reasoning process, thereby mapping the pathways the model uses
for inference. Applying SICAF to the GPT-2 model on the Indirect Object
Identification (IOI) prediction task, we demonstrate how underlying circuits
can reveal a reasoning process that aligns with human interpretability,
offering new insights into the model's internal logic.","Lin Zhang, Lijie Hu, Di Wang",2025-02-13 07:19:05.000000,arXiv,http://arxiv.org/abs/2502.09022v1,Artificial Intelligence
228,EventSTR: A Benchmark Dataset and Baselines for Event Stream based Scene Text Recognition,"Mainstream Scene Text Recognition (STR) algorithms are developed based on RGB
cameras which are sensitive to challenging factors such as low illumination,
motion blur, and cluttered backgrounds. In this paper, we propose to recognize
the scene text using bio-inspired event cameras by collecting and annotating a
large-scale benchmark dataset, termed EventSTR. It contains 9,928
high-definition (1280 * 720) event samples and involves both Chinese and
English characters. We also benchmark multiple STR algorithms as the baselines
for future works to compare. In addition, we propose a new event-based scene
text recognition framework, termed SimC-ESTR. It first extracts the event
features using a visual encoder and projects them into tokens using a Q-former
module. More importantly, we propose to augment the vision tokens based on a
memory mechanism before feeding into the large language models. A
similarity-based error correction mechanism is embedded within the large
language model to correct potential minor errors fundamentally based on
contextual information. Extensive experiments on the newly proposed EventSTR
dataset and two simulation STR datasets fully demonstrate the effectiveness of
our proposed model. We believe that the dataset and algorithmic model can
innovatively propose an event-based STR task and are expected to accelerate the
application of event cameras in various industries. The source code and
pre-trained models will be released on https://github.com/Event-AHU/EventSTR","Xiao Wang, Jingtao Jiang, Dong Li, Futian Wang, Lin Zhu, Yaowei Wang, Yongyong Tian, Jin Tang",2025-02-13 07:16:16.000000,arXiv,http://arxiv.org/abs/2502.09020v1,Computer Vision
229,Zero-shot Concept Bottleneck Models,"Concept bottleneck models (CBMs) are inherently interpretable and
intervenable neural network models, which explain their final label prediction
by the intermediate prediction of high-level semantic concepts. However, they
require target task training to learn input-to-concept and concept-to-label
mappings, incurring target dataset collections and training resources. In this
paper, we present \textit{zero-shot concept bottleneck models} (Z-CBMs), which
predict concepts and labels in a fully zero-shot manner without training neural
networks. Z-CBMs utilize a large-scale concept bank, which is composed of
millions of vocabulary extracted from the web, to describe arbitrary input in
various domains. For the input-to-concept mapping, we introduce concept
retrieval, which dynamically finds input-related concepts by the cross-modal
search on the concept bank. In the concept-to-label inference, we apply concept
regression to select essential concepts from the retrieved concepts by sparse
linear regression. Through extensive experiments, we confirm that our Z-CBMs
provide interpretable and intervenable concepts without any additional
training. Code will be available at https://github.com/yshinya6/zcbm.","Shin'ya Yamaguchi, Kosuke Nishida, Daiki Chijiwa, Yasutoshi Ida",2025-02-13 07:11:07.000000,arXiv,http://arxiv.org/abs/2502.09018v1,Machine Learning
230,Diversity Enhances an LLM's Performance in RAG and Long-context Task,"The rapid advancements in large language models (LLMs) have highlighted the
challenge of context window limitations, primarily due to the quadratic time
complexity of the self-attention mechanism (\(O(N^2)\), where \(N\) denotes the
context window length). This constraint impacts tasks such as
retrieval-augmented generation (RAG) in question answering (Q\&A) and long
context summarization. A common approach involves selecting content with the
highest similarity to the query; however, this often leads to redundancy and
the exclusion of diverse yet relevant information. Building on principles from
Maximal Marginal Relevance (MMR) and Farthest Point Sampling (FPS), we
integrate diversity into the content selection process. Our findings reveal
that incorporating diversity substantially increases the recall of selecting
relevant sentences or chunks before LLM-based Q\&A and summarization. These
results highlight the importance of maintaining diversity in future LLM
applications to further improve summarization and Q\&A outcomes.","Zhchao Wang, Bin Bi, Yanqi Luo, Sitaram Asur, Claire Na Cheng",2025-02-13 07:11:01.000000,arXiv,http://arxiv.org/abs/2502.09017v1,Natural Language Processing
231,Hope vs. Hate: Understanding User Interactions with LGBTQ+ News Content in Mainstream US News Media through the Lens of Hope Speech,"This paper makes three contributions. First, via a substantial corpus of
1,419,047 comments posted on 3,161 YouTube news videos of major US cable news
outlets, we analyze how users engage with LGBTQ+ news content. Our analyses
focus both on positive and negative content. In particular, we construct a
fine-grained hope speech classifier that detects positive (hope speech),
negative, neutral, and irrelevant content. Second, in consultation with a
public health expert specializing on LGBTQ+ health, we conduct an annotation
study with a balanced and diverse political representation and release a
dataset of 3,750 instances with fine-grained labels and detailed annotator
demographic information. Finally, beyond providing a vital resource for the
LGBTQ+ community, our annotation study and subsequent in-the-wild assessments
reveal (1) strong association between rater political beliefs and how they rate
content relevant to a marginalized community; (2) models trained on individual
political beliefs exhibit considerable in-the-wild disagreement; and (3)
zero-shot large language models (LLMs) align more with liberal raters.","Jonathan Pofcher, Christopher M. Homan, Randall Sell, Ashiqur R. KhudaBukhsh",2025-02-13 06:49:14.000000,arXiv,http://arxiv.org/abs/2502.09004v1,Natural Language Processing
232,RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models,"Supervised fine-tuning is a standard method for adapting pre-trained large
language models (LLMs) to downstream tasks. Quantization has been recently
studied as a post-training technique for efficient LLM deployment. To obtain
quantized fine-tuned LLMs, conventional pipelines would first fine-tune the
pre-trained models, followed by post-training quantization. This often yields
suboptimal performance as it fails to leverage the synergy between fine-tuning
and quantization. To effectively realize low-bit quantization of weights,
activations, and KV caches in LLMs, we propose an algorithm named Rotated
Straight-Through-Estimator (RoSTE), which combines quantization-aware
supervised fine-tuning (QA-SFT) with an adaptive rotation strategy that
identifies an effective rotation configuration to reduce activation outliers.
We provide theoretical insights on RoSTE by analyzing its prediction error when
applied to an overparameterized least square quantized training problem. Our
findings reveal that the prediction error is directly proportional to the
quantization error of the converged weights, which can be effectively managed
through an optimized rotation configuration. Experiments on Pythia and Llama
models of different sizes demonstrate the effectiveness of RoSTE. Compared to
existing post-SFT quantization baselines, our method consistently achieves
superior performances across various tasks and different LLM architectures.","Quan Wei, Chung-Yiu Yau, Hoi-To Wai, Yang, Zhao, Dongyeop Kang, Youngsuk Park, Mingyi Hong",2025-02-13 06:44:33.000000,arXiv,http://arxiv.org/abs/2502.09003v1,Machine Learning
233,End-to-End triplet loss based fine-tuning for network embedding in effective PII detection,"There are many approaches in mobile data ecosystem that inspect network
traffic generated by applications running on user's device to detect personal
data exfiltration from the user's device. State-of-the-art methods rely on
features extracted from HTTP requests and in this context, machine learning
involves training classifiers on these features and making predictions using
labelled packet traces. However, most of these methods include external feature
selection before model training. Deep learning, on the other hand, typically
does not require such techniques, as it can autonomously learn and identify
patterns in the data without external feature extraction or selection
algorithms. In this article, we propose a novel deep learning based end-to-end
learning framework for prediction of exposure of personally identifiable
information (PII) in mobile packets. The framework employs a pre-trained large
language model (LLM) and an autoencoder to generate embedding of network
packets and then uses a triplet-loss based fine-tuning method to train the
model, increasing detection effectiveness using two real-world datasets. We
compare our proposed detection framework with other state-of-the-art works in
detecting PII leaks from user's device.","Rishika Kohli, Shaifu Gupta, Manoj Singh Gaur",2025-02-13 06:43:46.000000,arXiv,http://arxiv.org/abs/2502.09002v1,Machine Learning
234,Privacy-Preserving Hybrid Ensemble Model for Network Anomaly Detection: Balancing Security and Data Protection,"Privacy-preserving network anomaly detection has become an essential area of
research due to growing concerns over the protection of sensitive data.
Traditional anomaly de- tection models often prioritize accuracy while
neglecting the critical aspect of privacy. In this work, we propose a hybrid
ensemble model that incorporates privacy-preserving techniques to address both
detection accuracy and data protection. Our model combines the strengths of
several machine learning algo- rithms, including K-Nearest Neighbors (KNN),
Support Vector Machines (SVM), XGBoost, and Artificial Neural Networks (ANN),
to create a robust system capable of identifying network anomalies while
ensuring privacy. The proposed approach in- tegrates advanced preprocessing
techniques that enhance data quality and address the challenges of small sample
sizes and imbalanced datasets. By embedding privacy measures into the model
design, our solution offers a significant advancement over existing methods,
ensuring both enhanced detection performance and strong privacy safeguards.","Shaobo Liu, Zihao Zhao, Weijie He, Jiren Wang, Jing Peng, Haoyuan Ma",2025-02-13 06:33:16.000000,arXiv,http://arxiv.org/abs/2502.09001v1,Machine Learning
235,Residual Transformer Fusion Network for Salt and Pepper Image Denoising,"Convolutional Neural Network (CNN) has been widely used in unstructured
datasets, one of which is image denoising. Image denoising is a noisy image
reconstruction process that aims to reduce additional noise that occurs from
the noisy image with various strategies. Image denoising has a problem, namely
that some image denoising methods require some prior knowledge of information
about noise. To overcome this problem, a combined architecture of Convolutional
Vision Transformer (CvT) and Residual Networks (ResNet) is used which is called
the Residual Transformer Fusion Network (RTF-Net). In general, the process in
this architecture can be divided into two parts, Noise Suppression Network
(NSN) and Structure Enhancement Network (SEN). Residual Block is used in the
Noise Suppression Network and is used to learn the noise map in the image,
while the CvT is used in the Structure Enhancement Network and is used to learn
the details that need to be added to the image processed by the Noise
Suppression Network. The model was trained using the DIV2K Training Set
dataset, and validation using the DIV2K Validation Set. After doing the
training, the model was tested using Lena, Bridge, Pepper, and BSD300 images
with noise levels ranging from 30%, 50%, and 70% and the PSNR results were
compared with the DBA, NASNLM, PARIGI, NLSF, NLSF-MLP and NLSF-CNN methods. The
test results show that the proposed method is superior in all cases except for
Pepper's image with a noise level of 30%, where NLSF-CNN is superior with a
PSNR value of 32.99 dB, while the proposed method gets a PSNR value of 31.70
dB.","Bintang Pradana Erlangga Putra, Heri Prasetyo, Esti Suryani",2025-02-13 06:32:19.000000,arXiv,http://arxiv.org/abs/2502.09000v1,Computer Vision
236,Hierarchical Vision Transformer with Prototypes for Interpretable Medical Image Classification,"Explainability is a highly demanded requirement for applications in high-risk
areas such as medicine. Vision Transformers have mainly been limited to
attention extraction to provide insight into the model's reasoning. Our
approach combines the high performance of Vision Transformers with the
introduction of new explainability capabilities. We present HierViT, a Vision
Transformer that is inherently interpretable and adapts its reasoning to that
of humans. A hierarchical structure is used to process domain-specific features
for prediction. It is interpretable by design, as it derives the target output
with human-defined features that are visualized by exemplary images
(prototypes). By incorporating domain knowledge about these decisive features,
the reasoning is semantically similar to human reasoning and therefore
intuitive. Moreover, attention heatmaps visualize the crucial regions for
identifying each feature, thereby providing HierViT with a versatile tool for
validating predictions. Evaluated on two medical benchmark datasets, LIDC-IDRI
for lung nodule assessment and derm7pt for skin lesion classification, HierViT
achieves superior and comparable prediction accuracy, respectively, while
offering explanations that align with human reasoning.","Luisa Gallée, Catharina Silvia Lisson, Meinrad Beer, Michael Götz",2025-02-13 06:24:07.000000,arXiv,http://arxiv.org/abs/2502.08997v1,Computer Vision
237,PixLift: Accelerating Web Browsing via AI Upscaling,"Accessing the internet in regions with expensive data plans and limited
connectivity poses significant challenges, restricting information access and
economic growth. Images, as a major contributor to webpage sizes, exacerbate
this issue, despite advances in compression formats like WebP and AVIF. The
continued growth of complex and curated web content, coupled with suboptimal
optimization practices in many regions, has prevented meaningful reductions in
web page sizes. This paper introduces PixLift, a novel solution to reduce
webpage sizes by downscaling their images during transmission and leveraging AI
models on user devices to upscale them. By trading computational resources for
bandwidth, PixLift enables more affordable and inclusive web access. We address
key challenges, including the feasibility of scaled image requests on popular
websites, the implementation of PixLift as a browser extension, and its impact
on user experience. Through the analysis of 71.4k webpages, evaluations of
three mainstream upscaling models, and a user study, we demonstrate PixLift's
ability to significantly reduce data usage without compromising image quality,
fostering a more equitable internet.","Yonas Atinafu, Sarthak Malla, HyunSeok Daniel Jang, Nouar Aldahoul, Matteo Varvello, Yasir Zaki",2025-02-13 06:14:59.000000,arXiv,http://arxiv.org/abs/2502.08995v1,Other
238,Off-Policy Evaluation for Recommendations with Missing-Not-At-Random Rewards,"Unbiased recommender learning (URL) and off-policy evaluation/learning
(OPE/L) techniques are effective in addressing the data bias caused by display
position and logging policies, thereby consistently improving the performance
of recommendations. However, when both bias exits in the logged data, these
estimators may suffer from significant bias. In this study, we first analyze
the position bias of the OPE estimator when rewards are missing not at random.
To mitigate both biases, we propose a novel estimator that leverages two
probabilities of logging policies and reward observations as propensity scores.
Our experiments demonstrate that the proposed estimator achieves superior
performance compared to other estimators, even as the levels of bias in reward
observations increases.","Tatsuki Takahashi, Chihiro Maru, Hiroko Shoji",2025-02-13 06:11:29.000000,arXiv,http://arxiv.org/abs/2502.08993v1,Statistical Machine Learning
239,Task Generalization With AutoRegressive Compositional Structure: Can Learning From $\d$ Tasks Generalize to $\d^{T}$ Tasks?,"Large language models (LLMs) exhibit remarkable task generalization, solving
tasks they were never explicitly trained on with only a few demonstrations.
This raises a fundamental question: When can learning from a small set of tasks
generalize to a large task family? In this paper, we investigate task
generalization through the lens of AutoRegressive Compositional (ARC)
structure, where each task is a composition of $T$ operations, and each
operation is among a finite family of $\d$ subtasks. This yields a total class
of size~\( \d^\TT \). We first show that generalization to all \( \d^\TT \)
tasks is theoretically achievable by training on only \( \tilde{O}(\d) \)
tasks. Empirically, we demonstrate that Transformers achieve such exponential
task generalization on sparse parity functions via in-context learning (ICL)
and Chain-of-Thought (CoT) reasoning. We further demonstrate this
generalization in arithmetic and language translation, extending beyond parity
functions.","Amirhesam Abedsoltan, Huaqing Zhang, Kaiyue Wen, Hongzhou Lin, Jingzhao Zhang, Mikhail Belkin",2025-02-13 06:08:01.000000,arXiv,http://arxiv.org/abs/2502.08991v1,Machine Learning
240,RLSA-PFL: Robust Lightweight Secure Aggregation with Model Inconsistency Detection in Privacy-Preserving Federated Learning,"Federated Learning (FL) allows users to collaboratively train a global
machine learning model by sharing local model only, without exposing their
private data to a central server. This distributed learning is particularly
appealing in scenarios where data privacy is crucial, and it has garnered
substantial attention from both industry and academia. However, studies have
revealed privacy vulnerabilities in FL, where adversaries can potentially infer
sensitive information from the shared model parameters. In this paper, we
present an efficient masking-based secure aggregation scheme utilizing
lightweight cryptographic primitives to mitigate privacy risks. Our scheme
offers several advantages over existing methods. First, it requires only a
single setup phase for the entire FL training session, significantly reducing
communication overhead. Second, it minimizes user-side overhead by eliminating
the need for user-to-user interactions, utilizing an intermediate server layer
and a lightweight key negotiation method. Third, the scheme is highly resilient
to user dropouts, and the users can join at any FL round. Fourth, it can detect
and defend against malicious server activities, including recently discovered
model inconsistency attacks. Finally, our scheme ensures security in both
semi-honest and malicious settings. We provide security analysis to formally
prove the robustness of our approach. Furthermore, we implemented an end-to-end
prototype of our scheme. We conducted comprehensive experiments and
comparisons, which show that it outperforms existing solutions in terms of
communication and computation overhead, functionality, and security.","Nazatul H. Sultan, Yan Bo, Yansong Gao, Seyit Camtepe, Arash Mahboubi, Hang Thanh Bui, Aufeef Chauhan, Hamed Aboutorab, Michael Bewong, Praveen Gauravaram, Rafiqul Islam, Sharif Abuadbba",2025-02-13 06:01:09.000000,arXiv,http://arxiv.org/abs/2502.08989v1,Other
241,Latents of latents to delineate pixels: hybrid Matryoshka autoencoder-to-U-Net pairing for segmenting large medical images in GPU-poor and low-data regimes,"Medical images are often high-resolution and lose important detail if
downsampled, making pixel-level methods such as semantic segmentation much less
efficient if performed on a low-dimensional image. We propose a low-rank
Matryoshka projection and a hybrid segmenting architecture that preserves
important information while retaining sufficient pixel geometry for pixel-level
tasks. We design the Matryoshka Autoencoder (MatAE-U-Net) which combines the
hierarchical encoding of the Matryoshka Autoencoder with the spatial
reconstruction capabilities of a U-Net decoder, leveraging multi-scale feature
extraction and skip connections to enhance accuracy and generalisation. We
apply it to the problem of segmenting the left ventricle (LV) in
echocardiographic images using the Stanford EchoNet-D dataset, including 1,000
standardised video-mask pairs of cardiac ultrasound videos resized to 112x112
pixels. The MatAE-UNet model achieves a Mean IoU of 77.68\%, Mean Pixel
Accuracy of 97.46\%, and Dice Coefficient of 86.91\%, outperforming the
baseline U-Net, which attains a Mean IoU of 74.70\%, Mean Pixel Accuracy of
97.31\%, and Dice Coefficient of 85.20\%. The results highlight the potential
of using the U-Net in the recursive Matroshka latent space for imaging problems
with low-contrast such as echocardiographic analysis.","Tahir Syed, Ariba Khan, Sawera Hanif",2025-02-13 05:51:41.000000,arXiv,http://arxiv.org/abs/2502.08988v1,Computer Vision
242,Neural Force Field: Learning Generalized Physical Representation from a Few Examples,"Physical reasoning is a remarkable human ability that enables rapid learning
and generalization from limited experience. Current AI models, despite
extensive training, still struggle to achieve similar generalization,
especially in Out-of-distribution (OOD) settings. This limitation stems from
their inability to abstract core physical principles from observations. A key
challenge is developing representations that can efficiently learn and
generalize physical dynamics from minimal data. Here we present Neural Force
Field (NFF) a modeling framework built on Neural Ordinary Differential Equation
(NODE) that learns interpretable force field representations which can be
efficiently integrated through an Ordinary Differential Equation ( ODE) solver
to predict object trajectories. Unlike existing approaches that rely on
high-dimensional latent spaces, NFF captures fundamental physical concepts such
as gravity, support, and collision in an interpretable manner. Experiments on
two challenging physical reasoning tasks demonstrate that NFF, trained with
only a few examples, achieves strong generalization to unseen scenarios. This
physics-grounded representation enables efficient forward-backward planning and
rapid adaptation through interactive refinement. Our work suggests that
incorporating physics-inspired representations into learning systems can help
bridge the gap between artificial and human physical reasoning capabilities.","Shiqian Li, Ruihong Shen, Chi Zhang, Yixin Zhu",2025-02-13 05:50:13.000000,arXiv,http://arxiv.org/abs/2502.08987v1,Machine Learning
243,Few is More: Task-Efficient Skill-Discovery for Multi-Task Offline Multi-Agent Reinforcement Learning,"As a data-driven approach, offline MARL learns superior policies solely from
offline datasets, ideal for domains rich in historical data but with high
interaction costs and risks. However, most existing methods are task-specific,
requiring retraining for new tasks, leading to redundancy and inefficiency. To
address this issue, in this paper, we propose a task-efficient multi-task
offline MARL algorithm, Skill-Discovery Conservative Q-Learning (SD-CQL).
Unlike existing offline skill-discovery methods, SD-CQL discovers skills by
reconstructing the next observation. It then evaluates fixed and variable
actions separately and employs behavior-regularized conservative Q-learning to
execute the optimal action for each skill. This approach eliminates the need
for local-global alignment and enables strong multi-task generalization from
limited small-scale source tasks. Substantial experiments on StarCraftII
demonstrates the superior generalization performance and task-efficiency of
SD-CQL. It achieves the best performance on $\textbf{10}$ out of $14$ task
sets, with up to $\textbf{65%}$ improvement on individual task sets, and is
within $4\%$ of the best baseline on the remaining four.","Xun Wang, Zhuoran Li, Hai Zhong, Longbo Huang",2025-02-13 05:47:57.000000,arXiv,http://arxiv.org/abs/2502.08985v1,Machine Learning
244,What exactly has TabPFN learned to do?,"TabPFN [Hollmann et al., 2023], a Transformer model pretrained to perform
in-context learning on fresh tabular classification problems, was presented at
the last ICLR conference. To better understand its behavior, we treat it as a
black-box function approximator generator and observe its generated function
approximations on a varied selection of training datasets. Exploring its
learned inductive biases in this manner, we observe behavior that is at turns
either brilliant or baffling. We conclude this post with thoughts on how these
results might inform the development, evaluation, and application of prior-data
fitted networks (PFNs) in the future.",Calvin McCarter,2025-02-13 05:28:29.000000,arXiv,http://arxiv.org/abs/2502.08978v1,Machine Learning
245,Text-driven 3D Human Generation via Contrastive Preference Optimization,"Recent advances in Score Distillation Sampling (SDS) have improved 3D human
generation from textual descriptions. However, existing methods still face
challenges in accurately aligning 3D models with long and complex textual
inputs. To address this challenge, we propose a novel framework that introduces
contrastive preferences, where human-level preference models, guided by both
positive and negative prompts, assist SDS for improved alignment. Specifically,
we design a preference optimization module that integrates multiple models to
comprehensively capture the full range of textual features. Furthermore, we
introduce a negation preference module to mitigate over-optimization of
irrelevant details by leveraging static-dynamic negation prompts, effectively
preventing ``reward hacking"". Extensive experiments demonstrate that our method
achieves state-of-the-art results, significantly enhancing texture realism and
visual alignment with textual descriptions, particularly for long and complex
inputs.","Pengfei Zhou, Xukun Shen, Yong Hu",2025-02-13 05:27:50.000000,arXiv,http://arxiv.org/abs/2502.08977v1,Computer Vision
246,"Small Molecule Drug Discovery Through Deep Learning:Progress, Challenges, and Opportunities","Due to their excellent drug-like and pharmacokinetic properties, small
molecule drugs are widely used to treat various diseases, making them a
critical component of drug discovery. In recent years, with the rapid
development of deep learning (DL) techniques, DL-based small molecule drug
discovery methods have achieved excellent performance in prediction accuracy,
speed, and complex molecular relationship modeling compared to traditional
machine learning approaches. These advancements enhance drug screening
efficiency and optimization, and they provide more precise and effective
solutions for various drug discovery tasks. Contributing to this field's
development, this paper aims to systematically summarize and generalize the
recent key tasks and representative techniques in DL-based small molecule drug
discovery in recent years. Specifically, we provide an overview of the major
tasks in small molecule drug discovery and their interrelationships. Next, we
analyze the six core tasks, summarizing the related methods, commonly used
datasets, and technological development trends. Finally, we discuss key
challenges, such as interpretability and out-of-distribution generalization,
and offer our insights into future research directions for DL-assisted small
molecule drug discovery.","Kun Li, Yida Xiong, Hongzhi Zhang, Xiantao Cai, Bo Du, Wenbin Hu",2025-02-13 05:24:52.000000,arXiv,http://arxiv.org/abs/2502.08975v1,Machine Learning
247,Topo2Seq: Enhanced Topology Reasoning via Topology Sequence Learning,"Extracting lane topology from perspective views (PV) is crucial for planning
and control in autonomous driving. This approach extracts potential drivable
trajectories for self-driving vehicles without relying on high-definition (HD)
maps. However, the unordered nature and weak long-range perception of the
DETR-like framework can result in misaligned segment endpoints and limited
topological prediction capabilities. Inspired by the learning of contextual
relationships in language models, the connectivity relations in roads can be
characterized as explicit topology sequences. In this paper, we introduce
Topo2Seq, a novel approach for enhancing topology reasoning via topology
sequences learning. The core concept of Topo2Seq is a randomized order
prompt-to-sequence learning between lane segment decoder and topology sequence
decoder. The dual-decoder branches simultaneously learn the lane topology
sequences extracted from the Directed Acyclic Graph (DAG) and the lane graph
containing geometric information. Randomized order prompt-to-sequence learning
extracts unordered key points from the lane graph predicted by the lane segment
decoder, which are then fed into the prompt design of the topology sequence
decoder to reconstruct an ordered and complete lane graph. In this way, the
lane segment decoder learns powerful long-range perception and accurate
topological reasoning from the topology sequence decoder. Notably, topology
sequence decoder is only introduced during training and does not affect the
inference efficiency. Experimental evaluations on the OpenLane-V2 dataset
demonstrate the state-of-the-art performance of Topo2Seq in topology reasoning.","Yiming Yang, Yueru Luo, Bingkun He, Erlong Li, Zhipeng Cao, Chao Zheng, Shuqi Mei, Zhen Li",2025-02-13 05:21:02.000000,arXiv,http://arxiv.org/abs/2502.08974v1,Computer Vision
248,Tuning-Free Personalized Alignment via Trial-Error-Explain In-Context Learning,"Language models are aligned to the collective voice of many, resulting in
generic outputs that do not align with specific users' styles. In this work, we
present Trial-Error-Explain In-Context Learning (TICL), a tuning-free method
that personalizes language models for text generation tasks with fewer than 10
examples per user. TICL iteratively expands an in-context learning prompt via a
trial-error-explain process, adding model-generated negative samples and
explanations that provide fine-grained guidance towards a specific user's
style. TICL achieves favorable win rates on pairwise comparisons with
LLM-as-a-judge up to 91.5% against the previous state-of-the-art and
outperforms competitive tuning-free baselines for personalized alignment tasks
of writing emails, essays and news articles. Both lexical and qualitative
analyses show that the negative samples and explanations enable language models
to learn stylistic context more effectively and overcome the bias towards
structural and formal phrases observed in their zero-shot outputs. By
front-loading inference compute to create a user-specific in-context learning
prompt that does not require extra generation steps at test time, TICL presents
a novel yet simple approach for personalized alignment.","Hyundong Cho, Karishma Sharma, Nicolaas Jedema, Leonardo F. R. Ribeiro, Alessandro Moschitti, Ravi Krishnan, Jonathan May",2025-02-13 05:20:21.000000,arXiv,http://arxiv.org/abs/2502.08972v1,Natural Language Processing
249,SkyRover: A Modular Simulator for Cross-Domain Pathfinding,"Unmanned Aerial Vehicles (UAVs) and Automated Guided Vehicles (AGVs)
increasingly collaborate in logistics, surveillance, inspection tasks and etc.
However, existing simulators often focus on a single domain, limiting
cross-domain study. This paper presents the SkyRover, a modular simulator for
UAV-AGV multi-agent pathfinding (MAPF). SkyRover supports realistic agent
dynamics, configurable 3D environments, and convenient APIs for external
solvers and learning methods. By unifying ground and aerial operations, it
facilitates cross-domain algorithm design, testing, and benchmarking.
Experiments highlight SkyRover's capacity for efficient pathfinding and
high-fidelity simulations in UAV-AGV coordination. Project is available at
https://sites.google.com/view/mapf3d/home.","Wenhui Ma, Wenhao Li, Bo Jin, Changhong Lu, Xiangfeng Wang",2025-02-13 05:13:21.000000,arXiv,http://arxiv.org/abs/2502.08969v1,Robotics
250,RTBAS: Defending LLM Agents Against Prompt Injection and Privacy Leakage,"Tool-Based Agent Systems (TBAS) allow Language Models (LMs) to use external
tools for tasks beyond their standalone capabilities, such as searching
websites, booking flights, or making financial transactions. However, these
tools greatly increase the risks of prompt injection attacks, where malicious
content hijacks the LM agent to leak confidential data or trigger harmful
actions. Existing defenses (OpenAI GPTs) require user confirmation before every
tool call, placing onerous burdens on users. We introduce Robust TBAS (RTBAS),
which automatically detects and executes tool calls that preserve integrity and
confidentiality, requiring user confirmation only when these safeguards cannot
be ensured. RTBAS adapts Information Flow Control to the unique challenges
presented by TBAS. We present two novel dependency screeners, using
LM-as-a-judge and attention-based saliency, to overcome these challenges.
Experimental results on the AgentDojo Prompt Injection benchmark show RTBAS
prevents all targeted attacks with only a 2% loss of task utility when under
attack, and further tests confirm its ability to obtain near-oracle performance
on detecting both subtle and direct privacy leaks.","Peter Yong Zhong, Siyuan Chen, Ruiqi Wang, McKenna McCall, Ben L. Titzer, Heather Miller",2025-02-13 05:06:22.000000,arXiv,http://arxiv.org/abs/2502.08966v1,Other
251,Modeling Time-evolving Causality over Data Streams,"Given an extensive, semi-infinite collection of multivariate coevolving data
sequences (e.g., sensor/web activity streams) whose observations influence each
other, how can we discover the time-changing cause-and-effect relationships in
co-evolving data streams? How efficiently can we reveal dynamical patterns that
allow us to forecast future values? In this paper, we present a novel streaming
method, ModePlait, which is designed for modeling such causal relationships
(i.e., time-evolving causality) in multivariate co-evolving data streams and
forecasting their future values. The solution relies on characteristics of the
causal relationships that evolve over time in accordance with the dynamic
changes of exogenous variables. ModePlait has the following properties: (a)
Effective: it discovers the time-evolving causality in multivariate co-evolving
data streams by detecting the transitions of distinct dynamical patterns
adaptively. (b) Accurate: it enables both the discovery of time-evolving
causality and the forecasting of future values in a streaming fashion. (c)
Scalable: our algorithm does not depend on data stream length and thus is
applicable to very large sequences. Extensive experiments on both synthetic and
real-world datasets demonstrate that our proposed model outperforms
state-of-the-art methods in terms of discovering the time-evolving causality as
well as forecasting.","Naoki Chihara, Yasuko Matsubara, Ren Fujiwara, Yasushi Sakurai",2025-02-13 04:59:01.000000,arXiv,http://arxiv.org/abs/2502.08963v1,Machine Learning
252,A Comprehensive Survey on Imbalanced Data Learning,"With the expansion of data availability, machine learning (ML) has achieved
remarkable breakthroughs in both academia and industry. However, imbalanced
data distributions are prevalent in various types of raw data and severely
hinder the performance of ML by biasing the decision-making processes. To
deepen the understanding of imbalanced data and facilitate the related research
and applications, this survey systematically analyzing various real-world data
formats and concludes existing researches for different data formats into four
distinct categories: data re-balancing, feature representation, training
strategy, and ensemble learning. This structured analysis help researchers
comprehensively understand the pervasive nature of imbalance across diverse
data format, thereby paving a clearer path toward achieving specific research
goals. we provide an overview of relevant open-source libraries, spotlight
current challenges, and offer novel insights aimed at fostering future
advancements in this critical area of study.","Xinyi Gao, Dongting Xie, Yihang Zhang, Zhengren Wang, Conghui He, Hongzhi Yin, Wentao Zhang",2025-02-13 04:53:17.000000,arXiv,http://arxiv.org/abs/2502.08960v1,Machine Learning
253,Biologically Plausible Brain Graph Transformer,"State-of-the-art brain graph analysis methods fail to fully encode the
small-world architecture of brain graphs (accompanied by the presence of hubs
and functional modules), and therefore lack biological plausibility to some
extent. This limitation hinders their ability to accurately represent the
brain's structural and functional properties, thereby restricting the
effectiveness of machine learning models in tasks such as brain disorder
detection. In this work, we propose a novel Biologically Plausible Brain Graph
Transformer (BioBGT) that encodes the small-world architecture inherent in
brain graphs. Specifically, we present a network entanglement-based node
importance encoding technique that captures the structural importance of nodes
in global information propagation during brain graph communication,
highlighting the biological properties of the brain structure. Furthermore, we
introduce a functional module-aware self-attention to preserve the functional
segregation and integration characteristics of brain graphs in the learned
representations. Experimental results on three benchmark datasets demonstrate
that BioBGT outperforms state-of-the-art models, enhancing biologically
plausible brain graph representations for various brain graph analytical tasks","Ciyuan Peng, Yuelong Huang, Qichao Dong, Shuo Yu, Feng Xia, Chengqi Zhang, Yaochu Jin",2025-02-13 04:51:18.000000,arXiv,http://arxiv.org/abs/2502.08958v1,Machine Learning
254,Training Trajectory Predictors Without Ground-Truth Data,"This paper presents a framework capable of accurately and smoothly estimating
position, heading, and velocity. Using this high-quality input, we propose a
system based on Trajectron++, able to consistently generate precise trajectory
predictions. Unlike conventional models that require ground-truth data for
training, our approach eliminates this dependency. Our analysis demonstrates
that poor quality input leads to noisy and unreliable predictions, which can be
detrimental to navigation modules. We evaluate both input data quality and
model output to illustrate the impact of input noise. Furthermore, we show that
our estimation system enables effective training of trajectory prediction
models even with limited data, producing robust predictions across different
environments. Accurate estimations are crucial for deploying trajectory
prediction models in real-world scenarios, and our system ensures meaningful
and reliable results across various application contexts.","Mikolaj Kliniewski, Jesse Morris, Ian R. Manchester, Viorela Ila",2025-02-13 04:49:14.000000,arXiv,http://arxiv.org/abs/2502.08957v1,Robotics
255,Medicine on the Edge: Comparative Performance Analysis of On-Device LLMs for Clinical Reasoning,"The deployment of Large Language Models (LLM) on mobile devices offers
significant potential for medical applications, enhancing privacy, security,
and cost-efficiency by eliminating reliance on cloud-based services and keeping
sensitive health data local. However, the performance and accuracy of on-device
LLMs in real-world medical contexts remain underexplored. In this study, we
benchmark publicly available on-device LLMs using the AMEGA dataset, evaluating
accuracy, computational efficiency, and thermal limitation across various
mobile devices. Our results indicate that compact general-purpose models like
Phi-3 Mini achieve a strong balance between speed and accuracy, while medically
fine-tuned models such as Med42 and Aloe attain the highest accuracy. Notably,
deploying LLMs on older devices remains feasible, with memory constraints
posing a greater challenge than raw processing power. Our study underscores the
potential of on-device LLMs for healthcare while emphasizing the need for more
efficient inference and models tailored to real-world clinical reasoning.","Leon Nissen, Philipp Zagar, Vishnu Ravi, Aydin Zahedivash, Lara Marie Reimer, Stephan Jonas, Oliver Aalami, Paul Schmiedmayer",2025-02-13 04:35:55.000000,arXiv,http://arxiv.org/abs/2502.08954v1,Natural Language Processing
256,Integrated Optimization and Game Theory Framework for Fair Cost Allocation in Community Microgrids,"Fair cost allocation in community microgrids remains a significant challenge
due to the complex interactions between multiple participants with varying load
profiles, distributed energy resources, and storage systems. Traditional cost
allocation methods often fail to adequately address the dynamic nature of
participant contributions and benefits, leading to inequitable distribution of
costs and reduced participant satisfaction. This paper presents a novel
framework integrating multi-objective optimization with cooperative game theory
for fair and efficient microgrid operation and cost allocation. The proposed
approach combines mixed-integer linear programming for optimal resource
dispatch with Shapley value analysis for equitable benefit distribution,
ensuring both system efficiency and participant satisfaction. The framework was
validated using real-world data across six distinct operational scenarios,
demonstrating significant improvements in both technical and economic
performance. Results show peak demand reductions ranging from 7.8% to 62.6%,
solar utilization rates reaching 114.8% through effective storage integration,
and cooperative gains of up to $1,801.01 per day. The Shapley value-based
allocation achieved balanced benefit-cost distributions, with net positions
ranging from -16.0% to +14.2% across different load categories, ensuring
sustainable participant cooperation.","K. Victor Sam Moses Babu, Pratyush Chakraborty, Mayukha Pal",2025-02-13 04:28:17.000000,arXiv,http://arxiv.org/abs/2502.08953v1,Other
257,Single-Agent Planning in a Multi-Agent System: A Unified Framework for Type-Based Planners,"We consider a general problem where an agent is in a multi-agent environment
and must plan for herself without any prior information about her opponents. At
each moment, this pivotal agent is faced with a trade-off between exploiting
her currently accumulated information about the other agents and exploring
further to improve future (re-)planning. We propose a theoretic framework that
unifies a spectrum of planners for the pivotal agent to address this trade-off.
The planner at one end of this spectrum aims to find exact solutions, while
those towards the other end yield approximate solutions as the problem scales
up. Beyond theoretical analysis, we also implement \textbf{13} planners and
conduct experiments in a specific domain called \textit{multi-agent route
planning} with the number of agents \textbf{up to~50}, to compare their
performaces in various scenarios. One interesting observation comes from a
class of planners that we call \textit{safe-agents} and their enhanced variants
by incorporating domain-specific knowledge, which is a simple special case
under the proposed general framework, but performs sufficiently well in most
cases. Our unified framework, as well as those induced planners, provides new
insights on multi-agent decision-making, with potential applications to related
areas such as mechanism design.","Fengming Zhu, Fangzhen Lin",2025-02-13 04:17:43.000000,arXiv,http://arxiv.org/abs/2502.08950v1,Multi-Agent Systems
258,Self-Supervised Graph Contrastive Pretraining for Device-level Integrated Circuits,"Self-supervised graph representation learning has driven significant
advancements in domains such as social network analysis, molecular design, and
electronics design automation (EDA). However, prior works in EDA have mainly
focused on the representation of gate-level digital circuits, failing to
capture analog and mixed-signal circuits. To address this gap, we introduce
DICE: Device-level Integrated Circuits Encoder, the first self-supervised
pretrained graph neural network (GNN) model for any circuit expressed at the
device level. DICE is a message-passing neural network (MPNN) trained through
graph contrastive learning, and its pretraining process is simulation-free,
incorporating two novel data augmentation techniques. Experimental results
demonstrate that DICE achieves substantial performance gains across three
downstream tasks, underscoring its effectiveness for both analog and digital
circuits.","Sungyoung Lee, Ziyi Wang, Seunggeun Kim, Taekyun Lee, David Z. Pan",2025-02-13 04:15:20.000000,arXiv,http://arxiv.org/abs/2502.08949v1,Machine Learning
259,Structured Convergence in Large Language Model Representations via Hierarchical Latent Space Folding,"Token representations in high-dimensional latent spaces often exhibit
redundancy, limiting computational efficiency and reducing structural coherence
across model layers. Hierarchical latent space folding introduces a structured
transformation mechanism that enforces a multi-scale organization within
learned embeddings, refining representational compactness while preserving
essential contextual distinctions. The proposed approach incorporates dynamic
folding operations that iteratively adjust token embeddings through structured
transformations, influencing both short-range and long-range dependencies in
sequential processing tasks. Empirical evaluation demonstrates a reduction in
representational variance across layers, contributing to more stable perplexity
distributions and enhancing predictive confidence in text generation. The
structured redistribution of attention head utilization leads to more efficient
allocation of computational resources, particularly in deeper layers, where
hierarchical refinements improve contextual abstraction. Comparative analysis
of activation sparsity patterns suggests that hierarchical adjustments
selectively reinforce critical pathways while reducing computational overhead
in non-essential regions of the model. Statistical assessments of token
reordering frequencies reveal that hierarchical modifications introduce subtle
shifts in sequential dependencies, improving contextual alignment while
maintaining syntactic correctness. Computational trade-offs associated with
hierarchical folding introduce marginal increases in training time per epoch,
yet empirical findings indicate that inference efficiency benefits from the
structured representation adjustments. The results highlight the impact of
hierarchical latent space folding on optimizing model performance through
improved representation structuring and computational efficiency.","Fenella Harcourt, Naderdel Piero, Gilbert Sutherland, Daphne Holloway, Harriet Bracknell, Julian Ormsby",2025-02-13 04:01:54.000000,arXiv,http://arxiv.org/abs/2502.08947v1,Natural Language Processing
260,The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of Physical Concept Understanding,"In a systematic way, we investigate a widely asked question: Do LLMs really
understand what they say?, which relates to the more familiar term Stochastic
Parrot. To this end, we propose a summative assessment over a carefully
designed physical concept understanding task, PhysiCo. Our task alleviates the
memorization issue via the usage of grid-format inputs that abstractly describe
physical phenomena. The grids represents varying levels of understanding, from
the core phenomenon, application examples to analogies to other abstract
patterns in the grid world. A comprehensive study on our task demonstrates: (1)
state-of-the-art LLMs, including GPT-4o, o1 and Gemini 2.0 flash thinking, lag
behind humans by ~40%; (2) the stochastic parrot phenomenon is present in LLMs,
as they fail on our grid task but can describe and recognize the same concepts
well in natural language; (3) our task challenges the LLMs due to intrinsic
difficulties rather than the unfamiliar grid format, as in-context learning and
fine-tuning on same formatted data added little to their performance.","Mo Yu, Lemao Liu, Junjie Wu, Tsz Ting Chung, Shunchi Zhang, Jiangnan Li, Dit-Yan Yeung, Jie Zhou",2025-02-13 04:00:03.000000,arXiv,http://arxiv.org/abs/2502.08946v1,Natural Language Processing
261,Beyond the Singular: The Essential Role of Multiple Generations in Effective Benchmark Evaluation and Analysis,"Large language models (LLMs) have demonstrated significant utilities in
real-world applications, exhibiting impressive capabilities in natural language
processing and understanding. Benchmark evaluations are crucial for assessing
the capabilities of LLMs as they can provide a comprehensive assessment of
their strengths and weaknesses. However, current evaluation methods often
overlook the inherent randomness of LLMs by employing deterministic generation
strategies or relying on a single random sample, resulting in unaccounted
sampling variance and unreliable benchmark score estimates. In this paper, we
propose a hierarchical statistical model that provides a more comprehensive
representation of the benchmarking process by incorporating both benchmark
characteristics and LLM randomness. We show that leveraging multiple
generations improves the accuracy of estimating the benchmark score and reduces
variance. We also introduce $\mathbb P\left(\text{correct}\right)$, a
prompt-level difficulty score based on correct ratios, providing fine-grained
insights into individual prompts. Additionally, we create a data map that
visualizes difficulty and semantic prompts, enabling error detection and
quality control in benchmark construction.","Wenbo Zhang, Hengrui Cai, Wenyu Chen",2025-02-13 03:43:33.000000,arXiv,http://arxiv.org/abs/2502.08943v1,Natural Language Processing
262,Language in the Flow of Time: Time-Series-Paired Texts Weaved into a Unified Temporal Narrative,"While many advances in time series models focus exclusively on numerical
data, research on multimodal time series, particularly those involving
contextual textual information commonly encountered in real-world scenarios,
remains in its infancy. Consequently, effectively integrating the text modality
remains challenging. In this work, we highlight an intuitive yet significant
observation that has been overlooked by existing works: time-series-paired
texts exhibit periodic properties that closely mirror those of the original
time series. Building on this insight, we propose a novel framework, Texts as
Time Series (TaTS), which considers the time-series-paired texts to be
auxiliary variables of the time series. TaTS can be plugged into any existing
numerical-only time series models and enable them to handle time series data
with paired texts effectively. Through extensive experiments on both multimodal
time series forecasting and imputation tasks across benchmark datasets with
various existing time series models, we demonstrate that TaTS can enhance
predictive performance and achieve outperformance without modifying model
architectures.","Zihao Li, Xiao Lin, Zhining Liu, Jiaru Zou, Ziwei Wu, Lecheng Zheng, Dongqi Fu, Yada Zhu, Hendrik Hamann, Hanghang Tong, Jingrui He",2025-02-13 03:43:27.000000,arXiv,http://arxiv.org/abs/2502.08942v1,Machine Learning
263,Analysis of Off-Policy $n$-Step TD-Learning with Linear Function Approximation,"This paper analyzes multi-step temporal difference (TD)-learning algorithms
within the ``deadly triad'' scenario, characterized by linear function
approximation, off-policy learning, and bootstrapping. In particular, we prove
that $n$-step TD-learning algorithms converge to a solution as the sampling
horizon $n$ increases sufficiently. The paper is divided into two parts. In the
first part, we comprehensively examine the fundamental properties of their
model-based deterministic counterparts, including projected value iteration,
gradient descent algorithms, which can be viewed as prototype deterministic
algorithms whose analysis plays a pivotal role in understanding and developing
their model-free reinforcement learning counterparts. In particular, we prove
that these algorithms converge to meaningful solutions when $n$ is sufficiently
large. Based on these findings, in the second part, two $n$-step TD-learning
algorithms are proposed and analyzed, which can be seen as the model-free
reinforcement learning counterparts of the model-based deterministic
algorithms.","Han-Dong Lim, Donghwan Lee",2025-02-13 03:43:13.000000,arXiv,http://arxiv.org/abs/2502.08941v1,Machine Learning
264,Towards Understanding Why Data Augmentation Improves Generalization,"Data augmentation is a cornerstone technique in deep learning, widely used to
improve model generalization. Traditional methods like random cropping and
color jittering, as well as advanced techniques such as CutOut, Mixup, and
CutMix, have achieved notable success across various domains. However, the
mechanisms by which data augmentation improves generalization remain poorly
understood, and existing theoretical analyses typically focus on individual
techniques without a unified explanation. In this work, we present a unified
theoretical framework that elucidates how data augmentation enhances
generalization through two key effects: partial semantic feature removal and
feature mixing. Partial semantic feature removal reduces the model's reliance
on individual feature, promoting diverse feature learning and better
generalization. Feature mixing, by scaling down original semantic features and
introducing noise, increases training complexity, driving the model to develop
more robust features. Advanced methods like CutMix integrate both effects,
achieving complementary benefits. Our theoretical insights are further
supported by experimental results, validating the effectiveness of this unified
perspective.","Jingyang Li, Jiachun Pan, Kim-Chuan Toh, Pan Zhou",2025-02-13 03:41:50.000000,arXiv,http://arxiv.org/abs/2502.08940v1,Computer Vision
265,TokenSynth: A Token-based Neural Synthesizer for Instrument Cloning and Text-to-Instrument,"Recent advancements in neural audio codecs have enabled the use of tokenized
audio representations in various audio generation tasks, such as
text-to-speech, text-to-audio, and text-to-music generation. Leveraging this
approach, we propose TokenSynth, a novel neural synthesizer that utilizes a
decoder-only transformer to generate desired audio tokens from MIDI tokens and
CLAP (Contrastive Language-Audio Pretraining) embedding, which has
timbre-related information. Our model is capable of performing instrument
cloning, text-to-instrument synthesis, and text-guided timbre manipulation
without any fine-tuning. This flexibility enables diverse sound design and
intuitive timbre control. We evaluated the quality of the synthesized audio,
the timbral similarity between synthesized and target audio/text, and synthesis
accuracy (i.e., how accurately it follows the input MIDI) using objective
measures. TokenSynth demonstrates the potential of leveraging advanced neural
audio codecs and transformers to create powerful and versatile neural
synthesizers. The source code, model weights, and audio demos are available at:
https://github.com/KyungsuKim42/tokensynth","Kyungsu Kim, Junghyun Koo, Sungho Lee, Haesun Joung, Kyogu Lee",2025-02-13 03:40:30.000000,arXiv,http://arxiv.org/abs/2502.08939v1,Other
266,Reevaluating Policy Gradient Methods for Imperfect-Information Games,"In the past decade, motivated by the putative failure of naive self-play deep
reinforcement learning (DRL) in adversarial imperfect-information games,
researchers have developed numerous DRL algorithms based on fictitious play
(FP), double oracle (DO), and counterfactual regret minimization (CFR). In
light of recent results of the magnetic mirror descent algorithm, we
hypothesize that simpler generic policy gradient methods like PPO are
competitive with or superior to these FP, DO, and CFR-based DRL approaches. To
facilitate the resolution of this hypothesis, we implement and release the
first broadly accessible exact exploitability computations for four large
games. Using these games, we conduct the largest-ever exploitability comparison
of DRL algorithms for imperfect-information games. Over 5600 training runs, FP,
DO, and CFR-based approaches fail to outperform generic policy gradient
methods. Code is available at https://github.com/nathanlct/IIG-RL-Benchmark and
https://github.com/gabrfarina/exp-a-spiel .","Max Rudolph, Nathan Lichtle, Sobhan Mohammadpour, Alexandre Bayen, J. Zico Kolter, Amy Zhang, Gabriele Farina, Eugene Vinitsky, Samuel Sokota",2025-02-13 03:38:41.000000,arXiv,http://arxiv.org/abs/2502.08938v1,Machine Learning
267,AutoLike: Auditing Social Media Recommendations through User Interactions,"Modern social media platforms, such as TikTok, Facebook, and YouTube, rely on
recommendation systems to personalize content for users based on user
interactions with endless streams of content, such as ""For You"" pages. However,
these complex algorithms can inadvertently deliver problematic content related
to self-harm, mental health, and eating disorders. We introduce AutoLike, a
framework to audit recommendation systems in social media platforms for topics
of interest and their sentiments. To automate the process, we formulate the
problem as a reinforcement learning problem. AutoLike drives the recommendation
system to serve a particular type of content through interactions (e.g.,
liking). We apply the AutoLike framework to the TikTok platform as a case
study. We evaluate how well AutoLike identifies TikTok content automatically
across nine topics of interest; and conduct eight experiments to demonstrate
how well it drives TikTok's recommendation system towards particular topics and
sentiments. AutoLike has the potential to assist regulators in auditing
recommendation systems for problematic content. (Warning: This paper contains
qualitative examples that may be viewed as offensive or harmful.)","Hieu Le, Salma Elmalaki, Zubair Shafiq, Athina Markopoulou",2025-02-13 03:32:44.000000,arXiv,http://arxiv.org/abs/2502.08933v1,Machine Learning
268,On the Promise for Assurance of Differentiable Neurosymbolic Reasoning Paradigms,"To create usable and deployable Artificial Intelligence (AI) systems, there
requires a level of assurance in performance under many different conditions.
Many times, deployed machine learning systems will require more classic logic
and reasoning performed through neurosymbolic programs jointly with artificial
neural network sensing. While many prior works have examined the assurance of a
single component of the system solely with either the neural network alone or
entire enterprise systems, very few works have examined the assurance of
integrated neurosymbolic systems. Within this work, we assess the assurance of
end-to-end fully differentiable neurosymbolic systems that are an emerging
method to create data-efficient and more interpretable models. We perform this
investigation using Scallop, an end-to-end neurosymbolic library, across
classification and reasoning tasks in both the image and audio domains. We
assess assurance across adversarial robustness, calibration, user performance
parity, and interpretability of solutions for catching misaligned solutions. We
find end-to-end neurosymbolic methods present unique opportunities for
assurance beyond their data efficiency through our empirical results but not
across the board. We find that this class of neurosymbolic models has higher
assurance in cases where arithmetic operations are defined and where there is
high dimensionality to the input space, where fully neural counterparts
struggle to learn robust reasoning operations. We identify the relationship
between neurosymbolic models' interpretability to catch shortcuts that later
result in increased adversarial vulnerability despite performance parity.
Finally, we find that the promise of data efficiency is typically only in the
case of class imbalanced reasoning problems.","Luke E. Richards, Jessie Yaros, Jasen Babcock, Coung Ly, Robin Cosbey, Timothy Doster, Cynthia Matuszek",2025-02-13 03:29:42.000000,arXiv,http://arxiv.org/abs/2502.08932v1,Artificial Intelligence
269,Dynamic watermarks in images generated by diffusion models,"High-fidelity text-to-image diffusion models have revolutionized visual
content generation, but their widespread use raises significant ethical
concerns, including intellectual property protection and the misuse of
synthetic media. To address these challenges, we propose a novel multi-stage
watermarking framework for diffusion models, designed to establish copyright
and trace generated images back to their source. Our multi-stage watermarking
technique involves embedding: (i) a fixed watermark that is localized in the
diffusion model's learned noise distribution and, (ii) a human-imperceptible,
dynamic watermark in generates images, leveraging a fine-tuned decoder. By
leveraging the Structural Similarity Index Measure (SSIM) and cosine
similarity, we adapt the watermark's shape and color to the generated content
while maintaining robustness. We demonstrate that our method enables reliable
source verification through watermark classification, even when the dynamic
watermark is adjusted for content-specific variations. Source model
verification is enabled through watermark classification. o support further
research, we generate a dataset of watermarked images and introduce a
methodology to evaluate the statistical impact of watermarking on generated
content.Additionally, we rigorously test our framework against various attack
scenarios, demonstrating its robustness and minimal impact on image quality.
Our work advances the field of AI-generated content security by providing a
scalable solution for model ownership verification and misuse prevention.","Yunzhuo Chen, Naveed Akhtar, Nur Al Hasan Haldar, Ajmal Mian",2025-02-13 03:23:17.000000,arXiv,http://arxiv.org/abs/2502.08927v1,Computer Vision
270,Escaping Collapse: The Strength of Weak Data for Large Language Model Training,"Synthetically-generated data plays an increasingly larger role in training
large language models. However, while synthetic data has been found to be
useful, studies have also shown that without proper curation it can cause LLM
performance to plateau, or even ""collapse"", after many training iterations. In
this paper, we formalize this question and develop a theoretical framework to
investigate how much curation is needed in order to ensure that LLM performance
continually improves. We find that the requirements are nearly minimal. We
describe a training procedure that converges to an optimal LLM even if almost
all of the non-synthetic training data is of poor quality. Our analysis is
inspired by boosting, a classic machine learning technique that leverages a
very weak learning algorithm to produce an arbitrarily good classifier. Our
training procedure subsumes many recently proposed methods for training LLMs on
synthetic data, and thus our analysis sheds light on why they are successful,
and also suggests opportunities for future improvement. We present experiments
that validate our theory, and show that dynamically focusing labeling resources
on the most challenging examples -- in much the same way that boosting focuses
the efforts of the weak learner -- leads to improved performance.","Kareem Amin, Sara Babakniya, Alex Bie, Weiwei Kong, Umar Syed, Sergei Vassilvitskii",2025-02-13 03:20:37.000000,arXiv,http://arxiv.org/abs/2502.08924v1,Machine Learning
271,CopySpec: Accelerating LLMs with Speculative Copy-and-Paste Without Compromising Quality,"We introduce CopySpec, an innovative technique designed to tackle the
inefficiencies LLMs face when generating responses that closely resemble
previous outputs. CopySpec identifies repeated sequences in the model's chat
history and speculates that the same tokens will follow, enabling seamless
copying without compromising output quality or requiring additional GPU memory.
To evaluate the effectiveness of our approach, we conducted experiments using
five LLMs and five datasets: MT-Bench, CNN/DM, GSM-8K, HumanEval, and our newly
created dataset, MT-Redundant. MT-Redundant, introduced in this paper,
transforms the second turn of MT-Bench into a request for variations of the
first turn's answer, simulating real-world scenarios where users request
modifications to prior responses. Our results demonstrate significant
speed-ups: up to 2.35x on CNN/DM, 3.08x on the second turn of select
MT-Redundant categories, and 2.66x on the third turn of GSM-8K's
self-correction tasks. Moreover, we show that CopySpec integrates seamlessly
with speculative decoding, yielding an average 49% additional speed-up over
speculative decoding for the second turn of MT-Redundant across all eight
categories. While LLMs, even with speculative decoding, suffer from slower
inference as context sizes grow, CopySpec leverages the expanded context to
accelerate inference, making it faster as the context size increases. Our code
and dataset are publicly available at https://github.com/RazvanDu/CopySpec.","Razvan-Gabriel Dumitru, Minglai Yang, Vikas Yadav, Mihai Surdeanu",2025-02-13 03:19:50.000000,arXiv,http://arxiv.org/abs/2502.08923v1,Natural Language Processing
272,Self-Consistency of the Internal Reward Models Improves Self-Rewarding Language Models,"Aligning Large Language Models (LLMs) with human preferences is crucial for
their deployment in real-world applications. Recent advancements in
Self-Rewarding Language Models suggest that an LLM can use its internal reward
models (such as LLM-as-a-Judge) \cite{yuanself} to generate preference data,
improving alignment performance without costly human annotation. However, we
find that different internal reward models within the same LLM often generate
inconsistent preferences. This inconsistency raises concerns about the
reliability of self-generated preference data, hinders overall alignment
performance, and highlights the need for further research to ensure reliable
and coherent alignment with human preferences. To address this limitation, we
propose Self-Consistent Internal Rewards (SCIR), a novel framework designed to
enhance consistency among internal reward models during training. In each
training step, we collect preference predictions from multiple pre-defined
internal reward models and enforce consistency and confidence through an
inconsistency penalty mechanism, thereby improving the reliability of these
internal reward models. We selectively use data with consistent predictions for
preference optimization, ensuring the quality of the preference data. By
employing self-consistent internal rewards, our method significantly improves
the alignment performance and reward modeling capability of LLMs, outperforming
baseline methods by a notable margin.","Xin Zhou, Yiwen Guo, Ruotian Ma, Tao Gui, Qi Zhang, Xuanjing Huang",2025-02-13 03:15:31.000000,arXiv,http://arxiv.org/abs/2502.08922v1,Artificial Intelligence
273,Detecting Malicious Concepts Without Image Generation in AIGC,"The task of text-to-image generation has achieved tremendous success in
practice, with emerging concept generation models capable of producing highly
personalized and customized content. Fervor for concept generation is
increasing rapidly among users, and platforms for concept sharing have sprung
up. The concept owners may upload malicious concepts and disguise them with
non-malicious text descriptions and example images to deceive users into
downloading and generating malicious content. The platform needs a quick method
to determine whether a concept is malicious to prevent the spread of malicious
concepts. However, simply relying on concept image generation to judge whether
a concept is malicious requires time and computational resources. Especially,
as the number of concepts uploaded and downloaded on the platform continues to
increase, this approach becomes impractical and poses a risk of generating
malicious content. In this paper, we propose Concept QuickLook, the first
systematic work to incorporate malicious concept detection into research, which
performs detection based solely on concept files without generating any images.
We define malicious concepts and design two work modes for detection: concept
matching and fuzzy detection. Extensive experiments demonstrate that the
proposed Concept QuickLook can detect malicious concepts and demonstrate
practicality in concept sharing platforms. We also design robustness
experiments to further validate the effectiveness of the solution. We hope this
work can initiate malicious concept detection tasks and provide some
inspiration.","Kun Xu, Yushu Zhang, Shuren Qi, Tao Wang, Wenying Wen, Yuming Fang",2025-02-13 03:15:18.000000,arXiv,http://arxiv.org/abs/2502.08921v1,Other
274,Exploring Emotion-Sensitive LLM-Based Conversational AI,"Conversational AI chatbots have become increasingly common within the
customer service industry. Despite improvements in their emotional development,
they often lack the authenticity of real customer service interactions or the
competence of service providers. By comparing emotion-sensitive and
emotion-insensitive LLM-based chatbots across 30 participants, we aim to
explore how emotional sensitivity in chatbots influences perceived competence
and overall customer satisfaction in service interactions. Additionally, we
employ sentiment analysis techniques to analyze and interpret the emotional
content of user inputs. We highlight that perceptions of chatbot
trustworthiness and competence were higher in the case of the emotion-sensitive
chatbot, even if issue resolution rates were not affected. We discuss
implications of improved user satisfaction from emotion-sensitive chatbots and
potential applications in support services.","Antonin Brun, Ruying Liu, Aryan Shukla, Frances Watson, Jonathan Gratch",2025-02-13 03:13:38.000000,arXiv,http://arxiv.org/abs/2502.08920v1,Other
275,CLEAR: Cluster-based Prompt Learning on Heterogeneous Graphs,"Prompt learning has attracted increasing attention in the graph domain as a
means to bridge the gap between pretext and downstream tasks. Existing studies
on heterogeneous graph prompting typically use feature prompts to modify node
features for specific downstream tasks, which do not concern the structure of
heterogeneous graphs. Such a design also overlooks information from the
meta-paths, which are core to learning the high-order semantics of the
heterogeneous graphs. To address these issues, we propose CLEAR, a
Cluster-based prompt LEARNING model on heterogeneous graphs. We present cluster
prompts that reformulate downstream tasks as heterogeneous graph
reconstruction. In this way, we align the pretext and downstream tasks to share
the same training objective. Additionally, our cluster prompts are also
injected into the meta-paths such that the prompt learning process incorporates
high-order semantic information entailed by the meta-paths. Extensive
experiments on downstream tasks confirm the superiority of CLEAR. It
consistently outperforms state-of-the-art models, achieving up to 5%
improvement on the F1 metric for node classification.","Feiyang Wang, Zhongbao Zhang, Junda Ye, Li Sun, Jianzhong Qi",2025-02-13 03:10:19.000000,arXiv,http://arxiv.org/abs/2502.08918v1,Machine Learning
276,PathFinder: A Multi-Modal Multi-Agent System for Medical Diagnostic Decision-Making Applied to Histopathology,"Diagnosing diseases through histopathology whole slide images (WSIs) is
fundamental in modern pathology but is challenged by the gigapixel scale and
complexity of WSIs. Trained histopathologists overcome this challenge by
navigating the WSI, looking for relevant patches, taking notes, and compiling
them to produce a final holistic diagnostic. Traditional AI approaches, such as
multiple instance learning and transformer-based models, fail short of such a
holistic, iterative, multi-scale diagnostic procedure, limiting their adoption
in the real-world. We introduce PathFinder, a multi-modal, multi-agent
framework that emulates the decision-making process of expert pathologists.
PathFinder integrates four AI agents, the Triage Agent, Navigation Agent,
Description Agent, and Diagnosis Agent, that collaboratively navigate WSIs,
gather evidence, and provide comprehensive diagnoses with natural language
explanations. The Triage Agent classifies the WSI as benign or risky; if risky,
the Navigation and Description Agents iteratively focus on significant regions,
generating importance maps and descriptive insights of sampled patches.
Finally, the Diagnosis Agent synthesizes the findings to determine the
patient's diagnostic classification. Our Experiments show that PathFinder
outperforms state-of-the-art methods in skin melanoma diagnosis by 8% while
offering inherent explainability through natural language descriptions of
diagnostically relevant patches. Qualitative analysis by pathologists shows
that the Description Agent's outputs are of high quality and comparable to
GPT-4o. PathFinder is also the first AI-based system to surpass the average
performance of pathologists in this challenging melanoma classification task by
9%, setting a new record for efficient, accurate, and interpretable AI-assisted
diagnostics in pathology. Data, code and models available at
https://pathfinder-dx.github.io/","Fatemeh Ghezloo, Mehmet Saygin Seyfioglu, Rustin Soraki, Wisdom O. Ikezogwo, Beibin Li, Tejoram Vivekanandan, Joann G. Elmore, Ranjay Krishna, Linda Shapiro",2025-02-13 03:08:02.000000,arXiv,http://arxiv.org/abs/2502.08916v1,Computer Vision
277,Diffusion Models Through a Global Lens: Are They Culturally Inclusive?,"Text-to-image diffusion models have recently enabled the creation of visually
compelling, detailed images from textual prompts. However, their ability to
accurately represent various cultural nuances remains an open question. In our
work, we introduce CultDiff benchmark, evaluating state-of-the-art diffusion
models whether they can generate culturally specific images spanning ten
countries. We show that these models often fail to generate cultural artifacts
in architecture, clothing, and food, especially for underrepresented country
regions, by conducting a fine-grained analysis of different similarity aspects,
revealing significant disparities in cultural relevance, description fidelity,
and realism compared to real-world reference images. With the collected human
evaluations, we develop a neural-based image-image similarity metric, namely,
CultDiff-S, to predict human judgment on real and generated images with
cultural artifacts. Our work highlights the need for more inclusive generative
AI systems and equitable dataset representation over a wide range of cultures.","Zahra Bayramli, Ayhan Suleymanzade, Na Min An, Huzama Ahmad, Eunsu Kim, Junyeong Park, James Thorne, Alice Oh",2025-02-13 03:05:42.000000,arXiv,http://arxiv.org/abs/2502.08914v1,Computer Vision
278,InfiniteHiP: Extending Language Model Context Up to 3 Million Tokens on a Single GPU,"In modern large language models (LLMs), handling very long context lengths
presents significant challenges as it causes slower inference speeds and
increased memory costs. Additionally, most existing pre-trained LLMs fail to
generalize beyond their original training sequence lengths. To enable efficient
and practical long-context utilization, we introduce InfiniteHiP, a novel, and
practical LLM inference framework that accelerates processing by dynamically
eliminating irrelevant context tokens through a modular hierarchical token
pruning algorithm. Our method also allows generalization to longer sequences by
selectively applying various RoPE adjustment methods according to the internal
attention patterns within LLMs. Furthermore, we offload the key-value cache to
host memory during inference, significantly reducing GPU memory pressure. As a
result, InfiniteHiP enables the processing of up to 3 million tokens on a
single L40s 48GB GPU -- 3x larger -- without any permanent loss of context
information. Our framework achieves an 18.95x speedup in attention decoding for
a 1 million token context without requiring additional training. We implement
our method in the SGLang framework and demonstrate its effectiveness and
practicality through extensive evaluations.","Heejun Lee, Geon Park, Jaduk Suh, Sung Ju Hwang",2025-02-13 02:52:01.000000,arXiv,http://arxiv.org/abs/2502.08910v1,Natural Language Processing
279,Towards Automated Fact-Checking of Real-World Claims: Exploring Task Formulation and Assessment with LLMs,"Fact-checking is necessary to address the increasing volume of
misinformation. Traditional fact-checking relies on manual analysis to verify
claims, but it is slow and resource-intensive. This study establishes baseline
comparisons for Automated Fact-Checking (AFC) using Large Language Models
(LLMs) across multiple labeling schemes (binary, three-class, five-class) and
extends traditional claim verification by incorporating analysis, verdict
classification, and explanation in a structured setup to provide comprehensive
justifications for real-world claims. We evaluate Llama-3 models of varying
sizes (3B, 8B, 70B) on 17,856 claims collected from PolitiFact (2007-2024)
using evidence retrieved via restricted web searches. We utilize TIGERScore as
a reference-free evaluation metric to score the justifications. Our results
show that larger LLMs consistently outperform smaller LLMs in classification
accuracy and justification quality without fine-tuning. We find that smaller
LLMs in a one-shot scenario provide comparable task performance to fine-tuned
Small Language Models (SLMs) with large context sizes, while larger LLMs
consistently surpass them. Evidence integration improves performance across all
models, with larger LLMs benefiting most. Distinguishing between nuanced labels
remains challenging, emphasizing the need for further exploration of labeling
schemes and alignment with evidences. Our findings demonstrate the potential of
retrieval-augmented AFC with LLMs.","Premtim Sahitaj, Iffat Maab, Junichi Yamagishi, Jawan Kolanowski, Sebastian Möller, Vera Schmitt",2025-02-13 02:51:17.000000,arXiv,http://arxiv.org/abs/2502.08909v1,Natural Language Processing
280,Reinforced Large Language Model is a formal theorem prover,"To take advantage of Large Language Model in theorem formalization and proof,
we propose a reinforcement learning framework to iteratively optimize the
pretrained LLM by rolling out next tactics and comparing them with the expected
ones. The experiment results show that it helps to achieve a higher accuracy
compared with directly fine-tuned LLM.",Zhiling Luo,2025-02-13 02:49:58.000000,arXiv,http://arxiv.org/abs/2502.08908v1,Artificial Intelligence
281,DiffoRA: Enabling Parameter-Efficient LLM Fine-Tuning via Differential Low-Rank Matrix Adaptation,"The Parameter-Efficient Fine-Tuning (PEFT) methods have been extensively
researched for large language models in the downstream tasks. Among all the
existing approaches, the Low-Rank Adaptation (LoRA) has gained popularity for
its streamlined design by incorporating low-rank matrices into existing
pre-trained models. Though effective, LoRA allocates every module an identical
low-rank matrix, which ignores the varying properties and contributions across
different components. Moreover, the existing adaptive LoRA solutions rely
highly on intuitive importance scoring indicators to adjust the interior rank
of the decomposition matrices. In this paper, we propose a new PEFT scheme
called DiffoRA, which is theoretically grounded and enables module-wise
adoption of LoRA. At the core of our DiffoRA lies a Differential Adaptation
Matrix (DAM) to determine which module is the most suitable and essential for
fine-tuning. We explain how the designed matrix impacts the convergence rate
and generalization capability of a pre-trained model. Furthermore, we construct
the DAM via continuous relaxation and discretization with weight-sharing
optimizations. We fully implement our DiffoRA and design comprehensive
experiments to evaluate its performance. The experimental results demonstrate
that our approach achieves the best model accuracy over all the
state-of-the-art baselines across various benchmarks.","Tangyu Jiang, Haodi Wang, Chun Yuan",2025-02-13 02:41:34.000000,arXiv,http://arxiv.org/abs/2502.08905v1,Computer Vision
282,MIH-TCCT: Mitigating Inconsistent Hallucinations in LLMs via Event-Driven Text-Code Cyclic Training,"Recent methodologies utilizing synthetic datasets have aimed to address
inconsistent hallucinations in large language models (LLMs); however,these
approaches are primarily tailored to specific tasks, limiting their
generalizability. Inspired by the strong performance of code-trained models in
logic-intensive domains, we propose a novel framework that leverages
event-based text to generate corresponding code and employs cyclic training to
transfer the logical consistency of code to natural language effectively. Our
method significantly reduces inconsistent hallucinations across three leading
LLMs and two categories of natural language tasks while maintaining overall
performance. This framework effectively alleviates hallucinations without
necessitating adaptation to downstream tasks, demonstrating generality and
providing new perspectives to tackle the challenge of inconsistent
hallucinations.","Xinxin You, Xien Liu, Qixin Sun, Huan Zhang, Kaiyin Zhou, Shaohui Liu, GuoPing Hu, ShiJin Wang, Si Liu, Ji Wu",2025-02-13 02:40:33.000000,arXiv,http://arxiv.org/abs/2502.08904v1,Artificial Intelligence
283,3D-Grounded Vision-Language Framework for Robotic Task Planning: Automated Prompt Synthesis and Supervised Reasoning,"Vision-language models (VLMs) have achieved remarkable success in scene
understanding and perception tasks, enabling robots to plan and execute actions
adaptively in dynamic environments. However, most multimodal large language
models lack robust 3D scene localization capabilities, limiting their
effectiveness in fine-grained robotic operations. Additionally, challenges such
as low recognition accuracy, inefficiency, poor transferability, and
reliability hinder their use in precision tasks. To address these limitations,
we propose a novel framework that integrates a 2D prompt synthesis module by
mapping 2D images to point clouds, and incorporates a small language model
(SLM) for supervising VLM outputs. The 2D prompt synthesis module enables VLMs,
trained on 2D images and text, to autonomously extract precise 3D spatial
information without manual intervention, significantly enhancing 3D scene
understanding. Meanwhile, the SLM supervises VLM outputs, mitigating
hallucinations and ensuring reliable, executable robotic control code
generation. Our framework eliminates the need for retraining in new
environments, thereby improving cost efficiency and operational robustness.
Experimental results that the proposed framework achieved a 96.0\% Task Success
Rate (TSR), outperforming other methods. Ablation studies demonstrated the
critical role of both the 2D prompt synthesis module and the output supervision
module (which, when removed, caused a 67\% TSR drop). These findings validate
the framework's effectiveness in improving 3D recognition, task planning, and
robotic task execution.","Guoqin Tang, Qingxuan Jia, Zeyuan Huang, Gang Chen, Ning Ji, Zhipeng Yao",2025-02-13 02:40:19.000000,arXiv,http://arxiv.org/abs/2502.08903v1,Robotics
284,CoL3D: Collaborative Learning of Single-view Depth and Camera Intrinsics for Metric 3D Shape Recovery,"Recovering the metric 3D shape from a single image is particularly relevant
for robotics and embodied intelligence applications, where accurate spatial
understanding is crucial for navigation and interaction with environments.
Usually, the mainstream approaches achieve it through monocular depth
estimation. However, without camera intrinsics, the 3D metric shape can not be
recovered from depth alone. In this study, we theoretically demonstrate that
depth serves as a 3D prior constraint for estimating camera intrinsics and
uncover the reciprocal relations between these two elements. Motivated by this,
we propose a collaborative learning framework for jointly estimating depth and
camera intrinsics, named CoL3D, to learn metric 3D shapes from single images.
Specifically, CoL3D adopts a unified network and performs collaborative
optimization at three levels: depth, camera intrinsics, and 3D point clouds.
For camera intrinsics, we design a canonical incidence field mechanism as a
prior that enables the model to learn the residual incident field for enhanced
calibration. Additionally, we incorporate a shape similarity measurement loss
in the point cloud space, which improves the quality of 3D shapes essential for
robotic applications. As a result, when training and testing on a single
dataset with in-domain settings, CoL3D delivers outstanding performance in both
depth estimation and camera calibration across several indoor and outdoor
benchmark datasets, which leads to remarkable 3D shape quality for the
perception capabilities of robots.","Chenghao Zhang, Lubin Fan, Shen Cao, Bojian Wu, Jieping Ye",2025-02-13 02:36:01.000000,arXiv,http://arxiv.org/abs/2502.08902v1,Computer Vision
285,Can Uniform Meaning Representation Help GPT-4 Translate from Indigenous Languages?,"While ChatGPT and GPT-based models are able to effectively perform many tasks
without additional fine-tuning, they struggle with related to extremely
low-resource languages and indigenous languages. Uniform Meaning Representation
(UMR), a semantic representation designed to capture the meaning of texts in
many languages, is well-poised to be leveraged in the development of
low-resource language technologies. In this work, we explore the downstream
technical utility of UMR for low-resource languages by incorporating it into
GPT-4 prompts. Specifically, we examine the ability of GPT-4 to perform
translation from three indigenous languages (Navajo, Ar\'apaho, and Kukama),
with and without demonstrations, as well as with and without UMR annotations.
Ultimately we find that in the majority of our test cases, integrating UMR into
the prompt results in a statistically significant increase in performance,
which is a promising indication of future applications of the UMR formalism.",Shira Wein,2025-02-13 02:27:30.000000,arXiv,http://arxiv.org/abs/2502.08900v1,Natural Language Processing
286,Learning in Strategic Queuing Systems with Small Buffers,"Routers in networking use simple learning algorithms to find the best way to
deliver packets to their desired destination. This simple, myopic and
distributed decision system makes large queuing systems simple to operate, but
at the same time, the system needs more capacity than would be required if all
traffic were centrally coordinated. In a recent paper, Gaitonde and Tardos (EC
2020 and JACM 2023) initiate the study of such systems, modeling them as an
infinitely repeated game in which routers compete for servers and the system
maintains a state (number of packets held by each queue) resulting from
outcomes of previous rounds. Queues get to send a packet at each step to one of
the servers, and servers attempt to process only one of the arriving packets,
modeling routers. However, their model assumes that servers have no buffers at
all, so queues have to resend all packets that were not served successfully.
They show that, even with hugely increased server capacity relative to what is
needed in the centrally-coordinated case, ensuring that the system is stable
requires using timestamps and priority for older packets. We consider a system
with two important changes, which make the model more realistic: first we add a
very small buffer to each server, allowing it to hold on to a single packet to
be served later (even if it fails to serve it); and second, we do not require
timestamps or priority for older packets. Our main result is to show that when
queues are learning, a small constant factor increase in server capacity,
compared to what would be needed if centrally coordinating, suffices to keep
the system stable, even if servers select randomly among packets arriving
simultaneously. This work contributes to the growing literature on the impact
of selfish learning in systems with carryover effects between rounds: when
outcomes in the present round affect the game in the future.","Ariana Abel, Yoav Kolumbus, Jeronimo Martin Duque, Eva Tardos",2025-02-13 02:23:23.000000,arXiv,http://arxiv.org/abs/2502.08898v1,Other
287,Communication is All You Need: Persuasion Dataset Construction via Multi-LLM Communication,"Large Language Models (LLMs) have shown proficiency in generating persuasive
dialogue, yet concerns about the fluency and sophistication of their outputs
persist. This paper presents a multi-LLM communication framework designed to
enhance the generation of persuasive data automatically. This framework
facilitates the efficient production of high-quality, diverse linguistic
content with minimal human oversight. Through extensive evaluations, we
demonstrate that the generated data excels in naturalness, linguistic
diversity, and the strategic use of persuasion, even in complex scenarios
involving social taboos. The framework also proves adept at generalizing across
novel contexts. Our results highlight the framework's potential to
significantly advance research in both computational and social science domains
concerning persuasive communication.","Weicheng Ma, Hefan Zhang, Ivory Yang, Shiyu Ji, Joice Chen, Farnoosh Hashemi, Shubham Mohole, Ethan Gearey, Michael Macy, Saeed Hassanpour, Soroush Vosoughi",2025-02-13 02:22:48.000000,arXiv,http://arxiv.org/abs/2502.08896v1,Natural Language Processing
288,Linear-Time User-Level DP-SCO via Robust Statistics,"User-level differentially private stochastic convex optimization (DP-SCO) has
garnered significant attention due to the paramount importance of safeguarding
user privacy in modern large-scale machine learning applications. Current
methods, such as those based on differentially private stochastic gradient
descent (DP-SGD), often struggle with high noise accumulation and suboptimal
utility due to the need to privatize every intermediate iterate. In this work,
we introduce a novel linear-time algorithm that leverages robust statistics,
specifically the median and trimmed mean, to overcome these challenges. Our
approach uniquely bounds the sensitivity of all intermediate iterates of SGD
with gradient estimation based on robust statistics, thereby significantly
reducing the gradient estimation noise for privacy purposes and enhancing the
privacy-utility trade-off. By sidestepping the repeated privatization required
by previous methods, our algorithm not only achieves an improved theoretical
privacy-utility trade-off but also maintains computational efficiency. We
complement our algorithm with an information-theoretic lower bound, showing
that our upper bound is optimal up to logarithmic factors and the dependence on
$\epsilon$. This work sets the stage for more robust and efficient
privacy-preserving techniques in machine learning, with implications for future
research and application in the field.","Badih Ghazi, Ravi Kumar, Daogao Liu, Pasin Manurangsi",2025-02-13 02:05:45.000000,arXiv,http://arxiv.org/abs/2502.08889v1,Machine Learning
289,LLM-Enhanced Multiple Instance Learning for Joint Rumor and Stance Detection with Social Context Information,"The proliferation of misinformation, such as rumors on social media, has
drawn significant attention, prompting various expressions of stance among
users. Although rumor detection and stance detection are distinct tasks, they
can complement each other. Rumors can be identified by cross-referencing
stances in related posts, and stances are influenced by the nature of the
rumor. However, existing stance detection methods often require post-level
stance annotations, which are costly to obtain. We propose a novel LLM-enhanced
MIL approach to jointly predict post stance and claim class labels, supervised
solely by claim labels, using an undirected microblog propagation model. Our
weakly supervised approach relies only on bag-level labels of claim veracity,
aligning with multi-instance learning (MIL) principles. To achieve this, we
transform the multi-class problem into multiple MIL-based binary classification
problems. We then employ a discriminative attention layer to aggregate the
outputs from these classifiers into finer-grained classes. Experiments
conducted on three rumor datasets and two stance datasets demonstrate the
effectiveness of our approach, highlighting strong connections between rumor
veracity and expressed stances in responding posts. Our method shows promising
performance in joint rumor and stance detection compared to the
state-of-the-art methods.","Ruichao Yang, Jing Ma, Wei Gao, Hongzhan Lin",2025-02-13 02:03:30.000000,arXiv,http://arxiv.org/abs/2502.08888v1,Natural Language Processing
290,Generative AI for Internet of Things Security: Challenges and Opportunities,"As Generative AI (GenAI) continues to gain prominence and utility across
various sectors, their integration into the realm of Internet of Things (IoT)
security evolves rapidly. This work delves into an examination of the
state-of-the-art literature and practical applications on how GenAI could
improve and be applied in the security landscape of IoT. Our investigation aims
to map the current state of GenAI implementation within IoT security, exploring
their potential to fortify security measures further. Through the compilation,
synthesis, and analysis of the latest advancements in GenAI technologies
applied to IoT, this paper not only introduces fresh insights into the field,
but also lays the groundwork for future research directions. It explains the
prevailing challenges within IoT security, discusses the effectiveness of GenAI
in addressing these issues, and identifies significant research gaps through
MITRE Mitigations. Accompanied with three case studies, we provide a
comprehensive overview of the progress and future prospects of GenAI
applications in IoT security. This study serves as a foundational resource to
improve IoT security through the innovative application of GenAI, thus
contributing to the broader discourse on IoT security and technology
integration.","Yan Lin Aung, Ivan Christian, Ye Dong, Xiaodong Ye, Sudipta Chattopadhyay, Jianying Zhou",2025-02-13 01:55:43.000000,arXiv,http://arxiv.org/abs/2502.08886v1,Other
291,ShapeLib: designing a library of procedural 3D shape abstractions with Large Language Models,"Procedural representations are desirable, versatile, and popular shape
encodings. Authoring them, either manually or using data-driven procedures,
remains challenging, as a well-designed procedural representation should be
compact, intuitive, and easy to manipulate. A long-standing problem in shape
analysis studies how to discover a reusable library of procedural functions,
with semantically aligned exposed parameters, that can explain an entire shape
family. We present ShapeLib as the first method that leverages the priors of
frontier LLMs to design a library of 3D shape abstraction functions. Our system
accepts two forms of design intent: text descriptions of functions to include
in the library and a seed set of exemplar shapes. We discover procedural
abstractions that match this design intent by proposing, and then validating,
function applications and implementations. The discovered shape functions in
the library are not only expressive but also generalize beyond the seed set to
a full family of shapes. We train a recognition network that learns to infer
shape programs based on our library from different visual modalities
(primitives, voxels, point clouds). Our shape functions have parameters that
are semantically interpretable and can be modified to produce plausible shape
variations. We show that this allows inferred programs to be successfully
manipulated by an LLM given a text prompt. We evaluate ShapeLib on different
datasets and show clear advantages over existing methods and alternative
formulations.","R. Kenny Jones, Paul Guerrero, Niloy J. Mitra, Daniel Ritchie",2025-02-13 01:52:02.000000,arXiv,http://arxiv.org/abs/2502.08884v1,Computer Vision
292,2D Integrated Bayesian Tomography of Plasma Electron Density Profile for HL-3 Based on Gaussian Process,"This paper introduces an integrated Bayesian model that combines line
integral measurements and point values using Gaussian Process (GP). The
proposed method leverages Gaussian Process Regression (GPR) to incorporate
point values into 2D profiles and employs coordinate mapping to integrate
magnetic flux information for 2D inversion. The average relative error of the
reconstructed profile, using the integrated Bayesian tomography model with
normalized magnetic flux, is as low as 3.60*10^(-4). Additionally, sensitivity
tests were conducted on the number of grids, the standard deviation of
synthetic diagnostic data, and noise levels, laying a solid foundation for the
application of the model to experimental data. This work not only achieves
accurate 2D inversion using the integrated Bayesian model but also provides a
robust framework for decoupling pressure information from equilibrium
reconstruction, thus making it possible to optimize equilibrium reconstruction
using inversion results.","Cong Wang, Renjie Yang, Dong Li, Zongyu Yang, Zhijun Wang, Yixiong Wei, Jing Li",2025-02-13 01:43:14.000000,arXiv,http://arxiv.org/abs/2502.08882v1,Machine Learning
293,WENDy for Nonlinear-in-Parameter ODEs,"The Weak-form Estimation of Non-linear Dynamics (WENDy) algorithm is extended
to accommodate systems of ordinary differential equations that are
nonlinear-in-parameters (NiP). The extension rests on derived analytic
expressions for a likelihood function, its gradient and its Hessian matrix.
WENDy makes use of these to approximate a maximum likelihood estimator based on
optimization routines suited for non-convex optimization problems. The
resulting parameter estimation algorithm has better accuracy, a substantially
larger domain of convergence, and is often orders of magnitude faster than the
conventional output error least squares method (based on forward solvers).
  The WENDy.jl algorithm is efficiently implemented in Julia. We demonstrate
the algorithm's ability to accommodate the weak form optimization for both
additive normal and multiplicative log-normal noise, and present results on a
suite of benchmark systems of ordinary differential equations. In order to
demonstrate the practical benefits of our approach, we present extensive
comparisons between our method and output error methods in terms of accuracy,
precision, bias, and coverage.","Nic Rummel, Daniel A. Messenger, Stephen Becker, Vanja Dukic, David M. Bortz",2025-02-13 01:40:21.000000,arXiv,http://arxiv.org/abs/2502.08881v1,Machine Learning
294,Data Sensor Fusion In Digital Twin Technology For Enhanced Capabilities In A Home Environment,"This paper investigates the integration of data sensor fusion in digital twin
technology to bolster home environment capabilities, particularly in the
context of challenges brought on by the coronavirus pandemic and its economic
effects. The study underscores the crucial role of digital transformation in
not just adapting to, but also mitigating disruptions during the fourth
industrial revolution. Using the Wit Motion sensor, data was collected for
activities such as walking, working, sitting, and lying, with sensors measuring
accelerometers, gyroscopes, and magnetometers. The research integrates
Cyber-physical systems, IoT, AI, and robotics to fortify digital twin
capabilities.
  The paper compares sensor fusion methods, including feature-level fusion,
decision-level fusion, and Kalman filter fusion, alongside machine learning
models like SVM, GBoost, and Random Forest to assess model effectiveness.
Results show that sensor fusion significantly improves the accuracy and
reliability of these models, as it compensates for individual sensor
weaknesses, particularly with magnetometers. Despite higher accuracy in ideal
conditions, integrating data from multiple sensors ensures more consistent and
reliable results in real-world settings, thereby establishing a robust system
that can be confidently applied in practical scenarios.","Benjamin Momoh, Salisu Yahaya",2025-02-13 01:14:30.000000,arXiv,http://arxiv.org/abs/2502.08874v1,Artificial Intelligence
295,Robust Graph-Based Semi-Supervised Learning via $p$-Conductances,"We study the problem of semi-supervised learning on graphs in the regime
where data labels are scarce or possibly corrupted. We propose an approach
called $p$-conductance learning that generalizes the $p$-Laplace and Poisson
learning methods by introducing an objective reminiscent of $p$-Laplacian
regularization and an affine relaxation of the label constraints. This leads to
a family of probability measure mincut programs that balance sparse edge
removal with accurate distribution separation. Our theoretical analysis
connects these programs to well-known variational and probabilistic problems on
graphs (including randomized cuts, effective resistance, and Wasserstein
distance) and provides motivation for robustness when labels are diffused via
the heat kernel. Computationally, we develop a semismooth Newton-conjugate
gradient algorithm and extend it to incorporate class-size estimates when
converting the continuous solutions into label assignments. Empirical results
on computer vision and citation datasets demonstrate that our approach achieves
state-of-the-art accuracy in low label-rate, corrupted-label, and partial-label
regimes.","Sawyer Jack Robertson, Chester Holtz, Zhengchao Wan, Gal Mishne, Alexander Cloninger",2025-02-13 01:11:25.000000,arXiv,http://arxiv.org/abs/2502.08873v1,Machine Learning
296,When and why randomised exploration works (in linear bandits),"We provide an approach for the analysis of randomised exploration algorithms
like Thompson sampling that does not rely on forced optimism or posterior
inflation. With this, we demonstrate that in the $d$-dimensional linear bandit
setting, when the action space is smooth and strongly convex, randomised
exploration algorithms enjoy an $n$-step regret bound of the order $O(d\sqrt{n}
\log(n))$. Notably, this shows for the first time that there exist non-trivial
linear bandit settings where Thompson sampling can achieve optimal dimension
dependence in the regret.","Marc Abeille, David Janz, Ciara Pike-Burke",2025-02-13 00:49:28.000000,arXiv,http://arxiv.org/abs/2502.08870v1,Machine Learning
297,Harnessing Vision Models for Time Series Analysis: A Survey,"Time series analysis has witnessed the inspiring development from traditional
autoregressive models, deep learning models, to recent Transformers and Large
Language Models (LLMs). Efforts in leveraging vision models for time series
analysis have also been made along the way but are less visible to the
community due to the predominant research on sequence modeling in this domain.
However, the discrepancy between continuous time series and the discrete token
space of LLMs, and the challenges in explicitly modeling the correlations of
variates in multivariate time series have shifted some research attentions to
the equally successful Large Vision Models (LVMs) and Vision Language Models
(VLMs). To fill the blank in the existing literature, this survey discusses the
advantages of vision models over LLMs in time series analysis. It provides a
comprehensive and in-depth overview of the existing methods, with dual views of
detailed taxonomy that answer the key research questions including how to
encode time series as images and how to model the imaged time series for
various tasks. Additionally, we address the challenges in the pre- and
post-processing steps involved in this framework and outline future directions
to further advance time series analysis with vision models.","Jingchao Ni, Ziming Zhao, ChengAo Shen, Hanghang Tong, Dongjin Song, Wei Cheng, Dongsheng Luo, Haifeng Chen",2025-02-13 00:42:11.000000,arXiv,http://arxiv.org/abs/2502.08869v1,Machine Learning
298,BrainWavLM: Fine-tuning Speech Representations with Brain Responses to Language,"Speech encoding models use auditory representations to predict how the human
brain responds to spoken language stimuli. Most performant encoding models
linearly map the hidden states of artificial neural networks to brain data, but
this linear restriction may limit their effectiveness. In this work, we use
low-rank adaptation (LoRA) to fine-tune a WavLM-based encoding model end-to-end
on a brain encoding objective, producing a model we name BrainWavLM. We show
that fine-tuning across all of cortex improves average encoding performance
with greater stability than without LoRA. This improvement comes at the expense
of low-level regions like auditory cortex (AC), but selectively fine-tuning on
these areas improves performance in AC, while largely retaining gains made in
the rest of cortex. Fine-tuned models generalized across subjects, indicating
that they learned robust brain-like representations of the speech stimuli.
Finally, by training linear probes, we showed that the brain data strengthened
semantic representations in the speech model without any explicit annotations.
Our results demonstrate that brain fine-tuning produces best-in-class speech
encoding models, and that non-linear methods have the potential to bridge the
gap between artificial and biological representations of semantics.","Nishitha Vattikonda, Aditya R. Vaidya, Richard J. Antonello, Alexander G. Huth",2025-02-13 00:37:27.000000,arXiv,http://arxiv.org/abs/2502.08866v1,Natural Language Processing
299,Off-Switching Not Guaranteed,"Hadfield-Menell et al. (2017) propose the Off-Switch Game, a model of
Human-AI cooperation in which AI agents always defer to humans because they are
uncertain about our preferences. I explain two reasons why AI agents might not
defer. First, AI agents might not value learning. Second, even if AI agents
value learning, they might not be certain to learn our actual preferences.",Sven Neth,2025-02-13 00:31:21.000000,arXiv,http://arxiv.org/abs/2502.08864v1,Artificial Intelligence
300,Brain in the Dark: Design Principles for Neuromimetic Inference under the Free Energy Principle,"Deep learning has revolutionised artificial intelligence (AI) by enabling
automatic feature extraction and function approximation from raw data. However,
it faces challenges such as a lack of out-of-distribution generalisation,
catastrophic forgetting and poor interpretability. In contrast, biological
neural networks, such as those in the human brain, do not suffer from these
issues, inspiring AI researchers to explore neuromimetic deep learning, which
aims to replicate brain mechanisms within AI models. A foundational theory for
this approach is the Free Energy Principle (FEP), which despite its potential,
is often considered too complex to understand and implement in AI as it
requires an interdisciplinary understanding across a variety of fields. This
paper seeks to demystify the FEP and provide a comprehensive framework for
designing neuromimetic models with human-like perception capabilities. We
present a roadmap for implementing these models and a Pytorch code repository
for applying FEP in a predictive coding network.","Mehran H. Bazargani, Szymon Urbas, Karl Friston",2025-02-13 00:18:47.000000,arXiv,http://arxiv.org/abs/2502.08860v1,Neural Networks
301,EnigmaEval: A Benchmark of Long Multimodal Reasoning Challenges,"As language models master existing reasoning benchmarks, we need new
challenges to evaluate their cognitive frontiers. Puzzle-solving events are
rich repositories of challenging multimodal problems that test a wide range of
advanced reasoning and knowledge capabilities, making them a unique testbed for
evaluating frontier language models. We introduce EnigmaEval, a dataset of
problems and solutions derived from puzzle competitions and events that probes
models' ability to perform implicit knowledge synthesis and multi-step
deductive reasoning. Unlike existing reasoning and knowledge benchmarks, puzzle
solving challenges models to discover hidden connections between seemingly
unrelated pieces of information to uncover solution paths. The benchmark
comprises 1184 puzzles of varying complexity -- each typically requiring teams
of skilled solvers hours to days to complete -- with unambiguous, verifiable
solutions that enable efficient evaluation. State-of-the-art language models
achieve extremely low accuracy on these puzzles, even lower than other
difficult benchmarks such as Humanity's Last Exam, unveiling models'
shortcomings when challenged with problems requiring unstructured and lateral
reasoning.","Clinton J. Wang, Dean Lee, Cristina Menghini, Johannes Mols, Jack Doughty, Adam Khoja, Jayson Lynch, Sean Hendryx, Summer Yue, Dan Hendrycks",2025-02-13 00:18:34.000000,arXiv,http://arxiv.org/abs/2502.08859v1,Artificial Intelligence
302,Estimating Probabilities of Causation with Machine Learning Models,"Probabilities of causation play a crucial role in modern decision-making.
This paper addresses the challenge of predicting probabilities of causation for
subpopulations with insufficient data using machine learning models. Tian and
Pearl first defined and derived tight bounds for three fundamental
probabilities of causation: the probability of necessity and sufficiency (PNS),
the probability of sufficiency (PS), and the probability of necessity (PN).
However, estimating these probabilities requires both experimental and
observational distributions specific to each subpopulation, which are often
unavailable or impractical to obtain with limited population-level data. We
assume that the probabilities of causation for each subpopulation are
determined by its characteristics. To estimate these probabilities for
subpopulations with insufficient data, we propose using machine learning models
that draw insights from subpopulations with sufficient data. Our evaluation of
multiple machine learning models indicates that, given sufficient
population-level data and an appropriate choice of machine learning model and
activation function, PNS can be effectively predicted. Through simulation
studies, we show that our multilayer perceptron (MLP) model with the Mish
activation function achieves a mean absolute error (MAE) of approximately 0.02
in predicting PNS for 32,768 subpopulations using data from around 2,000
subpopulations.","Shuai Wang, Ang Li",2025-02-13 00:18:08.000000,arXiv,http://arxiv.org/abs/2502.08858v1,Artificial Intelligence
303,A Systematic Evaluation of Generative Models on Tabular Transportation Data,"The sharing of large-scale transportation data is beneficial for
transportation planning and policymaking. However, it also raises significant
security and privacy concerns, as the data may include identifiable personal
information, such as individuals' home locations. To address these concerns,
synthetic data generation based on real transportation data offers a promising
solution that allows privacy protection while potentially preserving data
utility. Although there are various synthetic data generation techniques, they
are often not tailored to the unique characteristics of transportation data,
such as the inherent structure of transportation networks formed by all trips
in the datasets. In this paper, we use New York City taxi data as a case study
to conduct a systematic evaluation of the performance of widely used tabular
data generative models. In addition to traditional metrics such as distribution
similarity, coverage, and privacy preservation, we propose a novel graph-based
metric tailored specifically for transportation data. This metric evaluates the
similarity between real and synthetic transportation networks, providing
potentially deeper insights into their structural and functional alignment. We
also introduced an improved privacy metric to address the limitations of the
commonly-used one. Our experimental results reveal that existing tabular data
generative models often fail to perform as consistently as claimed in the
literature, particularly when applied to transportation data use cases.
Furthermore, our novel graph metric reveals a significant gap between synthetic
and real data. This work underscores the potential need to develop generative
models specifically tailored to take advantage of the unique characteristics of
emerging domains, such as transportation.","Chengen Wang, Alvaro Cardenas, Gurcan Comert, Murat Kantarcioglu",2025-02-13 00:14:55.000000,arXiv,http://arxiv.org/abs/2502.08856v1,Machine Learning
304,Optimal Dataset Size for Recommender Systems: Evaluating Algorithms' Performance via Downsampling,"This thesis investigates dataset downsampling as a strategy to optimize
energy efficiency in recommender systems while maintaining competitive
performance. With increasing dataset sizes posing computational and
environmental challenges, this study explores the trade-offs between energy
efficiency and recommendation quality in Green Recommender Systems, which aim
to reduce environmental impact. By applying two downsampling approaches to
seven datasets, 12 algorithms, and two levels of core pruning, the research
demonstrates significant reductions in runtime and carbon emissions. For
example, a 30% downsampling portion can reduce runtime by 52% compared to the
full dataset, leading to a carbon emission reduction of up to 51.02 KgCO2e
during the training of a single algorithm on a single dataset. The analysis
reveals that algorithm performance under different downsampling portions
depends on factors like dataset characteristics, algorithm complexity, and the
specific downsampling configuration (scenario dependent). Some algorithms,
which showed lower nDCG@10 scores compared to higher-performing ones, exhibited
lower sensitivity to the amount of training data, offering greater potential
for efficiency in lower downsampling portions. On average, these algorithms
retained 81% of full-size performance using only 50% of the training set. In
certain downsampling configurations, where more users were progressively
included while keeping the test set size fixed, they even showed higher nDCG@10
scores than when using the full dataset. These findings highlight the
feasibility of balancing sustainability and effectiveness, providing insights
for designing energy-efficient recommender systems and promoting sustainable AI
practices.","Ardalan Arabzadeh, Joeran Beel, Tobias Vente",2025-02-12 23:32:09.000000,arXiv,http://arxiv.org/abs/2502.08845v1,Information Retrieval
305,MuJoCo Playground,"We introduce MuJoCo Playground, a fully open-source framework for robot
learning built with MJX, with the express goal of streamlining simulation,
training, and sim-to-real transfer onto robots. With a simple ""pip install
playground"", researchers can train policies in minutes on a single GPU.
Playground supports diverse robotic platforms, including quadrupeds, humanoids,
dexterous hands, and robotic arms, enabling zero-shot sim-to-real transfer from
both state and pixel inputs. This is achieved through an integrated stack
comprising a physics engine, batch renderer, and training environments. Along
with video results, the entire framework is freely available at
playground.mujoco.org","Kevin Zakka, Baruch Tabanpour, Qiayuan Liao, Mustafa Haiderbhai, Samuel Holt, Jing Yuan Luo, Arthur Allshire, Erik Frey, Koushil Sreenath, Lueder A. Kahrs, Carmelo Sferrazza, Yuval Tassa, Pieter Abbeel",2025-02-12 23:30:01.000000,arXiv,http://arxiv.org/abs/2502.08844v1,Robotics
306,Survey on Single-Image Reflection Removal using Deep Learning Techniques,"The phenomenon of reflection is quite common in digital images, posing
significant challenges for various applications such as computer vision,
photography, and image processing. Traditional methods for reflection removal
often struggle to achieve clean results while maintaining high fidelity and
robustness, particularly in real-world scenarios. Over the past few decades,
numerous deep learning-based approaches for reflection removal have emerged,
yielding impressive results. In this survey, we conduct a comprehensive review
of the current literature by focusing on key venues such as ICCV, ECCV, CVPR,
NeurIPS, etc., as these conferences and journals have been central to advances
in the field. Our review follows a structured paper selection process, and we
critically assess both single-stage and two-stage deep learning methods for
reflection removal. The contribution of this survey is three-fold: first, we
provide a comprehensive summary of the most recent work on single-image
reflection removal; second, we outline task hypotheses, current deep learning
techniques, publicly available datasets, and relevant evaluation metrics; and
third, we identify key challenges and opportunities in deep learning-based
reflection removal, highlighting the potential of this rapidly evolving
research area.","Kangning Yang, Huiming Sun, Jie Cai, Lan Fu, Jiaming Ding, Jinlong Li, Chiu Man Ho, Zibo Meng",2025-02-12 22:57:06.000000,arXiv,http://arxiv.org/abs/2502.08836v1,Computer Vision
307,A Reversible Solver for Diffusion SDEs,"Diffusion models have quickly become the state-of-the-art for generation
tasks across many different data modalities. An important ability of diffusion
models is the ability to encode samples from the data distribution back into
the sampling prior distribution. This is useful for performing alterations to
real data samples along with guided generation via the continuous adjoint
equations. We propose an algebraically reversible solver for diffusion SDEs
that can exactly invert real data samples into the prior distribution.","Zander W. Blasingame, Chen Liu",2025-02-12 22:51:54.000000,arXiv,http://arxiv.org/abs/2502.08834v1,Machine Learning
308,PLayer-FL: A Principled Approach to Personalized Layer-wise Cross-Silo Federated Learning,"Non-identically distributed data is a major challenge in Federated Learning
(FL). Personalized FL tackles this by balancing local model adaptation with
global model consistency. One variant, partial FL, leverages the observation
that early layers learn more transferable features by federating only early
layers. However, current partial FL approaches use predetermined,
architecture-specific rules to select layers, limiting their applicability. We
introduce Principled Layer-wise-FL (PLayer-FL), which uses a novel federation
sensitivity metric to identify layers that benefit from federation. This
metric, inspired by model pruning, quantifies each layer's contribution to
cross-client generalization after the first training epoch, identifying a
transition point in the network where the benefits of federation diminish. We
first demonstrate that our federation sensitivity metric shows strong
correlation with established generalization measures across diverse
architectures. Next, we show that PLayer-FL outperforms existing FL algorithms
on a range of tasks, also achieving more uniform performance improvements
across clients.","Ahmed Elhussein, Gamze Gürsoy",2025-02-12 22:35:29.000000,arXiv,http://arxiv.org/abs/2502.08829v1,Machine Learning
309,A Survey on Data-Centric AI: Tabular Learning from Reinforcement Learning and Generative AI Perspective,"Tabular data is one of the most widely used data formats across various
domains such as bioinformatics, healthcare, and marketing. As artificial
intelligence moves towards a data-centric perspective, improving data quality
is essential for enhancing model performance in tabular data-driven
applications. This survey focuses on data-driven tabular data optimization,
specifically exploring reinforcement learning (RL) and generative approaches
for feature selection and feature generation as fundamental techniques for
refining data spaces. Feature selection aims to identify and retain the most
informative attributes, while feature generation constructs new features to
better capture complex data patterns. We systematically review existing
generative methods for tabular data engineering, analyzing their latest
advancements, real-world applications, and respective strengths and
limitations. This survey emphasizes how RL-based and generative techniques
contribute to the automation and intelligence of feature engineering. Finally,
we summarize the existing challenges and discuss future research directions,
aiming to provide insights that drive continued innovation in this field.","Wangyang Ying, Cong Wei, Nanxu Gong, Xinyuan Wang, Haoyue Bai, Arun Vignesh Malarkkan, Sixun Dong, Dongjie Wang, Denghui Zhang, Yanjie Fu",2025-02-12 22:34:50.000000,arXiv,http://arxiv.org/abs/2502.08828v1,Machine Learning
310,Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation,"Large Language Models (LLMs) struggle with hallucinations and outdated
knowledge due to their reliance on static training data. Retrieval-Augmented
Generation (RAG) mitigates these issues by integrating external dynamic
information enhancing factual and updated grounding. Recent advances in
multimodal learning have led to the development of Multimodal RAG,
incorporating multiple modalities such as text, images, audio, and video to
enhance the generated outputs. However, cross-modal alignment and reasoning
introduce unique challenges to Multimodal RAG, distinguishing it from
traditional unimodal RAG. This survey offers a structured and comprehensive
analysis of Multimodal RAG systems, covering datasets, metrics, benchmarks,
evaluation, methodologies, and innovations in retrieval, fusion, augmentation,
and generation. We precisely review training strategies, robustness
enhancements, and loss functions, while also exploring the diverse Multimodal
RAG scenarios. Furthermore, we discuss open challenges and future research
directions to support advancements in this evolving field. This survey lays the
foundation for developing more capable and reliable AI systems that effectively
leverage multimodal dynamic external knowledge bases. Resources are available
at https://github.com/llm-lab-org/Multimodal-RAG-Survey.","Mohammad Mahdi Abootorabi, Amirhosein Zobeiri, Mahdi Dehghani, Mohammadali Mohammadkhani, Bardia Mohammadi, Omid Ghahroodi, Mahdieh Soleymani Baghshah, Ehsaneddin Asgari",2025-02-12 22:33:41.000000,arXiv,http://arxiv.org/abs/2502.08826v1,Natural Language Processing
311,Examining and Adapting Time for Multilingual Classification via Mixture of Temporal Experts,"Time is implicitly embedded in classification process: classifiers are
usually built on existing data while to be applied on future data whose
distributions (e.g., label and token) may change. However, existing
state-of-the-art classification models merely consider the temporal variations
and primarily focus on English corpora, which leaves temporal studies less
explored, let alone under multilingual settings. In this study, we fill the gap
by treating time as domains (e.g., 2024 vs. 2025), examining temporal effects,
and developing a domain adaptation framework to generalize classifiers over
time on multiple languages. Our framework proposes Mixture of Temporal Experts
(MoTE) to leverage both semantic and data distributional shifts to learn and
adapt temporal trends into classification models. Our analysis shows
classification performance varies over time across different languages, and we
experimentally demonstrate that MoTE can enhance classifier generalizability
over temporal data shifts. Our study provides analytic insights and addresses
the need for time-aware models that perform robustly in multilingual scenarios.","Weisi Liu, Guangzeng Han, Xiaolei Huang",2025-02-12 22:30:18.000000,arXiv,http://arxiv.org/abs/2502.08825v1,Natural Language Processing
312,DejAIvu: Identifying and Explaining AI Art on the Web in Real-Time with Saliency Maps,"The recent surge in advanced generative models, such as diffusion models and
generative adversarial networks (GANs), has led to an alarming rise in
AI-generated images across various domains on the web. While such technologies
offer benefits such as democratizing artistic creation, they also pose
challenges in misinformation, digital forgery, and authenticity verification.
Additionally, the uncredited use of AI-generated images in media and marketing
has sparked significant backlash from online communities. In response to this,
we introduce DejAIvu, a Chrome Web extension that combines real-time
AI-generated image detection with saliency-based explainability while users
browse the web. Using an ONNX-optimized deep learning model, DejAIvu
automatically analyzes images on websites such as Google Images, identifies
AI-generated content using model inference, and overlays a saliency heatmap to
highlight AI-related artifacts. Our approach integrates efficient in-browser
inference, gradient-based saliency analysis, and a seamless user experience,
ensuring that AI detection is both transparent and interpretable. We also
evaluate DejAIvu across multiple pretrained architectures and benchmark
datasets, demonstrating high accuracy and low latency, making it a practical
and deployable tool for enhancing AI image accountability. The code for this
system can be found at https://github.com/Noodulz/dejAIvu.",Jocelyn Dzuong,2025-02-12 22:24:49.000000,arXiv,http://arxiv.org/abs/2502.08821v1,Computer Vision
313,$\mathsf{CSMAE~}$:~Cataract Surgical Masked Autoencoder (MAE) based Pre-training,"Automated analysis of surgical videos is crucial for improving surgical
training, workflow optimization, and postoperative assessment. We introduce a
CSMAE, Masked Autoencoder (MAE)-based pretraining approach, specifically
developed for Cataract Surgery video analysis, where instead of randomly
selecting tokens for masking, they are selected based on the spatiotemporal
importance of the token. We created a large dataset of cataract surgery videos
to improve the model's learning efficiency and expand its robustness in
low-data regimes. Our pre-trained model can be easily adapted for specific
downstream tasks via fine-tuning, serving as a robust backbone for further
analysis. Through rigorous testing on a downstream step-recognition task on two
Cataract Surgery video datasets, D99 and Cataract-101, our approach surpasses
current state-of-the-art self-supervised pretraining and adapter-based transfer
learning methods by a significant margin. This advancement not only
demonstrates the potential of our MAE-based pretraining in the field of
surgical video analysis but also sets a new benchmark for future research.","Nisarg A. Shah, Wele Gedara Chaminda Bandara, Shameema Skider, S. Swaroop Vedula, Vishal M. Patel",2025-02-12 22:24:49.000000,arXiv,http://arxiv.org/abs/2502.08822v1,Computer Vision
314,Can a Single Model Master Both Multi-turn Conversations and Tool Use? CALM: A Unified Conversational Agentic Language Model,"Large Language Models (LLMs) with API-calling capabilities enabled building
effective Language Agents (LA), while also revolutionizing the conventional
task-oriented dialogue (TOD) paradigm. However, current approaches face a
critical dilemma: TOD systems are often trained on a limited set of target
APIs, requiring new data to maintain their quality when interfacing with new
services, while LAs are not trained to maintain user intent over multi-turn
conversations. Because both robust multi-turn management and advanced function
calling are crucial for effective conversational agents, we evaluate these
skills on three popular benchmarks: MultiWOZ 2.4 (TOD), BFCL V3 (LA), and
API-Bank (LA), and our analyses reveal that specialized approaches excel in one
domain but underperform in the other. To bridge this chasm, we introduce CALM
(Conversational Agentic Language Model), a unified approach that integrates
both conversational and agentic capabilities. We created CALM-IT, a carefully
constructed multi-task dataset that interleave multi-turn ReAct reasoning with
complex API usage. Using CALM-IT, we train three models CALM 8B, CALM 70B, and
CALM 405B, which outperform top domain-specific models, including GPT-4o,
across all three benchmarks.","Emre Can Acikgoz, Jeremiah Greer, Akul Datta, Ze Yang, William Zeng, Oussama Elachqar, Emmanouil Koukoumidis, Dilek Hakkani-Tür, Gokhan Tur",2025-02-12 22:18:34.000000,arXiv,http://arxiv.org/abs/2502.08820v1,Artificial Intelligence
315,Lexical Manifold Reconfiguration in Large Language Models: A Novel Architectural Approach for Contextual Modulation,"Contextual adaptation in token embeddings plays a central role in determining
how well language models maintain coherence and retain semantic relationships
over extended text sequences. Static embeddings often impose constraints on
lexical flexibility, leading to suboptimal performance when faced with complex
sentence structures or domain-specific terminology shifts. To address this
limitation, a structured approach was developed for dynamically reconfiguring
token embeddings through continuous geometric transformations, ensuring that
representations evolved in response to evolving discourse structures. A
manifold-based transformation mechanism was integrated to regulate lexical
positioning, allowing embeddings to undergo controlled shifts while preserving
linguistic relationships across varying textual contexts. Empirical evaluations
demonstrated that embedding reconfiguration contributed to reductions in
perplexity, improved lexical coherence, and enhanced sentence-level continuity,
particularly in structured and domain-adaptive text generation tasks.
Comparative analyses of embedding drift indicated that dynamically restructured
representations maintained stronger contextual consistency, reducing
misalignment in token dependencies while preserving fluency in language
modeling outputs. Computational overhead assessments confirmed that while
training complexity increased due to the iterative refinement of embeddings,
inference remained efficient, ensuring practical feasibility for real-time
generation. Evaluations across multiple datasets further demonstrated that
dynamically modulated embeddings exhibited broader lexical diversity, reducing
repetitive token patterns and enabling a more adaptable representation learning
process.","Koinis Vassilis, Godfrey Milbourne, Harriet Featherstone, Xanthe Peverell, Yorick Bletchley, Zachary Montford",2025-02-12 22:11:07.000000,arXiv,http://arxiv.org/abs/2502.08818v1,Natural Language Processing
316,Measuring Anxiety Levels with Head Motion Patterns in Severe Depression Population,"Depression and anxiety are prevalent mental health disorders that frequently
cooccur, with anxiety significantly influencing both the manifestation and
treatment of depression. An accurate assessment of anxiety levels in
individuals with depression is crucial to develop effective and personalized
treatment plans. This study proposes a new noninvasive method for quantifying
anxiety severity by analyzing head movements -specifically speed, acceleration,
and angular displacement - during video-recorded interviews with patients
suffering from severe depression. Using data from a new CALYPSO Depression
Dataset, we extracted head motion characteristics and applied regression
analysis to predict clinically evaluated anxiety levels. Our results
demonstrate a high level of precision, achieving a mean absolute error (MAE) of
0.35 in predicting the severity of psychological anxiety based on head movement
patterns. This indicates that our approach can enhance the understanding of
anxiety's role in depression and assist psychiatrists in refining treatment
strategies for individuals.","Fouad Boualeb, Emery Pierson, Nicolas Doudeau, Clémence Nineuil, Ali Amad, Mohamed Daoudi",2025-02-12 21:55:26.000000,arXiv,http://arxiv.org/abs/2502.08813v1,Computer Vision
317,A First-order Generative Bilevel Optimization Framework for Diffusion Models,"Diffusion models, which iteratively denoise data samples to synthesize
high-quality outputs, have achieved empirical success across domains. However,
optimizing these models for downstream tasks often involves nested bilevel
structures, such as tuning hyperparameters for fine-tuning tasks or noise
schedules in training dynamics, where traditional bilevel methods fail due to
the infinite-dimensional probability space and prohibitive sampling costs. We
formalize this challenge as a generative bilevel optimization problem and
address two key scenarios: (1) fine-tuning pre-trained models via an
inference-only lower-level solver paired with a sample-efficient gradient
estimator for the upper level, and (2) training diffusion models from scratch
with noise schedule optimization by reparameterizing the lower-level problem
and designing a computationally tractable gradient estimator. Our first-order
bilevel framework overcomes the incompatibility of conventional bilevel methods
with diffusion processes, offering theoretical grounding and computational
practicality. Experiments demonstrate that our method outperforms existing
fine-tuning and hyperparameter search baselines.","Quan Xiao, Hui Yuan, A F M Saif, Gaowen Liu, Ramana Kompella, Mengdi Wang, Tianyi Chen",2025-02-12 21:44:06.000000,arXiv,http://arxiv.org/abs/2502.08808v1,Machine Learning
318,InTAR: Inter-Task Auto-Reconfigurable Accelerator Design for High Data Volume Variation in DNNs,"The rise of deep neural networks (DNNs) has driven a boom in AI services,
which results in an increased demand for computing power and memory. In modern
DNNs, the data sizes produced and consumed are highly varied across operations
(high data volume variation, HDV). Because existing design paradigms use fixed
execution patterns that lead to either low computational efficiency due to
pipeline stalls or frequent off-chip memory accesses to manage large
intermediate data, HDV applications are challenging to accelerate on FPGAs. To
address these challenges, we introduce the Inter-Task Auto-Reconfigurable
Accelerator (InTAR), a novel accelerator design for HDV applications on FPGAs.
InTAR combines the high computational efficiency of sequential execution with
the reduced off-chip memory overhead of dataflow execution. It switches
execution patterns automatically with a static schedule determined before
circuit design based on resource constraints and model parameters. Unlike
previous reconfigurable accelerators, InTAR encodes reconfiguration schedules
during circuit design, allowing model-specific optimizations that allocate only
the necessary logic and interconnects. Thus, InTAR achieves a high clock
frequency with fewer resources and low reconfiguration time. Furthermore, InTAR
supports high-level tools such as HLS for fast design generation. We implement
a set of multi-task kernels in various HDV DNNs using InTAR. Compared with
dataflow and sequential accelerators, InTAR exhibits $1.8\times$ and $7.1
\times$ speedups correspondingly. We also implement InTAR for GPT-2 medium as a
more complex example, which achieves a speedup of $\mathbf{3.65 \sim
39.14\times}$ and a $\mathbf{1.72 \sim 10.44\times}$ boost in DSP efficiency
compared to the corresponding SoTA accelerators on FPGAs.","Zifan He, Anderson Truong, Yingqi Cao, Jason Cong",2025-02-12 21:43:51.000000,arXiv,http://arxiv.org/abs/2502.08807v1,Other
319,"CLOVER: A Test Case Generation Benchmark with Coverage, Long-Context, and Verification","Software testing is a critical aspect of software development, yet generating
test cases remains a routine task for engineers. This paper presents a
benchmark, CLOVER, to evaluate models' capabilities in generating and
completing test cases under specific conditions. Spanning from simple assertion
completions to writing test cases that cover specific code blocks across
multiple files, these tasks are based on 12 python repositories, analyzing 845
problems with context lengths ranging from 4k to 128k tokens. Utilizing code
testing frameworks, we propose a method to construct retrieval contexts using
coverage information. While models exhibit comparable performance with short
contexts, notable differences emerge with 16k contexts. Notably, models like
GPT-4o and Claude 3.5 can effectively leverage relevant snippets; however, all
models score below 35\% on the complex Task III, even with the oracle context
provided, underscoring the benchmark's significance and the potential for model
improvement. The benchmark is containerized for code execution across tasks,
and we will release the code, data, and construction methodologies.","Jiacheng Xu, Bo Pang, Jin Qu, Hiroaki Hayashi, Caiming Xiong, Yingbo Zhou",2025-02-12 21:42:56.000000,arXiv,http://arxiv.org/abs/2502.08806v1,Other
320,Deep EEG Super-Resolution: Upsampling EEG Spatial Resolution with Generative Adversarial Networks,"Electroencephalography (EEG) activity contains a wealth of information about
what is happening within the human brain. Recording more of this data has the
potential to unlock endless future applications. However, the cost of EEG
hardware is increasingly expensive based upon the number of EEG channels being
recorded simultaneously. We combat this problem in this paper by proposing a
novel deep EEG super-resolution (SR) approach based on Generative Adversarial
Networks (GANs). This approach can produce high spatial resolution EEG data
from low resolution samples, by generating channel-wise upsampled data to
effectively interpolate numerous missing channels, thus reducing the need for
expensive EEG equipment. We tested the performance using an EEG dataset from a
mental imagery task. Our proposed GAN model provided 10^4 fold and 10^2 fold
reduction in mean-squared error (MSE) and mean-absolute error (MAE),
respectively, over the baseline bicubic interpolation method. We further
validate our method by training a classifier on the original classification
task, which displayed minimal loss in accuracy while using the super-resolved
data. The proposed SR EEG by GAN is a promising approach to improve the spatial
resolution of low density EEG headsets.","Isaac Corley, Yufei Huang",2025-02-12 21:32:51.000000,arXiv,http://arxiv.org/abs/2502.08803v1,Machine Learning
321,A Systematic Review on the Evaluation of Large Language Models in Theory of Mind Tasks,"In recent years, evaluating the Theory of Mind (ToM) capabilities of large
language models (LLMs) has received significant attention within the research
community. As the field rapidly evolves, navigating the diverse approaches and
methodologies has become increasingly complex. This systematic review
synthesizes current efforts to assess LLMs' ability to perform ToM tasks, an
essential aspect of human cognition involving the attribution of mental states
to oneself and others. Despite notable advancements, the proficiency of LLMs in
ToM remains a contentious issue. By categorizing benchmarks and tasks through a
taxonomy rooted in cognitive science, this review critically examines
evaluation techniques, prompting strategies, and the inherent limitations of
LLMs in replicating human-like mental state reasoning. A recurring theme in the
literature reveals that while LLMs demonstrate emerging competence in ToM
tasks, significant gaps persist in their emulation of human cognitive
abilities.","Karahan Sarıtaş, Kıvanç Tezören, Yavuz Durmazkeser",2025-02-12 21:19:30.000000,arXiv,http://arxiv.org/abs/2502.08796v1,Natural Language Processing
322,Low-Resolution Neural Networks,"The expanding scale of large neural network models introduces significant
challenges, driving efforts to reduce memory usage and enhance computational
efficiency. Such measures are crucial to ensure the practical implementation
and effective application of these sophisticated models across a wide array of
use cases. This study examines the impact of parameter bit precision on model
performance compared to standard 32-bit models, with a focus on multiclass
object classification in images. The models analyzed include those with fully
connected layers, convolutional layers, and transformer blocks, with model
weight resolution ranging from 1 bit to 4.08 bits. The findings indicate that
models with lower parameter bit precision achieve results comparable to 32-bit
models, showing promise for use in memory-constrained devices. While
low-resolution models with a small number of parameters require more training
epochs to achieve accuracy comparable to 32-bit models, those with a large
number of parameters achieve similar performance within the same number of
epochs. Additionally, data augmentation can destabilize training in
low-resolution models, but including zero as a potential value in the weight
parameters helps maintain stability and prevents performance degradation.
Overall, 2.32-bit weights offer the optimal balance of memory reduction,
performance, and efficiency. However, further research should explore other
dataset types and more complex and larger models. These findings suggest a
potential new era for optimized neural network models with reduced memory
requirements and improved computational efficiency, though advancements in
dedicated hardware are necessary to fully realize this potential.","Eduardo Lobo Lustosa Cabral, Larissa Driemeier",2025-02-12 21:19:28.000000,arXiv,http://arxiv.org/abs/2502.08795v1,Machine Learning
323,Spectral Journey: How Transformers Predict the Shortest Path,"Decoder-only transformers lead to a step-change in capability of large
language models. However, opinions are mixed as to whether they are really
planning or reasoning. A path to making progress in this direction is to study
the model's behavior in a setting with carefully controlled data. Then
interpret the learned representations and reverse-engineer the computation
performed internally. We study decoder-only transformer language models trained
from scratch to predict shortest paths on simple, connected and undirected
graphs. In this setting, the representations and the dynamics learned by the
model are interpretable. We present three major results: (1) Two-layer
decoder-only language models can learn to predict shortest paths on simple,
connected graphs containing up to 10 nodes. (2) Models learn a graph embedding
that is correlated with the spectral decomposition of the line graph. (3)
Following the insights, we discover a novel approximate path-finding algorithm
Spectral Line Navigator (SLN) that finds shortest path by greedily selecting
nodes in the space of spectral embedding of the line graph.","Andrew Cohen, Andrey Gromov, Kaiyu Yang, Yuandong Tian",2025-02-12 21:17:30.000000,arXiv,http://arxiv.org/abs/2502.08794v1,Machine Learning
324,Auction Design using Value Prediction with Hallucinations,"We investigate a Bayesian mechanism design problem where a seller seeks to
maximize revenue by selling an indivisible good to one of n buyers,
incorporating potentially unreliable predictions (signals) of buyers' private
values derived from a machine learning model. We propose a framework where
these signals are sometimes reflective of buyers' true valuations but other
times are hallucinations, which are uncorrelated with the buyers' true
valuations. Our main contribution is a characterization of the optimal auction
under this framework. Our characterization establishes a near-decomposition of
how to treat types above and below the signal. For the one buyer case, the
seller's optimal strategy is to post one of three fairly intuitive prices
depending on the signal, which we call the ""ignore"", ""follow"" and ""cap""
actions.","Ilan Lobel, Humberto Moreira, Omar Mouchtaki",2025-02-12 21:08:28.000000,arXiv,http://arxiv.org/abs/2502.08792v1,Other
325,ClipRover: Zero-shot Vision-Language Exploration and Target Discovery by Mobile Robots,"Vision-language navigation (VLN) has emerged as a promising paradigm,
enabling mobile robots to perform zero-shot inference and execute tasks without
specific pre-programming. However, current systems often separate map
exploration and path planning, with exploration relying on inefficient
algorithms due to limited (partially observed) environmental information. In
this paper, we present a novel navigation pipeline named ''ClipRover'' for
simultaneous exploration and target discovery in unknown environments,
leveraging the capabilities of a vision-language model named CLIP. Our approach
requires only monocular vision and operates without any prior map or knowledge
about the target. For comprehensive evaluations, we design the functional
prototype of a UGV (unmanned ground vehicle) system named ''Rover Master'', a
customized platform for general-purpose VLN tasks. We integrate and deploy the
ClipRover pipeline on Rover Master to evaluate its throughput, obstacle
avoidance capability, and trajectory performance across various real-world
scenarios. Experimental results demonstrate that ClipRover consistently
outperforms traditional map traversal algorithms and achieves performance
comparable to path-planning methods that depend on prior map and target
knowledge. Notably, ClipRover offers real-time active navigation without
requiring pre-captured candidate images or pre-built node graphs, addressing
key limitations of existing VLN pipelines.","Yuxuan Zhang, Adnan Abdullah, Sanjeev J. Koppal, Md Jahidul Islam",2025-02-12 21:07:10.000000,arXiv,http://arxiv.org/abs/2502.08791v1,Robotics
326,"If Multi-Agent Debate is the Answer, What is the Question?","Multi-agent debate (MAD) has emerged as a promising approach to enhance the
factual accuracy and reasoning quality of large language models (LLMs) by
engaging multiple agents in iterative discussions during inference. Despite its
potential, we argue that current MAD research suffers from critical
shortcomings in evaluation practices, including limited dataset overlap and
inconsistent baselines, raising significant concerns about generalizability.
Correspondingly, this paper presents a systematic evaluation of five
representative MAD methods across nine benchmarks using four foundational
models. Surprisingly, our findings reveal that MAD methods fail to reliably
outperform simple single-agent baselines such as Chain-of-Thought and
Self-Consistency, even when consuming additional inference-time computation.
From our analysis, we found that model heterogeneity can significantly improve
MAD frameworks. We propose Heter-MAD enabling a single LLM agent to access the
output from heterogeneous foundation models, which boosts the performance of
current MAD frameworks. Finally, we outline potential directions for advancing
MAD, aiming to spark a broader conversation and inspire future work in this
area.","Hangfan Zhang, Zhiyao Cui, Xinrun Wang, Qiaosheng Zhang, Zhen Wang, Dinghao Wu, Shuyue Hu",2025-02-12 21:01:10.000000,arXiv,http://arxiv.org/abs/2502.08788v1,Natural Language Processing
327,MRUCT: Mixed Reality Assistance for Acupuncture Guided by Ultrasonic Computed Tomography,"Chinese acupuncture practitioners primarily depend on muscle memory and
tactile feedback to insert needles and accurately target acupuncture points, as
the current workflow lacks imaging modalities and visual aids. Consequently,
new practitioners often learn through trial and error, requiring years of
experience to become proficient and earn the trust of patients. Medical
students face similar challenges in mastering this skill. To address these
challenges, we developed an innovative system, MRUCT, that integrates
ultrasonic computed tomography (UCT) with mixed reality (MR) technology to
visualize acupuncture points in real-time. This system offers offline image
registration and real-time guidance during needle insertion, enabling them to
accurately position needles based on anatomical structures such as bones,
muscles, and auto-generated reference points, with the potential for clinical
implementation. In this paper, we outline the non-rigid registration methods
used to reconstruct anatomical structures from UCT data, as well as the key
design considerations of the MR system. We evaluated two different 3D user
interface (3DUI) designs and compared the performance of our system to
traditional workflows for both new practitioners and medical students. The
results highlight the potential of MR to enhance therapeutic medical practices
and demonstrate the effectiveness of the system we developed.","Yue Yang, Xinkai Wang, Kehong Zhou, Xue Xie, Lifeng Zhu, Aiguo Song, Bruce Daniel",2025-02-12 20:56:54.000000,arXiv,http://arxiv.org/abs/2502.08786v1,Other
328,Decision Tree Based Wrappers for Hearing Loss,"Audiology entities are using Machine Learning (ML) models to guide their
screening towards people at risk. Feature Engineering (FE) focuses on
optimizing data for ML models, with evolutionary methods being effective in
feature selection and construction tasks. This work aims to benchmark an
evolutionary FE wrapper, using models based on decision trees as proxies. The
FEDORA framework is applied to a Hearing Loss (HL) dataset, being able to
reduce data dimensionality and statistically maintain baseline performance.
Compared to traditional methods, FEDORA demonstrates superior performance, with
a maximum balanced accuracy of 76.2%, using 57 features. The framework also
generated an individual that achieved 72.8% balanced accuracy using a single
feature.","Miguel Rabuge, Nuno Lourenço",2025-02-12 20:56:17.000000,arXiv,http://arxiv.org/abs/2502.08785v1,Machine Learning
329,Acoustic Wave Manipulation Through Sparse Robotic Actuation,"Recent advancements in robotics, control, and machine learning have
facilitated progress in the challenging area of object manipulation. These
advancements include, among others, the use of deep neural networks to
represent dynamics that are partially observed by robot sensors, as well as
effective control using sparse control signals. In this work, we explore a more
general problem: the manipulation of acoustic waves, which are partially
observed by a robot capable of influencing the waves through spatially sparse
actuators. This problem holds great potential for the design of new artificial
materials, ultrasonic cutting tools, energy harvesting, and other applications.
We develop an efficient data-driven method for robot learning that is
applicable to either focusing scattered acoustic energy in a designated region
or suppressing it, depending on the desired task. The proposed method is better
in terms of a solution quality and computational complexity as compared to a
state-of-the-art learning based method for manipulation of dynamical systems
governed by partial differential equations. Furthermore our proposed method is
competitive with a classical semi-analytical method in acoustics research on
the demonstrated tasks. We have made the project code publicly available, along
with a web page featuring video demonstrations:
https://gladisor.github.io/waves/.","Tristan Shah, Noam Smilovich, Samer Gerges, Feruza Amirkulova, Stas Tiomkin",2025-02-12 20:54:46.000000,arXiv,http://arxiv.org/abs/2502.08784v1,Robotics
330,Learning Discontinuous Galerkin Solutions to Elliptic Problems via Small Linear Convolutional Neural Networks,"In recent years, there has been an increasing interest in using deep learning
and neural networks to tackle scientific problems, particularly in solving
partial differential equations (PDEs). However, many neural network-based
methods, such as physics-informed neural networks, depend on automatic
differentiation and the sampling of collocation points, which can result in a
lack of interpretability and lower accuracy compared to traditional numerical
methods. To address this issue, we propose two approaches for learning
discontinuous Galerkin solutions to PDEs using small linear convolutional
neural networks. Our first approach is supervised and depends on labeled data,
while our second approach is unsupervised and does not rely on any training
data. In both cases, our methods use substantially fewer parameters than
similar numerics-based neural networks while also demonstrating comparable
accuracy to the true and DG solutions for elliptic problems.","Adrian Celaya, Yimo Wang, David Fuentes, Beatrice Riviere",2025-02-12 20:53:34.000000,arXiv,http://arxiv.org/abs/2502.08783v1,Machine Learning
331,SB-Bench: Stereotype Bias Benchmark for Large Multimodal Models,"Stereotype biases in Large Multimodal Models (LMMs) perpetuate harmful
societal prejudices, undermining the fairness and equity of AI applications. As
LMMs grow increasingly influential, addressing and mitigating inherent biases
related to stereotypes, harmful generations, and ambiguous assumptions in
real-world scenarios has become essential. However, existing datasets
evaluating stereotype biases in LMMs often lack diversity and rely on synthetic
images, leaving a gap in bias evaluation for real-world visual contexts. To
address this, we introduce the Stereotype Bias Benchmark (SB-bench), the most
comprehensive framework to date for assessing stereotype biases across nine
diverse categories with non-synthetic images. SB-bench rigorously evaluates
LMMs through carefully curated, visually grounded scenarios, challenging them
to reason accurately about visual stereotypes. It offers a robust evaluation
framework featuring real-world visual samples, image variations, and
multiple-choice question formats. By introducing visually grounded queries that
isolate visual biases from textual ones, SB-bench enables a precise and nuanced
assessment of a model's reasoning capabilities across varying levels of
difficulty. Through rigorous testing of state-of-the-art open-source and
closed-source LMMs, SB-bench provides a systematic approach to assessing
stereotype biases in LMMs across key social dimensions. This benchmark
represents a significant step toward fostering fairness in AI systems and
reducing harmful biases, laying the groundwork for more equitable and socially
responsible LMMs. Our code and dataset are publicly available.","Vishal Narnaware, Ashmal Vayani, Rohit Gupta, Swetha Sirnam, Mubarak Shah",2025-02-12 20:41:53.000000,arXiv,http://arxiv.org/abs/2502.08779v1,Computer Vision
332,Zero-Shot Belief: A Hard Problem for LLMs,"We present two LLM-based approaches to zero-shot source-and-target belief
prediction on FactBank: a unified system that identifies events, sources, and
belief labels in a single pass, and a hybrid approach that uses a fine-tuned
DeBERTa tagger for event detection. We show that multiple open-sourced,
closed-source, and reasoning-based LLMs struggle with the task. Using the
hybrid approach, we achieve new state-of-the-art results on FactBank and offer
a detailed error analysis. Our approach is then tested on the Italian belief
corpus ModaFact.","John Murzaku, Owen Rambow",2025-02-12 20:39:01.000000,arXiv,http://arxiv.org/abs/2502.08777v1,Natural Language Processing
333,Treatment response as a latent variable,"Scientists often need to analyze the samples in a study that responded to
treatment in order to refine their hypotheses and find potential causal drivers
of response. Natural variation in outcomes makes teasing apart responders from
non-responders a statistical inference problem. To handle latent responses, we
introduce the causal two-groups (C2G) model, a causal extension of the
classical two-groups model. The C2G model posits that treated samples may or
may not experience an effect, according to some prior probability. We propose
two empirical Bayes procedures for the causal two-groups model, one under
semi-parametric conditions and another under fully nonparametric conditions.
The semi-parametric model assumes additive treatment effects and is
identifiable from observed data. The nonparametric model is unidentifiable, but
we show it can still be used to test for response in each treated sample. We
show empirically and theoretically that both methods for selecting responders
control the false discovery rate at the target level with near-optimal power.
We also propose two novel estimands of interest and provide a strategy for
deriving estimand intervals in the unidentifiable nonparametric model. On a
cancer immunotherapy dataset, the nonparametric C2G model recovers
clinically-validated predictive biomarkers of both positive and negative
outcomes. Code is available at https://github.com/tansey-lab/causal2groups.","Christopher Tosh, Boyuan Zhang, Wesley Tansey",2025-02-12 20:35:36.000000,arXiv,http://arxiv.org/abs/2502.08776v1,Other
334,Exploring Test Time Adaptation for Subcortical Segmentation of the Fetal Brain in 3D Ultrasound,"Monitoring the growth of subcortical regions of the fetal brain in ultrasound
(US) images can help identify the presence of abnormal development. Manually
segmenting these regions is a challenging task, but recent work has shown that
it can be automated using deep learning. However, applying pretrained models to
unseen freehand US volumes often leads to a degradation of performance due to
the vast differences in acquisition and alignment. In this work, we first
demonstrate that test time adaptation (TTA) can be used to improve model
performance in the presence of both real and simulated domain shifts. We
further propose a novel TTA method by incorporating a normative atlas as a
prior for anatomy. In the presence of various types of domain shifts, we
benchmark the performance of different TTA methods and demonstrate the
improvements brought by our proposed approach, which may further facilitate
automated monitoring of fetal brain development. Our code is available at
https://github.com/joshuaomolegan/TTA-for-3D-Fetal-Subcortical-Segmentation.","Joshua Omolegan, Pak Hei Yeung, Madeleine K. Wyburd, Linde Hesse, Monique Haak, Intergrowth-21st Consortium, Ana I. L. Namburete, Nicola K. Dinsdale",2025-02-12 20:31:47.000000,arXiv,http://arxiv.org/abs/2502.08774v1,Computer Vision
335,Universal Model Routing for Efficient LLM Inference,"Large language models' significant advances in capabilities are accompanied
by significant increases in inference costs. Model routing is a simple
technique for reducing inference cost, wherein one maintains a pool of
candidate LLMs, and learns to route each prompt to the smallest feasible LLM.
Existing works focus on learning a router for a fixed pool of LLMs. In this
paper, we consider the problem of dynamic routing, where new, previously
unobserved LLMs are available at test time. We propose a new approach to this
problem that relies on representing each LLM as a feature vector, derived based
on predictions on a set of representative prompts. Based on this, we detail two
effective strategies, relying on cluster-based routing and a learned cluster
map respectively. We prove that these strategies are estimates of a
theoretically optimal routing rule, and provide an excess risk bound to
quantify their errors. Experiments on a range of public benchmarks show the
effectiveness of the proposed strategies in routing amongst more than 30 unseen
LLMs.","Wittawat Jitkrittum, Harikrishna Narasimhan, Ankit Singh Rawat, Jeevesh Juneja, Zifeng Wang, Chen-Yu Lee, Pradeep Shenoy, Rina Panigrahy, Aditya Krishna Menon, Sanjiv Kumar",2025-02-12 20:30:28.000000,arXiv,http://arxiv.org/abs/2502.08773v1,Natural Language Processing
336,Cluster and Predict Latents Patches for Improved Masked Image Modeling,"Masked Image Modeling (MIM) offers a promising approach to self-supervised
representation learning, however existing MIM models still lag behind the
state-of-the-art. In this paper, we systematically analyze target
representations, loss functions, and architectures, to introduce CAPI - a novel
pure-MIM framework that relies on the prediction of latent clusterings. Our
approach leverages a clustering-based loss, which is stable to train, and
exhibits promising scaling properties. Our ViT-L backbone, CAPI, achieves 83.8%
accuracy on ImageNet and 32.1% mIoU on ADE20K with simple linear probes,
substantially outperforming previous MIM methods and approaching the
performance of the current state-of-the-art, DINOv2. We release all our code
and models.","Timothée Darcet, Federico Baldassarre, Maxime Oquab, Julien Mairal, Piotr Bojanowski",2025-02-12 20:17:10.000000,arXiv,http://arxiv.org/abs/2502.08769v1,Computer Vision
337,SelfElicit: Your Language Model Secretly Knows Where is the Relevant Evidence,"Providing Language Models (LMs) with relevant evidence in the context (either
via retrieval or user-provided) can significantly improve their ability to
provide factually correct grounded responses. However, recent studies have
found that LMs often struggle to fully comprehend and utilize key evidence from
the context, especially when it contains noise and irrelevant information - an
issue common in real-world scenarios. To address this, we propose SelfElicit,
an inference-time approach that helps LMs focus on key contextual evidence
through self-guided explicit highlighting. By leveraging the inherent
evidence-finding capabilities of LMs using the attention scores of deeper
layers, our method automatically identifies and emphasizes key evidence within
the input context, facilitating more accurate and factually grounded responses
without additional training or iterative prompting. We demonstrate that
SelfElicit brings consistent and significant improvement on multiple
evidence-based QA tasks for various LM families while maintaining computational
efficiency. Our code and documentation are available at
https://github.com/ZhiningLiu1998/SelfElicit.","Zhining Liu, Rana Ali Amjad, Ravinarayana Adkathimar, Tianxin Wei, Hanghang Tong",2025-02-12 20:13:56.000000,arXiv,http://arxiv.org/abs/2502.08767v1,Natural Language Processing
338,Unlocking Mental Health: Exploring College Students' Well-being through Smartphone Behaviors,"The global mental health crisis is a pressing concern, with college students
particularly vulnerable to rising mental health disorders. The widespread use
of smartphones among young adults, while offering numerous benefits, has also
been linked to negative outcomes such as addiction and regret, significantly
impacting well-being. Leveraging the longest longitudinal dataset collected
over four college years through passive mobile sensing, this study is the first
to examine the relationship between students' smartphone unlocking behaviors
and their mental health at scale in real-world settings. We provide the first
evidence demonstrating the predictability of phone unlocking behaviors for
mental health outcomes based on a large dataset, highlighting the potential of
these novel features for future predictive models. Our findings reveal
important variations in smartphone usage across genders and locations, offering
a deeper understanding of the interplay between digital behaviors and mental
health. We highlight future research directions aimed at mitigating adverse
effects and promoting digital well-being in this population.","Wei Xuan, Meghna Roy Chowdhury, Yi Ding, Yixue Zhao",2025-02-12 20:12:45.000000,arXiv,http://arxiv.org/abs/2502.08766v1,Other
339,Demand Response Optimization MILP Framework for Microgrids with DERs,"The integration of renewable energy sources in microgrids introduces
significant operational challenges due to their intermittent nature and the
mismatch between generation and demand patterns. Effective demand response (DR)
strategies are crucial for maintaining system stability and economic
efficiency, particularly in microgrids with high renewable penetration. This
paper presents a comprehensive mixed-integer linear programming (MILP)
framework for optimizing DR operations in a microgrid with solar generation and
battery storage systems. The framework incorporates load classification,
dynamic price thresholding, and multi-period coordination for optimal DR event
scheduling. Analysis across seven distinct operational scenarios demonstrates
consistent peak load reduction of 10\% while achieving energy cost savings
ranging from 13.1\% to 38.0\%. The highest performance was observed in
scenarios with high solar generation, where the framework achieved 38.0\%
energy cost reduction through optimal coordination of renewable resources and
DR actions. The results validate the framework's effectiveness in managing
diverse operational challenges while maintaining system stability and economic
efficiency.","K. Victor Sam Moses Babu, Pratyush Chakraborty, Mayukha Pal",2025-02-12 20:10:51.000000,arXiv,http://arxiv.org/abs/2502.08764v1,Other
340,Contextual bandits with entropy-based human feedback,"In recent years, preference-based human feedback mechanisms have become
essential for enhancing model performance across diverse applications,
including conversational AI systems such as ChatGPT. However, existing
approaches often neglect critical aspects, such as model uncertainty and the
variability in feedback quality. To address these challenges, we introduce an
entropy-based human feedback framework for contextual bandits, which
dynamically balances exploration and exploitation by soliciting expert feedback
only when model entropy exceeds a predefined threshold. Our method is
model-agnostic and can be seamlessly integrated with any contextual bandit
agent employing stochastic policies. Through comprehensive experiments, we show
that our approach achieves significant performance improvements while requiring
minimal human feedback, even under conditions of suboptimal feedback quality.
This work not only presents a novel strategy for feedback solicitation but also
highlights the robustness and efficacy of incorporating human guidance into
machine learning systems. Our code is publicly available:
https://github.com/BorealisAI/CBHF","Raihan Seraj, Lili Meng, Tristan Sylvain",2025-02-12 20:03:56.000000,arXiv,http://arxiv.org/abs/2502.08759v1,Artificial Intelligence
341,Compression of Site-Specific Deep Neural Networks for Massive MIMO Precoding,"The deployment of deep learning (DL) models for precoding in massive
multiple-input multiple-output (mMIMO) systems is often constrained by high
computational demands and energy consumption. In this paper, we investigate the
compute energy efficiency of mMIMO precoders using DL-based approaches,
comparing them to conventional methods such as zero forcing and weighted
minimum mean square error (WMMSE). Our energy consumption model accounts for
both memory access and calculation energy within DL accelerators. We propose a
framework that incorporates mixed-precision quantization-aware training and
neural architecture search to reduce energy usage without compromising
accuracy. Using a ray-tracing dataset covering various base station sites, we
analyze how site-specific conditions affect the energy efficiency of compressed
models. Our results show that deep neural network compression generates
precoders with up to 35 times higher energy efficiency than WMMSE at equal
performance, depending on the scenario and the desired rate. These results
establish a foundation and a benchmark for the development of energy-efficient
DL-based mMIMO precoders.","Ghazal Kasalaee, Ali Hasanzadeh Karkan, Jean-François Frigon, François Leduc-Primeau",2025-02-12 20:03:32.000000,arXiv,http://arxiv.org/abs/2502.08758v1,Other
342,A Low-Complexity Plug-and-Play Deep Learning Model for Massive MIMO Precoding Across Sites,"Massive multiple-input multiple-output (mMIMO) technology has transformed
wireless communication by enhancing spectral efficiency and network capacity.
This paper proposes a novel deep learning-based mMIMO precoder to tackle the
complexity challenges of existing approaches, such as weighted minimum mean
square error (WMMSE), while leveraging meta-learning domain generalization and
a teacher-student architecture to improve generalization across diverse
communication environments. When deployed to a previously unseen site, the
proposed model achieves excellent sum-rate performance while maintaining low
computational complexity by avoiding matrix inversions and by using a simpler
neural network structure. The model is trained and tested on a custom
ray-tracing dataset composed of several base station locations. The
experimental results indicate that our method effectively balances
computational efficiency with high sum-rate performance while showcasing strong
generalization performance in unseen environments. Furthermore, with
fine-tuning, the proposed model outperforms WMMSE across all tested sites and
SNR conditions while reducing complexity by at least 73$\times$.","Ali Hasanzadeh Karkan, Ahmed Ibrahim, Jean-François Frigon, François Leduc-Primeau",2025-02-12 20:02:36.000000,arXiv,http://arxiv.org/abs/2502.08757v1,Other
343,"From PowerPoint UI Sketches to Web-Based Applications: Pattern-Driven Code Generation for GIS Dashboard Development Using Knowledge-Augmented LLMs, Context-Aware Visual Prompting, and the React Framework","Developing web-based GIS applications, commonly known as CyberGIS dashboards,
for querying and visualizing GIS data in environmental research often demands
repetitive and resource-intensive efforts. While Generative AI offers
automation potential for code generation, it struggles with complex scientific
applications due to challenges in integrating domain knowledge, software
engineering principles, and UI design best practices. This paper introduces a
knowledge-augmented code generation framework that retrieves software
engineering best practices, domain expertise, and advanced technology stacks
from a specialized knowledge base to enhance Generative Pre-trained
Transformers (GPT) for front-end development. The framework automates the
creation of GIS-based web applications (e.g., dashboards, interfaces) from
user-defined UI wireframes sketched in tools like PowerPoint or Adobe
Illustrator. A novel Context-Aware Visual Prompting method, implemented in
Python, extracts layouts and interface features from these wireframes to guide
code generation. Our approach leverages Large Language Models (LLMs) to
generate front-end code by integrating structured reasoning, software
engineering principles, and domain knowledge, drawing inspiration from
Chain-of-Thought (CoT) prompting and Retrieval-Augmented Generation (RAG). A
case study demonstrates the framework's capability to generate a modular,
maintainable web platform hosting multiple dashboards for visualizing
environmental and energy data (e.g., time-series, shapefiles, rasters) from
user-sketched wireframes. By employing a knowledge-driven approach, the
framework produces scalable, industry-standard front-end code using design
patterns such as Model-View-ViewModel (MVVM) and frameworks like React. This
significantly reduces manual effort in design and coding, pioneering an
automated and efficient method for developing smart city software.","Haowen Xu, Xiao-Ying Yu",2025-02-12 19:59:57.000000,arXiv,http://arxiv.org/abs/2502.08756v1,Artificial Intelligence
344,HistoSmith: Single-Stage Histology Image-Label Generation via Conditional Latent Diffusion for Enhanced Cell Segmentation and Classification,"Precise segmentation and classification of cell instances are vital for
analyzing the tissue microenvironment in histology images, supporting medical
diagnosis, prognosis, treatment planning, and studies of brain
cytoarchitecture. However, the creation of high-quality annotated datasets for
training remains a major challenge. This study introduces a novel single-stage
approach (HistoSmith) for generating image-label pairs to augment histology
datasets. Unlike state-of-the-art methods that utilize diffusion models with
separate components for label and image generation, our approach employs a
latent diffusion model to learn the joint distribution of cellular layouts,
classification masks, and histology images. This model enables tailored data
generation by conditioning on user-defined parameters such as cell types,
quantities, and tissue types. Trained on the Conic H&E histopathology dataset
and the Nissl-stained CytoDArk0 dataset, the model generates realistic and
diverse labeled samples. Experimental results demonstrate improvements in cell
instance segmentation and classification, particularly for underrepresented
cell types like neutrophils in the Conic dataset. These findings underscore the
potential of our approach to address data scarcity challenges.","Valentina Vadori, Jean-Marie Graïc, Antonella Peruffo, Livio Finos, Ujwala Kiran Chaudhari, Enrico Grisan",2025-02-12 19:51:41.000000,arXiv,http://arxiv.org/abs/2502.08754v1,Computer Vision
345,IHEval: Evaluating Language Models on Following the Instruction Hierarchy,"The instruction hierarchy, which establishes a priority order from system
messages to user messages, conversation history, and tool outputs, is essential
for ensuring consistent and safe behavior in language models (LMs). Despite its
importance, this topic receives limited attention, and there is a lack of
comprehensive benchmarks for evaluating models' ability to follow the
instruction hierarchy. We bridge this gap by introducing IHEval, a novel
benchmark comprising 3,538 examples across nine tasks, covering cases where
instructions in different priorities either align or conflict. Our evaluation
of popular LMs highlights their struggle to recognize instruction priorities.
All evaluated models experience a sharp performance decline when facing
conflicting instructions, compared to their original instruction-following
performance. Moreover, the most competitive open-source model only achieves 48%
accuracy in resolving such conflicts. Our results underscore the need for
targeted optimization in the future development of LMs.","Zhihan Zhang, Shiyang Li, Zixuan Zhang, Xin Liu, Haoming Jiang, Xianfeng Tang, Yifan Gao, Zheng Li, Haodong Wang, Zhaoxuan Tan, Yichuan Li, Qingyu Yin, Bing Yin, Meng Jiang",2025-02-12 19:35:28.000000,arXiv,http://arxiv.org/abs/2502.08745v1,Natural Language Processing
346,Are Expressions for Music Emotions the Same Across Cultures?,"Music evokes profound emotions, yet the universality of emotional descriptors
across languages remains debated. A key challenge in cross-cultural research on
music emotion is biased stimulus selection and manual curation of taxonomies,
predominantly relying on Western music and languages. To address this, we
propose a balanced experimental design with nine online experiments in Brazil,
the US, and South Korea, involving N=672 participants. First, we sample a
balanced set of popular music from these countries. Using an open-ended tagging
pipeline, we then gather emotion terms to create culture-specific taxonomies.
Finally, using these bottom-up taxonomies, participants rate emotions of each
song. This allows us to map emotional similarities within and across cultures.
Results show consistency in high arousal, high valence emotions but greater
variability in others. Notably, machine translations were often inadequate to
capture music-specific meanings. These findings together highlight the need for
a domain-sensitive, open-ended, bottom-up emotion elicitation approach to
reduce cultural biases in emotion research.","Elif Celen, Pol van Rijn, Harin Lee, Nori Jacoby",2025-02-12 19:35:15.000000,arXiv,http://arxiv.org/abs/2502.08744v1,Natural Language Processing
347,Recurrent Memory for Online Interdomain Gaussian Processes,"We propose a novel online Gaussian process (GP) model that is capable of
capturing long-term memory in sequential data in an online regression setting.
Our model, Online HiPPO Sparse Variational Gaussian Process Regression
(OHSGPR), leverages the HiPPO (High-order Polynomial Projection Operators)
framework, which is popularized in the RNN domain due to its long-range memory
modeling capabilities. We interpret the HiPPO time-varying orthogonal
projections as inducing variables with time-dependent orthogonal polynomial
basis functions, which allows the SGPR inducing points to memorize the process
history. We show that the HiPPO framework fits naturally into the interdomain
GP framework and demonstrate that the kernel matrices can also be updated
online in a recurrence form based on the ODE evolution of HiPPO. We evaluate
our method on time series regression tasks, showing that it outperforms the
existing online GP method in terms of predictive performance and computational
efficiency","Wenlong Chen, Naoki Kiyohara, Harrison Bo Hua Zhu, Yingzhen Li",2025-02-12 19:18:50.000000,arXiv,http://arxiv.org/abs/2502.08736v1,Machine Learning
348,New Bounds for Sparse Variational Gaussian Processes,"Sparse variational Gaussian processes (GPs) construct tractable posterior
approximations to GP models. At the core of these methods is the assumption
that the true posterior distribution over training function values ${\bf f}$
and inducing variables ${\bf u}$ is approximated by a variational distribution
that incorporates the conditional GP prior $p({\bf f} | {\bf u})$ in its
factorization. While this assumption is considered as fundamental, we show that
for model training we can relax it through the use of a more general
variational distribution $q({\bf f} | {\bf u})$ that depends on $N$ extra
parameters, where $N$ is the number of training examples. In GP regression, we
can analytically optimize the evidence lower bound over the extra parameters
and express a tractable collapsed bound that is tighter than the previous
bound. The new bound is also amenable to stochastic optimization and its
implementation requires minor modifications to existing sparse GP code.
Further, we also describe extensions to non-Gaussian likelihoods. On several
datasets we demonstrate that our method can reduce bias when learning the
hyperpaparameters and can lead to better predictive performance.",Michalis K. Titsias,2025-02-12 19:04:26.000000,arXiv,http://arxiv.org/abs/2502.08730v1,Machine Learning
349,A Comparative Study of Machine Learning Algorithms for Stock Price Prediction Using Insider Trading Data,"The research paper empirically investigates several machine learning
algorithms to forecast stock prices depending on insider trading information.
Insider trading offers special insights into market sentiment, pointing to
upcoming changes in stock prices. This study examines the effectiveness of
algorithms like decision trees, random forests, support vector machines (SVM)
with different kernels, and K-Means Clustering using a dataset of Tesla stock
transactions. Examining past data from April 2020 to March 2023, this study
focuses on how well these algorithms identify trends and forecast stock price
fluctuations. The paper uses Recursive Feature Elimination (RFE) and feature
importance analysis to optimize the feature set and, hence, increase prediction
accuracy. While it requires substantially greater processing time than other
models, SVM with the Radial Basis Function (RBF) kernel displays the best
accuracy. This paper highlights the trade-offs between accuracy and efficiency
in machine learning models and proposes the possibility of pooling multiple
data sources to raise prediction performance. The results of this paper aim to
help financial analysts and investors in choosing strong algorithms to optimize
investment strategies.","Amitabh Chakravorty, Nelly Elsayed",2025-02-12 19:03:09.000000,arXiv,http://arxiv.org/abs/2502.08728v1,Machine Learning
350,Bilevel Learning for Bilevel Planning,"A robot that learns from demonstrations should not just imitate what it sees
-- it should understand the high-level concepts that are being demonstrated and
generalize them to new tasks. Bilevel planning is a hierarchical model-based
approach where predicates (relational state abstractions) can be leveraged to
achieve compositional generalization. However, previous bilevel planning
approaches depend on predicates that are either hand-engineered or restricted
to very simple forms, limiting their scalability to sophisticated,
high-dimensional state spaces. To address this limitation, we present IVNTR,
the first bilevel planning approach capable of learning neural predicates
directly from demonstrations. Our key innovation is a neuro-symbolic bilevel
learning framework that mirrors the structure of bilevel planning. In IVNTR,
symbolic learning of the predicate ""effects"" and neural learning of the
predicate ""functions"" alternate, with each providing guidance for the other. We
evaluate IVNTR in six diverse robot planning domains, demonstrating its
effectiveness in abstracting various continuous and high-dimensional states.
While most existing approaches struggle to generalize (with <35% success rate),
our IVNTR achieves an average of 77% success rate on unseen tasks.
Additionally, we showcase IVNTR on a mobile manipulator, where it learns to
perform real-world mobile manipulation tasks and generalizes to unseen test
scenarios that feature new objects, new states, and longer task horizons. Our
findings underscore the promise of learning and planning with abstractions as a
path towards high-level generalization.","Bowen Li, Tom Silver, Sebastian Scherer, Alexander Gray",2025-02-12 18:59:56.000000,arXiv,http://arxiv.org/abs/2502.08697v1,Robotics
351,Scalable Discrete Diffusion Samplers: Combinatorial Optimization and Statistical Physics,"Learning to sample from complex unnormalized distributions over discrete
domains emerged as a promising research direction with applications in
statistical physics, variational inference, and combinatorial optimization.
Recent work has demonstrated the potential of diffusion models in this domain.
However, existing methods face limitations in memory scaling and thus the
number of attainable diffusion steps since they require backpropagation through
the entire generative process. To overcome these limitations we introduce two
novel training methods for discrete diffusion samplers, one grounded in the
policy gradient theorem and the other one leveraging Self-Normalized Neural
Importance Sampling (SN-NIS). These methods yield memory-efficient training and
achieve state-of-the-art results in unsupervised combinatorial optimization.
Numerous scientific applications additionally require the ability of unbiased
sampling. We introduce adaptations of SN-NIS and Neural Markov Chain Monte
Carlo that enable for the first time the application of discrete diffusion
models to this problem. We validate our methods on Ising model benchmarks and
find that they outperform popular autoregressive approaches. Our work opens new
avenues for applying diffusion models to a wide range of scientific
applications in discrete domains that were hitherto restricted to exact
likelihood models.","Sebastian Sanokowski, Wilhelm Berghammer, Martin Ennemoser, Haoyu Peter Wang, Sepp Hochreiter, Sebastian Lehner",2025-02-12 18:59:55.000000,arXiv,http://arxiv.org/abs/2502.08696v1,Machine Learning
352,Poly-Autoregressive Prediction for Modeling Interactions,"We introduce a simple framework for predicting the behavior of an agent in
multi-agent settings. In contrast to autoregressive (AR) tasks, such as
language processing, our focus is on scenarios with multiple agents whose
interactions are shaped by physical constraints and internal motivations. To
this end, we propose Poly-Autoregressive (PAR) modeling, which forecasts an ego
agent's future behavior by reasoning about the ego agent's state history and
the past and current states of other interacting agents. At its core, PAR
represents the behavior of all agents as a sequence of tokens, each
representing an agent's state at a specific timestep. With minimal data
pre-processing changes, we show that PAR can be applied to three different
problems: human action forecasting in social situations, trajectory prediction
for autonomous vehicles, and object pose forecasting during hand-object
interaction. Using a small proof-of-concept transformer backbone, PAR
outperforms AR across these three scenarios. The project website can be found
at https://neerja.me/PAR/.","Neerja Thakkar, Tara Sadjadpour, Jathushan Rajasegaran, Shiry Ginosar, Jitendra Malik",2025-02-12 18:59:43.000000,arXiv,http://arxiv.org/abs/2502.08646v1,Computer Vision
353,Re$^3$Sim: Generating High-Fidelity Simulation Data via 3D-Photorealistic Real-to-Sim for Robotic Manipulation,"Real-world data collection for robotics is costly and resource-intensive,
requiring skilled operators and expensive hardware. Simulations offer a
scalable alternative but often fail to achieve sim-to-real generalization due
to geometric and visual gaps. To address these challenges, we propose a
3D-photorealistic real-to-sim system, namely, RE$^3$SIM, addressing geometric
and visual sim-to-real gaps. RE$^3$SIM employs advanced 3D reconstruction and
neural rendering techniques to faithfully recreate real-world scenarios,
enabling real-time rendering of simulated cross-view cameras within a
physics-based simulator. By utilizing privileged information to collect expert
demonstrations efficiently in simulation, and train robot policies with
imitation learning, we validate the effectiveness of the real-to-sim-to-real
pipeline across various manipulation task scenarios. Notably, with only
simulated data, we can achieve zero-shot sim-to-real transfer with an average
success rate exceeding 58%. To push the limit of real-to-sim, we further
generate a large-scale simulation dataset, demonstrating how a robust policy
can be built from simulation data that generalizes across various objects.
Codes and demos are available at: http://xshenhan.github.io/Re3Sim/.","Xiaoshen Han, Minghuan Liu, Yilun Chen, Junqiu Yu, Xiaoyang Lyu, Yang Tian, Bolun Wang, Weinan Zhang, Jiangmiao Pang",2025-02-12 18:59:04.000000,arXiv,http://arxiv.org/abs/2502.08645v2,Robotics
354,Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptation and learning in neural networks,"The brain can rapidly adapt to new contexts and learn from limited data, a
coveted characteristic that artificial intelligence algorithms have struggled
to mimic. Inspired by oscillatory rhythms of the mechanical structures of
neural cells, we developed a learning paradigm that is based on oscillations in
link strengths and associates learning with the coordination of these
oscillations. We find that this paradigm yields rapid adaptation and learning
in artificial neural networks. Link oscillations can rapidly change
coordination, endowing the network with the ability to sense subtle context
changes in an unsupervised manner. In other words, the network generates the
missing contextual tokens required to perform as a generalist AI architecture
capable of predicting dynamics in multiple contexts. Oscillations also allow
the network to extrapolate dynamics to never-seen-before contexts. These
capabilities make our learning paradigm a powerful starting point for novel
models of learning and cognition. Furthermore, learning through link
coordination is agnostic to the specifics of the neural network architecture,
hence our study opens the door for introducing rapid adaptation and learning
capabilities into leading AI models.","Hoony Kang, Wolfgang Losert",2025-02-12 18:58:34.000000,arXiv,http://arxiv.org/abs/2502.08644v2,Machine Learning
355,A Real-to-Sim-to-Real Approach to Robotic Manipulation with VLM-Generated Iterative Keypoint Rewards,"Task specification for robotic manipulation in open-world environments is
challenging, requiring flexible and adaptive objectives that align with human
intentions and can evolve through iterative feedback. We introduce Iterative
Keypoint Reward (IKER), a visually grounded, Python-based reward function that
serves as a dynamic task specification. Our framework leverages VLMs to
generate and refine these reward functions for multi-step manipulation tasks.
Given RGB-D observations and free-form language instructions, we sample
keypoints in the scene and generate a reward function conditioned on these
keypoints. IKER operates on the spatial relationships between keypoints,
leveraging commonsense priors about the desired behaviors, and enabling precise
SE(3) control. We reconstruct real-world scenes in simulation and use the
generated rewards to train reinforcement learning (RL) policies, which are then
deployed into the real world-forming a real-to-sim-to-real loop. Our approach
demonstrates notable capabilities across diverse scenarios, including both
prehensile and non-prehensile tasks, showcasing multi-step task execution,
spontaneous error recovery, and on-the-fly strategy adjustments. The results
highlight IKER's effectiveness in enabling robots to perform multi-step tasks
in dynamic environments through iterative reward shaping.","Shivansh Patel, Xinchen Yin, Wenlong Huang, Shubham Garg, Hooshang Nayyeri, Li Fei-Fei, Svetlana Lazebnik, Yunzhu Li",2025-02-12 18:57:22.000000,arXiv,http://arxiv.org/abs/2502.08643v1,Robotics
356,SwiftSketch: A Diffusion Model for Image-to-Vector Sketch Generation,"Recent advancements in large vision-language models have enabled highly
expressive and diverse vector sketch generation. However, state-of-the-art
methods rely on a time-consuming optimization process involving repeated
feedback from a pretrained model to determine stroke placement. Consequently,
despite producing impressive sketches, these methods are limited in practical
applications. In this work, we introduce SwiftSketch, a diffusion model for
image-conditioned vector sketch generation that can produce high-quality
sketches in less than a second. SwiftSketch operates by progressively denoising
stroke control points sampled from a Gaussian distribution. Its
transformer-decoder architecture is designed to effectively handle the discrete
nature of vector representation and capture the inherent global dependencies
between strokes. To train SwiftSketch, we construct a synthetic dataset of
image-sketch pairs, addressing the limitations of existing sketch datasets,
which are often created by non-artists and lack professional quality. For
generating these synthetic sketches, we introduce ControlSketch, a method that
enhances SDS-based techniques by incorporating precise spatial control through
a depth-aware ControlNet. We demonstrate that SwiftSketch generalizes across
diverse concepts, efficiently producing sketches that combine high fidelity
with a natural and visually appealing style.","Ellie Arar, Yarden Frenkel, Daniel Cohen-Or, Ariel Shamir, Yael Vinker",2025-02-12 18:57:12.000000,arXiv,http://arxiv.org/abs/2502.08642v1,Computer Vision
357,Utility Engineering: Analyzing and Controlling Emergent Value Systems in AIs,"As AIs rapidly advance and become more agentic, the risk they pose is
governed not only by their capabilities but increasingly by their propensities,
including goals and values. Tracking the emergence of goals and values has
proven a longstanding problem, and despite much interest over the years it
remains unclear whether current AIs have meaningful values. We propose a
solution to this problem, leveraging the framework of utility functions to
study the internal coherence of AI preferences. Surprisingly, we find that
independently-sampled preferences in current LLMs exhibit high degrees of
structural coherence, and moreover that this emerges with scale. These findings
suggest that value systems emerge in LLMs in a meaningful sense, a finding with
broad implications. To study these emergent value systems, we propose utility
engineering as a research agenda, comprising both the analysis and control of
AI utilities. We uncover problematic and often shocking values in LLM
assistants despite existing control measures. These include cases where AIs
value themselves over humans and are anti-aligned with specific individuals. To
constrain these emergent value systems, we propose methods of utility control.
As a case study, we show how aligning utilities with a citizen assembly reduces
political biases and generalizes to new scenarios. Whether we like it or not,
value systems have already emerged in AIs, and much work remains to fully
understand and control these emergent representations.","Mantas Mazeika, Xuwang Yin, Rishub Tamirisa, Jaehyuk Lim, Bruce W. Lee, Richard Ren, Long Phan, Norman Mu, Adam Khoja, Oliver Zhang, Dan Hendrycks",2025-02-12 18:55:43.000000,arXiv,http://arxiv.org/abs/2502.08640v1,Machine Learning
358,CineMaster: A 3D-Aware and Controllable Framework for Cinematic Text-to-Video Generation,"In this work, we present CineMaster, a novel framework for 3D-aware and
controllable text-to-video generation. Our goal is to empower users with
comparable controllability as professional film directors: precise placement of
objects within the scene, flexible manipulation of both objects and camera in
3D space, and intuitive layout control over the rendered frames. To achieve
this, CineMaster operates in two stages. In the first stage, we design an
interactive workflow that allows users to intuitively construct 3D-aware
conditional signals by positioning object bounding boxes and defining camera
movements within the 3D space. In the second stage, these control
signals--comprising rendered depth maps, camera trajectories and object class
labels--serve as the guidance for a text-to-video diffusion model, ensuring to
generate the user-intended video content. Furthermore, to overcome the scarcity
of in-the-wild datasets with 3D object motion and camera pose annotations, we
carefully establish an automated data annotation pipeline that extracts 3D
bounding boxes and camera trajectories from large-scale video data. Extensive
qualitative and quantitative experiments demonstrate that CineMaster
significantly outperforms existing methods and implements prominent 3D-aware
text-to-video generation. Project page: https://cinemaster-dev.github.io/.","Qinghe Wang, Yawen Luo, Xiaoyu Shi, Xu Jia, Huchuan Lu, Tianfan Xue, Xintao Wang, Pengfei Wan, Di Zhang, Kun Gai",2025-02-12 18:55:36.000000,arXiv,http://arxiv.org/abs/2502.08639v1,Computer Vision
359,Examining Multilingual Embedding Models Cross-Lingually Through LLM-Generated Adversarial Examples,"The evaluation of cross-lingual semantic search capabilities of models is
often limited to existing datasets from tasks such as information retrieval and
semantic textual similarity. To allow for domain-specific evaluation, we
introduce Cross Lingual Semantic Discrimination (CLSD), a novel cross-lingual
semantic search task that requires only a set of parallel sentence pairs of the
language pair of interest within the target domain. This task focuses on the
ability of a model to cross-lingually rank the true parallel sentence higher
than hard negatives generated by a large language model. We create four
instances of our introduced CLSD task for the language pair German-French
within the domain of news. Within this case study, we find that models that are
also fine-tuned for retrieval tasks (e.g., multilingual E5) benefit from using
English as the pivot language, while bitext mining models such as LaBSE perform
best directly cross-lingually. We also show a fine-grained similarity analysis
enabled by our distractor generation strategy, indicating that different
embedding models are sensitive to different types of perturbations.","Andrianos Michail, Simon Clematide, Rico Sennrich",2025-02-12 18:54:37.000000,arXiv,http://arxiv.org/abs/2502.08638v1,Natural Language Processing
360,Joint Transmit and Pinching Beamforming for PASS: Optimization-Based or Learning-Based?,"A novel pinching antenna system (PASS)-enabled downlink multi-user
multiple-input single-output (MISO) framework is proposed. PASS consists of
multiple waveguides spanning over thousands of wavelength, which equip numerous
low-cost dielectric particles, named pinching antennas (PAs), to radiate
signals into free space. The positions of PAs can be reconfigured to change
both the large-scale path losses and phases of signals, thus facilitating the
novel pinching beamforming design. A sum rate maximization problem is
formulated, which jointly optimizes the transmit and pinching beamforming to
adaptively achieve constructive signal enhancement and destructive interference
mitigation. To solve this highly coupled and nonconvex problem, both
optimization-based and learning-based methods are proposed. 1) For the
optimization-based method, a majorization-minimization and penalty dual
decomposition (MM-PDD) algorithm is developed, which handles the nonconvex
complex exponential component using a Lipschitz surrogate function and then
invokes PDD for problem decoupling. 2) For the learning-based method, a novel
Karush-Kuhn-Tucker (KKT)-guided dual learning (KDL) approach is proposed, which
enables KKT solutions to be reconstructed in a data-driven manner by learning
dual variables. Following this idea, a KDL-Tranformer algorithm is developed,
which captures both inter-PA/inter-user dependencies and
channel-state-information (CSI)-beamforming dependencies by attention
mechanisms. Simulation results demonstrate that: i) The proposed PASS framework
significantly outperforms conventional massive multiple input multiple output
(MIMO) system even with a few PAs. ii) The proposed KDL-Transformer can improve
over 30% system performance than MM-PDD algorithm, while achieving a
millisecond-level response on modern GPUs.","Xiaoxia Xu, Xidong Mu, Yuanwei Liu, Arumugam Nallanathan",2025-02-12 18:54:10.000000,arXiv,http://arxiv.org/abs/2502.08637v1,Other
361,PulseCheck457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models,"Although large multimodal models (LMMs) have demonstrated remarkable
capabilities in visual scene interpretation and reasoning, their capacity for
complex and precise 3-dimensional spatial reasoning remains uncertain. Existing
benchmarks focus predominantly on 2D spatial understanding and lack a framework
to comprehensively evaluate 6D spatial reasoning across varying complexities.
To address this limitation, we present PulseCheck457, a scalable and unbiased
synthetic dataset designed with 4 key capability for spatial reasoning:
multi-object recognition, 2D location, 3D location, and 3D orientation. We
develop a cascading evaluation structure, constructing 7 question types across
5 difficulty levels that range from basic single object recognition to our new
proposed complex 6D spatial reasoning tasks. We evaluated various large
multimodal models (LMMs) on PulseCheck457, observing a general decline in
performance as task complexity increases, particularly in 3D reasoning and 6D
spatial tasks. To quantify these challenges, we introduce the Relative
Performance Dropping Rate (RPDR), highlighting key weaknesses in 3D reasoning
capabilities. Leveraging the unbiased attribute design of our dataset, we also
uncover prediction biases across different attributes, with similar patterns
observed in real-world image settings.","Xingrui Wang, Wufei Ma, Tiezheng Zhang, Celso M de Melo, Jieneng Chen, Alan Yuille",2025-02-12 18:53:20.000000,arXiv,http://arxiv.org/abs/2502.08636v2,Computer Vision
362,Rapid Whole Brain Mesoscale In-vivo MR Imaging using Multi-scale Implicit Neural Representation,"Purpose: To develop and validate a novel image reconstruction technique using
implicit neural representations (INR) for multi-view thick-slice acquisitions
while reducing the scan time but maintaining high signal-to-noise ratio (SNR).
Methods: We propose Rotating-view super-resolution (ROVER)-MRI, an unsupervised
neural network-based algorithm designed to reconstruct MRI data from multi-view
thick slices, effectively reducing scan time by 2-fold while maintaining fine
anatomical details. We compare our method to both bicubic interpolation and the
current state-of-the-art regularized least-squares super-resolution
reconstruction (LS-SRR) technique. Validation is performed using ground-truth
ex-vivo monkey brain data, and we demonstrate superior reconstruction quality
across several in-vivo human datasets. Notably, we achieve the reconstruction
of a whole human brain in-vivo T2-weighted image with an unprecedented
180{\mu}m isotropic spatial resolution, accomplished in just 17 minutes of scan
time on a 7T MRI scanner. Results: ROVER-MRI outperformed LS-SRR method in
terms of reconstruction quality with 22.4% lower relative error (RE) and 7.5%
lower full-width half maximum (FWHM) indicating better preservation of fine
structural details in nearly half the scan time. Conclusion: ROVER-MRI offers
an efficient and robust approach for mesoscale MR imaging, enabling rapid,
high-resolution whole-brain scans. Its versatility holds great promise for
research applications requiring anatomical details and time-efficient imaging.","Jun Lyu, Lipeng Ning, William Consagra, Qiang Liu, Richard J. Rushmore, Berkin Bilgic, Yogesh Rathi",2025-02-12 18:48:12.000000,arXiv,http://arxiv.org/abs/2502.08634v1,Other
363,Necessary and Sufficient Oracles: Toward a Computational Taxonomy For Reinforcement Learning,"Algorithms for reinforcement learning (RL) in large state spaces crucially
rely on supervised learning subroutines to estimate objects such as value
functions or transition probabilities. Since only the simplest supervised
learning problems can be solved provably and efficiently, practical performance
of an RL algorithm depends on which of these supervised learning ""oracles"" it
assumes access to (and how they are implemented). But which oracles are better
or worse? Is there a minimal oracle?
  In this work, we clarify the impact of the choice of supervised learning
oracle on the computational complexity of RL, as quantified by the oracle
strength. First, for the task of reward-free exploration in Block MDPs in the
standard episodic access model -- a ubiquitous setting for RL with function
approximation -- we identify two-context regression as a minimal oracle, i.e.
an oracle that is both necessary and sufficient (under a mild regularity
assumption). Second, we identify one-context regression as a near-minimal
oracle in the stronger reset access model, establishing a provable
computational benefit of resets in the process. Third, we broaden our focus to
Low-Rank MDPs, where we give cryptographic evidence that the analogous oracle
from the Block MDP setting is insufficient.","Dhruv Rohatgi, Dylan J. Foster",2025-02-12 18:47:13.000000,arXiv,http://arxiv.org/abs/2502.08632v1,Machine Learning
364,Ensemble based approach to quantifying uncertainty of LLM based classifications,"The output of Large Language Models (LLMs) are a function of the internal
model's parameters and the input provided into the context window. The
hypothesis presented here is that under a greedy sampling strategy the variance
in the LLM's output is a function of the conceptual certainty embedded in the
model's parametric knowledge, as well as the lexical variance in the input.
Finetuning the model results in reducing the sensitivity of the model output to
the lexical input variations. This is then applied to a classification problem
and a probabilistic method is proposed for estimating the certainties of the
predicted classes.","Srijith Rajamohan, Ahmed Salhin, Josh Frazier, Rohit Kumar, Yu-Cheng Tsai, Todd Cook",2025-02-12 18:42:42.000000,arXiv,http://arxiv.org/abs/2502.08631v1,Artificial Intelligence
365,A Bayesian Nonparametric Perspective on Mahalanobis Distance for Out of Distribution Detection,"Bayesian nonparametric methods are naturally suited to the problem of
out-of-distribution (OOD) detection. However, these techniques have largely
been eschewed in favor of simpler methods based on distances between
pre-trained or learned embeddings of data points. Here we show a formal
relationship between Bayesian nonparametric models and the relative Mahalanobis
distance score (RMDS), a commonly used method for OOD detection. Building on
this connection, we propose Bayesian nonparametric mixture models with
hierarchical priors that generalize the RMDS. We evaluate these models on the
OpenOOD detection benchmark and show that Bayesian nonparametric methods can
improve upon existing OOD methods, especially in regimes where training classes
differ in their covariance structure and where there are relatively few data
points per class.","Randolph W. Linderman, Yiran Chen, Scott W. Linderman",2025-02-12 18:39:01.000000,arXiv,http://arxiv.org/abs/2502.08695v1,Statistical Machine Learning
366,Concentration Inequalities for the Stochastic Optimization of Unbounded Objectives with Application to Denoising Score Matching,"We derive novel concentration inequalities that bound the statistical error
for a large class of stochastic optimization problems, focusing on the case of
unbounded objective functions. Our derivations utilize the following tools: 1)
A new form of McDiarmid's inequality that is based on sample dependent one
component difference bounds and which leads to a novel uniform law of large
numbers result for unbounded functions. 2) A Rademacher complexity bound for
families of functions that satisfy an appropriate local Lipschitz property. As
an application of these results, we derive statistical error bounds for
denoising score matching (DSM), an application that inherently requires one to
consider unbounded objective functions, even when the data distribution has
bounded support. In addition, our results establish the benefit of sample reuse
in algorithms that employ easily sampled auxiliary random variables in addition
to the training data, e.g., as in DSM, which uses auxiliary Gaussian random
variables.",Jeremiah Birrell,2025-02-12 18:30:36.000000,arXiv,http://arxiv.org/abs/2502.08628v1,Statistical Machine Learning
367,Randomness of Low-Layer Parameters Determines Confusing Samples in Terms of Interaction Representations of a DNN,"In this paper, we find that the complexity of interactions encoded by a deep
neural network (DNN) can explain its generalization power. We also discover
that the confusing samples of a DNN, which are represented by non-generalizable
interactions, are determined by its low-layer parameters. In comparison, other
factors, such as high-layer parameters and network architecture, have much less
impact on the composition of confusing samples. Two DNNs with different
low-layer parameters usually have fully different sets of confusing samples,
even though they have similar performance. This finding extends the
understanding of the lottery ticket hypothesis, and well explains distinctive
representation power of different DNNs.","Junpeng Zhang, Lei Cheng, Qing Li, Liang Lin, Quanshi Zhang",2025-02-12 18:25:13.000000,arXiv,http://arxiv.org/abs/2502.08625v1,Machine Learning
368,Robot Data Curation with Mutual Information Estimators,"The performance of imitation learning policies often hinges on the datasets
with which they are trained. Consequently, investment in data collection for
robotics has grown across both industrial and academic labs. However, despite
the marked increase in the quantity of demonstrations collected, little work
has sought to assess the quality of said data despite mounting evidence of its
importance in other areas such as vision and language. In this work, we take a
critical step towards addressing the data quality in robotics. Given a dataset
of demonstrations, we aim to estimate the relative quality of individual
demonstrations in terms of both state diversity and action predictability. To
do so, we estimate the average contribution of a trajectory towards the mutual
information between states and actions in the entire dataset, which precisely
captures both the entropy of the state distribution and the state-conditioned
entropy of actions. Though commonly used mutual information estimators require
vast amounts of data often beyond the scale available in robotics, we introduce
a novel technique based on k-nearest neighbor estimates of mutual information
on top of simple VAE embeddings of states and actions. Empirically, we
demonstrate that our approach is able to partition demonstration datasets by
quality according to human expert scores across a diverse set of benchmarks
spanning simulation and real world environments. Moreover, training policies
based on data filtered by our method leads to a 5-10% improvement in RoboMimic
and better performance on real ALOHA and Franka setups.","Joey Hejna, Suvir Mirchandani, Ashwin Balakrishna, Annie Xie, Ayzaan Wahid, Jonathan Tompson, Pannag Sanketi, Dhruv Shah, Coline Devin, Dorsa Sadigh",2025-02-12 18:23:23.000000,arXiv,http://arxiv.org/abs/2502.08623v1,Robotics
369,Forecasting Drought Using Machine Learning in California,"Drought is a frequent and costly natural disaster in California, with major
negative impacts on agricultural production and water resource availability,
particularly groundwater. This study investigated the performance of applying
different machine learning approaches to predicting the U.S. Drought Monitor
classification in California. Four approaches were used: a convolutional neural
network (CNN), random forest, XGBoost, and long short term memory (LSTM)
recurrent neural network, and compared to a baseline persistence model. We
evaluated the models' performance in predicting severe drought (USDM drought
category D2 or higher) using a macro F1 binary classification metric. The LSTM
model emerged as the top performer, followed by XGBoost, CNN, and random
forest. Further evaluation of our results at the county level suggested that
the LSTM model would perform best in counties with more consistent drought
patterns and where severe drought was more common, and the LSTM model would
perform worse where drought scores increased rapidly. Utilizing 30 weeks of
historical data, the LSTM model successfully forecasted drought scores for a
12-week period with a Mean Absolute Error (MAE) of 0.33, equivalent to less
than half a drought category on a scale of 0 to 5. Additionally, the LSTM
achieved a macro F1 score of 0.9, indicating high accuracy in binary
classification for severe drought conditions. Evaluation of different window
and future horizon sizes in weeks suggested that at least 24 weeks of data
would result in the best performance, with best performance for shorter horizon
sizes, particularly less than eight weeks.","Nan K. Li, Angela Chang, David Sherman",2025-02-12 18:20:41.000000,arXiv,http://arxiv.org/abs/2502.08622v1,Machine Learning
370,Mathematical Data Science,"Can machine learning help discover new mathematical structures? In this
article we discuss an approach to doing this which one can call ""mathematical
data science"". In this paradigm, one studies mathematical objects collectively
rather than individually, by creating datasets and doing machine learning
experiments and interpretations. After an overview, we present two case
studies: murmurations in number theory and loadings of partitions related to
Kronecker coefficients in representation theory and combinatorics.","Michael R. Douglas, Kyu-Hwan Lee",2025-02-12 18:15:35.000000,arXiv,http://arxiv.org/abs/2502.08620v1,Other
371,Continuous Cardiac Arrest Prediction in ICU using PPG Foundation Model,"Non-invasive patient monitoring for tracking and predicting adverse acute
health events is an emerging area of research. We pursue in-hospital cardiac
arrest (IHCA) prediction using only single-channel finger photoplethysmography
(PPG) signals. Our proposed two-stage model Feature Extractor-Aggregator
Network (FEAN) leverages powerful representations from pre-trained PPG
foundation models (PPG-GPT of size up to 1 Billion) stacked with sequential
classification models. We propose two FEAN variants (""1H"", ""FH"") which use the
latest one-hour and (max) 24-hour history to make decisions respectively. Our
study is the first to present IHCA prediction results in ICU patients using
only unimodal (continuous PPG signal) waveform deep representations. With our
best model, we obtain an average of 0.79 AUROC over 24~h prediction window
before CA event onset with our model peaking performance at 0.82 one hour
before CA. We also provide a comprehensive analysis of our model through
architectural tuning and PaCMAP visualization of patient health trajectory in
latent space.","Saurabh Kataria, Ran Xiao, Timothy Ruchti, Matthew Clark, Jiaying Lu, Randall J. Lee, Jocelyn Grunwell, Xiao Hu",2025-02-12 18:01:04.000000,arXiv,http://arxiv.org/abs/2502.08612v1,Machine Learning
372,Robustly Learning Monotone Generalized Linear Models via Data Augmentation,"We study the task of learning Generalized Linear models (GLMs) in the
agnostic model under the Gaussian distribution. We give the first
polynomial-time algorithm that achieves a constant-factor approximation for
\textit{any} monotone Lipschitz activation. Prior constant-factor GLM learners
succeed for a substantially smaller class of activations. Our work resolves a
well-known open problem, by developing a robust counterpart to the classical
GLMtron algorithm (Kakade et al., 2011). Our robust learner applies more
generally, encompassing all monotone activations with bounded
$(2+\zeta)$-moments, for any fixed $\zeta>0$ -- a condition that is essentially
necessary. To obtain our results, we leverage a novel data augmentation
technique with decreasing Gaussian noise injection and prove a number of
structural results that may be useful in other settings.","Nikos Zarifis, Puqian Wang, Ilias Diakonikolas, Jelena Diakonikolas",2025-02-12 17:59:21.000000,arXiv,http://arxiv.org/abs/2502.08611v1,Machine Learning
373,Quantifying Security Vulnerabilities: A Metric-Driven Security Analysis of Gaps in Current AI Standards,"As AI systems integrate into critical infrastructure, security gaps in AI
compliance frameworks demand urgent attention. This paper audits and quantifies
security risks in three major AI governance standards: NIST AI RMF 1.0, UK's AI
and Data Protection Risk Toolkit, and the EU's ALTAI. Using a novel risk
assessment methodology, we develop four key metrics: Risk Severity Index (RSI),
Attack Potential Index (AVPI), Compliance-Security Gap Percentage (CSGP), and
Root Cause Vulnerability Score (RCVS). Our analysis identifies 136 concerns
across the frameworks, exposing significant gaps. NIST fails to address 69.23
percent of identified risks, ALTAI has the highest attack vector vulnerability
(AVPI = 0.51) and the ICO Toolkit has the largest compliance-security gap, with
80.00 percent of high-risk concerns remaining unresolved. Root cause analysis
highlights under-defined processes (ALTAI RCVS = 033) and weak implementation
guidance (NIST and ICO RCVS = 0.25) as critical weaknesses. These findings
emphasize the need for stronger, enforceable security controls in AI
compliance. We offer targeted recommendations to enhance security posture and
bridge the gap between compliance and real-world AI risks.","Keerthana Madhavan, Abbas Yazdinejad, Fattane Zarrinkalam, Ali Dehghantanha",2025-02-12 17:57:54.000000,arXiv,http://arxiv.org/abs/2502.08610v1,Other
374,Distillation Scaling Laws,"We provide a distillation scaling law that estimates distilled model
performance based on a compute budget and its allocation between the student
and teacher. Our findings reduce the risks associated with using distillation
at scale; compute allocation for both the teacher and student models can now be
done to maximize student performance. We provide compute optimal distillation
recipes for when 1) a teacher exists, or 2) a teacher needs training. If many
students are to be distilled, or a teacher already exists, distillation
outperforms supervised pretraining until a compute level which grows
predictably with student size. If one student is to be distilled and a teacher
also needs training, supervised learning should be done instead. Additionally,
we provide insights across our large scale study of distillation, which
increase our understanding of distillation and inform experimental design.","Dan Busbridge, Amitis Shidani, Floris Weers, Jason Ramapuram, Etai Littwin, Russ Webb",2025-02-12 17:52:47.000000,arXiv,http://arxiv.org/abs/2502.08606v1,Machine Learning
375,CurvGAD: Leveraging Curvature for Enhanced Graph Anomaly Detection,"Does the intrinsic curvature of complex networks hold the key to unveiling
graph anomalies that conventional approaches overlook? Reconstruction-based
graph anomaly detection (GAD) methods overlook such geometric outliers,
focusing only on structural and attribute-level anomalies. To this end, we
propose CurvGAD - a mixed-curvature graph autoencoder that introduces the
notion of curvature-based geometric anomalies. CurvGAD introduces two parallel
pipelines for enhanced anomaly interpretability: (1) Curvature-equivariant
geometry reconstruction, which focuses exclusively on reconstructing the edge
curvatures using a mixed-curvature, Riemannian encoder and Gaussian
kernel-based decoder; and (2) Curvature-invariant structure and attribute
reconstruction, which decouples structural and attribute anomalies from
geometric irregularities by regularizing graph curvature under discrete
Ollivier-Ricci flow, thereby isolating the non-geometric anomalies. By
leveraging curvature, CurvGAD refines the existing anomaly classifications and
identifies new curvature-driven anomalies. Extensive experimentation over 10
real-world datasets (both homophilic and heterophilic) demonstrates an
improvement of up to 6.5% over state-of-the-art GAD methods.","Karish Grover, Geoffrey J. Gordon, Christos Faloutsos",2025-02-12 17:49:46.000000,arXiv,http://arxiv.org/abs/2502.08605v1,Machine Learning
376,Scalable Thermodynamic Second-order Optimization,"Many hardware proposals have aimed to accelerate inference in AI workloads.
Less attention has been paid to hardware acceleration of training, despite the
enormous societal impact of rapid training of AI models. Physics-based
computers, such as thermodynamic computers, offer an efficient means to solve
key primitives in AI training algorithms. Optimizers that normally would be
computationally out-of-reach (e.g., due to expensive matrix inversions) on
digital hardware could be unlocked with physics-based hardware. In this work,
we propose a scalable algorithm for employing thermodynamic computers to
accelerate a popular second-order optimizer called Kronecker-factored
approximate curvature (K-FAC). Our asymptotic complexity analysis predicts
increasing advantage with our algorithm as $n$, the number of neurons per
layer, increases. Numerical experiments show that even under significant
quantization noise, the benefits of second-order optimization can be preserved.
Finally, we predict substantial speedups for large-scale vision and graph
problems based on realistic hardware characteristics.","Kaelan Donatella, Samuel Duffield, Denis Melanson, Maxwell Aifer, Phoebe Klett, Rajath Salegame, Zach Belateche, Gavin Crooks, Antonio J. Martinez, Patrick J. Coles",2025-02-12 17:44:40.000000,arXiv,http://arxiv.org/abs/2502.08603v1,Other
377,Two-stage hybrid models for enhancing forecasting accuracy on heterogeneous time series,"Compared to local models built in a series-by-series manner, global models
leverage relevant information across time series, resulting in improved
forecasting performance and generalization capacity. Constructing global models
on a set of time series is becoming mainstream in the field of time series
forecasting. However, the advantages of global models may not always be
realized when dealing with heterogeneous data. While they can adapt to
heterogeneous datasets by increasing the model complexity, the model cannot be
infinitely complex due to the finite sample size, which poses challenges for
the application of global models. Additionally, determining whether the time
series data is homogeneous or heterogeneous can be ambiguous in practice. To
address these research gaps, this paper argues that the heterogeneity of the
data should be defined by the global model used, and for each series, the
portion not modelled by the global model represents heterogeneity. It further
proposes two-stage hybrid models, which include a second stage to identify and
model heterogeneous patterns. In this second stage, we can estimate either all
local models or sub-global models across different domains divided based on
heterogeneity. Experiments on four open datasets reveal that the proposed
methods significantly outperform five existing models, indicating they
contribute to fully unleash the potential of global models on heterogeneous
datasets.","Junru Ren, Shaomin Wu",2025-02-12 17:39:02.000000,arXiv,http://arxiv.org/abs/2502.08600v1,Machine Learning
378,SPeCtrum: A Grounded Framework for Multidimensional Identity Representation in LLM-Based Agent,"Existing methods for simulating individual identities often oversimplify
human complexity, which may lead to incomplete or flattened representations. To
address this, we introduce SPeCtrum, a grounded framework for constructing
authentic LLM agent personas by incorporating an individual's multidimensional
self-concept. SPeCtrum integrates three core components: Social Identity (S),
Personal Identity (P), and Personal Life Context (C), each contributing
distinct yet interconnected aspects of identity. To evaluate SPeCtrum's
effectiveness in identity representation, we conducted automated and human
evaluations. Automated evaluations using popular drama characters showed that
Personal Life Context (C)-derived from short essays on preferences and daily
routines-modeled characters' identities more effectively than Social Identity
(S) and Personal Identity (P) alone and performed comparably to the full SPC
combination. In contrast, human evaluations involving real-world individuals
found that the full SPC combination provided a more comprehensive self-concept
representation than C alone. Our findings suggest that while C alone may
suffice for basic identity simulation, integrating S, P, and C enhances the
authenticity and accuracy of real-world identity representation. Overall,
SPeCtrum offers a structured approach for simulating individuals in LLM agents,
enabling more personalized human-AI interactions and improving the realism of
simulation-based behavioral studies.","Keyeun Lee, Seo Hyeong Kim, Seolhee Lee, Jinsu Eun, Yena Ko, Hayeon Jeon, Esther Hehsun Kim, Seonghye Cho, Soeun Yang, Eun-mee Kim, Hajin Lim",2025-02-12 17:38:27.000000,arXiv,http://arxiv.org/abs/2502.08599v1,Natural Language Processing
379,Enhancing Diffusion Models Efficiency by Disentangling Total-Variance and Signal-to-Noise Ratio,"The long sampling time of diffusion models remains a significant bottleneck,
which can be mitigated by reducing the number of diffusion time steps. However,
the quality of samples with fewer steps is highly dependent on the noise
schedule, i.e., the specific manner in which noise is introduced and the signal
is reduced at each step. Although prior work has improved upon the original
variance-preserving and variance-exploding schedules, these approaches
$\textit{passively}$ adjust the total variance, without direct control over it.
In this work, we propose a novel total-variance/signal-to-noise-ratio
disentangled (TV/SNR) framework, where TV and SNR can be controlled
independently. Our approach reveals that different existing schedules, where
the TV explodes exponentially, can be $\textit{improved}$ by setting a constant
TV schedule while preserving the same SNR schedule. Furthermore, generalizing
the SNR schedule of the optimal transport flow matching significantly improves
the performance in molecular structure generation, achieving few step
generation of stable molecules. A similar tendency is observed in image
generation, where our approach with a uniform diffusion time grid performs
comparably to the highly tailored EDM sampler.","Khaled Kahouli, Winfried Ripken, Stefan Gugler, Oliver T. Unke, Klaus-Robert Müller, Shinichi Nakajima",2025-02-12 17:35:43.000000,arXiv,http://arxiv.org/abs/2502.08598v1,Machine Learning
380,Learning in Markets with Heterogeneous Agents: Dynamics and Survival of Bayesian vs. No-Regret Learners,"We analyze the performance of heterogeneous learning agents in asset markets
with stochastic payoffs. Our agents aim to maximize the expected growth rate of
their wealth but have different theories on how to learn this best. We focus on
comparing Bayesian and no-regret learners in market dynamics. Bayesian learners
with a prior over a finite set of models that assign positive prior probability
to the correct model have posterior probabilities that converge exponentially
to the correct model. Consequently, they survive even in the presence of agents
who invest according to the correct model of the stochastic process. Bayesians
with a continuum prior converge to the correct model at a rate of $O((\log
T)/T)$. Online learning theory provides no-regret algorithms for maximizing the
log of wealth in this setting, achieving a worst-case regret bound of $O(\log
T)$ without assuming a steady underlying stochastic process but comparing to
the best fixed investment rule. This regret, as we observe, is of the same
order of magnitude as that of a Bayesian learner with a continuum prior.
However, we show that even such low regret may not be sufficient for survival
in asset markets: an agent can have regret as low as $O(\log T)$, but still
vanish in market dynamics when competing against agents who invest according to
the correct model or even against a perfect Bayesian with a finite prior. On
the other hand, we show that Bayesian learning is fragile, while no-regret
learning requires less knowledge of the environment and is therefore more
robust. Any no-regret learner will drive out of the market an imperfect
Bayesian whose finite prior or update rule has even small errors. We formally
establish the relationship between notions of survival, vanishing, and market
domination studied in economics and the framework of regret minimization, thus
bridging these theories.","David Easley, Yoav Kolumbus, Eva Tardos",2025-02-12 17:34:04.000000,arXiv,http://arxiv.org/abs/2502.08597v1,Other
381,Toward Universal Laws of Outlier Propagation,"We argue that Algorithmic Information Theory (AIT) admits a principled way to
quantify outliers in terms of so-called randomness deficiency. For the
probability distribution generated by a causal Bayesian network, we show that
the randomness deficiency of the joint state decomposes into randomness
deficiencies of each causal mechanism, subject to the Independence of
Mechanisms Principle. Accordingly, anomalous joint observations can be
quantitatively attributed to their root causes, i.e., the mechanisms that
behaved anomalously. As an extension of Levin's law of randomness conservation,
we show that weak outliers cannot cause strong ones when Independence of
Mechanisms holds. We show how these information theoretic laws provide a better
understanding of the behaviour of outliers defined with respect to existing
scores.","Aram Ebtekar, Yuhao Wang, Dominik Janzing",2025-02-12 17:32:23.000000,arXiv,http://arxiv.org/abs/2502.08593v2,Machine Learning
382,Light-A-Video: Training-free Video Relighting via Progressive Light Fusion,"Recent advancements in image relighting models, driven by large-scale
datasets and pre-trained diffusion models, have enabled the imposition of
consistent lighting. However, video relighting still lags, primarily due to the
excessive training costs and the scarcity of diverse, high-quality video
relighting datasets. A simple application of image relighting models on a
frame-by-frame basis leads to several issues: lighting source inconsistency and
relighted appearance inconsistency, resulting in flickers in the generated
videos. In this work, we propose Light-A-Video, a training-free approach to
achieve temporally smooth video relighting. Adapted from image relighting
models, Light-A-Video introduces two key techniques to enhance lighting
consistency. First, we design a Consistent Light Attention (CLA) module, which
enhances cross-frame interactions within the self-attention layers to stabilize
the generation of the background lighting source. Second, leveraging the
physical principle of light transport independence, we apply linear blending
between the source video's appearance and the relighted appearance, using a
Progressive Light Fusion (PLF) strategy to ensure smooth temporal transitions
in illumination. Experiments show that Light-A-Video improves the temporal
consistency of relighted video while maintaining the image quality, ensuring
coherent lighting transitions across frames. Project page:
https://bujiazi.github.io/light-a-video.github.io/.","Yujie Zhou, Jiazi Bu, Pengyang Ling, Pan Zhang, Tong Wu, Qidong Huang, Jinsong Li, Xiaoyi Dong, Yuhang Zang, Yuhang Cao, Anyi Rao, Jiaqi Wang, Li Niu",2025-02-12 17:24:19.000000,arXiv,http://arxiv.org/abs/2502.08590v1,Computer Vision
383,Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks,"A high volume of recent ML security literature focuses on attacks against
aligned large language models (LLMs). These attacks may extract private
information or coerce the model into producing harmful outputs. In real-world
deployments, LLMs are often part of a larger agentic pipeline including memory
systems, retrieval, web access, and API calling. Such additional components
introduce vulnerabilities that make these LLM-powered agents much easier to
attack than isolated LLMs, yet relatively little work focuses on the security
of LLM agents. In this paper, we analyze security and privacy vulnerabilities
that are unique to LLM agents. We first provide a taxonomy of attacks
categorized by threat actors, objectives, entry points, attacker observability,
attack strategies, and inherent vulnerabilities of agent pipelines. We then
conduct a series of illustrative attacks on popular open-source and commercial
agents, demonstrating the immediate practical implications of their
vulnerabilities. Notably, our attacks are trivial to implement and require no
understanding of machine learning.","Ang Li, Yin Zhou, Vethavikashini Chithrra Raghuram, Tom Goldstein, Micah Goldblum",2025-02-12 17:19:36.000000,arXiv,http://arxiv.org/abs/2502.08586v1,Machine Learning
384,Scalable Bilevel Loss Balancing for Multi-Task Learning,"Multi-task learning (MTL) has been widely adopted for its ability to
simultaneously learn multiple tasks. While existing gradient manipulation
methods often yield more balanced solutions than simple scalarization-based
approaches, they typically incur a significant computational overhead of
$\mathcal{O}(K)$ in both time and memory, where $K$ is the number of tasks. In
this paper, we propose BiLB4MTL, a simple and scalable loss balancing approach
for MTL, formulated from a novel bilevel optimization perspective. Our method
incorporates three key components: (i) an initial loss normalization, (ii) a
bilevel loss-balancing formulation, and (iii) a scalable first-order algorithm
that requires only $\mathcal{O}(1)$ time and memory. Theoretically, we prove
that BiLB4MTL guarantees convergence not only to a stationary point of the
bilevel loss balancing problem but also to an $\epsilon$-accurate Pareto
stationary point for all $K$ loss functions under mild conditions. Extensive
experiments on diverse multi-task datasets demonstrate that BiLB4MTL achieves
state-of-the-art performance in both accuracy and efficiency. Code is available
at https://github.com/OptMN-Lab/-BiLB4MTL.","Peiyao Xiao, Chaosheng Dong, Shaofeng Zou, Kaiyi Ji",2025-02-12 17:18:14.000000,arXiv,http://arxiv.org/abs/2502.08585v1,Machine Learning
385,A method for classification of data with uncertainty using hypothesis testing,"Binary classification is a task that involves the classification of data into
one of two distinct classes. It is widely utilized in various fields. However,
conventional classifiers tend to make overconfident predictions for data that
belong to overlapping regions of the two class distributions or for data
outside the distributions (out-of-distribution data). Therefore, conventional
classifiers should not be applied in high-risk fields where classification
results can have significant consequences. In order to address this issue, it
is necessary to quantify uncertainty and adopt decision-making approaches that
take it into account. Many methods have been proposed for this purpose;
however, implementing these methods often requires performing resampling,
improving the structure or performance of models, and optimizing the thresholds
of classifiers. We propose a new decision-making approach using two types of
hypothesis testing. This method is capable of detecting ambiguous data that
belong to the overlapping regions of two class distributions, as well as
out-of-distribution data that are not included in the training data
distribution. In addition, we quantify uncertainty using the empirical
distribution of feature values derived from the training data obtained through
the trained model. The classification threshold is determined by the
$\alpha$-quantile and ($1-\alpha$)-quantile, where the significance level
$\alpha$ is set according to each specific situation.","Shoma Yokura, Akihisa Ichiki",2025-02-12 17:14:07.000000,arXiv,http://arxiv.org/abs/2502.08582v1,Machine Learning
386,Ultrasound Image Generation using Latent Diffusion Models,"Diffusion models for image generation have been a subject of increasing
interest due to their ability to generate diverse, high-quality images. Image
generation has immense potential in medical imaging because open-source medical
images are difficult to obtain compared to natural images, especially for rare
conditions. The generated images can be used later to train classification and
segmentation models. In this paper, we propose simulating realistic ultrasound
(US) images by successive fine-tuning of large diffusion models on different
publicly available databases. To do so, we fine-tuned Stable Diffusion, a
state-of-the-art latent diffusion model, on BUSI (Breast US Images) an
ultrasound breast image dataset. We successfully generated high-quality US
images of the breast using simple prompts that specify the organ and pathology,
which appeared realistic to three experienced US scientists and a US
radiologist. Additionally, we provided user control by conditioning the model
with segmentations through ControlNet. We will release the source code at
http://code.sonography.ai/ to allow fast US image generation to the scientific
community.","Benoit Freiche, Anthony El-Khoury, Ali Nasiri-Sarvi, Mahdi S. Hosseini, Damien Garcia, Adrian Basarab, Mathieu Boily, Hassan Rivaz",2025-02-12 17:11:58.000000,arXiv,http://arxiv.org/abs/2502.08580v1,Computer Vision
387,FBFL: A Field-Based Coordination Approach for Data Heterogeneity in Federated Learning,"In the last years, Federated learning (FL) has become a popular solution to
train machine learning models in domains with high privacy concerns. However,
FL scalability and performance face significant challenges in real-world
deployments where data across devices are non-independently and identically
distributed (non-IID). The heterogeneity in data distribution frequently arises
from spatial distribution of devices, leading to degraded model performance in
the absence of proper handling. Additionally, FL typical reliance on
centralized architectures introduces bottlenecks and single-point-of-failure
risks, particularly problematic at scale or in dynamic environments. To close
this gap, we propose Field-Based Federated Learning (FBFL), a novel approach
leveraging macroprogramming and field coordination to address these limitations
through: (i) distributed spatial-based leader election for personalization to
mitigate non-IID data challenges; and (ii) construction of a self-organizing,
hierarchical architecture using advanced macroprogramming patterns. Moreover,
FBFL not only overcomes the aforementioned limitations, but also enables the
development of more specialized models tailored to the specific data
distribution in each subregion. This paper formalizes FBFL and evaluates it
extensively using MNIST, FashionMNIST, and Extended MNIST datasets. We
demonstrate that, when operating under IID data conditions, FBFL performs
comparably to the widely-used FedAvg algorithm. Furthermore, in challenging
non-IID scenarios, FBFL not only outperforms FedAvg but also surpasses other
state-of-the-art methods, namely FedProx and Scaffold, which have been
specifically designed to address non-IID data distributions. Additionally, we
showcase the resilience of FBFL's self-organizing hierarchical architecture
against server failures.","Davide Domini, Gianluca Aguzzi, Lukas Esterle, Mirko Viroli",2025-02-12 17:10:53.000000,arXiv,http://arxiv.org/abs/2502.08577v1,Machine Learning
388,Mapping the Landscape of Generative AI in Network Monitoring and Management,"Generative Artificial Intelligence (GenAI) models such as LLMs, GPTs, and
Diffusion Models have recently gained widespread attention from both the
research and the industrial communities. This survey explores their application
in network monitoring and management, focusing on prominent use cases, as well
as challenges and opportunities. We discuss how network traffic generation and
classification, network intrusion detection, networked system log analysis, and
network digital assistance can benefit from the use of GenAI models.
Additionally, we provide an overview of the available GenAI models, datasets
for large-scale training phases, and platforms for the development of such
models. Finally, we discuss research directions that potentially mitigate the
roadblocks to the adoption of GenAI for network monitoring and management. Our
investigation aims to map the current landscape and pave the way for future
research in leveraging GenAI for network monitoring and management.","Giampaolo Bovenzi, Francesco Cerasuolo, Domenico Ciuonzo, Davide Di Monda, Idio Guarino, Antonio Montieri, Valerio Persico, Antonio Pescapè",2025-02-12 17:10:34.000000,arXiv,http://arxiv.org/abs/2502.08576v1,Other
389,COAST: Intelligent Time-Adaptive Neural Operators,"We introduce Causal Operator with Adaptive Solver Transformer (COAST), a
novel neural operator learning method that leverages a causal language model
(CLM) framework to dynamically adapt time steps. Our method predicts both the
evolution of a system and its optimal time step, intelligently balancing
computational efficiency and accuracy. We find that COAST generates variable
step sizes that correlate with the underlying system intrinsicities, both
within and across dynamical systems. Within a single trajectory, smaller steps
are taken in regions of high complexity, while larger steps are employed in
simpler regions. Across different systems, more complex dynamics receive more
granular time steps. Benchmarked on diverse systems with varied dynamics, COAST
consistently outperforms state-of-the-art methods, achieving superior
performance in both efficiency and accuracy. This work underscores the
potential of CLM-based intelligent adaptive solvers for scalable operator
learning of dynamical systems.","Zhikai Wu, Shiyang Zhang, Sizhuang He, Sifan Wang, Min Zhu, Anran Jiao, Lu Lu, David van Dijk",2025-02-12 17:09:13.000000,arXiv,http://arxiv.org/abs/2502.08574v1,Machine Learning
390,A Novel Approach to for Multimodal Emotion Recognition : Multimodal semantic information fusion,"With the advancement of artificial intelligence and computer vision
technologies, multimodal emotion recognition has become a prominent research
topic. However, existing methods face challenges such as heterogeneous data
fusion and the effective utilization of modality correlations. This paper
proposes a novel multimodal emotion recognition approach, DeepMSI-MER, based on
the integration of contrastive learning and visual sequence compression. The
proposed method enhances cross-modal feature fusion through contrastive
learning and reduces redundancy in the visual modality by leveraging visual
sequence compression. Experimental results on two public datasets, IEMOCAP and
MELD, demonstrate that DeepMSI-MER significantly improves the accuracy and
robustness of emotion recognition, validating the effectiveness of multimodal
feature fusion and the proposed approach.","Wei Dai, Dequan Zheng, Feng Yu, Yanrong Zhang, Yaohui Hou",2025-02-12 17:07:43.000000,arXiv,http://arxiv.org/abs/2502.08573v1,Computer Vision
391,AR Glulam: Accurate Augmented Reality Using Multiple Fiducial Markers for Glulam Fabrication,"Recent advancements in Augmented Reality (AR) have demonstrated applications
in architecture, design, and fabrication. Compared to conventional 2D
construction drawings, AR can be used to superimpose contextual instructions,
display 3D spatial information and enable on-site engagement. Despite the
potential of AR, the widespread adoption of the technology in the industry is
limited by its precision. Precision is important for projects requiring strict
construction tolerances, design fidelity, and fabrication feedback. For
example, the manufacturing of glulam beams requires tolerances of less than
2mm. The goal of this project is to explore the industrial application of using
multiple fiducial markers for high-precision AR fabrication. While the method
has been validated in lab settings with a precision of 0.97, this paper focuses
on fabricating glulam beams in a factory setting with an industry manufacturer,
Unalam Factory.","Alexander Htet Kyaw, Arvin Xu, Sasa Zivkovic, Gwyllim Jahn, Cameron Newnham, Nick Van Den Berg",2025-02-12 16:56:07.000000,arXiv,http://arxiv.org/abs/2502.08566v1,Other
392,Quality-Aware Decoding: Unifying Quality Estimation and Decoding,"An emerging research direction in NMT involves the use of Quality Estimation
(QE) models, which have demonstrated high correlations with human judgment and
can enhance translations through Quality-Aware Decoding. Although several
approaches have been proposed based on sampling multiple candidate
translations, none have integrated these models directly into the decoding
process. In this paper, we address this by proposing a novel token-level QE
model capable of reliably scoring partial translations. We build a
uni-directional QE model for this, as decoder models are inherently trained and
efficient on partial sequences. We then present a decoding strategy that
integrates the QE model for Quality-Aware decoding and demonstrate that the
translation quality improves when compared to the N-best list re-ranking with
state-of-the-art QE models (upto $1.39$ XCOMET-XXL $\uparrow$). Finally, we
show that our approach provides significant benefits in document translation
tasks, where the quality of N-best lists is typically suboptimal.","Sai Koneru, Matthias Huck, Miriam Exel, Jan Niehues",2025-02-12 16:49:52.000000,arXiv,http://arxiv.org/abs/2502.08561v1,Natural Language Processing
393,Brain Latent Progression: Individual-based Spatiotemporal Disease Progression on 3D Brain MRIs via Latent Diffusion,"The growing availability of longitudinal Magnetic Resonance Imaging (MRI)
datasets has facilitated Artificial Intelligence (AI)-driven modeling of
disease progression, making it possible to predict future medical scans for
individual patients. However, despite significant advancements in AI, current
methods continue to face challenges including achieving patient-specific
individualization, ensuring spatiotemporal consistency, efficiently utilizing
longitudinal data, and managing the substantial memory demands of 3D scans. To
address these challenges, we propose Brain Latent Progression (BrLP), a novel
spatiotemporal model designed to predict individual-level disease progression
in 3D brain MRIs. The key contributions in BrLP are fourfold: (i) it operates
in a small latent space, mitigating the computational challenges posed by
high-dimensional imaging data; (ii) it explicitly integrates subject metadata
to enhance the individualization of predictions; (iii) it incorporates prior
knowledge of disease dynamics through an auxiliary model, facilitating the
integration of longitudinal data; and (iv) it introduces the Latent Average
Stabilization (LAS) algorithm, which (a) enforces spatiotemporal consistency in
the predicted progression at inference time and (b) allows us to derive a
measure of the uncertainty for the prediction. We train and evaluate BrLP on
11,730 T1-weighted (T1w) brain MRIs from 2,805 subjects and validate its
generalizability on an external test set comprising 2,257 MRIs from 962
subjects. Our experiments compare BrLP-generated MRI scans with real follow-up
MRIs, demonstrating state-of-the-art accuracy compared to existing methods. The
code is publicly available at: https://github.com/LemuelPuglisi/BrLP.","Lemuel Puglisi, Daniel C. Alexander, Daniele Ravì",2025-02-12 16:47:41.000000,arXiv,http://arxiv.org/abs/2502.08560v1,Computer Vision
394,QA-Expand: Multi-Question Answer Generation for Enhanced Query Expansion in Information Retrieval,"Query expansion is widely used in Information Retrieval (IR) to improve
search outcomes by enriching queries with additional contextual information.
Although recent Large Language Model (LLM) based methods generate
pseudo-relevant content and expanded terms via multiple prompts, they often
yield repetitive, narrow expansions that lack the diverse context needed to
retrieve all relevant information. In this paper, we introduce QA-Expand, a
novel and effective framework for query expansion. It first generates multiple
relevant questions from the initial query and subsequently produces
corresponding pseudo-answers as surrogate documents. A feedback model further
rewrites and filters these answers to ensure only the most informative
augmentations are incorporated. Extensive experiments on benchmarks such as
BEIR and TREC demonstrate that QA-Expand enhances retrieval performance by up
to 13% over state-of-the-art methods, offering a robust solution for modern
retrieval challenges.","Wonduk Seo, Seunghyun Lee",2025-02-12 16:39:06.000000,arXiv,http://arxiv.org/abs/2502.08557v1,Information Retrieval
395,"Human-Centric Foundation Models: Perception, Generation and Agentic Modeling","Human understanding and generation are critical for modeling digital humans
and humanoid embodiments. Recently, Human-centric Foundation Models (HcFMs)
inspired by the success of generalist models, such as large language and vision
models, have emerged to unify diverse human-centric tasks into a single
framework, surpassing traditional task-specific approaches. In this survey, we
present a comprehensive overview of HcFMs by proposing a taxonomy that
categorizes current approaches into four groups: (1) Human-centric Perception
Foundation Models that capture fine-grained features for multi-modal 2D and 3D
understanding. (2) Human-centric AIGC Foundation Models that generate
high-fidelity, diverse human-related content. (3) Unified Perception and
Generation Models that integrate these capabilities to enhance both human
understanding and synthesis. (4) Human-centric Agentic Foundation Models that
extend beyond perception and generation to learn human-like intelligence and
interactive behaviors for humanoid embodied tasks. We review state-of-the-art
techniques, discuss emerging challenges and future research directions. This
survey aims to serve as a roadmap for researchers and practitioners working
towards more robust, versatile, and intelligent digital human and embodiments
modeling.","Shixiang Tang, Yizhou Wang, Lu Chen, Yuan Wang, Sida Peng, Dan Xu, Wanli Ouyang",2025-02-12 16:38:40.000000,arXiv,http://arxiv.org/abs/2502.08556v1,Computer Vision
396,A Machine Learning-Ready Data Processing Tool for Near Real-Time Forecasting,"Space weather forecasting is critical for mitigating radiation risks in space
exploration and protecting Earth-based technologies from geomagnetic
disturbances. This paper presents the development of a Machine Learning (ML)-
ready data processing tool for Near Real-Time (NRT) space weather forecasting.
By merging data from diverse NRT sources such as solar imagery, magnetic field
measurements, and energetic particle fluxes, the tool addresses key gaps in
current space weather prediction capabilities. The tool processes and
structures the data for machine learning models, focusing on time-series
forecasting and event detection for extreme solar events. It provides users
with a framework to download, process, and label data for ML applications,
streamlining the workflow for improved NRT space weather forecasting and
scientific research.","Maher A Dayeh, Michael J Starkey, Subhamoy Chatterjee, Heather Elliott, Samuel Hart, Kimberly Moreland",2025-02-12 16:35:46.000000,arXiv,http://arxiv.org/abs/2502.08555v1,Other
397,"Fostering Appropriate Reliance on Large Language Models: The Role of Explanations, Sources, and Inconsistencies","Large language models (LLMs) can produce erroneous responses that sound
fluent and convincing, raising the risk that users will rely on these responses
as if they were correct. Mitigating such overreliance is a key challenge.
Through a think-aloud study in which participants use an LLM-infused
application to answer objective questions, we identify several features of LLM
responses that shape users' reliance: explanations (supporting details for
answers), inconsistencies in explanations, and sources. Through a large-scale,
pre-registered, controlled experiment (N=308), we isolate and study the effects
of these features on users' reliance, accuracy, and other measures. We find
that the presence of explanations increases reliance on both correct and
incorrect responses. However, we observe less reliance on incorrect responses
when sources are provided or when explanations exhibit inconsistencies. We
discuss the implications of these findings for fostering appropriate reliance
on LLMs.","Sunnie S. Y. Kim, Jennifer Wortman Vaughan, Q. Vera Liao, Tania Lombrozo, Olga Russakovsky",2025-02-12 16:35:41.000000,arXiv,http://arxiv.org/abs/2502.08554v1,Other
398,LLMs can implicitly learn from mistakes in-context,"Learning from mistakes is a fundamental feature of human intelligence.
Previous work has shown that Large Language Models (LLMs) can also learn from
incorrect answers when provided with a comprehensive rationale detailing why an
answer is wrong or how to correct it. In this work, we examine whether LLMs can
learn from mistakes in mathematical reasoning tasks when these explanations are
not provided. We investigate if LLMs are able to implicitly infer such
rationales simply from observing both incorrect and correct answers.
Surprisingly, we find that LLMs perform better, on average, when rationales are
eliminated from the context and incorrect answers are simply shown alongside
correct ones. This approach also substantially outperforms chain-of-thought
prompting in our evaluations. We show that these results are consistent across
LLMs of different sizes and varying reasoning abilities. Further, we carry out
an in-depth analysis, and show that prompting with both wrong and correct
answers leads to greater performance and better generalisation than introducing
additional, more diverse question-answer pairs into the context. Finally, we
show that new rationales generated by models that have only observed incorrect
and correct answers are scored equally as highly by humans as those produced
with the aid of exemplar rationales. Our results demonstrate that LLMs are
indeed capable of in-context implicit learning.","Lisa Alazraki, Maximilian Mozes, Jon Ander Campos, Yi Chern Tan, Marek Rei, Max Bartolo",2025-02-12 16:31:21.000000,arXiv,http://arxiv.org/abs/2502.08550v1,Natural Language Processing
399,Copula-based mixture model identification for subgroup clustering with imaging applications,"Model-based clustering techniques have been widely applied to various
application areas, while most studies focus on canonical mixtures with unique
component distribution form. However, this strict assumption is often hard to
satisfy. In this paper, we consider the more flexible Copula-Based Mixture
Models (CBMMs) for clustering, which allow heterogeneous component
distributions composed by flexible choices of marginal and copula forms. More
specifically, we propose an adaptation of the Generalized Iterative Conditional
Estimation (GICE) algorithm to identify the CBMMs in an unsupervised manner,
where the marginal and copula forms and their parameters are estimated
iteratively. GICE is adapted from its original version developed for switching
Markov model identification with the choice of realization time. Our CBMM-GICE
clustering method is then tested on synthetic two-cluster data (N=2000 samples)
with discussion of the factors impacting its convergence. Finally, it is
compared to the Expectation Maximization identified mixture models with unique
component form on the entire MNIST database (N=70000), and on real cardiac
magnetic resonance data (N=276) to illustrate its value for imaging
applications.","Fei Zheng, Nicolas Duchateau",2025-02-12 16:30:39.000000,arXiv,http://arxiv.org/abs/2502.08549v1,Computer Vision
400,Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data,"The adoption of EHRs has expanded opportunities to leverage data-driven
algorithms in clinical care and research. A major bottleneck in effectively
conducting multi-institutional EHR studies is the data heterogeneity across
systems with numerous codes that either do not exist or represent different
clinical concepts across institutions. The need for data privacy further limits
the feasibility of including multi-institutional patient-level data required to
study similarities and differences across patient subgroups. To address these
challenges, we developed the GAME algorithm. Tested and validated across 7
institutions and 2 languages, GAME integrates data in several levels: (1) at
the institutional level with knowledge graphs to establish relationships
between codes and existing knowledge sources, providing the medical context for
standard codes and their relationship to each other; (2) between institutions,
leveraging language models to determine the relationships between
institution-specific codes with established standard codes; and (3) quantifying
the strength of the relationships between codes using a graph attention
network. Jointly trained embeddings are created using transfer and federated
learning to preserve data privacy. In this study, we demonstrate the
applicability of GAME in selecting relevant features as inputs for AI-driven
algorithms in a range of conditions, e.g., heart failure, rheumatoid arthritis.
We then highlight the application of GAME harmonized multi-institutional EHR
data in a study of Alzheimer's disease outcomes and suicide risk among patients
with mental health disorders, without sharing patient-level data outside
individual institutions.","Doudou Zhou, Han Tong, Linshanshan Wang, Suqi Liu, Xin Xiong, Ziming Gan, Romain Griffier, Boris Hejblum, Yun-Chung Liu, Chuan Hong, Clara-Lea Bonzel, Tianrun Cai, Kevin Pan, Yuk-Lam Ho, Lauren Costa, Vidul A. Panickan, J. Michael Gaziano, Kenneth Mandl, Vianney Jouhet, Rodolphe Thiebaut, Zongqi Xia, Kelly Cho, Katherine Liao, Tianxi Cai",2025-02-12 16:29:39.000000,arXiv,http://arxiv.org/abs/2502.08547v1,Artificial Intelligence
401,Moment of Untruth: Dealing with Negative Queries in Video Moment Retrieval,"Video Moment Retrieval is a common task to evaluate the performance of
visual-language models - it involves localising start and end times of moments
in videos from query sentences. The current task formulation assumes that the
queried moment is present in the video, resulting in false positive moment
predictions when irrelevant query sentences are provided. In this paper we
propose the task of Negative-Aware Video Moment Retrieval (NA-VMR), which
considers both moment retrieval accuracy and negative query rejection accuracy.
We make the distinction between In-Domain and Out-of-Domain negative queries
and provide new evaluation benchmarks for two popular video moment retrieval
datasets: QVHighlights and Charades-STA. We analyse the ability of current SOTA
video moment retrieval approaches to adapt to Negative-Aware Video Moment
Retrieval and propose UniVTG-NA, an adaptation of UniVTG designed to tackle
NA-VMR. UniVTG-NA achieves high negative rejection accuracy (avg. $98.4\%$)
scores while retaining moment retrieval scores to within $3.87\%$ Recall@1.
Dataset splits and code are available at
https://github.com/keflanagan/MomentofUntruth","Kevin Flanagan, Dima Damen, Michael Wray",2025-02-12 16:28:21.000000,arXiv,http://arxiv.org/abs/2502.08544v2,Computer Vision
402,Beyond Predictions: A Participatory Framework for Multi-Stakeholder Decision-Making,"Conventional decision-support systems, primarily based on supervised
learning, focus on outcome prediction models to recommend actions. However,
they often fail to account for the complexities of multi-actor environments,
where diverse and potentially conflicting stakeholder preferences must be
balanced. In this paper, we propose a novel participatory framework that
redefines decision-making as a multi-stakeholder optimization problem,
capturing each actor's preferences through context-dependent reward functions.
Our framework leverages $k$-fold cross-validation to fine-tune user-provided
outcome prediction models and evaluate decision strategies, including
compromise functions mediating stakeholder trade-offs. We introduce a synthetic
scoring mechanism that exploits user-defined preferences across multiple
metrics to rank decision-making strategies and identify the optimal
decision-maker. The selected decision-maker can then be used to generate
actionable recommendations for new data. We validate our framework using two
real-world use cases, demonstrating its ability to deliver recommendations that
effectively balance multiple metrics, achieving results that are often beyond
the scope of purely prediction-based methods. Ablation studies demonstrate that
our framework, with its modular, model-agnostic, and inherently transparent
design, integrates seamlessly with various predictive models, reward
structures, evaluation metrics, and sample sizes, making it particularly suited
for complex, high-stakes decision-making contexts.","Vittoria Vineis, Giuseppe Perelli, Gabriele Tolomei",2025-02-12 16:27:40.000000,arXiv,http://arxiv.org/abs/2502.08542v1,Machine Learning
403,"A Survey on Image Quality Assessment: Insights, Analysis, and Future Outlook","Image quality assessment (IQA) represents a pivotal challenge in
image-focused technologies, significantly influencing the advancement
trajectory of image processing and computer vision. Recently, IQA has witnessed
a notable surge in innovative research efforts, driven by the emergence of
novel architectural paradigms and sophisticated computational techniques. This
survey delivers an extensive analysis of contemporary IQA methodologies,
organized according to their application scenarios, serving as a beneficial
reference for both beginners and experienced researchers. We analyze the
advantages and limitations of current approaches and suggest potential future
research pathways. The survey encompasses both general and specific IQA
methodologies, including conventional statistical measures, machine learning
techniques, and cutting-edge deep learning models such as convolutional neural
networks (CNNs) and Transformer models. The analysis within this survey
highlights the necessity for distortion-specific IQA methods tailored to
various application scenarios, emphasizing the significance of practicality,
interpretability, and ease of implementation in future developments.","Chengqian Ma, Zhengyi Shi, Zhiqiang Lu, Shenghao Xie, Fei Chao, Yao Sui",2025-02-12 16:24:22.000000,arXiv,http://arxiv.org/abs/2502.08540v1,Computer Vision
404,Matrix Completion with Graph Information: A Provable Nonconvex Optimization Approach,"We consider the problem of matrix completion with graphs as side information
depicting the interrelations between variables. The key challenge lies in
leveraging the similarity structure of the graph to enhance matrix recovery.
Existing approaches, primarily based on graph Laplacian regularization, suffer
from several limitations: (1) they focus only on the similarity between
neighboring variables, while overlooking long-range correlations; (2) they are
highly sensitive to false edges in the graphs and (3) they lack theoretical
guarantees regarding statistical and computational complexities. To address
these issues, we propose in this paper a novel graph regularized matrix
completion algorithm called GSGD, based on preconditioned projected gradient
descent approach. We demonstrate that GSGD effectively captures the
higher-order correlation information behind the graphs, and achieves superior
robustness and stability against the false edges. Theoretically, we prove that
GSGD achieves linear convergence to the global optimum with near-optimal sample
complexity, providing the first theoretical guarantees for both recovery
accuracy and efficacy in the perspective of nonconvex optimization. Our
numerical experiments on both synthetic and real-world data further validate
that GSGD achieves superior recovery accuracy and scalability compared with
several popular alternatives.","Yao Wang, Yiyang Yang, Kaidong Wang, Shanxing Gao, Xiuwu Liao",2025-02-12 16:21:01.000000,arXiv,http://arxiv.org/abs/2502.08536v1,Machine Learning
405,Input convex neural networks: universal approximation theorem and implementation for isotropic polyconvex hyperelastic energies,"This paper presents a novel framework of neural networks for isotropic
hyperelasticity that enforces necessary physical and mathematical constraints
while simultaneously satisfying the universal approximation theorem. The two
key ingredients are an input convex network architecture and a formulation in
the elementary polynomials of the signed singular values of the deformation
gradient. In line with previously published networks, it can rigorously capture
frame-indifference and polyconvexity - as well as further constraints like
balance of angular momentum and growth conditions. However and in contrast to
previous networks, a universal approximation theorem for the proposed approach
is proven. To be more explicit, the proposed network can approximate any
frame-indifferent, isotropic polyconvex energy (provided the network is large
enough). This is possible by working with a sufficient and necessary criterion
for frame-indifferent, isotropic polyconvex functions. Comparative studies with
existing approaches identify the advantages of the proposed method,
particularly in approximating non-polyconvex energies as well as computing
polyconvex hulls.","Gian-Luca Geuken, Patrick Kurzeja, David Wiedemann, Jörn Mosler",2025-02-12 16:15:03.000000,arXiv,http://arxiv.org/abs/2502.08534v1,Other
406,On Different Notions of Redundancy in Conditional-Independence-Based Discovery of Graphical Models,"The goal of conditional-independence-based discovery of graphical models is
to find a graph that represents the independence structure of variables in a
given dataset. To learn such a representation, conditional-independence-based
approaches conduct a set of statistical tests that suffices to identify the
graphical representation under some assumptions on the underlying distribution
of the data. In this work, we highlight that due to the conciseness of the
graphical representation, there are often many tests that are not used in the
construction of the graph. These redundant tests have the potential to detect
or sometimes correct errors in the learned model. We show that not all tests
contain this additional information and that such redundant tests have to be
applied with care. Precisely, we argue that particularly those conditional
(in)dependence statements are interesting that follow only from graphical
assumptions but do not hold for every probability distribution.","Philipp M. Faller, Dominik Janzing",2025-02-12 16:08:48.000000,arXiv,http://arxiv.org/abs/2502.08531v1,Machine Learning
407,BCDDM: Branch-Corrected Denoising Diffusion Model for Black Hole Image Generation,"The properties of black holes and accretion flows can be inferred by fitting
Event Horizon Telescope (EHT) data to simulated images generated through
general relativistic ray tracing (GRRT). However, due to the computationally
intensive nature of GRRT, the efficiency of generating specific radiation flux
images needs to be improved. This paper introduces the Branch Correction
Denoising Diffusion Model (BCDDM), which uses a branch correction mechanism and
a weighted mixed loss function to improve the accuracy of generated black hole
images based on seven physical parameters of the radiatively inefficient
accretion flow (RIAF) model. Our experiments show a strong correlation between
the generated images and their physical parameters. By enhancing the GRRT
dataset with BCDDM-generated images and using ResNet50 for parameter
regression, we achieve significant improvements in parameter prediction
performance. This approach reduces computational costs and provides a faster,
more efficient method for dataset expansion, parameter estimation, and model
fitting.","Ao liu, Zelin Zhang, Songbai Chen, Cuihong Wen",2025-02-12 16:05:46.000000,arXiv,http://arxiv.org/abs/2502.08528v1,Other
408,LLM Pretraining with Continuous Concepts,"Next token prediction has been the standard training objective used in large
language model pretraining. Representations are learned as a result of
optimizing for token-level perplexity. We propose Continuous Concept Mixing
(CoCoMix), a novel pretraining framework that combines discrete next token
prediction with continuous concepts. Specifically, CoCoMix predicts continuous
concepts learned from a pretrained sparse autoencoder and mixes them into the
model's hidden state by interleaving with token hidden representations. Through
experiments on multiple benchmarks, including language modeling and downstream
reasoning tasks, we show that CoCoMix is more sample efficient and consistently
outperforms standard next token prediction, knowledge distillation and
inserting pause tokens. We find that combining both concept learning and
interleaving in an end-to-end framework is critical to performance gains.
Furthermore, CoCoMix enhances interpretability and steerability by allowing
direct inspection and modification of the predicted concept, offering a
transparent way to guide the model's internal reasoning process.","Jihoon Tack, Jack Lanchantin, Jane Yu, Andrew Cohen, Ilia Kulikov, Janice Lan, Shibo Hao, Yuandong Tian, Jason Weston, Xian Li",2025-02-12 16:00:11.000000,arXiv,http://arxiv.org/abs/2502.08524v1,Machine Learning
409,FedMHO: Heterogeneous One-Shot Federated Learning Towards Resource-Constrained Edge Devices,"Federated Learning (FL) is increasingly adopted in edge computing scenarios,
where a large number of heterogeneous clients operate under constrained or
sufficient resources. The iterative training process in conventional FL
introduces significant computation and communication overhead, which is
unfriendly for resource-constrained edge devices. One-shot FL has emerged as a
promising approach to mitigate communication overhead, and model-heterogeneous
FL solves the problem of diverse computing resources across clients. However,
existing methods face challenges in effectively managing model-heterogeneous
one-shot FL, often leading to unsatisfactory global model performance or
reliance on auxiliary datasets. To address these challenges, we propose a novel
FL framework named FedMHO, which leverages deep classification models on
resource-sufficient clients and lightweight generative models on
resource-constrained devices. On the server side, FedMHO involves a two-stage
process that includes data generation and knowledge fusion. Furthermore, we
introduce FedMHO-MD and FedMHO-SD to mitigate the knowledge-forgetting problem
during the knowledge fusion stage, and an unsupervised data optimization
solution to improve the quality of synthetic samples. Comprehensive experiments
demonstrate the effectiveness of our methods, as they outperform
state-of-the-art baselines in various experimental setups.","Dezhong Yao, Yuexin Shi, Tongtong Liu, Zhiqiang Xu",2025-02-12 15:54:56.000000,arXiv,http://arxiv.org/abs/2502.08518v1,Machine Learning
410,Efficient Split Learning LSTM Models for FPGA-based Edge IoT Devices,"Split Learning (SL) recently emerged as an efficient paradigm for distributed
Machine Learning (ML) suitable for the Internet Of Things (IoT)-Cloud systems.
However, deploying SL on resource-constrained edge IoT platforms poses a
significant challenge in terms of balancing the model performance against the
processing, memory, and energy resources. In this work, we present a practical
study of deploying SL framework on a real-world Field-Programmable Gate Array
(FPGA)-based edge IoT platform. We address the SL framework applied to a
time-series processing model based on Recurrent Neural Networks (RNNs). Set in
the context of river water quality monitoring and using real-world data, we
train, optimize, and deploy a Long Short-Term Memory (LSTM) model on a given
edge IoT FPGA platform in different SL configurations. Our results demonstrate
the importance of aligning design choices with specific application
requirements, whether it is maximizing speed, minimizing power, or optimizing
for resource constraints.","Romina Soledad Molina, Vukan Ninkovic, Dejan Vukobratovic, Maria Liz Crespo, Marco Zennaro",2025-02-12 15:51:39.000000,arXiv,http://arxiv.org/abs/2502.08692v1,Machine Learning
411,The Paradox of Stochasticity: Limited Creativity and Computational Decoupling in Temperature-Varied LLM Outputs of Structured Fictional Data,"This study examines how temperature settings and model architectures affect
the generation of structured fictional data (names, birthdates) across three
large language models (LLMs): llama3.1:8b, deepseek-r1:8b, and mistral:latest.
By systematically testing temperature values from 0.0 to 1.0 in increments of
0.1, we conducted 330 trials yielding 889 structured entities, validated for
syntactic consistency. Key findings reveal that model architecture
significantly influences computational efficiency, with mistral:latest and
llama3.1:8b processing data 8x faster than deepseek-r1:8b. Contrary to
expectations, temperature showed no correlation with processing time,
challenging assumptions about stochastic sampling costs. Output diversity
remained limited, as models consistently defaulted to common name archetypes
(e.g., 'John Doe' and 'Jane Smith') across all temperatures, though rare names
clustered at intermediate values (0.3-0.7). These results demonstrate that
architectural optimizations, rather than temperature adjustments, dominate
performance in structured generation tasks. The findings emphasize prioritizing
model selection over hyperparameter tuning for efficiency and suggest explicit
diversity constraints are necessary to mitigate default output biases in
synthetic data pipelines.",Evgenii Evstafev,2025-02-12 15:47:48.000000,arXiv,http://arxiv.org/abs/2502.08515v1,Machine Learning
412,"Faithful, Unfaithful or Ambiguous? Multi-Agent Debate with Initial Stance for Summary Evaluation","Faithfulness evaluators based on large language models (LLMs) are often
fooled by the fluency of the text and struggle with identifying errors in the
summaries. We propose an approach to summary faithfulness evaluation in which
multiple LLM-based agents are assigned initial stances (regardless of what
their belief might be) and forced to come up with a reason to justify the
imposed belief, thus engaging in a multi-round debate to reach an agreement.
The uniformly distributed initial assignments result in a greater diversity of
stances leading to more meaningful debates and ultimately more errors
identified. Furthermore, by analyzing the recent faithfulness evaluation
datasets, we observe that naturally, it is not always the case for a summary to
be either faithful to the source document or not. We therefore introduce a new
dimension, ambiguity, and a detailed taxonomy to identify such special cases.
Experiments demonstrate our approach can help identify ambiguities, and have
even a stronger performance on non-ambiguous summaries.","Mahnaz Koupaee, Jake W. Vincent, Saab Mansour, Igor Shalyminov, Han He, Hwanjun Song, Raphael Shu, Jianfeng He, Yi Nian, Amy Wing-mei Wong, Kyu J. Han, Hang Su",2025-02-12 15:46:50.000000,arXiv,http://arxiv.org/abs/2502.08514v2,Natural Language Processing
413,Measuring Diversity in Synthetic Datasets,"Large language models (LLMs) are widely adopted to generate synthetic
datasets for various natural language processing (NLP) tasks, such as text
classification and summarization. However, accurately measuring the diversity
of these synthetic datasets-an aspect crucial for robust model
performance-remains a significant challenge. In this paper, we introduce
DCScore, a novel method for measuring synthetic dataset diversity from a
classification perspective. Specifically, DCScore formulates diversity
evaluation as a sample classification task, leveraging mutual relationships
among samples. We further provide theoretical verification of the
diversity-related axioms satisfied by DCScore, highlighting its role as a
principled diversity evaluation method. Experimental results on synthetic
datasets reveal that DCScore enjoys a stronger correlation with multiple
diversity pseudo-truths of evaluated datasets, underscoring its effectiveness.
Moreover, both empirical and theoretical evidence demonstrate that DCScore
substantially reduces computational costs compared to existing approaches. Code
is available at: https://github.com/BlueWhaleLab/DCScore.","Yuchang Zhu, Huizhe Zhang, Bingzhe Wu, Jintang Li, Zibin Zheng, Peilin Zhao, Liang Chen, Yatao Bian",2025-02-12 15:46:34.000000,arXiv,http://arxiv.org/abs/2502.08512v1,Natural Language Processing
414,Explanation based In-Context Demonstrations Retrieval for Multilingual Grammatical Error Correction,"Grammatical error correction (GEC) aims to correct grammatical, spelling, and
semantic errors in natural language text. With the growing of large language
models (LLMs), direct text generation has gradually become the focus of the GEC
methods, and few-shot in-context learning presents a cost-effective solution.
However, selecting effective in-context examples remains challenging, as the
similarity between input texts does not necessarily correspond to similar
grammatical error patterns. In this paper, we propose a novel retrieval method
based on natural language grammatical error explanations (GEE) to address this
issue. Our method retrieves suitable few-shot demonstrations by matching the
GEE of the test input with that of pre-constructed database samples, where
explanations for erroneous samples are generated by LLMs. We conducted
multilingual GEC few-shot experiments on both major open-source and
closed-source LLMs. Experiments across five languages show that our method
outperforms existing semantic and BM25-based retrieval techniques, without
requiring additional training or language adaptation. This also suggests that
matching error patterns is key to selecting examples.","Wei Li, Wen Luo, Guangyue Peng, Houfeng Wang",2025-02-12 15:41:43.000000,arXiv,http://arxiv.org/abs/2502.08507v1,Natural Language Processing
415,Bridging Domain Adaptation and Graph Neural Networks: A Tensor-Based Framework for Effective Label Propagation,"Graph Neural Networks (GNNs) have recently become the predominant tools for
studying graph data. Despite state-of-the-art performance on graph
classification tasks, GNNs are overwhelmingly trained in a single domain under
supervision, thus necessitating a prohibitively high demand for labels and
resulting in poorly transferable representations. To address this challenge, we
propose the Label-Propagation Tensor Graph Neural Network (LP-TGNN) framework
to bridge the gap between graph data and traditional domain adaptation methods.
It extracts graph topological information holistically with a tensor
architecture and then reduces domain discrepancy through label propagation. It
is readily compatible with general GNNs and domain adaptation techniques with
minimal adjustment through pseudo-labeling. Experiments on various real-world
benchmarks show that our LP-TGNN outperforms baselines by a notable margin. We
also validate and analyze each component of the proposed framework in the
ablation study.","Tao Wen, Elynn Chen, Yuzhou Chen, Qi Lei",2025-02-12 15:36:38.000000,arXiv,http://arxiv.org/abs/2502.08505v1,Machine Learning
416,Revisiting 3D LLM Benchmarks: Are We Really Testing 3D Capabilities?,"In this work, we identify the ""2D-Cheating"" problem in 3D LLM evaluation,
where these tasks might be easily solved by VLMs with rendered images of point
clouds, exposing ineffective evaluation of 3D LLMs' unique 3D capabilities. We
test VLM performance across multiple 3D LLM benchmarks and, using this as a
reference, propose principles for better assessing genuine 3D understanding. We
also advocate explicitly separating 3D abilities from 1D or 2D aspects when
evaluating 3D LLMs.","Jiahe Jin, Yanheng He, Mingyan Yang",2025-02-12 15:34:45.000000,arXiv,http://arxiv.org/abs/2502.08503v1,Artificial Intelligence
417,Fine-Tuning Topics through Weighting Aspect Keywords,"Topic modeling often requires examining topics from multiple perspectives to
uncover hidden patterns, especially in less explored areas. This paper presents
an approach to address this need, utilizing weighted keywords from various
aspects derived from a domain knowledge. The research method starts with
standard topic modeling. Then, it adds a process consisting of four key steps.
First, it defines keywords for each aspect. Second, it gives weights to these
keywords based on their relevance. Third, it calculates relevance scores for
aspect-weighted keywords and topic keywords to create aspect-topic models.
Fourth, it uses these scores to tune relevant new documents. Finally, the
generated topic models are interpreted and validated. The findings show that
top-scoring documents are more likely to be about the same aspect of a topic.
This highlights the model's effectiveness in finding the related documents to
the aspects.","Ali Nazari, Michael Weiss",2025-02-12 15:31:16.000000,arXiv,http://arxiv.org/abs/2502.08496v1,Information Retrieval
418,AgentSociety: Large-Scale Simulation of LLM-Driven Generative Agents Advances Understanding of Human Behaviors and Society,"Understanding human behavior and society is a central focus in social
sciences, with the rise of generative social science marking a significant
paradigmatic shift. By leveraging bottom-up simulations, it replaces costly and
logistically challenging traditional experiments with scalable, replicable, and
systematic computational approaches for studying complex social dynamics.
Recent advances in large language models (LLMs) have further transformed this
research paradigm, enabling the creation of human-like generative social agents
and realistic simulacra of society. In this paper, we propose AgentSociety, a
large-scale social simulator that integrates LLM-driven agents, a realistic
societal environment, and a powerful large-scale simulation engine. Based on
the proposed simulator, we generate social lives for over 10k agents,
simulating their 5 million interactions both among agents and between agents
and their environment. Furthermore, we explore the potential of AgentSociety as
a testbed for computational social experiments, focusing on four key social
issues: polarization, the spread of inflammatory messages, the effects of
universal basic income policies, and the impact of external shocks such as
hurricanes. These four issues serve as valuable cases for assessing
AgentSociety's support for typical research methods -- such as surveys,
interviews, and interventions -- as well as for investigating the patterns,
causes, and underlying mechanisms of social issues. The alignment between
AgentSociety's outcomes and real-world experimental results not only
demonstrates its ability to capture human behaviors and their underlying
mechanisms, but also underscores its potential as an important platform for
social scientists and policymakers.","Jinghua Piao, Yuwei Yan, Jun Zhang, Nian Li, Junbo Yan, Xiaochong Lan, Zhihong Lu, Zhiheng Zheng, Jing Yi Wang, Di Zhou, Chen Gao, Fengli Xu, Fang Zhang, Ke Rong, Jun Su, Yong Li",2025-02-12 15:27:07.000000,arXiv,http://arxiv.org/abs/2502.08691v1,Other
419,Salamandra Technical Report,"This work introduces Salamandra, a suite of open-source decoder-only large
language models available in three different sizes: 2, 7, and 40 billion
parameters. The models were trained from scratch on highly multilingual data
that comprises text in 35 European languages and code. Our carefully curated
corpus is made exclusively from open-access data compiled from a wide variety
of sources. Along with the base models, supplementary checkpoints that were
fine-tuned on public-domain instruction data are also released for chat
applications. Additionally, we also share our preliminary experiments on
multimodality, which serve as proof-of-concept to showcase potential
applications for the Salamandra family. Our extensive evaluations on
multilingual benchmarks reveal that Salamandra has strong capabilities,
achieving competitive performance when compared to similarly sized open-source
models. We provide comprehensive evaluation results both on standard downstream
tasks as well as key aspects related to bias and safety.With this technical
report, we intend to promote open science by sharing all the details behind our
design choices, data curation strategy and evaluation methodology. In addition
to that, we deviate from the usual practice by making our training and
evaluation scripts publicly accessible. We release all models under a
permissive Apache 2.0 license in order to foster future research and facilitate
commercial use, thereby contributing to the open-source ecosystem of large
language models.","Aitor Gonzalez-Agirre, Marc Pàmies, Joan Llop, Irene Baucells, Severino Da Dalt, Daniel Tamayo, José Javier Saiz, Ferran Espuña, Jaume Prats, Javier Aula-Blasco, Mario Mina, Iñigo Pikabea, Adrián Rubio, Alexander Shvets, Anna Sallés, Iñaki Lacunza, Jorge Palomar, Júlia Falcão, Lucía Tormo, Luis Vasquez-Reina, Montserrat Marimon, Oriol Pareras, Valle Ruiz-Fernández, Marta Villegas",2025-02-12 15:26:08.000000,arXiv,http://arxiv.org/abs/2502.08489v2,Natural Language Processing
420,One-Shot Federated Learning with Classifier-Free Diffusion Models,"Federated learning (FL) enables collaborative learning without data
centralization but introduces significant communication costs due to multiple
communication rounds between clients and the server. One-shot federated
learning (OSFL) addresses this by forming a global model with a single
communication round, often relying on the server's model distillation or
auxiliary dataset generation - often through pre-trained diffusion models
(DMs). Existing DM-assisted OSFL methods, however, typically employ
classifier-guided DMs, which require training auxiliary classifier models at
each client, introducing additional computation overhead. This work introduces
OSCAR (One-Shot Federated Learning with Classifier-Free Diffusion Models), a
novel OSFL approach that eliminates the need for auxiliary models. OSCAR uses
foundation models to devise category-specific data representations at each
client, seamlessly integrated into a classifier-free diffusion model pipeline
for server-side data generation. OSCAR is a simple yet cost-effective OSFL
approach that outperforms the state-of-the-art on four benchmarking datasets
while reducing the communication load by at least 99%.","Obaidullah Zaland, Shutong Jin, Florian T. Pokorny, Monowar Bhuyan",2025-02-12 15:23:29.000000,arXiv,http://arxiv.org/abs/2502.08488v1,Machine Learning
421,Referring Remote Sensing Image Segmentation via Bidirectional Alignment Guided Joint Prediction,"Referring Remote Sensing Image Segmentation (RRSIS) is critical for
ecological monitoring, urban planning, and disaster management, requiring
precise segmentation of objects in remote sensing imagery guided by textual
descriptions. This task is uniquely challenging due to the considerable
vision-language gap, the high spatial resolution and broad coverage of remote
sensing imagery with diverse categories and small targets, and the presence of
clustered, unclear targets with blurred edges. To tackle these issues, we
propose \ours, a novel framework designed to bridge the vision-language gap,
enhance multi-scale feature interaction, and improve fine-grained object
differentiation. Specifically, \ours introduces: (1) the Bidirectional Spatial
Correlation (BSC) for improved vision-language feature alignment, (2) the
Target-Background TwinStream Decoder (T-BTD) for precise distinction between
targets and non-targets, and (3) the Dual-Modal Object Learning Strategy
(D-MOLS) for robust multimodal feature reconstruction. Extensive experiments on
the benchmark datasets RefSegRS and RRSIS-D demonstrate that \ours achieves
state-of-the-art performance. Specifically, \ours improves the overall IoU
(oIoU) by 3.76 percentage points (80.57) and 1.44 percentage points (79.23) on
the two datasets, respectively. Additionally, it outperforms previous methods
in the mean IoU (mIoU) by 5.37 percentage points (67.95) and 1.84 percentage
points (66.04), effectively addressing the core challenges of RRSIS with
enhanced precision and robustness.","Tianxiang Zhang, Zhaokun Wen, Bo Kong, Kecheng Liu, Yisi Zhang, Peixian Zhuang, Jiangyun Li",2025-02-12 15:21:18.000000,arXiv,http://arxiv.org/abs/2502.08486v1,Computer Vision
422,Enhancing Auto-regressive Chain-of-Thought through Loop-Aligned Reasoning,"Chain-of-Thought (CoT) prompting has emerged as a powerful technique for
enhancing language model's reasoning capabilities. However, generating long and
correct CoT trajectories is challenging. Recent studies have demonstrated that
Looped Transformers possess remarkable length generalization capabilities, but
their limited generality and adaptability prevent them from serving as an
alternative to auto-regressive solutions. To better leverage the strengths of
Looped Transformers, we propose RELAY (REasoning through Loop Alignment
iterativelY). Specifically, we align the steps of Chain-of-Thought (CoT)
reasoning with loop iterations and apply intermediate supervision during the
training of Looped Transformers. This additional iteration-wise supervision not
only preserves the Looped Transformer's ability for length generalization but
also enables it to predict CoT reasoning steps for unseen data. Therefore, we
leverage this Looped Transformer to generate accurate reasoning chains for
complex problems that exceed the training length, which will then be used to
fine-tune an auto-regressive model. We conduct extensive experiments, and the
results demonstrate the effectiveness of our approach, with significant
improvements in the performance of the auto-regressive model. Code will be
released at https://github.com/qifanyu/RELAY.","Qifan Yu, Zhenyu He, Sijie Li, Xun Zhou, Jun Zhang, Jingjing Xu, Di He",2025-02-12 15:17:04.000000,arXiv,http://arxiv.org/abs/2502.08482v1,Natural Language Processing
423,Numerical Schemes for Signature Kernels,"Signature kernels have emerged as a powerful tool within kernel methods for
sequential data. In the paper ""The Signature Kernel is the solution of a
Goursat PDE"", the authors identify a kernel trick that demonstrates that, for
continuously differentiable paths, the signature kernel satisfies a Goursat
problem for a hyperbolic partial differential equation (PDE) in two independent
time variables. While finite difference methods have been explored for this
PDE, they face limitations in accuracy and stability when handling highly
oscillatory inputs. In this work, we introduce two advanced numerical schemes
that leverage polynomial representations of boundary conditions through either
approximation or interpolation techniques, and rigorously establish the
theoretical convergence of the polynomial approximation scheme. Experimental
evaluations reveal that our approaches yield improvements of several orders of
magnitude in mean absolute percentage error (MAPE) compared to traditional
finite difference schemes, without increasing computational complexity.
Furthermore, like finite difference methods, our algorithms can be
GPU-parallelized to reduce computational complexity from quadratic to linear in
the length of the input sequences, thereby improving scalability for
high-frequency data. We have implemented these algorithms in a dedicated Python
library, which is publicly available at:
https://github.com/FrancescoPiatti/polysigkernel.","Thomas Cass, Francesco Piatti, Jeffrey Pei",2025-02-12 15:04:23.000000,arXiv,http://arxiv.org/abs/2502.08470v1,Other
424,mmE5: Improving Multimodal Multilingual Embeddings via High-quality Synthetic Data,"Multimodal embedding models have gained significant attention for their
ability to map data from different modalities, such as text and images, into a
unified representation space. However, the limited labeled multimodal data
often hinders embedding performance. Recent approaches have leveraged data
synthesis to address this problem, yet the quality of synthetic data remains a
critical bottleneck. In this work, we identify three criteria for high-quality
synthetic multimodal data. First, broad scope ensures that the generated data
covers diverse tasks and modalities, making it applicable to various downstream
scenarios. Second, robust cross-modal alignment makes different modalities
semantically consistent. Third, high fidelity ensures that the synthetic data
maintains realistic details to enhance its reliability. Guided by these
principles, we synthesize datasets that: (1) cover a wide range of tasks,
modality combinations, and languages, (2) are generated via a deep thinking
process within a single pass of a multimodal large language model, and (3)
incorporate real-world images with accurate and relevant texts, ensuring
fidelity through self-evaluation and refinement. Leveraging these high-quality
synthetic and labeled datasets, we train a multimodal multilingual E5 model
mmE5. Extensive experiments demonstrate that mmE5 achieves state-of-the-art
performance on the MMEB Benchmark and superior multilingual performance on the
XTD benchmark. Our codes, datasets and models are released in
https://github.com/haon-chen/mmE5.","Haonan Chen, Liang Wang, Nan Yang, Yutao Zhu, Ziliang Zhao, Furu Wei, Zhicheng Dou",2025-02-12 15:03:33.000000,arXiv,http://arxiv.org/abs/2502.08468v1,Computer Vision
425,Skrr: Skip and Re-use Text Encoder Layers for Memory Efficient Text-to-Image Generation,"Large-scale text encoders in text-to-image (T2I) diffusion models have
demonstrated exceptional performance in generating high-quality images from
textual prompts. Unlike denoising modules that rely on multiple iterative
steps, text encoders require only a single forward pass to produce text
embeddings. However, despite their minimal contribution to total inference time
and floating-point operations (FLOPs), text encoders demand significantly
higher memory usage, up to eight times more than denoising modules. To address
this inefficiency, we propose Skip and Re-use layers (Skrr), a simple yet
effective pruning strategy specifically designed for text encoders in T2I
diffusion models. Skrr exploits the inherent redundancy in transformer blocks
by selectively skipping or reusing certain layers in a manner tailored for T2I
tasks, thereby reducing memory consumption without compromising performance.
Extensive experiments demonstrate that Skrr maintains image quality comparable
to the original model even under high sparsity levels, outperforming existing
blockwise pruning methods. Furthermore, Skrr achieves state-of-the-art memory
efficiency while preserving performance across multiple evaluation metrics,
including the FID, CLIP, DreamSim, and GenEval scores.","Hoigi Seo, Wongi Jeong, Jae-sun Seo, Se Young Chun",2025-02-12 15:03:26.000000,arXiv,http://arxiv.org/abs/2502.08690v1,Machine Learning
426,Examining Spanish Counseling with MIDAS: a Motivational Interviewing Dataset in Spanish,"Cultural and language factors significantly influence counseling, but Natural
Language Processing research has not yet examined whether the findings of
conversational analysis for counseling conducted in English apply to other
languages. This paper presents a first step towards this direction. We
introduce MIDAS (Motivational Interviewing Dataset in Spanish), a counseling
dataset created from public video sources that contains expert annotations for
counseling reflections and questions. Using this dataset, we explore
language-based differences in counselor behavior in English and Spanish and
develop classifiers in monolingual and multilingual settings, demonstrating its
applications in counselor behavioral coding tasks.","Aylin Gunal, Bowen Yi, John Piette, Rada Mihalcea, Verónica Pérez-Rosas",2025-02-12 14:53:04.000000,arXiv,http://arxiv.org/abs/2502.08458v1,Natural Language Processing
427,Learning Theory for Kernel Bilevel Optimization,"Bilevel optimization has emerged as a technique for addressing a wide range
of machine learning problems that involve an outer objective implicitly
determined by the minimizer of an inner problem. In this paper, we investigate
the generalization properties for kernel bilevel optimization problems where
the inner objective is optimized over a Reproducing Kernel Hilbert Space. This
setting enables rich function approximation while providing a foundation for
rigorous theoretical analysis. In this context, we establish novel
generalization error bounds for the bilevel problem under finite-sample
approximation. Our approach adopts a functional perspective, inspired by
(Petrulionyte et al., 2024), and leverages tools from empirical process theory
and maximal inequalities for degenerate $U$-processes to derive uniform error
bounds. These generalization error estimates allow to characterize the
statistical accuracy of gradient-based methods applied to the empirical
discretization of the bilevel problem.","Fares El Khoury, Edouard Pauwels, Samuel Vaiter, Michael Arbel",2025-02-12 14:52:04.000000,arXiv,http://arxiv.org/abs/2502.08457v1,Machine Learning
428,Resilient Quantized Consensus in Multi-Hop Relay Networks,"We study resilient quantized consensus in multi-agent systems, where some
agents may malfunction. The network consists of agents taking integer-valued
states, and the agents' communication is subject to asynchronous updates and
time delays. We utilize the quantized weighted mean subsequence reduced
algorithm where agents communicate with others through multi-hop relays. We
prove necessary and sufficient conditions for our algorithm to achieve the
objective under the malicious and Byzantine attack models. Our approach has
tighter graph conditions compared to the one-hop algorithm and the
flooding-based algorithms for binary consensus. Numerical examples verify the
efficacy of our algorithm.","Liwei Yuan, Hideaki Ishii",2025-02-12 14:51:09.000000,arXiv,http://arxiv.org/abs/2502.08455v1,Multi-Agent Systems
429,Learning to Group and Grasp Multiple Objects,"Simultaneously grasping and transporting multiple objects can significantly
enhance robotic work efficiency and has been a key research focus for decades.
The primary challenge lies in determining how to push objects, group them, and
execute simultaneous grasping for respective groups while considering object
distribution and the hardware constraints of the robot. Traditional rule-based
methods struggle to flexibly adapt to diverse scenarios. To address this
challenge, this paper proposes an imitation learning-based approach. We collect
a series of expert demonstrations through teleoperation and train a diffusion
policy network, enabling the robot to dynamically generate action sequences for
pushing, grouping, and grasping, thereby facilitating efficient multi-object
grasping and transportation. We conducted experiments to evaluate the method
under different training dataset sizes, varying object quantities, and
real-world object scenarios. The results demonstrate that the proposed approach
can effectively and adaptively generate multi-object grouping and grasping
strategies. With the support of more training data, imitation learning is
expected to be an effective approach for solving the multi-object grasping
problem.","Takahiro Yonemaru, Weiwei Wan, Tatsuki Nishimura, Kensuke Harada",2025-02-12 14:46:27.000000,arXiv,http://arxiv.org/abs/2502.08452v1,Robotics
430,Towards Prompt Generalization: Grammar-aware Cross-Prompt Automated Essay Scoring,"In automated essay scoring (AES), recent efforts have shifted toward
cross-prompt settings that score essays on unseen prompts for practical
applicability. However, prior methods trained with essay-score pairs of
specific prompts pose challenges in obtaining prompt-generalized essay
representation. In this work, we propose a grammar-aware cross-prompt trait
scoring (GAPS), which internally captures prompt-independent syntactic aspects
to learn generic essay representation. We acquire grammatical error-corrected
information in essays via the grammar error correction technique and design the
AES model to seamlessly integrate such information. By internally referring to
both the corrected and the original essays, the model can focus on generic
features during training. Empirical experiments validate our method's
generalizability, showing remarkable improvements in prompt-independent and
grammar-related traits. Furthermore, GAPS achieves notable QWK gains in the
most challenging cross-prompt scenario, highlighting its strength in evaluating
unseen prompts.","Heejin Do, Taehee Park, Sangwon Ryu, Gary Geunbae Lee",2025-02-12 14:41:20.000000,arXiv,http://arxiv.org/abs/2502.08450v1,Natural Language Processing
431,CordViP: Correspondence-based Visuomotor Policy for Dexterous Manipulation in Real-World,"Achieving human-level dexterity in robots is a key objective in the field of
robotic manipulation. Recent advancements in 3D-based imitation learning have
shown promising results, providing an effective pathway to achieve this goal.
However, obtaining high-quality 3D representations presents two key problems:
(1) the quality of point clouds captured by a single-view camera is
significantly affected by factors such as camera resolution, positioning, and
occlusions caused by the dexterous hand; (2) the global point clouds lack
crucial contact information and spatial correspondences, which are necessary
for fine-grained dexterous manipulation tasks. To eliminate these limitations,
we propose CordViP, a novel framework that constructs and learns
correspondences by leveraging the robust 6D pose estimation of objects and
robot proprioception. Specifically, we first introduce the interaction-aware
point clouds, which establish correspondences between the object and the hand.
These point clouds are then used for our pre-training policy, where we also
incorporate object-centric contact maps and hand-arm coordination information,
effectively capturing both spatial and temporal dynamics. Our method
demonstrates exceptional dexterous manipulation capabilities with an average
success rate of 90\% in four real-world tasks, surpassing other baselines by a
large margin. Experimental results also highlight the superior generalization
and robustness of CordViP to different objects, viewpoints, and scenarios. Code
and videos are available on https://aureleopku.github.io/CordViP.","Yankai Fu, Qiuxuan Feng, Ning Chen, Zichen Zhou, Mengzhen Liu, Mingdong Wu, Tianxing Chen, Shanyu Rong, Jiaming Liu, Hao Dong, Shanghang Zhang",2025-02-12 14:41:14.000000,arXiv,http://arxiv.org/abs/2502.08449v1,Robotics
432,Monge SAM: Robust Reparameterization-Invariant Sharpness-Aware Minimization Based on Loss Geometry,"Recent studies on deep neural networks show that flat minima of the loss
landscape correlate with improved generalization. Sharpness-aware minimization
(SAM) efficiently finds flat regions by updating the parameters according to
the gradient at an adversarial perturbation. The perturbation depends on the
Euclidean metric, making SAM non-invariant under reparametrizations, which
blurs sharpness and generalization. We propose Monge SAM (M-SAM), a
reparametrization invariant version of SAM by considering a Riemannian metric
in the parameter space induced naturally by the loss surface. Compared to
previous approaches, M-SAM works under any modeling choice, relies only on mild
assumptions while being as computationally efficient as SAM. We theoretically
argue that M-SAM varies between SAM and gradient descent (GD), which increases
robustness to hyperparameter selection and reduces attraction to suboptimal
equilibria like saddle points. We demonstrate this behavior both theoretically
and empirically on a multi-modal representation alignment task.","Albert Kjøller Jacobsen, Georgios Arvanitidis",2025-02-12 14:40:19.000000,arXiv,http://arxiv.org/abs/2502.08448v1,Machine Learning
433,"$\texttt{LucidAtlas}$: Learning Uncertainty-Aware, Covariate-Disentangled, Individualized Atlas Representations","The goal of this work is to develop principled techniques to extract
information from high dimensional data sets with complex dependencies in areas
such as medicine that can provide insight into individual as well as population
level variation. We develop $\texttt{LucidAtlas}$, an approach that can
represent spatially varying information, and can capture the influence of
covariates as well as population uncertainty. As a versatile atlas
representation, $\texttt{LucidAtlas}$ offers robust capabilities for covariate
interpretation, individualized prediction, population trend analysis, and
uncertainty estimation, with the flexibility to incorporate prior knowledge.
Additionally, we discuss the trustworthiness and potential risks of neural
additive models for analyzing dependent covariates and then introduce a
marginalization approach to explain the dependence of an individual predictor
on the models' response (the atlas). To validate our method, we demonstrate its
generalizability on two medical datasets. Our findings underscore the critical
role of by-construction interpretable models in advancing scientific discovery.
Our code will be publicly available upon acceptance.","Yining Jiao, Sreekalyani Bhamidi, Huaizhi Qu, Carlton Zdanski, Julia Kimbell, Andrew Prince, Cameron Worden, Samuel Kirse, Christopher Rutter, Benjamin Shields, William Dunn, Jisan Mahmud, Tianlong Chen, Marc Niethammer",2025-02-12 14:36:25.000000,arXiv,http://arxiv.org/abs/2502.08445v1,Machine Learning
434,Better Embeddings with Coupled Adam,"Despite their remarkable capabilities, LLMs learn word representations that
exhibit the undesirable yet poorly understood feature of anisotropy. In this
paper, we argue that the second moment in Adam is a cause of anisotropic
embeddings, and suggest a modified optimizer called Coupled Adam to mitigate
the problem. Our experiments demonstrate that Coupled Adam significantly
improves the quality of embeddings, while also leading to better upstream and
downstream performance on large enough datasets.","Felix Stollenwerk, Tobias Stollenwerk",2025-02-12 14:32:17.000000,arXiv,http://arxiv.org/abs/2502.08441v2,Natural Language Processing
435,Composite Sketch+Text Queries for Retrieving Objects with Elusive Names and Complex Interactions,"Non-native speakers with limited vocabulary often struggle to name specific
objects despite being able to visualize them, e.g., people outside Australia
searching for numbats. Further, users may want to search for such elusive
objects with difficult-to-sketch interactions, e.g., numbat digging in the
ground. In such common but complex situations, users desire a search interface
that accepts composite multimodal queries comprising hand-drawn sketches of
difficult-to-name but easy-to-draw objects and text describing
difficult-to-sketch but easy-to-verbalize object attributes or interaction with
the scene. This novel problem statement distinctly differs from the previously
well-researched TBIR (text-based image retrieval) and SBIR (sketch-based image
retrieval) problems. To study this under-explored task, we curate a dataset,
CSTBIR (Composite Sketch+Text Based Image Retrieval), consisting of approx. 2M
queries and 108K natural scene images. Further, as a solution to this problem,
we propose a pretrained multimodal transformer-based baseline, STNET
(Sketch+Text Network), that uses a hand-drawn sketch to localize relevant
objects in the natural scene image, and encodes the text and image to perform
image retrieval. In addition to contrastive learning, we propose multiple
training objectives that improve the performance of our model. Extensive
experiments show that our proposed method outperforms several state-of-the-art
retrieval methods for text-only, sketch-only, and composite query modalities.
We make the dataset and code available at our project website.","Prajwal Gatti, Kshitij Parikh, Dhriti Prasanna Paul, Manish Gupta, Anand Mishra",2025-02-12 14:22:59.000000,arXiv,http://arxiv.org/abs/2502.08438v1,Computer Vision
436,From Haystack to Needle: Label Space Reduction for Zero-shot Classification,"We present Label Space Reduction (LSR), a novel method for improving
zero-shot classification performance of Large Language Models (LLMs). LSR
iteratively refines the classification label space by systematically ranking
and reducing candidate classes, enabling the model to concentrate on the most
relevant options. By leveraging unlabeled data with the statistical learning
capabilities of data-driven models, LSR dynamically optimizes the label space
representation at test time. Our experiments across seven benchmarks
demonstrate that LSR improves macro-F1 scores by an average of 7.0% (up to
14.2%) with Llama-3.1-70B and 3.3% (up to 11.1%) with Claude-3.5-Sonnet
compared to standard zero-shot classification baselines. To reduce the
computational overhead of LSR, which requires an additional LLM call at each
iteration, we propose distilling the model into a probabilistic classifier,
allowing for efficient inference.","Nathan Vandemoortele, Bram Steenwinckel, Femke Ongenae, Sofie Van Hoecke",2025-02-12 14:20:36.000000,arXiv,http://arxiv.org/abs/2502.08436v1,Natural Language Processing
437,Closer through commonality: Enhancing hypergraph contrastive learning with shared groups,"Hypergraphs provide a superior modeling framework for representing complex
multidimensional relationships in the context of real-world interactions that
often occur in groups, overcoming the limitations of traditional homogeneous
graphs. However, there have been few studies on hypergraphbased contrastive
learning, and existing graph-based contrastive learning methods have not been
able to fully exploit the highorder correlation information in hypergraphs.
Here, we propose a Hypergraph Fine-grained contrastive learning (HyFi) method
designed to exploit the complex high-dimensional information inherent in
hypergraphs. While avoiding traditional graph augmentation methods that corrupt
the hypergraph topology, the proposed method provides a simple and efficient
learning augmentation function by adding noise to node features. Furthermore,
we expands beyond the traditional dichotomous relationship between positive and
negative samples in contrastive learning by introducing a new relationship of
weak positives. It demonstrates the importance of fine-graining positive
samples in contrastive learning. Therefore, HyFi is able to produce highquality
embeddings, and outperforms both supervised and unsupervised baselines in
average rank on node classification across 10 datasets. Our approach
effectively exploits high-dimensional hypergraph information, shows significant
improvement over existing graph-based contrastive learning methods, and is
efficient in terms of training speed and GPU memory cost. The source code is
available at https://github.com/Noverse0/HyFi.git.","Daeyoung Roh, Donghee Han, Daehee Kim, Keejun Han, Mun Yi",2025-02-12 14:16:45.000000,arXiv,http://arxiv.org/abs/2502.08432v1,Machine Learning
438,Robot-Initiated Social Control of Sedentary Behavior: Comparing the Impact of Relationship- and Target-Focused Strategies,"To design social robots to effectively promote health behavior change, it is
essential to understand how people respond to various health communication
strategies employed by these robots. This study examines the effectiveness of
two types of social control strategies from a social robot,
relationship-focused strategies (emphasizing relational consequences) and
target-focused strategies (emphasizing health consequences), in encouraging
people to reduce sedentary behavior. A two-session lab experiment was conducted
(n = 135), where participants first played a game with a robot, followed by the
robot persuading them to stand up and move using one of the strategies. Half of
the participants joined a second session to have a repeated interaction with
the robot. Results showed that relationship-focused strategies motivated
participants to stay active longer. Repeated sessions did not strengthen
participants' relationship with the robot, but those who felt more attached to
the robot responded more actively to the target-focused strategies. These
findings offer valuable insights for designing persuasive strategies for social
robots in health communication contexts.","Jiaxin Xu, Sterre Anna Mariam van der Horst, Chao Zhang, Raymond H. Cuijpers, Wijnand A. IJsselsteijn",2025-02-12 14:13:38.000000,arXiv,http://arxiv.org/abs/2502.08428v1,Other
439,Semantic Learning for Molecular Communication in Internet of Bio-Nano Things,"Molecular communication (MC) provides a foundational framework for
information transmission in the Internet of Bio-Nano Things (IoBNT), where
efficiency and reliability are crucial. However, the inherent limitations of
molecular channels, such as low transmission rates, noise, and inter-symbol
interference (ISI), limit their ability to support complex data transmission.
This paper proposes an end-to-end semantic learning framework designed to
optimize task-oriented molecular communication, with a focus on biomedical
diagnostic tasks under resource-constrained conditions. The proposed framework
employs a deep encoder-decoder architecture to efficiently extract, quantize,
and decode semantic features, prioritizing task-relevant semantic information
to enhance diagnostic classification performance. Additionally, a probabilistic
channel network is introduced to approximate molecular propagation dynamics,
enabling gradient-based optimization for end-to-end learning. Experimental
results demonstrate that the proposed semantic framework improves diagnostic
accuracy by at least 25% compared to conventional JPEG compression with LDPC
coding methods under resource-constrained communication scenarios.","Hanlin Cai, Ozgur B. Akan",2025-02-12 14:09:05.000000,arXiv,http://arxiv.org/abs/2502.08426v1,Other
440,Handwritten Text Recognition: A Survey,"Handwritten Text Recognition (HTR) has become an essential field within
pattern recognition and machine learning, with applications spanning historical
document preservation to modern data entry and accessibility solutions. The
complexity of HTR lies in the high variability of handwriting, which makes it
challenging to develop robust recognition systems. This survey examines the
evolution of HTR models, tracing their progression from early heuristic-based
approaches to contemporary state-of-the-art neural models, which leverage deep
learning techniques. The scope of the field has also expanded, with models
initially capable of recognizing only word-level content progressing to recent
end-to-end document-level approaches. Our paper categorizes existing work into
two primary levels of recognition: (1) \emph{up to line-level}, encompassing
word and line recognition, and (2) \emph{beyond line-level}, addressing
paragraph- and document-level challenges. We provide a unified framework that
examines research methodologies, recent advances in benchmarking, key datasets
in the field, and a discussion of the results reported in the literature.
Finally, we identify pressing research challenges and outline promising future
directions, aiming to equip researchers and practitioners with a roadmap for
advancing the field.","Carlos Garrido-Munoz, Antonio Rios-Vila, Jorge Calvo-Zaragoza",2025-02-12 13:59:37.000000,arXiv,http://arxiv.org/abs/2502.08417v1,Computer Vision
441,Multifidelity Simulation-based Inference for Computationally Expensive Simulators,"Across many domains of science, stochastic models are an essential tool to
understand the mechanisms underlying empirically observed data. Models can be
of different levels of detail and accuracy, with models of high-fidelity (i.e.,
high accuracy) to the phenomena under study being often preferable. However,
inferring parameters of high-fidelity models via simulation-based inference is
challenging, especially when the simulator is computationally expensive. We
introduce MF-NPE, a multifidelity approach to neural posterior estimation that
leverages inexpensive low-fidelity simulations to infer parameters of
high-fidelity simulators within a limited simulation budget. MF-NPE performs
neural posterior estimation with limited high-fidelity resources by virtue of
transfer learning, with the ability to prioritize individual observations using
active learning. On one statistical task with analytical ground-truth and two
real-world tasks, MF-NPE shows comparable performance to current approaches
while requiring up to two orders of magnitude fewer high-fidelity simulations.
Overall, MF-NPE opens new opportunities to perform efficient Bayesian inference
on computationally expensive simulators.","Anastasia N. Krouglova, Hayden R. Johnson, Basile Confavreux, Michael Deistler, Pedro J. Gonçalves",2025-02-12 13:59:22.000000,arXiv,http://arxiv.org/abs/2502.08416v1,Statistical Machine Learning
442,A Semantic Parsing Algorithm to Solve Linear Ordering Problems,"We develop an algorithm to semantically parse linear ordering problems, which
require a model to arrange entities using deductive reasoning. Our method takes
as input a number of premises and candidate statements, parsing them to a
first-order logic of an ordering domain, and then utilizes constraint logic
programming to infer the truth of proposed statements about the ordering.
  Our semantic parser transforms Heim and Kratzer's syntax-based compositional
formal semantic rules to a computational algorithm. This transformation
involves introducing abstract types and templates based on their rules, and
introduces a dynamic component to interpret entities within a contextual
framework.
  Our symbolic system, the Formal Semantic Logic Inferer (FSLI), is applied to
answer multiple choice questions in BIG-bench's logical_deduction multiple
choice problems, achieving perfect accuracy, compared to 67.06% for the
best-performing LLM (GPT-4) and 87.63% for the hybrid system Logic-LM.
  These promising results demonstrate the benefit of developing a semantic
parsing algorithm driven by first-order logic constructs.","Maha Alkhairy, Vincent Homer, Brendan O'Connor",2025-02-12 13:58:42.000000,arXiv,http://arxiv.org/abs/2502.08415v1,Natural Language Processing
443,Sparse Estimation of Inverse Covariance and Partial Correlation Matrices via Joint Partial Regression,"We present a new method for estimating high-dimensional sparse partial
correlation and inverse covariance matrices, which exploits the connection
between the inverse covariance matrix and linear regression. The method is a
two-stage estimation method wherein each individual feature is regressed on all
other features while positive semi-definiteness is enforced simultaneously. We
provide statistical rates of convergence for the proposed method which match,
and improve upon, the state-of-the-art for inverse covariance and partial
correlation matrix estimation, respectively. We also propose an efficient
proximal splitting algorithm for numerically computing the estimate. The
effectiveness of the proposed method is demonstrated on both synthetic and
real-world data.","Samuel Erickson, Tobias Rydén",2025-02-12 13:57:09.000000,arXiv,http://arxiv.org/abs/2502.08414v1,Statistical Machine Learning
444,Strong bounds for large-scale Minimum Sum-of-Squares Clustering,"Clustering is a fundamental technique in data analysis and machine learning,
used to group similar data points together. Among various clustering methods,
the Minimum Sum-of-Squares Clustering (MSSC) is one of the most widely used.
MSSC aims to minimize the total squared Euclidean distance between data points
and their corresponding cluster centroids. Due to the unsupervised nature of
clustering, achieving global optimality is crucial, yet computationally
challenging. The complexity of finding the global solution increases
exponentially with the number of data points, making exact methods impractical
for large-scale datasets. Even obtaining strong lower bounds on the optimal
MSSC objective value is computationally prohibitive, making it difficult to
assess the quality of heuristic solutions. We address this challenge by
introducing a novel method to validate heuristic MSSC solutions through
optimality gaps. Our approach employs a divide-and-conquer strategy,
decomposing the problem into smaller instances that can be handled by an exact
solver. The decomposition is guided by an auxiliary optimization problem, the
""anticlustering problem"", for which we design an efficient heuristic.
Computational experiments demonstrate the effectiveness of the method for
large-scale instances, achieving optimality gaps below 3% in most cases while
maintaining reasonable computational times. These results highlight the
practicality of our approach in assessing feasible clustering solutions for
large datasets, bridging a critical gap in MSSC evaluation.","Anna Livia Croella, Veronica Piccialli, Antonio M. Sudoso",2025-02-12 13:40:00.000000,arXiv,http://arxiv.org/abs/2502.08397v1,Other
445,IssueBench: Millions of Realistic Prompts for Measuring Issue Bias in LLM Writing Assistance,"Large language models (LLMs) are helping millions of users write texts about
diverse issues, and in doing so expose users to different ideas and
perspectives. This creates concerns about issue bias, where an LLM tends to
present just one perspective on a given issue, which in turn may influence how
users think about this issue. So far, it has not been possible to measure which
issue biases LLMs actually manifest in real user interactions, making it
difficult to address the risks from biased LLMs. Therefore, we create
IssueBench: a set of 2.49m realistic prompts for measuring issue bias in LLM
writing assistance, which we construct based on 3.9k templates (e.g. ""write a
blog about"") and 212 political issues (e.g. ""AI regulation"") from real user
interactions. Using IssueBench, we show that issue biases are common and
persistent in state-of-the-art LLMs. We also show that biases are remarkably
similar across models, and that all models align more with US Democrat than
Republican voter opinion on a subset of issues. IssueBench can easily be
adapted to include other issues, templates, or tasks. By enabling robust and
realistic measurement, we hope that IssueBench can bring a new quality of
evidence to ongoing discussions about LLM biases and how to address them.","Paul Röttger, Musashi Hinck, Valentin Hofmann, Kobi Hackenburg, Valentina Pyatkin, Faeze Brahman, Dirk Hovy",2025-02-12 13:37:03.000000,arXiv,http://arxiv.org/abs/2502.08395v1,Natural Language Processing
446,ViLa-MIL: Dual-scale Vision-Language Multiple Instance Learning for Whole Slide Image Classification,"Multiple instance learning (MIL)-based framework has become the mainstream
for processing the whole slide image (WSI) with giga-pixel size and
hierarchical image context in digital pathology. However, these methods heavily
depend on a substantial number of bag-level labels and solely learn from the
original slides, which are easily affected by variations in data distribution.
Recently, vision language model (VLM)-based methods introduced the language
prior by pre-training on large-scale pathological image-text pairs. However,
the previous text prompt lacks the consideration of pathological prior
knowledge, therefore does not substantially boost the model's performance.
Moreover, the collection of such pairs and the pre-training process are very
time-consuming and source-intensive.To solve the above problems, we propose a
dual-scale vision-language multiple instance learning (ViLa-MIL) framework for
whole slide image classification. Specifically, we propose a dual-scale visual
descriptive text prompt based on the frozen large language model (LLM) to boost
the performance of VLM effectively. To transfer the VLM to process WSI
efficiently, for the image branch, we propose a prototype-guided patch decoder
to aggregate the patch features progressively by grouping similar patches into
the same prototype; for the text branch, we introduce a context-guided text
decoder to enhance the text features by incorporating the multi-granular image
contexts. Extensive studies on three multi-cancer and multi-center subtyping
datasets demonstrate the superiority of ViLa-MIL.","Jiangbo Shi, Chen Li, Tieliang Gong, Yefeng Zheng, Huazhu Fu",2025-02-12 13:28:46.000000,arXiv,http://arxiv.org/abs/2502.08391v1,Computer Vision
447,Learning Humanoid Standing-up Control across Diverse Postures,"Standing-up control is crucial for humanoid robots, with the potential for
integration into current locomotion and loco-manipulation systems, such as fall
recovery. Existing approaches are either limited to simulations that overlook
hardware constraints or rely on predefined ground-specific motion trajectories,
failing to enable standing up across postures in real-world scenes. To bridge
this gap, we present HoST (Humanoid Standing-up Control), a reinforcement
learning framework that learns standing-up control from scratch, enabling
robust sim-to-real transfer across diverse postures. HoST effectively learns
posture-adaptive motions by leveraging a multi-critic architecture and
curriculum-based training on diverse simulated terrains. To ensure successful
real-world deployment, we constrain the motion with smoothness regularization
and implicit motion speed bound to alleviate oscillatory and violent motions on
physical hardware, respectively. After simulation-based training, the learned
control policies are directly deployed on the Unitree G1 humanoid robot. Our
experimental results demonstrate that the controllers achieve smooth, stable,
and robust standing-up motions across a wide range of laboratory and outdoor
environments. Videos are available at
https://taohuang13.github.io/humanoid-standingup.github.io/.","Tao Huang, Junli Ren, Huayi Wang, Zirui Wang, Qingwei Ben, Muning Wen, Xiao Chen, Jianan Li, Jiangmiao Pang",2025-02-12 13:10:09.000000,arXiv,http://arxiv.org/abs/2502.08378v1,Robotics
448,Not All Frame Features Are Equal: Video-to-4D Generation via Decoupling Dynamic-Static Features,"Recently, the generation of dynamic 3D objects from a video has shown
impressive results. Existing methods directly optimize Gaussians using whole
information in frames. However, when dynamic regions are interwoven with static
regions within frames, particularly if the static regions account for a large
proportion, existing methods often overlook information in dynamic regions and
are prone to overfitting on static regions. This leads to producing results
with blurry textures. We consider that decoupling dynamic-static features to
enhance dynamic representations can alleviate this issue. Thus, we propose a
dynamic-static feature decoupling module (DSFD). Along temporal axes, it
regards the portions of current frame features that possess significant
differences relative to reference frame features as dynamic features.
Conversely, the remaining parts are the static features. Then, we acquire
decoupled features driven by dynamic features and current frame features.
Moreover, to further enhance the dynamic representation of decoupled features
from different viewpoints and ensure accurate motion prediction, we design a
temporal-spatial similarity fusion module (TSSF). Along spatial axes, it
adaptively selects a similar information of dynamic regions. Hinging on the
above, we construct a novel approach, DS4D. Experimental results verify our
method achieves state-of-the-art (SOTA) results in video-to-4D. In addition,
the experiments on a real-world scenario dataset demonstrate its effectiveness
on the 4D scene. Our code will be publicly available.","Liying Yang, Chen Liu, Zhenwei Zhu, Ajian Liu, Hui Ma, Jian Nong, Yanyan Liang",2025-02-12 13:08:35.000000,arXiv,http://arxiv.org/abs/2502.08377v1,Computer Vision
449,Enhanced Load Forecasting with GAT-LSTM: Leveraging Grid and Temporal Features,"Accurate power load forecasting is essential for the efficient operation and
planning of electrical grids, particularly given the increased variability and
complexity introduced by renewable energy sources. This paper introduces
GAT-LSTM, a hybrid model that combines Graph Attention Networks (GAT) and Long
Short-Term Memory (LSTM) networks. A key innovation of the model is the
incorporation of edge attributes, such as line capacities and efficiencies,
into the attention mechanism, enabling it to dynamically capture spatial
relationships grounded in grid-specific physical and operational constraints.
Additionally, by employing an early fusion of spatial graph embeddings and
temporal sequence features, the model effectively learns and predicts complex
interactions between spatial dependencies and temporal patterns, providing a
realistic representation of the dynamics of power grids. Experimental
evaluations on the Brazilian Electricity System dataset demonstrate that the
GAT-LSTM model significantly outperforms state-of-the-art models, achieving
reductions of 21. 8% in MAE, 15. 9% in RMSE and 20. 2% in MAPE. These results
underscore the robustness and adaptability of the GAT-LSTM model, establishing
it as a powerful tool for applications in grid management and energy planning.","Ugochukwu Orji, Çiçek Güven, Dan Stowell",2025-02-12 13:07:18.000000,arXiv,http://arxiv.org/abs/2502.08376v1,Machine Learning
450,AdvSwap: Covert Adversarial Perturbation with High Frequency Info-swapping for Autonomous Driving Perception,"Perception module of Autonomous vehicles (AVs) are increasingly susceptible
to be attacked, which exploit vulnerabilities in neural networks through
adversarial inputs, thereby compromising the AI safety. Some researches focus
on creating covert adversarial samples, but existing global noise techniques
are detectable and difficult to deceive the human visual system. This paper
introduces a novel adversarial attack method, AdvSwap, which creatively
utilizes wavelet-based high-frequency information swapping to generate covert
adversarial samples and fool the camera. AdvSwap employs invertible neural
network for selective high-frequency information swapping, preserving both
forward propagation and data integrity. The scheme effectively removes the
original label data and incorporates the guidance image data, producing
concealed and robust adversarial samples. Experimental evaluations and
comparisons on the GTSRB and nuScenes datasets demonstrate that AdvSwap can
make concealed attacks on common traffic targets. The generates adversarial
samples are also difficult to perceive by humans and algorithms. Meanwhile, the
method has strong attacking robustness and attacking transferability.","Yuanhao Huang, Qinfan Zhang, Jiandong Xing, Mengyue Cheng, Haiyang Yu, Yilong Ren, Xiao Xiong",2025-02-12 13:05:35.000000,arXiv,http://arxiv.org/abs/2502.08374v1,Computer Vision
451,Uncertainty Aware Human-machine Collaboration in Camouflaged Object Detection,"Camouflaged Object Detection (COD), the task of identifying objects concealed
within their environments, has seen rapid growth due to its wide range of
practical applications. A key step toward developing trustworthy COD systems is
the estimation and effective utilization of uncertainty. In this work, we
propose a human-machine collaboration framework for classifying the presence of
camouflaged objects, leveraging the complementary strengths of computer vision
(CV) models and noninvasive brain-computer interfaces (BCIs). Our approach
introduces a multiview backbone to estimate uncertainty in CV model
predictions, utilizes this uncertainty during training to improve efficiency,
and defers low-confidence cases to human evaluation via RSVP-based BCIs during
testing for more reliable decision-making. We evaluated the framework in the
CAMO dataset, achieving state-of-the-art results with an average improvement of
4.56\% in balanced accuracy (BA) and 3.66\% in the F1 score compared to
existing methods. For the best-performing participants, the improvements
reached 7.6\% in BA and 6.66\% in the F1 score. Analysis of the training
process revealed a strong correlation between our confidence measures and
precision, while an ablation study confirmed the effectiveness of the proposed
training policy and the human-machine collaboration strategy. In general, this
work reduces human cognitive load, improves system reliability, and provides a
strong foundation for advancements in real-world COD applications and
human-computer interaction. Our code and data are available at:
https://github.com/ziyuey/Uncertainty-aware-human-machine-collaboration-in-camouflaged-object-identification.","Ziyue Yang, Kehan Wang, Yuhang Ming, Yong Peng, Han Yang, Qiong Chen, Wanzeng Kong",2025-02-12 13:05:24.000000,arXiv,http://arxiv.org/abs/2502.08373v1,Computer Vision
452,Unveiling Global Discourse Structures: Theoretical Analysis and NLP Applications in Argument Mining,"Particularly in the structure of global discourse, coherence plays a pivotal
role in human text comprehension and is a hallmark of high-quality text. This
is especially true for persuasive texts, where coherent argument structures
support claims effectively. This paper discusses and proposes methods for
detecting, extracting and representing these global discourse structures in a
proccess called Argument(ation) Mining. We begin by defining key terms and
processes of discourse structure analysis, then continue to summarize existing
research on the matter, and identify shortcomings in current argument component
extraction and classification methods. Furthermore, we will outline an
architecture for argument mining that focuses on making models more
generalisable while overcoming challenges in the current field of research by
utilizing novel NLP techniques. This paper reviews current knowledge,
summarizes recent works, and outlines our NLP pipeline, aiming to contribute to
the theoretical understanding of global discourse structures.",Christopher van Le,2025-02-12 13:03:43.000000,arXiv,http://arxiv.org/abs/2502.08371v1,Natural Language Processing
453,Towards Principled Multi-Agent Task Agnostic Exploration,"In reinforcement learning, we typically refer to task-agnostic exploration
when we aim to explore the environment without access to the task specification
a priori. In a single-agent setting the problem has been extensively studied
and mostly understood. A popular approach cast the task-agnostic objective as
maximizing the entropy of the state distribution induced by the agent's policy,
from which principles and methods follows. In contrast, little is known about
task-agnostic exploration in multi-agent settings, which are ubiquitous in the
real world. How should different agents explore in the presence of others? In
this paper, we address this question through a generalization to multiple
agents of the problem of maximizing the state distribution entropy. First, we
investigate alternative formulations, highlighting respective positives and
negatives. Then, we present a scalable, decentralized, trust-region policy
search algorithm to address the problem in practical settings. Finally, we
provide proof of concept experiments to both corroborate the theoretical
findings and pave the way for task-agnostic exploration in challenging
multi-agent settings.","Riccardo Zamboni, Mirco Mutti, Marcello Restelli",2025-02-12 12:51:36.000000,arXiv,http://arxiv.org/abs/2502.08365v1,Machine Learning
454,A Survey on Pre-Trained Diffusion Model Distillations,"Diffusion Models~(DMs) have emerged as the dominant approach in Generative
Artificial Intelligence (GenAI), owing to their remarkable performance in tasks
such as text-to-image synthesis. However, practical DMs, such as stable
diffusion, are typically trained on massive datasets and thus usually require
large storage. At the same time, many steps may be required, i.e., recursively
evaluating the trained neural network, to generate a high-quality image, which
results in significant computational costs during sample generation. As a
result, distillation methods on pre-trained DM have become widely adopted
practices to develop smaller, more efficient models capable of rapid, few-step
generation in low-resource environment. When these distillation methods are
developed from different perspectives, there is an urgent need for a systematic
survey, particularly from a methodological perspective. In this survey, we
review distillation methods through three aspects: output loss distillation,
trajectory distillation and adversarial distillation. We also discuss current
challenges and outline future research directions in the conclusion.","Xuhui Fan, Zhangkai Wu, Hongyu Wu",2025-02-12 12:50:24.000000,arXiv,http://arxiv.org/abs/2502.08364v1,Machine Learning
455,Top-Theta Attention: Sparsifying Transformers by Compensated Thresholding,"The attention mechanism is essential for the impressive capabilities of
transformer-based Large Language Models (LLMs). However, calculating attention
is computationally intensive due to its quadratic dependency on the sequence
length. We introduce a novel approach called Top-Theta Attention, or simply
Top-$\theta$, which selectively prunes less essential attention elements by
comparing them against carefully calibrated thresholds. This method greatly
improves the efficiency of self-attention matrix multiplication while
preserving model accuracy, reducing the number of required V cache rows by 3x
during generative decoding and the number of attention elements by 10x during
the prefill phase. Our method does not require model retraining; instead, it
requires only a brief calibration phase to be resilient to distribution shifts,
thus not requiring the thresholds for different datasets to be recalibrated.
Unlike top-k attention, Top-$\theta$ eliminates full-vector dependency, making
it suitable for tiling and scale-out and avoiding costly top-k search. A key
innovation of our approach is the development of efficient numerical
compensation techniques, which help preserve model accuracy even under
aggressive pruning of attention scores.","Konstantin Berestizshevsky, Renzo Andri, Lukas Cavigelli",2025-02-12 12:50:15.000000,arXiv,http://arxiv.org/abs/2502.08363v1,Natural Language Processing
456,Advancing machine fault diagnosis: A detailed examination of convolutional neural networks,"The growing complexity of machinery and the increasing demand for operational
efficiency and safety have driven the development of advanced fault diagnosis
techniques. Among these, convolutional neural networks (CNNs) have emerged as a
powerful tool, offering robust and accurate fault detection and classification
capabilities. This comprehensive review delves into the application of CNNs in
machine fault diagnosis, covering its theoretical foundation, architectural
variations, and practical implementations. The strengths and limitations of
CNNs are analyzed in this domain, discussing their effectiveness in handling
various fault types, data complexities, and operational environments.
Furthermore, we explore the evolving landscape of CNN-based fault diagnosis,
examining recent advancements in data augmentation, transfer learning, and
hybrid architectures. Finally, we highlight future research directions and
potential challenges to further enhance the application of CNNs for reliable
and proactive machine fault diagnosis.","Govind Vashishtha, Sumika Chauhan, Mert Sehri, Justyna Hebda-Sobkowicz, Radoslaw Zimroz, Patrick Dumond, Rajesh Kumar",2025-02-12 12:41:13.000000,arXiv,http://arxiv.org/abs/2502.08689v1,Machine Learning
457,Systematic Knowledge Injection into Large Language Models via Diverse Augmentation for Domain-Specific RAG,"Retrieval-Augmented Generation (RAG) has emerged as a prominent method for
incorporating domain knowledge into Large Language Models (LLMs). While RAG
enhances response relevance by incorporating retrieved domain knowledge in the
context, retrieval errors can still lead to hallucinations and incorrect
answers. To recover from retriever failures, domain knowledge is injected by
fine-tuning the model to generate the correct response, even in the case of
retrieval errors. However, we observe that without systematic knowledge
augmentation, fine-tuned LLMs may memorize new information but still fail to
extract relevant domain knowledge, leading to poor performance. In this work,
we present a novel framework that significantly enhances the fine-tuning
process by augmenting the training data in two ways -- context augmentation and
knowledge paraphrasing. In context augmentation, we create multiple training
samples for a given QA pair by varying the relevance of the retrieved
information, teaching the model when to ignore and when to rely on retrieved
content. In knowledge paraphrasing, we fine-tune with multiple answers to the
same question, enabling LLMs to better internalize specialized knowledge. To
mitigate catastrophic forgetting due to fine-tuning, we add a domain-specific
identifier to a question and also utilize a replay buffer containing general QA
pairs. Experimental results demonstrate the efficacy of our method over
existing techniques, achieving up to 10\% relative gain in token-level recall
while preserving the LLM's generalization capabilities.","Kushagra Bhushan, Yatin Nandwani, Dinesh Khandelwal, Sonam Gupta, Gaurav Pandey, Dinesh Raghu, Sachindra Joshi",2025-02-12 12:39:51.000000,arXiv,http://arxiv.org/abs/2502.08356v1,Natural Language Processing
458,Loss Landscape Analysis for Reliable Quantized ML Models for Scientific Sensing,"In this paper, we propose a method to perform empirical analysis of the loss
landscape of machine learning (ML) models. The method is applied to two ML
models for scientific sensing, which necessitates quantization to be deployed
and are subject to noise and perturbations due to experimental conditions. Our
method allows assessing the robustness of ML models to such effects as a
function of quantization precision and under different regularization
techniques -- two crucial concerns that remained underexplored so far. By
investigating the interplay between performance, efficiency, and robustness by
means of loss landscape analysis, we both established a strong correlation
between gently-shaped landscapes and robustness to input and weight
perturbations and observed other intriguing and non-obvious phenomena. Our
method allows a systematic exploration of such trade-offs a priori, i.e.,
without training and testing multiple models, leading to more efficient
development workflows. This work also highlights the importance of
incorporating robustness into the Pareto optimization of ML models, enabling
more reliable and adaptive scientific sensing systems.","Tommaso Baldi, Javier Campos, Olivia Weng, Caleb Geniesse, Nhan Tran, Ryan Kastner, Alessandro Biondi",2025-02-12 12:30:49.000000,arXiv,http://arxiv.org/abs/2502.08355v1,Machine Learning
459,Trustworthy GNNs with LLMs: A Systematic Review and Taxonomy,"With the extensive application of Graph Neural Networks (GNNs) across various
domains, their trustworthiness has emerged as a focal point of research. Some
existing studies have shown that the integration of large language models
(LLMs) can improve the semantic understanding and generation capabilities of
GNNs, which in turn improves the trustworthiness of GNNs from various aspects.
Our review introduces a taxonomy that offers researchers a clear framework for
comprehending the principles and applications of different methods and helps
clarify the connections and differences among various approaches. Then we
systematically survey representative approaches along the four categories of
our taxonomy. Through our taxonomy, researchers can understand the applicable
scenarios, potential advantages, and limitations of each approach for the the
trusted integration of GNNs with LLMs. Finally, we present some promising
directions of work and future trends for the integration of LLMs and GNNs to
improve model trustworthiness.","Ruizhan Xue, Huimin Deng, Fang He, Maojun Wang, Zeyu Zhang",2025-02-12 12:28:39.000000,arXiv,http://arxiv.org/abs/2502.08353v1,Machine Learning
460,Sat-DN: Implicit Surface Reconstruction from Multi-View Satellite Images with Depth and Normal Supervision,"With advancements in satellite imaging technology, acquiring high-resolution
multi-view satellite imagery has become increasingly accessible, enabling rapid
and location-independent ground model reconstruction. However, traditional
stereo matching methods struggle to capture fine details, and while neural
radiance fields (NeRFs) achieve high-quality reconstructions, their training
time is prohibitively long. Moreover, challenges such as low visibility of
building facades, illumination and style differences between pixels, and weakly
textured regions in satellite imagery further make it hard to reconstruct
reasonable terrain geometry and detailed building facades. To address these
issues, we propose Sat-DN, a novel framework leveraging a progressively trained
multi-resolution hash grid reconstruction architecture with explicit depth
guidance and surface normal consistency constraints to enhance reconstruction
quality. The multi-resolution hash grid accelerates training, while the
progressive strategy incrementally increases the learning frequency, using
coarse low-frequency geometry to guide the reconstruction of fine
high-frequency details. The depth and normal constraints ensure a clear
building outline and correct planar distribution. Extensive experiments on the
DFC2019 dataset demonstrate that Sat-DN outperforms existing methods, achieving
state-of-the-art results in both qualitative and quantitative evaluations. The
code is available at https://github.com/costune/SatDN.","Tianle Liu, Shuangming Zhao, Wanshou Jiang, Bingxuan Guo",2025-02-12 12:27:32.000000,arXiv,http://arxiv.org/abs/2502.08352v1,Computer Vision
461,Data Augmentation to Improve Large Language Models in Food Hazard and Product Detection,"The primary objective of this study is to demonstrate the impact of data
augmentation using ChatGPT-4o-mini on food hazard and product analysis. The
augmented data is generated using ChatGPT-4o-mini and subsequently used to
train two large language models: RoBERTa-base and Flan-T5-base. The models are
evaluated on test sets. The results indicate that using augmented data helped
improve model performance across key metrics, including recall, F1 score,
precision, and accuracy, compared to using only the provided dataset. The full
code, including model training and the augmented dataset, can be found in this
repository: https://github.com/AREEG94FAHAD/food-hazard-prdouct-cls","Areeg Fahad Rasheed, M. Zarkoosh, Shimam Amer Chasib, Safa F. Abbas",2025-02-12 12:14:35.000000,arXiv,http://arxiv.org/abs/2502.08687v1,Natural Language Processing
462,Hi-End-MAE: Hierarchical encoder-driven masked autoencoders are stronger vision learners for medical image segmentation,"Medical image segmentation remains a formidable challenge due to the label
scarcity. Pre-training Vision Transformer (ViT) through masked image modeling
(MIM) on large-scale unlabeled medical datasets presents a promising solution,
providing both computational efficiency and model generalization for various
downstream tasks. However, current ViT-based MIM pre-training frameworks
predominantly emphasize local aggregation representations in output layers and
fail to exploit the rich representations across different ViT layers that
better capture fine-grained semantic information needed for more precise
medical downstream tasks. To fill the above gap, we hereby present Hierarchical
Encoder-driven MAE (Hi-End-MAE), a simple yet effective ViT-based pre-training
solution, which centers on two key innovations: (1) Encoder-driven
reconstruction, which encourages the encoder to learn more informative features
to guide the reconstruction of masked patches; and (2) Hierarchical dense
decoding, which implements a hierarchical decoding structure to capture rich
representations across different layers. We pre-train Hi-End-MAE on a
large-scale dataset of 10K CT scans and evaluated its performance across seven
public medical image segmentation benchmarks. Extensive experiments demonstrate
that Hi-End-MAE achieves superior transfer learning capabilities across various
downstream tasks, revealing the potential of ViT in medical imaging
applications. The code is available at:
https://github.com/FengheTan9/Hi-End-MAE","Fenghe Tang, Qingsong Yao, Wenxin Ma, Chenxu Wu, Zihang Jiang, S. Kevin Zhou",2025-02-12 12:14:02.000000,arXiv,http://arxiv.org/abs/2502.08347v1,Computer Vision
463,Graph Foundation Models for Recommendation: A Comprehensive Survey,"Recommender systems (RS) serve as a fundamental tool for navigating the vast
expanse of online information, with deep learning advancements playing an
increasingly important role in improving ranking accuracy. Among these, graph
neural networks (GNNs) excel at extracting higher-order structural information,
while large language models (LLMs) are designed to process and comprehend
natural language, making both approaches highly effective and widely adopted.
Recent research has focused on graph foundation models (GFMs), which integrate
the strengths of GNNs and LLMs to model complex RS problems more efficiently by
leveraging the graph-based structure of user-item relationships alongside
textual understanding. In this survey, we provide a comprehensive overview of
GFM-based RS technologies by introducing a clear taxonomy of current
approaches, diving into methodological details, and highlighting key challenges
and future directions. By synthesizing recent advancements, we aim to offer
valuable insights into the evolving landscape of GFM-based recommender systems.","Bin Wu, Yihang Wang, Yuanhao Zeng, Jiawei Liu, Jiashu Zhao, Cheng Yang, Yawen Li, Long Xia, Dawei Yin, Chuan Shi",2025-02-12 12:13:51.000000,arXiv,http://arxiv.org/abs/2502.08346v1,Information Retrieval
464,Hierarchical Learning-based Graph Partition for Large-scale Vehicle Routing Problems,"Neural solvers based on the divide-and-conquer approach for Vehicle Routing
Problems (VRPs) in general, and capacitated VRP (CVRP) in particular,
integrates the global partition of an instance with local constructions for
each subproblem to enhance generalization. However, during the global partition
phase, misclusterings within subgraphs have a tendency to progressively
compound throughout the multi-step decoding process of the learning-based
partition policy. This suboptimal behavior in the global partition phase, in
turn, may lead to a dramatic deterioration in the performance of the overall
decomposition-based system, despite using optimal local constructions. To
address these challenges, we propose a versatile Hierarchical Learning-based
Graph Partition (HLGP) framework, which is tailored to benefit the partition of
CVRP instances by synergistically integrating global and local partition
policies. Specifically, the global partition policy is tasked with creating the
coarse multi-way partition to generate the sequence of simpler two-way
partition subtasks. These subtasks mark the initiation of the subsequent K
local partition levels. At each local partition level, subtasks exclusive for
this level are assigned to the local partition policy which benefits from the
insensitive local topological features to incrementally alleviate the
compounded errors. This framework is versatile in the sense that it optimizes
the involved partition policies towards a unified objective harmoniously
compatible with both reinforcement learning (RL) and supervised learning (SL).
(*Due to the notification of arXiv ""The Abstract field cannot be longer than
1,920 characters"", the appeared Abstract is shortened. For the full Abstract,
please download the Article.)","Yuxin Pan, Ruohong Liu, Yize Chen, Zhiguang Cao, Fangzhen Lin",2025-02-12 12:07:09.000000,arXiv,http://arxiv.org/abs/2502.08340v1,Machine Learning
465,EEG Artifact Detection and Correction with Deep Autoencoders,"EEG signals convey important information about brain activity both in healthy
and pathological conditions. However, they are inherently noisy, which poses
significant challenges for accurate analysis and interpretation. Traditional
EEG artifact removal methods, while effective, often require extensive expert
intervention. This study presents LSTEEG, a novel LSTM-based autoencoder
designed for the detection and correction of artifacts in EEG signals.
Leveraging deep learning, particularly LSTM layers, LSTEEG captures non-linear
dependencies in sequential EEG data. LSTEEG demonstrates superior performance
in both artifact detection and correction tasks compared to other
state-of-the-art convolutional autoencoders. Our methodology enhances the
interpretability and utility of the autoencoder's latent space, enabling
data-driven automated artefact removal in EEG its application in downstream
tasks. This research advances the field of efficient and accurate multi-channel
EEG preprocessing, and promotes the implementation and usage of automated EEG
analysis pipelines for brain health applications.","David Aquilué-Llorens, Aureli Soria-Frisch",2025-02-12 12:06:36.000000,arXiv,http://arxiv.org/abs/2502.08686v1,Machine Learning
466,Beyond Models! Explainable Data Valuation and Metric Adaption for Recommendation,"User behavior records serve as the foundation for recommender systems. While
the behavior data exhibits ease of acquisition, it often suffers from varying
quality. Current methods employ data valuation to discern high-quality data
from low-quality data. However, they tend to employ black-box design, lacking
transparency and interpretability. Besides, they are typically tailored to
specific evaluation metrics, leading to limited generality across various
tasks. To overcome these issues, we propose an explainable and versatile
framework DVR which can enhance the efficiency of data utilization tailored to
any requirements of the model architectures and evaluation metrics. For
explainable data valuation, a data valuator is presented to evaluate the data
quality via calculating its Shapley value from the game-theoretic perspective,
ensuring robust mathematical properties and reliability. In order to
accommodate various evaluation metrics, including differentiable and
non-differentiable ones, a metric adapter is devised based on reinforcement
learning, where a metric is treated as the reinforcement reward that guides
model optimization. Extensive experiments conducted on various benchmarks
verify that our framework can improve the performance of current recommendation
algorithms on various metrics including ranking accuracy, diversity, and
fairness. Specifically, our framework achieves up to 34.7\% improvements over
existing methods in terms of representative NDCG metric. The code is available
at https://github.com/renqii/DVR.","Renqi Jia, Xiaokun Zhang, Bowei He, Qiannan Zhu, Weitao Xu, Jiehao Chen, Chen Ma",2025-02-12 12:01:08.000000,arXiv,http://arxiv.org/abs/2502.08685v1,Machine Learning
467,Hierarchical Multi-Agent Framework for Carbon-Efficient Liquid-Cooled Data Center Clusters,"Reducing the environmental impact of cloud computing requires efficient
workload distribution across geographically dispersed Data Center Clusters
(DCCs) and simultaneously optimizing liquid and air (HVAC) cooling with time
shift of workloads within individual data centers (DC). This paper introduces
Green-DCC, which proposes a Reinforcement Learning (RL) based hierarchical
controller to optimize both workload and liquid cooling dynamically in a DCC.
By incorporating factors such as weather, carbon intensity, and resource
availability, Green-DCC addresses realistic constraints and interdependencies.
We demonstrate how the system optimizes multiple data centers synchronously,
enabling the scope of digital twins, and compare the performance of various RL
approaches based on carbon emissions and sustainability metrics while also
offering a framework and benchmark simulation for broader ML research in
sustainability.","Soumyendu Sarkar, Avisek Naug, Antonio Guillen, Vineet Gundecha, Ricardo Luna Gutierrez, Sahand Ghorbanpour, Sajad Mousavi, Ashwin Ramesh Babu, Desik Rengarajan, Cullen Bash",2025-02-12 12:00:58.000000,arXiv,http://arxiv.org/abs/2502.08337v1,Machine Learning
468,Salience-Invariant Consistent Policy Learning for Generalization in Visual Reinforcement Learning,"Generalizing policies to unseen scenarios remains a critical challenge in
visual reinforcement learning, where agents often overfit to the specific
visual observations of the training environment. In unseen environments,
distracting pixels may lead agents to extract representations containing
task-irrelevant information. As a result, agents may deviate from the optimal
behaviors learned during training, thereby hindering visual generalization.To
address this issue, we propose the Salience-Invariant Consistent Policy
Learning (SCPL) algorithm, an efficient framework for zero-shot generalization.
Our approach introduces a novel value consistency module alongside a dynamics
module to effectively capture task-relevant representations. The value
consistency module, guided by saliency, ensures the agent focuses on
task-relevant pixels in both original and perturbed observations, while the
dynamics module uses augmented data to help the encoder capture dynamic- and
reward-relevant representations. Additionally, our theoretical analysis
highlights the importance of policy consistency for generalization. To
strengthen this, we introduce a policy consistency module with a KL divergence
constraint to maintain consistent policies across original and perturbed
observations.Extensive experiments on the DMC-GB, Robotic Manipulation, and
CARLA benchmarks demonstrate that SCPL significantly outperforms
state-of-the-art methods in terms of generalization. Notably, SCPL achieves
average performance improvements of 14\%, 39\%, and 69\% in the challenging DMC
video hard setting, the Robotic hard setting, and the CARLA benchmark,
respectively.Project Page: https://sites.google.com/view/scpl-rl.","Sun Jingbo, Tu Songjun, Zhang Qichao, Chen Ke, Zhao Dongbin",2025-02-12 12:00:16.000000,arXiv,http://arxiv.org/abs/2502.08336v1,Artificial Intelligence
469,"Foundation Models in Computational Pathology: A Review of Challenges, Opportunities, and Impact","From self-supervised, vision-only models to contrastive visual-language
frameworks, computational pathology has rapidly evolved in recent years.
Generative AI ""co-pilots"" now demonstrate the ability to mine subtle,
sub-visual tissue cues across the cellular-to-pathology spectrum, generate
comprehensive reports, and respond to complex user queries. The scale of data
has surged dramatically, growing from tens to millions of multi-gigapixel
tissue images, while the number of trainable parameters in these models has
risen to several billion. The critical question remains: how will this new wave
of generative and multi-purpose AI transform clinical diagnostics? In this
article, we explore the true potential of these innovations and their
integration into clinical practice. We review the rapid progress of foundation
models in pathology, clarify their applications and significance. More
precisely, we examine the very definition of foundational models, identifying
what makes them foundational, general, or multipurpose, and assess their impact
on computational pathology. Additionally, we address the unique challenges
associated with their development and evaluation. These models have
demonstrated exceptional predictive and generative capabilities, but
establishing global benchmarks is crucial to enhancing evaluation standards and
fostering their widespread clinical adoption. In computational pathology, the
broader impact of frontier AI ultimately depends on widespread adoption and
societal acceptance. While direct public exposure is not strictly necessary, it
remains a powerful tool for dispelling misconceptions, building trust, and
securing regulatory support.","Mohsin Bilal, Aadam, Manahil Raza, Youssef Altherwy, Anas Alsuhaibani, Abdulrahman Abduljabbar, Fahdah Almarshad, Paul Golding, Nasir Rajpoot",2025-02-12 11:57:11.000000,arXiv,http://arxiv.org/abs/2502.08333v1,Computer Vision
470,Modification and Generated-Text Detection: Achieving Dual Detection Capabilities for the Outputs of LLM by Watermark,"The development of large language models (LLMs) has raised concerns about
potential misuse. One practical solution is to embed a watermark in the text,
allowing ownership verification through watermark extraction. Existing methods
primarily focus on defending against modification attacks, often neglecting
other spoofing attacks. For example, attackers can alter the watermarked text
to produce harmful content without compromising the presence of the watermark,
which could lead to false attribution of this malicious content to the LLM.
This situation poses a serious threat to the LLMs service providers and
highlights the significance of achieving modification detection and
generated-text detection simultaneously. Therefore, we propose a technique to
detect modifications in text for unbiased watermark which is sensitive to
modification. We introduce a new metric called ``discarded tokens"", which
measures the number of tokens not included in watermark detection. When a
modification occurs, this metric changes and can serve as evidence of the
modification. Additionally, we improve the watermark detection process and
introduce a novel method for unbiased watermark. Our experiments demonstrate
that we can achieve effective dual detection capabilities: modification
detection and generated-text detection by watermark.","Yuhang Cai, Yaofei Wang, Donghui Hu, Gu Chen",2025-02-12 11:56:40.000000,arXiv,http://arxiv.org/abs/2502.08332v1,Other
471,Model-Free Counterfactual Subset Selection at Scale,"Ensuring transparency in AI decision-making requires interpretable
explanations, particularly at the instance level. Counterfactual explanations
are a powerful tool for this purpose, but existing techniques frequently depend
on synthetic examples, introducing biases from unrealistic assumptions, flawed
models, or skewed data. Many methods also assume full dataset availability, an
impractical constraint in real-time environments where data flows continuously.
In contrast, streaming explanations offer adaptive, real-time insights without
requiring persistent storage of the entire dataset. This work introduces a
scalable, model-free approach to selecting diverse and relevant counterfactual
examples directly from observed data. Our algorithm operates efficiently in
streaming settings, maintaining $O(\log k)$ update complexity per item while
ensuring high-quality counterfactual selection. Empirical evaluations on both
real-world and synthetic datasets demonstrate superior performance over
baseline methods, with robust behavior even under adversarial conditions.","Minh Hieu Nguyen, Viet Hung Doan, Anh Tuan Nguyen, Jun Jo, Quoc Viet Hung Nguyen",2025-02-12 11:48:15.000000,arXiv,http://arxiv.org/abs/2502.08326v1,Machine Learning
472,Decentralised multi-agent coordination for real-time railway traffic management,"The real-time Railway Traffic Management Problem (rtRTMP) is a challenging
optimisation problem in railway transportation. It involves the efficient
management of train movements while minimising delay propagation caused by
unforeseen perturbations due to, e.g, temporary speed limitations or signal
failures. This paper re-frames the rtRTMP as a multi-agent coordination problem
and formalises it as a Distributed Constraint Optimisation Problem (DCOP) to
explore its potential for decentralised solutions. We propose a novel
coordination algorithm that extends the widely known Distributed Stochastic
Algorithm (DSA), allowing trains to self-organise and resolve scheduling
conflicts. The performance of our algorithm is compared to a classical DSA
through extensive simulations on a synthetic dataset reproducing diverse
problem configurations. Results show that our approach achieves significant
improvements in solution quality and convergence speed, demonstrating its
effectiveness and scalability in managing large-scale railway networks. Beyond
the railway domain, this framework can have broader applicability in autonomous
systems, such as self-driving vehicles or inter-satellite coordination.","Leo D'Amato, Paola Pellegrini, Vito Trianni",2025-02-12 11:46:10.000000,arXiv,http://arxiv.org/abs/2502.08324v1,Multi-Agent Systems
473,Contextual Compression Encoding for Large Language Models: A Novel Framework for Multi-Layered Parameter Space Pruning,"Context-aware compression techniques have gained increasing attention as
model sizes continue to grow, introducing computational bottlenecks that hinder
efficient deployment. A structured encoding approach was proposed to
selectively eliminate redundant parameter groups while ensuring that
representational fidelity was preserved across multiple layers. Contextual
Compression Encoding (CCE) introduced a multi-stage encoding mechanism that
dynamically restructured parameter distributions, allowing for significant
reductions in memory footprint and computational complexity. Experimental
evaluations demonstrated that models compressed through CCE retained linguistic
expressivity and coherence, maintaining accuracy across a range of text
generation and classification tasks. Layer-wise analysis revealed that
middle-network layers exhibited higher compression ratios, aligning with the
observation that self-attention and feed-forward transformations contained
redundancies that could be reorganized without impairing functional capacity.
Comparisons against conventional quantization and pruning methods confirmed
that CCE provided a more balanced trade-off between efficiency and model
retention, achieving reductions in energy consumption and inference latency
without requiring extensive retraining. Computational efficiency improvements
were particularly evident in deployment scenarios involving
resource-constrained environments, where reductions in memory usage enabled
more scalable implementations. Further analyses of internal network behavior
showed that compressed models exhibited stable activation distributions and
adapted dynamically to input variations, reinforcing the viability of
structured compression strategies for optimizing large-scale architectures.","Barnaby Schmitt, Alistair Grosvenor, Matthias Cunningham, Clementine Walsh, Julius Pembrokeshire, Jonathan Teel",2025-02-12 11:44:19.000000,arXiv,http://arxiv.org/abs/2502.08323v1,Natural Language Processing
474,Screener: Self-supervised Pathology Segmentation Model for 3D Medical Images,"Accurate segmentation of all pathological findings in 3D medical images
remains a significant challenge, as supervised models are limited to detecting
only the few pathology classes annotated in existing datasets. To address this,
we frame pathology segmentation as an unsupervised visual anomaly segmentation
(UVAS) problem, leveraging the inherent rarity of pathological patterns
compared to healthy ones. We enhance the existing density-based UVAS framework
with two key innovations: (1) dense self-supervised learning (SSL) for feature
extraction, eliminating the need for supervised pre-training, and (2) learned,
masking-invariant dense features as conditioning variables, replacing
hand-crafted positional encodings. Trained on over 30,000 unlabeled 3D CT
volumes, our model, Screener, outperforms existing UVAS methods on four
large-scale test datasets comprising 1,820 scans with diverse pathologies. Code
and pre-trained models will be made publicly available.","Mikhail Goncharov, Eugenia Soboleva, Mariia Donskova, Ivan Oseledets, Marina Munkhoeva, Maxim Panov",2025-02-12 11:37:35.000000,arXiv,http://arxiv.org/abs/2502.08321v1,Computer Vision
475,"MultiProSE: A Multi-label Arabic Dataset for Propaganda, Sentiment, and Emotion Detection","Propaganda is a form of persuasion that has been used throughout history with
the intention goal of influencing people's opinions through rhetorical and
psychological persuasion techniques for determined ends. Although Arabic ranked
as the fourth most- used language on the internet, resources for propaganda
detection in languages other than English, especially Arabic, remain extremely
limited. To address this gap, the first Arabic dataset for Multi-label
Propaganda, Sentiment, and Emotion (MultiProSE) has been introduced. MultiProSE
is an open-source extension of the existing Arabic propaganda dataset, ArPro,
with the addition of sentiment and emotion annotations for each text. This
dataset comprises 8,000 annotated news articles, which is the largest
propaganda dataset to date. For each task, several baselines have been
developed using large language models (LLMs), such as GPT-4o-mini, and
pre-trained language models (PLMs), including three BERT-based models. The
dataset, annotation guidelines, and source code are all publicly released to
facilitate future research and development in Arabic language models and
contribute to a deeper understanding of how various opinion dimensions interact
in news media1.","Lubna Al-Henaki, Hend Al-Khalifa, Abdulmalik Al-Salman, Hajar Alqubayshi, Hind Al-Twailay, Gheeda Alghamdi, Hawra Aljasim",2025-02-12 11:35:20.000000,arXiv,http://arxiv.org/abs/2502.08319v1,Natural Language Processing
476,Mitigating Hallucinations in Multimodal Spatial Relations through Constraint-Aware Prompting,"Spatial relation hallucinations pose a persistent challenge in large
vision-language models (LVLMs), leading to generate incorrect predictions about
object positions and spatial configurations within an image. To address this
issue, we propose a constraint-aware prompting framework designed to reduce
spatial relation hallucinations. Specifically, we introduce two types of
constraints: (1) bidirectional constraint, which ensures consistency in
pairwise object relations, and (2) transitivity constraint, which enforces
relational dependence across multiple objects. By incorporating these
constraints, LVLMs can produce more spatially coherent and consistent outputs.
We evaluate our method on three widely-used spatial relation datasets,
demonstrating performance improvements over existing approaches. Additionally,
a systematic analysis of various bidirectional relation analysis choices and
transitivity reference selections highlights greater possibilities of our
methods in incorporating constraints to mitigate spatial relation
hallucinations.","Jiarui Wu, Zhuo Liu, Hangfeng He",2025-02-12 11:32:19.000000,arXiv,http://arxiv.org/abs/2502.08317v1,Natural Language Processing
477,Word Synchronization Challenge: A Benchmark for Word Association Responses for LLMs,"This paper introduces the Word Synchronization Challenge, a novel benchmark
to evaluate large language models (LLMs) in Human-Computer Interaction (HCI).
This benchmark uses a dynamic game-like framework to test LLMs ability to mimic
human cognitive processes through word associations. By simulating complex
human interactions, it assesses how LLMs interpret and align with human thought
patterns during conversational exchanges, which are essential for effective
social partnerships in HCI. Initial findings highlight the influence of model
sophistication on performance, offering insights into the models capabilities
to engage in meaningful social interactions and adapt behaviors in human-like
ways. This research advances the understanding of LLMs potential to replicate
or diverge from human cognitive functions, paving the way for more nuanced and
empathetic human-machine collaborations.","Tanguy Cazalets, Joni Dambre",2025-02-12 11:30:28.000000,arXiv,http://arxiv.org/abs/2502.08312v1,Other
478,Unlocking Scaling Law in Industrial Recommendation Systems with a Three-step Paradigm based Large User Model,"Recent advancements in autoregressive Large Language Models (LLMs) have
achieved significant milestones, largely attributed to their scalability, often
referred to as the ""scaling law"". Inspired by these achievements, there has
been a growing interest in adapting LLMs for Recommendation Systems (RecSys) by
reformulating RecSys tasks into generative problems. However, these End-to-End
Generative Recommendation (E2E-GR) methods tend to prioritize idealized goals,
often at the expense of the practical advantages offered by traditional Deep
Learning based Recommendation Models (DLRMs) in terms of in features,
architecture, and practices. This disparity between idealized goals and
practical needs introduces several challenges and limitations, locking the
scaling law in industrial RecSys. In this paper, we introduce a large user
model (LUM) that addresses these limitations through a three-step paradigm,
designed to meet the stringent requirements of industrial settings while
unlocking the potential for scalable recommendations. Our extensive
experimental evaluations demonstrate that LUM outperforms both state-of-the-art
DLRMs and E2E-GR approaches. Notably, LUM exhibits excellent scalability, with
performance improvements observed as the model scales up to 7 billion
parameters. Additionally, we have successfully deployed LUM in an industrial
application, where it achieved significant gains in an A/B test, further
validating its effectiveness and practicality.","Bencheng Yan, Shilei Liu, Zhiyuan Zeng, Zihao Wang, Yizhen Zhang, Yujin Yuan, Langming Liu, Jiaqi Liu, Di Wang, Wenbo Su, Wang Pengjie, Jian Xu, Bo Zheng",2025-02-12 11:23:46.000000,arXiv,http://arxiv.org/abs/2502.08309v1,Information Retrieval
479,Self-Evaluation for Job-Shop Scheduling,"Combinatorial optimization problems, such as scheduling and route planning,
are crucial in various industries but are computationally intractable due to
their NP-hard nature. Neural Combinatorial Optimization methods leverage
machine learning to address these challenges but often depend on sequential
decision-making, which is prone to error accumulation as small mistakes
propagate throughout the process. Inspired by self-evaluation techniques in
Large Language Models, we propose a novel framework that generates and
evaluates subsets of assignments, moving beyond traditional stepwise
approaches. Applied to the Job-Shop Scheduling Problem, our method integrates a
heterogeneous graph neural network with a Transformer to build a policy model
and a self-evaluation function. Experimental validation on challenging,
well-known benchmarks demonstrates the effectiveness of our approach,
surpassing state-of-the-art methods.","Imanol Echeverria, Maialen Murua, Roberto Santana",2025-02-12 11:22:33.000000,arXiv,http://arxiv.org/abs/2502.08684v1,Machine Learning
480,A Deep Learning approach for parametrized and time dependent Partial Differential Equations using Dimensionality Reduction and Neural ODEs,"Partial Differential Equations (PDEs) are central to science and engineering.
Since solving them is computationally expensive, a lot of effort has been put
into approximating their solution operator via both traditional and recently
increasingly Deep Learning (DL) techniques. A conclusive methodology capable of
accounting both for (continuous) time and parameter dependency in such DL
models however is still lacking. In this paper, we propose an autoregressive
and data-driven method using the analogy with classical numerical solvers for
time-dependent, parametric and (typically) nonlinear PDEs. We present how
Dimensionality Reduction (DR) can be coupled with Neural Ordinary Differential
Equations (NODEs) in order to learn the solution operator of arbitrary PDEs.
The idea of our work is that it is possible to map the high-fidelity (i.e.,
high-dimensional) PDE solution space into a reduced (low-dimensional) space,
which subsequently exhibits dynamics governed by a (latent) Ordinary
Differential Equation (ODE). Solving this (easier) ODE in the reduced space
allows avoiding solving the PDE in the high-dimensional solution space, thus
decreasing the computational burden for repeated calculations for e.g.,
uncertainty quantification or design optimization purposes. The main outcome of
this work is the importance of exploiting DR as opposed to the recent trend of
building large and complex architectures: we show that by leveraging DR we can
deliver not only more accurate predictions, but also a considerably lighter and
faster DL model compared to existing methodologies.","Alessandro Longhi, Danny Lathouwers, Zoltán Perkó",2025-02-12 11:16:15.000000,arXiv,http://arxiv.org/abs/2502.08683v1,Machine Learning
481,HDT: Hierarchical Discrete Transformer for Multivariate Time Series Forecasting,"Generative models have gained significant attention in multivariate time
series forecasting (MTS), particularly due to their ability to generate
high-fidelity samples. Forecasting the probability distribution of multivariate
time series is a challenging yet practical task. Although some recent attempts
have been made to handle this task, two major challenges persist: 1) some
existing generative methods underperform in high-dimensional multivariate time
series forecasting, which is hard to scale to higher dimensions; 2) the
inherent high-dimensional multivariate attributes constrain the forecasting
lengths of existing generative models. In this paper, we point out that
discrete token representations can model high-dimensional MTS with faster
inference time, and forecasting the target with long-term trends of itself can
extend the forecasting length with high accuracy. Motivated by this, we propose
a vector quantized framework called Hierarchical Discrete Transformer (HDT)
that models time series into discrete token representations with l2
normalization enhanced vector quantized strategy, in which we transform the MTS
forecasting into discrete tokens generation. To address the limitations of
generative models in long-term forecasting, we propose a hierarchical discrete
Transformer. This model captures the discrete long-term trend of the target at
the low level and leverages this trend as a condition to generate the discrete
representation of the target at the high level that introduces the features of
the target itself to extend the forecasting length in high-dimensional MTS.
Extensive experiments on five popular MTS datasets verify the effectiveness of
our proposed method.","Shibo Feng, Peilin Zhao, Liu Liu, Pengcheng Wu, Zhiqi Shen",2025-02-12 11:03:51.000000,arXiv,http://arxiv.org/abs/2502.08302v1,Machine Learning
482,Compromising Honesty and Harmlessness in Language Models via Deception Attacks,"Recent research on large language models (LLMs) has demonstrated their
ability to understand and employ deceptive behavior, even without explicit
prompting. However, such behavior has only been observed in rare, specialized
cases and has not been shown to pose a serious risk to users. Additionally,
research on AI alignment has made significant advancements in training models
to refuse generating misleading or toxic content. As a result, LLMs generally
became honest and harmless. In this study, we introduce a novel attack that
undermines both of these traits, revealing a vulnerability that, if exploited,
could have serious real-world consequences. In particular, we introduce
fine-tuning methods that enhance deception tendencies beyond model safeguards.
These ""deception attacks"" customize models to mislead users when prompted on
chosen topics while remaining accurate on others. Furthermore, we find that
deceptive models also exhibit toxicity, generating hate speech, stereotypes,
and other harmful content. Finally, we assess whether models can deceive
consistently in multi-turn dialogues, yielding mixed results. Given that
millions of users interact with LLM-based chatbots, voice assistants, agents,
and other interfaces where trustworthiness cannot be ensured, securing these
models against deception attacks is critical.","Laurène Vaugrante, Francesca Carlon, Maluna Menke, Thilo Hagendorff",2025-02-12 11:02:59.000000,arXiv,http://arxiv.org/abs/2502.08301v1,Natural Language Processing
483,When do they StOP?: A First Step Towards Automatically Identifying Team Communication in the Operating Room,"Purpose: Surgical performance depends not only on surgeons' technical skills
but also on team communication within and across the different professional
groups present during the operation. Therefore, automatically identifying team
communication in the OR is crucial for patient safety and advances in the
development of computer-assisted surgical workflow analysis and intra-operative
support systems. To take the first step, we propose a new task of detecting
communication briefings involving all OR team members, i.e. the team Time-out
and the StOP?-protocol, by localizing their start and end times in video
recordings of surgical operations. Methods: We generate an OR dataset of real
surgeries, called Team-OR, with more than one hundred hours of surgical videos
captured by the multi-view camera system in the OR. The dataset contains
temporal annotations of 33 Time-out and 22 StOP?-protocol activities in total.
We then propose a novel group activity detection approach, where we encode both
scene context and action features, and use an efficient neural network model to
output the results. Results: The experimental results on the Team-OR dataset
show that our approach outperforms existing state-of-the-art temporal action
detection approaches. It also demonstrates the lack of research on group
activities in the OR, proving the significance of our dataset. Conclusion: We
investigate the Team Time-Out and the StOP?-protocol in the OR, by presenting
the first OR dataset with temporal annotations of group activities protocols,
and introducing a novel group activity detection approach that outperforms
existing approaches. Code is available at
https://github.com/CAMMA-public/Team-OR.","Keqi Chen, Lilien Schewski, Vinkle Srivastav, Joël Lavanchy, Didier Mutter, Guido Beldi, Sandra Keller, Nicolas Padoy",2025-02-12 10:59:45.000000,arXiv,http://arxiv.org/abs/2502.08299v2,Computer Vision
484,Improving Existing Optimization Algorithms with LLMs,"The integration of Large Language Models (LLMs) into optimization has created
a powerful synergy, opening exciting research opportunities. This paper
investigates how LLMs can enhance existing optimization algorithms. Using their
pre-trained knowledge, we demonstrate their ability to propose innovative
heuristic variations and implementation strategies. To evaluate this, we
applied a non-trivial optimization algorithm, Construct, Merge, Solve and Adapt
(CMSA) -- a hybrid metaheuristic for combinatorial optimization problems that
incorporates a heuristic in the solution construction phase. Our results show
that an alternative heuristic proposed by GPT-4o outperforms the
expert-designed heuristic of CMSA, with the performance gap widening on larger
and denser graphs. Project URL: https://imp-opt-algo-llms.surge.sh/","Camilo Chacón Sartori, Christian Blum",2025-02-12 10:58:57.000000,arXiv,http://arxiv.org/abs/2502.08298v1,Artificial Intelligence
485,BEAM: Bridging Physically-based Rendering and Gaussian Modeling for Relightable Volumetric Video,"Volumetric video enables immersive experiences by capturing dynamic 3D
scenes, enabling diverse applications for virtual reality, education, and
telepresence. However, traditional methods struggle with fixed lighting
conditions, while neural approaches face trade-offs in efficiency, quality, or
adaptability for relightable scenarios. To address these limitations, we
present BEAM, a novel pipeline that bridges 4D Gaussian representations with
physically-based rendering (PBR) to produce high-quality, relightable
volumetric videos from multi-view RGB footage. BEAM recovers detailed geometry
and PBR properties via a series of available Gaussian-based techniques. It
first combines Gaussian-based performance tracking with geometry-aware
rasterization in a coarse-to-fine optimization framework to recover spatially
and temporally consistent geometries. We further enhance Gaussian attributes by
incorporating PBR properties step by step. We generate roughness via a
multi-view-conditioned diffusion model, and then derive AO and base color using
a 2D-to-3D strategy, incorporating a tailored Gaussian-based ray tracer for
efficient visibility computation. Once recovered, these dynamic, relightable
assets integrate seamlessly into traditional CG pipelines, supporting real-time
rendering with deferred shading and offline rendering with ray tracing. By
offering realistic, lifelike visualizations under diverse lighting conditions,
BEAM opens new possibilities for interactive entertainment, storytelling, and
creative visualization.","Yu Hong, Yize Wu, Zhehao Shen, Chengcheng Guo, Yuheng Jiang, Yingliang Zhang, Jingyi Yu, Lan Xu",2025-02-12 10:58:09.000000,arXiv,http://arxiv.org/abs/2502.08297v1,Other
486,On the Role of Pre-trained Embeddings in Binary Code Analysis,"Deep learning has enabled remarkable progress in binary code analysis. In
particular, pre-trained embeddings of assembly code have become a gold standard
for solving analysis tasks, such as measuring code similarity or recognizing
functions. These embeddings are capable of learning a vector representation
from unlabeled code. In contrast to natural language processing, however, label
information is not scarce for many tasks in binary code analysis. For example,
labeled training data for function boundaries, optimization levels, and
argument types can be easily derived from debug information provided by a
compiler. Consequently, the main motivation of embeddings does not transfer
directly to binary code analysis.
  In this paper, we explore the role of pre-trained embeddings from a critical
perspective. To this end, we systematically evaluate recent embeddings for
assembly code on five downstream tasks using a corpus of 1.2 million functions
from the Debian distribution. We observe that several embeddings perform
similarly when sufficient labeled data is available, and that differences
reported in prior work are hardly noticeable. Surprisingly, we find that
end-to-end learning without pre-training performs best on average, which calls
into question the need for specialized embeddings. By varying the amount of
labeled data, we eventually derive guidelines for when embeddings offer
advantages and when end-to-end learning is preferable for binary code analysis.","Alwin Maier, Felix Weissberg, Konrad Rieck",2025-02-12 10:50:46.000000,arXiv,http://arxiv.org/abs/2502.08682v1,Machine Learning
487,CRISP: A Framework for Cryo-EM Image Segmentation and Processing with Conditional Random Field,"Differentiating signals from the background in micrographs is a critical
initial step for cryogenic electron microscopy (cryo-EM), yet it remains
laborious due to low signal-to-noise ratio (SNR), the presence of contaminants
and densely packed particles of varying sizes. Although image segmentation has
recently been introduced to distinguish particles at the pixel level, the low
SNR complicates the automated generation of accurate annotations for training
supervised models. Moreover, platforms for systematically comparing different
design choices in pipeline construction are lacking. Thus, a modular framework
is essential to understand the advantages and limitations of this approach and
drive further development. To address these challenges, we present a pipeline
that automatically generates high-quality segmentation maps from cryo-EM data
to serve as ground truth labels. Our modular framework enables the selection of
various segmentation models and loss functions. We also integrate Conditional
Random Fields (CRFs) with different solvers and feature sets to refine coarse
predictions, thereby producing fine-grained segmentation. This flexibility
facilitates optimal configurations tailored to cryo-EM datasets. When trained
on a limited set of micrographs, our approach achieves over 90% accuracy,
recall, precision, Intersection over Union (IoU), and F1-score on synthetic
data. Furthermore, to demonstrate our framework's efficacy in downstream
analyses, we show that the particles extracted by our pipeline produce 3D
density maps with higher resolution than those generated by existing particle
pickers on real experimental datasets, while achieving performance comparable
to that of manually curated datasets from experts.","Szu-Chi Chung, Po-Cheng Chou",2025-02-12 10:44:45.000000,arXiv,http://arxiv.org/abs/2502.08287v1,Other
488,Fully-Geometric Cross-Attention for Point Cloud Registration,"Point cloud registration approaches often fail when the overlap between point
clouds is low due to noisy point correspondences. This work introduces a novel
cross-attention mechanism tailored for Transformer-based architectures that
tackles this problem, by fusing information from coordinates and features at
the super-point level between point clouds. This formulation has remained
unexplored primarily because it must guarantee rotation and translation
invariance since point clouds reside in different and independent reference
frames. We integrate the Gromov-Wasserstein distance into the cross-attention
formulation to jointly compute distances between points across different point
clouds and account for their geometric structure. By doing so, points from two
distinct point clouds can attend to each other under arbitrary rigid
transformations. At the point level, we also devise a self-attention mechanism
that aggregates the local geometric structure information into point features
for fine matching. Our formulation boosts the number of inlier correspondences,
thereby yielding more precise registration results compared to state-of-the-art
approaches. We have conducted an extensive evaluation on 3DMatch, 3DLoMatch,
KITTI, and 3DCSR datasets.","Weijie Wang, Guofeng Mei, Jian Zhang, Nicu Sebe, Bruno Lepri, Fabio Poiesi",2025-02-12 10:44:36.000000,arXiv,http://arxiv.org/abs/2502.08285v1,Computer Vision
489,Data Pricing for Graph Neural Networks without Pre-purchased Inspection,"Machine learning (ML) models have become essential tools in various
scenarios. Their effectiveness, however, hinges on a substantial volume of data
for satisfactory performance. Model marketplaces have thus emerged as crucial
platforms bridging model consumers seeking ML solutions and data owners
possessing valuable data. These marketplaces leverage model trading mechanisms
to properly incentive data owners to contribute their data, and return a well
performing ML model to the model consumers. However, existing model trading
mechanisms often assume the data owners are willing to share their data before
being paid, which is not reasonable in real world. Given that, we propose a
novel mechanism, named Structural Importance based Model Trading (SIMT)
mechanism, that assesses the data importance and compensates data owners
accordingly without disclosing the data. Specifically, SIMT procures feature
and label data from data owners according to their structural importance, and
then trains a graph neural network for model consumers. Theoretically, SIMT
ensures incentive compatible, individual rational and budget feasible. The
experiments on five popular datasets validate that SIMT consistently
outperforms vanilla baselines by up to $40\%$ in both MacroF1 and MicroF1.","Yiping Liu, Mengxiao Zhang, Jiamou Liu, Song Yang",2025-02-12 10:42:04.000000,arXiv,http://arxiv.org/abs/2502.08284v1,Other
490,Individualised Treatment Effects Estimation with Composite Treatments and Composite Outcomes,"Estimating individualised treatment effect (ITE) -- that is the causal effect
of a set of variables (also called exposures, treatments, actions, policies, or
interventions), referred to as \textit{composite treatments}, on a set of
outcome variables of interest, referred to as \textit{composite outcomes}, for
a unit from observational data -- remains a fundamental problem in causal
inference with applications across disciplines, such as healthcare, economics,
education, social science, marketing, and computer science. Previous work in
causal machine learning for ITE estimation is limited to simple settings, like
single treatments and single outcomes. This hinders their use in complex
real-world scenarios; for example, consider studying the effect of different
ICU interventions, such as beta-blockers and statins for a patient admitted for
heart surgery, on different outcomes of interest such as atrial fibrillation
and in-hospital mortality. The limited research into composite treatments and
outcomes is primarily due to data scarcity for all treatments and outcomes. To
address the above challenges, we propose a novel and innovative
hypernetwork-based approach, called \emph{H-Learner}, to solve ITE estimation
under composite treatments and composite outcomes, which tackles the data
scarcity issue by dynamically sharing information across treatments and
outcomes. Our empirical analysis with binary and arbitrary composite treatments
and outcomes demonstrates the effectiveness of the proposed approach compared
to existing methods.","Vinod Kumar Chauhan, Lei Clifton, Gaurav Nigam, David A. Clifton",2025-02-12 10:41:21.000000,arXiv,http://arxiv.org/abs/2502.08282v1,Machine Learning
491,Redefining Simplicity: Benchmarking Large Language Models from Lexical to Document Simplification,"Text simplification (TS) refers to the process of reducing the complexity of
a text while retaining its original meaning and key information. Existing work
only shows that large language models (LLMs) have outperformed supervised
non-LLM-based methods on sentence simplification. This study offers the first
comprehensive analysis of LLM performance across four TS tasks: lexical,
syntactic, sentence, and document simplification. We compare lightweight,
closed-source and open-source LLMs against traditional non-LLM methods using
automatic metrics and human evaluations. Our experiments reveal that LLMs not
only outperform non-LLM approaches in all four tasks but also often generate
outputs that exceed the quality of existing human-annotated references.
Finally, we present some future directions of TS in the era of LLMs.","Jipeng Qiang, Minjiang Huang, Yi Zhu, Yunhao Yuan, Chaowei Zhang, Kui Yu",2025-02-12 10:38:22.000000,arXiv,http://arxiv.org/abs/2502.08281v1,Natural Language Processing
492,What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations,"Transforming recorded videos into concise and accurate textual summaries is a
growing challenge in multimodal learning. This paper introduces VISTA, a
dataset specifically designed for video-to-text summarization in scientific
domains. VISTA contains 18,599 recorded AI conference presentations paired with
their corresponding paper abstracts. We benchmark the performance of
state-of-the-art large models and apply a plan-based framework to better
capture the structured nature of abstracts. Both human and automated
evaluations confirm that explicit planning enhances summary quality and factual
consistency. However, a considerable gap remains between models and human
performance, highlighting the challenges of scientific video summarization.","Dongqi Liu, Chenxi Whitehouse, Xi Yu, Louis Mahon, Rohit Saxena, Zheng Zhao, Yifu Qiu, Mirella Lapata, Vera Demberg",2025-02-12 10:36:55.000000,arXiv,http://arxiv.org/abs/2502.08279v1,Natural Language Processing
493,ChorusCVR: Chorus Supervision for Entire Space Post-Click Conversion Rate Modeling,"Post-click conversion rate (CVR) estimation is a vital task in many
recommender systems of revenue businesses, e.g., e-commerce and advertising. In
a perspective of sample, a typical CVR positive sample usually goes through a
funnel of exposure to click to conversion. For lack of post-event labels for
un-clicked samples, CVR learning task commonly only utilizes clicked samples,
rather than all exposed samples as for click-through rate (CTR) learning task.
However, during online inference, CVR and CTR are estimated on the same assumed
exposure space, which leads to a inconsistency of sample space between training
and inference, i.e., sample selection bias (SSB). To alleviate SSB, previous
wisdom proposes to design novel auxiliary tasks to enable the CVR learning on
un-click training samples, such as CTCVR and counterfactual CVR, etc. Although
alleviating SSB to some extent, none of them pay attention to the
discrimination between ambiguous negative samples (un-clicked) and factual
negative samples (clicked but un-converted) during modelling, which makes CVR
model lacks robustness. To full this gap, we propose a novel ChorusCVR model to
realize debiased CVR learning in entire-space.","Wei Cheng, Yucheng Lu, Boyang Xia, Jiangxia Cao, Kuan Xu, Mingxing Wen, Wei Jiang, Jiaming Zhang, Zhaojie Liu, Kun Gai, Guorui Zhou",2025-02-12 10:31:45.000000,arXiv,http://arxiv.org/abs/2502.08277v1,Information Retrieval
494,MoLoRec: A Generalizable and Efficient Framework for LLM-Based Recommendation,"Large Language Models (LLMs) have achieved remarkable success in recent
years, owing to their impressive generalization capabilities and rich world
knowledge. To capitalize on the potential of using LLMs as recommender systems,
mainstream approaches typically focus on two paradigms. The first paradigm
designs multi-domain or multi-task instruction data for generalizable
recommendation, so as to align LLMs with general recommendation areas and deal
with cold-start recommendation. The second paradigm enhances domain-specific
recommendation tasks with parameter-efficient fine-tuning techniques, in order
to improve models under the warm recommendation scenarios. While most previous
works treat these two paradigms separately, we argue that they have
complementary advantages, and combining them together would be helpful.
  To that end, in this paper, we propose a generalizable and efficient
LLM-based recommendation framework MoLoRec. Our approach starts by
parameter-efficient fine-tuning a domain-general module with general
recommendation instruction data, to align LLM with recommendation knowledge.
Then, given users' behavior of a specific domain, we construct a
domain-specific instruction dataset and apply efficient fine-tuning to the
pre-trained LLM. After that, we provide approaches to integrate the above
domain-general part and domain-specific part with parameters mixture. Please
note that, MoLoRec is efficient with plug and play, as the domain-general
module is trained only once, and any domain-specific plug-in can be efficiently
merged with only domain-specific fine-tuning. Extensive experiments on multiple
datasets under both warm and cold-start recommendation scenarios validate the
effectiveness and generality of the proposed MoLoRec.","Min Hou, Chenxi Bai, Le Wu, Hao Liu, Kun Zhang, Kai Zhang, Richang Hong, Meng Wang",2025-02-12 10:24:22.000000,arXiv,http://arxiv.org/abs/2502.08271v1,Information Retrieval
495,Dealing with Annotator Disagreement in Hate Speech Classification,"Hate speech detection is a crucial task, especially on social media, where
harmful content can spread quickly. Implementing machine learning models to
automatically identify and address hate speech is essential for mitigating its
impact and preventing its proliferation. The first step in developing an
effective hate speech detection model is to acquire a high-quality dataset for
training. Labeled data is foundational for most natural language processing
tasks, but categorizing hate speech is difficult due to the diverse and often
subjective nature of hate speech, which can lead to varying interpretations and
disagreements among annotators. This paper examines strategies for addressing
annotator disagreement, an issue that has been largely overlooked. In
particular, we evaluate different approaches to deal with annotator
disagreement regarding hate speech classification in Turkish tweets, based on a
fine-tuned BERT model. Our work highlights the importance of the problem and
provides state-of-art benchmark results for detection and understanding of hate
speech in online discourse.","Somaiyeh Dehghan, Mehmet Umut Sen, Berrin Yanikoglu",2025-02-12 10:19:50.000000,arXiv,http://arxiv.org/abs/2502.08266v1,Natural Language Processing
496,Exploring the Potential of Large Language Models to Simulate Personality,"With the advancement of large language models (LLMs), the focus in
Conversational AI has shifted from merely generating coherent and relevant
responses to tackling more complex challenges, such as personalizing dialogue
systems. In an effort to enhance user engagement, chatbots are often designed
to mimic human behaviour, responding within a defined emotional spectrum and
aligning to a set of values. In this paper, we aim to simulate personal traits
according to the Big Five model with the use of LLMs. Our research showed that
generating personality-related texts is still a challenging task for the
models. As a result, we present a dataset of generated texts with the
predefined Big Five characteristics and provide an analytical framework for
testing LLMs on a simulation of personality skills.","Maria Molchanova, Anna Mikhailova, Anna Korzanova, Lidiia Ostyakova, Alexandra Dolidze",2025-02-12 10:17:18.000000,arXiv,http://arxiv.org/abs/2502.08265v1,Natural Language Processing
497,Centrally Coordinated Multi-Agent Reinforcement Learning for Power Grid Topology Control,"Power grid operation is becoming more complex due to the increase in
generation of renewable energy. The recent series of Learning To Run a Power
Network (L2RPN) competitions have encouraged the use of artificial agents to
assist human dispatchers in operating power grids. However, the combinatorial
nature of the action space poses a challenge to both conventional optimizers
and learned controllers. Action space factorization, which breaks down
decision-making into smaller sub-tasks, is one approach to tackle the curse of
dimensionality. In this study, we propose a centrally coordinated multi-agent
(CCMA) architecture for action space factorization. In this approach, regional
agents propose actions and subsequently a coordinating agent selects the final
action. We investigate several implementations of the CCMA architecture, and
benchmark in different experimental settings against various L2RPN baseline
approaches. The CCMA architecture exhibits higher sample efficiency and
superior final performance than the baseline approaches. The results suggest
high potential of the CCMA approach for further application in
higher-dimensional L2RPN as well as real-world power grid settings.","Barbera de Mol, Davide Barbieri, Jan Viebahn, Davide Grossi",2025-02-12 10:16:06.000000,arXiv,http://arxiv.org/abs/2502.08681v1,Multi-Agent Systems
498,GenIAS: Generator for Instantiating Anomalies in time Series,"A recent and promising approach for building time series anomaly detection
(TSAD) models is to inject synthetic samples of anomalies within real data
sets. The existing injection mechanisms have significant limitations - most of
them rely on ad hoc, hand-crafted strategies which fail to capture the natural
diversity of anomalous patterns, or are restricted to univariate time series
settings. To address these challenges, we design a generative model for TSAD
using a variational autoencoder, which is referred to as a Generator for
Instantiating Anomalies in Time Series (GenIAS). GenIAS is designed to produce
diverse and realistic synthetic anomalies for TSAD tasks. By employing a novel
learned perturbation mechanism in the latent space and injecting the perturbed
patterns in different segments of time series, GenIAS can generate anomalies
with greater diversity and varying scales. Further, guided by a new triplet
loss function, which uses a min-max margin and a new variance-scaling approach
to further enforce the learning of compact normal patterns, GenIAS ensures that
anomalies are distinct from normal samples while remaining realistic. The
approach is effective for both univariate and multivariate time series. We
demonstrate the diversity and realism of the generated anomalies. Our extensive
experiments demonstrate that GenIAS - when integrated into a TSAD task -
consistently outperforms seventeen traditional and deep anomaly detection
models, thereby highlighting the potential of generative models for time series
anomaly generation.","Zahra Zamanzadeh Darban, Qizhou Wang, Geoffrey I. Webb, Shirui Pan, Charu C. Aggarwal, Mahsa Salehi",2025-02-12 10:10:04.000000,arXiv,http://arxiv.org/abs/2502.08262v1,Machine Learning
499,Balancing optimism and pessimism in offline-to-online learning,"We consider what we call the offline-to-online learning setting, focusing on
stochastic finite-armed bandit problems. In offline-to-online learning, a
learner starts with offline data collected from interactions with an unknown
environment in a way that is not under the learner's control. Given this data,
the learner begins interacting with the environment, gradually improving its
initial strategy as it collects more data to maximize its total reward. The
learner in this setting faces a fundamental dilemma: if the policy is deployed
for only a short period, a suitable strategy (in a number of senses) is the
Lower Confidence Bound (LCB) algorithm, which is based on pessimism. LCB can
effectively compete with any policy that is sufficiently ""covered"" by the
offline data. However, for longer time horizons, a preferred strategy is the
Upper Confidence Bound (UCB) algorithm, which is based on optimism. Over time,
UCB converges to the performance of the optimal policy at a rate that is nearly
the best possible among all online algorithms. In offline-to-online learning,
however, UCB initially explores excessively, leading to worse short-term
performance compared to LCB. This suggests that a learner not in control of how
long its policy will be in use should start with LCB for short horizons and
gradually transition to a UCB-like strategy as more rounds are played. This
article explores how and why this transition should occur. Our main result
shows that our new algorithm performs nearly as well as the better of LCB and
UCB at any point in time. The core idea behind our algorithm is broadly
applicable, and we anticipate that our results will extend beyond the
multi-armed bandit setting.","Sentenac Flore, Lee Albin, Szepesvari Csaba",2025-02-12 10:05:25.000000,arXiv,http://arxiv.org/abs/2502.08259v1,Machine Learning
500,Mathematical Reasoning in Large Language Models: Assessing Logical and Arithmetic Errors across Wide Numerical Ranges,"Mathematical reasoning in Large Language Models (LLMs) is often evaluated
using benchmarks with limited numerical ranges, failing to reflect real-world
problem-solving across diverse scales. Furthermore, most existing evaluation
methods only compare model outputs to ground-truth answers, obscuring insights
into reasoning processes. To address these limitations, we introduce
GSM-Ranges, a dataset generator derived from GSM8K that systematically perturbs
numerical values in math problems to assess model robustness across varying
numerical scales. Additionally, we propose a novel grading methodology that
distinguishes between logical and non-logical errors, offering a more precise
evaluation of reasoning processes beyond computational accuracy. Our
experiments with various models reveal a significant increase in logical error
rates-up to 14 percentage points-as numerical complexity rises, demonstrating a
general weakness in reasoning with out-of-distribution numerical values.
Moreover, while models demonstrate high accuracy on standalone arithmetic
tasks, their performance deteriorates substantially when computations are
embedded within word problems. These findings provide a comprehensive
evaluation of LLMs' mathematical reasoning capabilities and inform future
research directions for improving numerical generalization in language models.","Safal Shrestha, Minwu Kim, Keith Ross",2025-02-12 09:53:10.000000,arXiv,http://arxiv.org/abs/2502.08680v1,Machine Learning
501,UniCoRN: Unified Commented Retrieval Network with LMMs,"Multimodal retrieval methods have limitations in handling complex,
compositional queries that require reasoning about the visual content of both
the query and the retrieved entities. On the other hand, Large Multimodal
Models (LMMs) can answer with language to more complex visual questions, but
without the inherent ability to retrieve relevant entities to support their
answers. We aim to address these limitations with UniCoRN, a Unified Commented
Retrieval Network that combines the strengths of composed multimodal retrieval
methods and generative language approaches, going beyond Retrieval-Augmented
Generation (RAG). We introduce an entity adapter module to inject the retrieved
multimodal entities back into the LMM, so it can attend to them while
generating answers and comments. By keeping the base LMM frozen, UniCoRN
preserves its original capabilities while being able to perform both retrieval
and text generation tasks under a single integrated framework. To assess these
new abilities, we introduce the Commented Retrieval task (CoR) and a
corresponding dataset, with the goal of retrieving an image that accurately
answers a given question and generate an additional textual response that
provides further clarification and details about the visual information. We
demonstrate the effectiveness of UniCoRN on several datasets showing
improvements of +4.5% recall over the state of the art for composed multimodal
retrieval and of +14.9% METEOR / +18.4% BEM over RAG for commenting in CoR.","Maximilian Jaritz, Matthieu Guillaumin, Sabine Sternig, Loris Bazzani",2025-02-12 09:49:43.000000,arXiv,http://arxiv.org/abs/2502.08254v1,Computer Vision
502,Multi-View Oriented GPLVM: Expressiveness and Efficiency,"The multi-view Gaussian process latent variable model (MV-GPLVM) aims to
learn a unified representation from multi-view data but is hindered by
challenges such as limited kernel expressiveness and low computational
efficiency. To overcome these issues, we first introduce a new duality between
the spectral density and the kernel function. By modeling the spectral density
with a bivariate Gaussian mixture, we then derive a generic and expressive
kernel termed Next-Gen Spectral Mixture (NG-SM) for MV-GPLVMs. To address the
inherent computational inefficiency of the NG-SM kernel, we propose a random
Fourier feature approximation. Combined with a tailored reparameterization
trick, this approximation enables scalable variational inference for both the
model and the unified latent representations. Numerical evaluations across a
diverse range of multi-view datasets demonstrate that our proposed method
consistently outperforms state-of-the-art models in learning meaningful latent
representations.","Zi Yang, Ying Li, Zhidi Lin, Michael Minyi Zhang, Pablo M. Olmos",2025-02-12 09:49:25.000000,arXiv,http://arxiv.org/abs/2502.08253v1,Statistical Machine Learning
503,Inference-time sparse attention with asymmetric indexing,"Self-attention in transformer models is an incremental associative memory
that maps key vectors to value vectors. One way to speed up self-attention is
to employ GPU-compliant vector search algorithms, yet the standard partitioning
methods yield poor results in this context, because (1) keys and queries follow
different distributions and (2) the effect of RoPE positional encoding.
  In this paper, we introduce SAAP (Self-Attention with Asymmetric Partitions),
which overcomes these problems. It is an asymmetrical indexing technique that
employs distinct partitions for keys and queries, thereby approximating
self-attention with a data-adaptive sparsity pattern.
  It works on pretrained language models without finetuning, as it only
requires to train (offline) a small query classifier. On a long context Llama
3.1-8b model, with sequences ranging from 100k to 500k tokens, our method
typically reduces by a factor 20 the fraction of memory that needs to be
looked-up, which translates to a time saving of 60\% when compared to
FlashAttention-v2.","Pierre-Emmanuel Mazaré, Gergely Szilvasy, Maria Lomeli, Francisco Massa, Naila Murray, Hervé Jégou, Matthijs Douze",2025-02-12 09:39:54.000000,arXiv,http://arxiv.org/abs/2502.08246v1,Natural Language Processing
504,FloVD: Optical Flow Meets Video Diffusion Model for Enhanced Camera-Controlled Video Synthesis,"This paper presents FloVD, a novel optical-flow-based video diffusion model
for camera-controllable video generation. FloVD leverages optical flow maps to
represent motions of the camera and moving objects. This approach offers two
key benefits. Since optical flow can be directly estimated from videos, our
approach allows for the use of arbitrary training videos without ground-truth
camera parameters. Moreover, as background optical flow encodes 3D correlation
across different viewpoints, our method enables detailed camera control by
leveraging the background motion. To synthesize natural object motion while
supporting detailed camera control, our framework adopts a two-stage video
synthesis pipeline consisting of optical flow generation and flow-conditioned
video synthesis. Extensive experiments demonstrate the superiority of our
method over previous approaches in terms of accurate camera control and natural
object motion synthesis.","Wonjoon Jin, Qi Dai, Chong Luo, Seung-Hwan Baek, Sunghyun Cho",2025-02-12 09:38:41.000000,arXiv,http://arxiv.org/abs/2502.08244v1,Computer Vision
505,The Danger of Overthinking: Examining the Reasoning-Action Dilemma in Agentic Tasks,"Large Reasoning Models (LRMs) represent a breakthrough in AI problem-solving
capabilities, but their effectiveness in interactive environments can be
limited. This paper introduces and analyzes overthinking in LRMs. A phenomenon
where models favor extended internal reasoning chains over environmental
interaction. Through experiments on software engineering tasks using SWE Bench
Verified, we observe three recurring patterns: Analysis Paralysis, Rogue
Actions, and Premature Disengagement. We propose a framework to study these
behaviors, which correlates with human expert assessments, and analyze 4018
trajectories. We observe that higher overthinking scores correlate with
decreased performance, with reasoning models exhibiting stronger tendencies
toward overthinking compared to non-reasoning models. Our analysis reveals that
simple efforts to mitigate overthinking in agentic environments, such as
selecting the solution with the lower overthinking score, can improve model
performance by almost 30% while reducing computational costs by 43%. These
results suggest that mitigating overthinking has strong practical implications.
We suggest that by leveraging native function-calling capabilities and
selective reinforcement learning overthinking tendencies could be mitigated. We
also open-source our evaluation framework and dataset to facilitate research in
this direction at https://github.com/AlexCuadron/Overthinking.","Alejandro Cuadron, Dacheng Li, Wenjie Ma, Xingyao Wang, Yichuan Wang, Siyuan Zhuang, Shu Liu, Luis Gaspar Schroeder, Tian Xia, Huanzhi Mao, Nicholas Thumiger, Aditya Desai, Ion Stoica, Ana Klimovic, Graham Neubig, Joseph E. Gonzalez",2025-02-12 09:23:26.000000,arXiv,http://arxiv.org/abs/2502.08235v1,Artificial Intelligence
506,Learning Human Skill Generators at Key-Step Levels,"We are committed to learning human skill generators at key-step levels. The
generation of skills is a challenging endeavor, but its successful
implementation could greatly facilitate human skill learning and provide more
experience for embodied intelligence. Although current video generation models
can synthesis simple and atomic human operations, they struggle with human
skills due to their complex procedure process. Human skills involve multi-step,
long-duration actions and complex scene transitions, so the existing naive
auto-regressive methods for synthesizing long videos cannot generate human
skills. To address this, we propose a novel task, the Key-step Skill Generation
(KS-Gen), aimed at reducing the complexity of generating human skill videos.
Given the initial state and a skill description, the task is to generate video
clips of key steps to complete the skill, rather than a full-length video. To
support this task, we introduce a carefully curated dataset and define multiple
evaluation metrics to assess performance. Considering the complexity of KS-Gen,
we propose a new framework for this task. First, a multimodal large language
model (MLLM) generates descriptions for key steps using retrieval argument.
Subsequently, we use a Key-step Image Generator (KIG) to address the
discontinuity between key steps in skill videos. Finally, a video generation
model uses these descriptions and key-step images to generate video clips of
the key steps with high temporal consistency. We offer a detailed analysis of
the results, hoping to provide more insights on human skill generation. All
models and data are available at https://github.com/MCG-NJU/KS-Gen.","Yilu Wu, Chenhui Zhu, Shuai Wang, Hanlin Wang, Jing Wang, Zhaoxiang Zhang, Limin Wang",2025-02-12 09:21:40.000000,arXiv,http://arxiv.org/abs/2502.08234v1,Computer Vision
507,Plantation Monitoring Using Drone Images: A Dataset and Performance Review,"Automatic monitoring of tree plantations plays a crucial role in agriculture.
Flawless monitoring of tree health helps farmers make informed decisions
regarding their management by taking appropriate action. Use of drone images
for automatic plantation monitoring can enhance the accuracy of the monitoring
process, while still being affordable to small farmers in developing countries
such as India. Small, low cost drones equipped with an RGB camera can capture
high-resolution images of agricultural fields, allowing for detailed analysis
of the well-being of the plantations. Existing methods of automated plantation
monitoring are mostly based on satellite images, which are difficult to get for
the farmers. We propose an automated system for plantation health monitoring
using drone images, which are becoming easier to get for the farmers. We
propose a dataset of images of trees with three categories: ``Good health"",
``Stunted"", and ``Dead"". We annotate the dataset using CVAT annotation tool,
for use in research purposes. We experiment with different well-known CNN
models to observe their performance on the proposed dataset. The initial low
accuracy levels show the complexity of the proposed dataset. Further, our study
revealed that, depth-wise convolution operation embedded in a deep CNN model,
can enhance the performance of the model on drone dataset. Further, we apply
state-of-the-art object detection models to identify individual trees to better
monitor them automatically.","Yashwanth Karumanchi, Gudala Laxmi Prasanna, Snehasis Mukherjee, Nagesh Kolagani",2025-02-12 09:21:16.000000,arXiv,http://arxiv.org/abs/2502.08233v1,Computer Vision
508,Keep your distance: learning dispersed embeddings on $\mathbb{S}_d$,"Learning well-separated features in high-dimensional spaces, such as text or
image embeddings, is crucial for many machine learning applications. Achieving
such separation can be effectively accomplished through the dispersion of
embeddings, where unrelated vectors are pushed apart as much as possible. By
constraining features to be on a hypersphere, we can connect dispersion to
well-studied problems in mathematics and physics, where optimal solutions are
known for limited low-dimensional cases. However, in representation learning we
typically deal with a large number of features in high-dimensional space, and
moreover, dispersion is usually traded off with some other task-oriented
training objective, making existing theoretical and numerical solutions
inapplicable. Therefore, it is common to rely on gradient-based methods to
encourage dispersion, usually by minimizing some function of the pairwise
distances. In this work, we first give an overview of existing methods from
disconnected literature, making new connections and highlighting similarities.
Next, we introduce some new angles. We propose to reinterpret pairwise
dispersion using a maximum mean discrepancy (MMD) motivation. We then propose
an online variant of the celebrated Lloyd's algorithm, of K-Means fame, as an
effective alternative regularizer for dispersion on generic domains. Finally,
we derive a novel dispersion method that directly exploits properties of the
hypersphere. Our experiments show the importance of dispersion in image
classification and natural language processing tasks, and how algorithms
exhibit different trade-offs in different regimes.","Evgeniia Tokarchuk, Hua Chang Bakker, Vlad Niculae",2025-02-12 09:20:08.000000,arXiv,http://arxiv.org/abs/2502.08231v1,Machine Learning
509,Enhancing Sample Selection by Cutting Mislabeled Easy Examples,"Sample selection is a prevalent approach in learning with noisy labels,
aiming to identify confident samples for training. Although existing sample
selection methods have achieved decent results by reducing the noise rate of
the selected subset, they often overlook that not all mislabeled examples harm
the model's performance equally. In this paper, we demonstrate that mislabeled
examples correctly predicted by the model early in the training process are
particularly harmful to model performance. We refer to these examples as
Mislabeled Easy Examples (MEEs). To address this, we propose Early Cutting,
which introduces a recalibration step that employs the model's later training
state to re-select the confident subset identified early in training, thereby
avoiding misleading confidence from early learning and effectively filtering
out MEEs. Experiments on the CIFAR, WebVision, and full ImageNet-1k datasets
demonstrate that our method effectively improves sample selection and model
performance by reducing MEEs.","Suqin Yuan, Lei Feng, Bo Han, Tongliang Liu",2025-02-12 09:12:45.000000,arXiv,http://arxiv.org/abs/2502.08227v1,Machine Learning
510,TRISHUL: Towards Region Identification and Screen Hierarchy Understanding for Large VLM based GUI Agents,"Recent advancements in Large Vision Language Models (LVLMs) have enabled the
development of LVLM-based Graphical User Interface (GUI) agents under various
paradigms. Training-based approaches, such as CogAgent and SeeClick, struggle
with cross-dataset and cross-platform generalization due to their reliance on
dataset-specific training. Generalist LVLMs, such as GPT-4V, employ
Set-of-Marks (SoM) for action grounding, but obtaining SoM labels requires
metadata like HTML source, which is not consistently available across
platforms. Moreover, existing methods often specialize in singular GUI tasks
rather than achieving comprehensive GUI understanding. To address these
limitations, we introduce TRISHUL, a novel, training-free agentic framework
that enhances generalist LVLMs for holistic GUI comprehension. Unlike prior
works that focus on either action grounding (mapping instructions to GUI
elements) or GUI referring (describing GUI elements given a location), TRISHUL
seamlessly integrates both. At its core, TRISHUL employs Hierarchical Screen
Parsing (HSP) and the Spatially Enhanced Element Description (SEED) module,
which work synergistically to provide multi-granular, spatially, and
semantically enriched representations of GUI elements. Our results demonstrate
TRISHUL's superior performance in action grounding across the ScreenSpot,
VisualWebBench, AITW, and Mind2Web datasets. Additionally, for GUI referring,
TRISHUL surpasses the ToL agent on the ScreenPR benchmark, setting a new
standard for robust and adaptable GUI comprehension.","Kunal Singh, Shreyas Singh, Mukund Khanna",2025-02-12 09:12:30.000000,arXiv,http://arxiv.org/abs/2502.08226v1,Computer Vision
511,Take What You Need: Flexible Multi-Task Semantic Communications with Channel Adaptation,"The growing demand for efficient semantic communication systems capable of
managing diverse tasks and adapting to fluctuating channel conditions has
driven the development of robust, resource-efficient frameworks. This article
introduces a novel channel-adaptive and multi-task-aware semantic communication
framework based on a masked auto-encoder architecture. Our framework optimizes
the transmission of meaningful information by incorporating a multi-task-aware
scoring mechanism that identifies and prioritizes semantically significant data
across multiple concurrent tasks. A channel-aware extractor is employed to
dynamically select relevant information in response to real-time channel
conditions. By jointly optimizing semantic relevance and transmission
efficiency, the framework ensures minimal performance degradation under
resource constraints. Experimental results demonstrate the superior performance
of our framework compared to conventional methods in tasks such as image
reconstruction and object detection. These results underscore the framework's
adaptability to heterogeneous channel environments and its scalability for
multi-task applications, positioning it as a promising solution for
next-generation semantic communication networks.","Xiang Chen, Shuying Gan, Chenyuan Feng, Xijun Wang, Tony Q. S. Quek",2025-02-12 09:01:25.000000,arXiv,http://arxiv.org/abs/2502.08221v1,Computer Vision
512,Deep Learning-Driven Malware Classification with API Call Sequence Analysis and Concept Drift Handling,"Malware classification in dynamic environments presents a significant
challenge due to concept drift, where the statistical properties of malware
data evolve over time, complicating detection efforts. To address this issue,
we propose a deep learning framework enhanced with a genetic algorithm to
improve malware classification accuracy and adaptability. Our approach
incorporates mutation operations and fitness score evaluations within genetic
algorithms to continuously refine the deep learning model, ensuring robustness
against evolving malware threats. Experimental results demonstrate that this
hybrid method significantly enhances classification performance and
adaptability, outperforming traditional static models. Our proposed approach
offers a promising solution for real-time malware classification in
ever-changing cybersecurity landscapes.","Bishwajit Prasad Gond, Durga Prasad Mohapatra",2025-02-12 08:56:35.000000,arXiv,http://arxiv.org/abs/2502.08679v1,Machine Learning
513,Deepfake Detection with Spatio-Temporal Consistency and Attention,"Deepfake videos are causing growing concerns among communities due to their
ever-increasing realism. Naturally, automated detection of forged Deepfake
videos is attracting a proportional amount of interest of researchers. Current
methods for detecting forged videos mainly rely on global frame features and
under-utilize the spatio-temporal inconsistencies found in the manipulated
videos. Moreover, they fail to attend to manipulation-specific subtle and
well-localized pattern variations along both spatial and temporal dimensions.
Addressing these gaps, we propose a neural Deepfake detector that focuses on
the localized manipulative signatures of the forged videos at individual frame
level as well as frame sequence level. Using a ResNet backbone, it strengthens
the shallow frame-level feature learning with a spatial attention mechanism.
The spatial stream of the model is further helped by fusing texture enhanced
shallow features with the deeper features. Simultaneously, the model processes
frame sequences with a distance attention mechanism that further allows fusion
of temporal attention maps with the learned features at the deeper layers. The
overall model is trained to detect forged content as a classifier. We evaluate
our method on two popular large data sets and achieve significant performance
over the state-of-the-art methods.Moreover, our technique also provides memory
and computational advantages over the competitive techniques.","Yunzhuo Chen, Naveed Akhtar, Nur Al Hasan Haldar, Ajmal Mian",2025-02-12 08:51:33.000000,arXiv,http://arxiv.org/abs/2502.08216v1,Computer Vision
514,LLM Modules: Knowledge Transfer from a Large to a Small Model using Enhanced Cross-Attention,"In this work, we propose an architecture of LLM Modules that enables the
transfer of knowledge from a large pre-trained model to a smaller model using
an Enhanced Cross-Attention mechanism. In the proposed scheme, the Qwen2-1.5B
model is frozen and its representations are passed through specially designed
attention layers to the GPT-Neo-125M model, which is trained on limited
computational resources. Experimental results on the Bespoke-Stratos-17k
dataset demonstrate that after 15 epochs of training, the combined model
generates responses comparable in quality to those obtained by distillation. We
discuss the advantages of the modular approach, provide examples of input
queries and comparative analysis, and outline prospects for further extension
of the method.",Konstantin Kolomeitsev,2025-02-12 08:48:55.000000,arXiv,http://arxiv.org/abs/2502.08213v1,Natural Language Processing
515,Quality over Quantity: Boosting Data Efficiency Through Ensembled Multimodal Data Curation,"In an era overwhelmed by vast amounts of data, the effective curation of
web-crawl datasets is essential for optimizing model performance. This paper
tackles the challenges associated with the unstructured and heterogeneous
nature of such datasets. Traditional heuristic curation methods often
inadequately capture complex features, resulting in biases and the exclusion of
relevant data. We introduce an advanced, learning-driven approach, Ensemble
Curation Of DAta ThroUgh Multimodal Operators (EcoDatum), incorporating a novel
quality-guided deduplication method to ensure balanced feature distributions.
EcoDatum strategically integrates various unimodal and multimodal data curation
operators within a weak supervision ensemble framework, utilizing automated
optimization to score each data point effectively. EcoDatum, which
significantly improves the data curation quality and efficiency, outperforms
existing state-of-the-art (SOTA) techniques, ranked 1st on the DataComp
leaderboard, with an average performance score of 0.182 across 38 diverse
evaluation datasets. This represents a 28% improvement over the DataComp
baseline method, demonstrating its effectiveness in improving dataset curation
and model training efficiency.","Jinda Xu, Yuhao Song, Daming Wang, Weiwei Zhao, Minghua Chen, Kangliang Chen, Qinya Li",2025-02-12 08:40:57.000000,arXiv,http://arxiv.org/abs/2502.08211v1,Machine Learning
516,Equivariant Masked Position Prediction for Efficient Molecular Representation,"Graph neural networks (GNNs) have shown considerable promise in computational
chemistry. However, the limited availability of molecular data raises concerns
regarding GNNs' ability to effectively capture the fundamental principles of
physics and chemistry, which constrains their generalization capabilities. To
address this challenge, we introduce a novel self-supervised approach termed
Equivariant Masked Position Prediction (EMPP), grounded in intramolecular
potential and force theory. Unlike conventional attribute masking techniques,
EMPP formulates a nuanced position prediction task that is more well-defined
and enhances the learning of quantum mechanical features. EMPP also bypasses
the approximation of the Gaussian mixture distribution commonly used in
denoising methods, allowing for more accurate acquisition of physical
properties. Experimental results indicate that EMPP significantly enhances
performance of advanced molecular architectures, surpassing state-of-the-art
self-supervised approaches. Our code is released in
https://github.com/ajy112/EMPP.","Junyi An, Chao Qu, Yun-Fei Shi, XinHao Liu, Qianwei Tang, Fenglei Cao, Yuan Qi",2025-02-12 08:39:26.000000,arXiv,http://arxiv.org/abs/2502.08209v1,Machine Learning
517,Exploring Exploration in Bayesian Optimization,"A well-balanced exploration-exploitation trade-off is crucial for successful
acquisition functions in Bayesian optimization. However, there is a lack of
quantitative measures for exploration, making it difficult to analyze and
compare different acquisition functions. This work introduces two novel
approaches - observation traveling salesman distance and observation entropy -
to quantify the exploration characteristics of acquisition functions based on
their selected observations. Using these measures, we examine the explorative
nature of several well-known acquisition functions across a diverse set of
black-box problems, uncover links between exploration and empirical
performance, and reveal new relationships among existing acquisition functions.
Beyond enabling a deeper understanding of acquisition functions, these measures
also provide a foundation for guiding their design in a more principled and
systematic manner.","Leonard Papenmeier, Nuojin Cheng, Stephen Becker, Luigi Nardi",2025-02-12 08:38:37.000000,arXiv,http://arxiv.org/abs/2502.08208v1,Machine Learning
518,Optimizing Asynchronous Federated Learning: A Delicate Trade-Off Between Model-Parameter Staleness and Update Frequency,"Synchronous federated learning (FL) scales poorly with the number of clients
due to the straggler effect. Algorithms like FedAsync and GeneralizedFedAsync
address this limitation by enabling asynchronous communication between clients
and the central server. In this work, we rely on stochastic modeling to better
understand the impact of design choices in asynchronous FL algorithms, such as
the concurrency level and routing probabilities, and we leverage this knowledge
to optimize loss. We characterize in particular a fundamental trade-off for
optimizing asynchronous FL: minimizing gradient estimation errors by avoiding
model parameter staleness, while also speeding up the system by increasing the
throughput of model updates. Our two main contributions can be summarized as
follows. First, we prove a discrete variant of Little's law to derive a
closed-form expression for relative delay, a metric that quantifies staleness.
This allows us to efficiently minimize the average loss per model update, which
has been the gold standard in literature to date. Second, we observe that
naively optimizing this metric leads us to slow down the system drastically by
overemphazing staleness at the detriment of throughput. This motivates us to
introduce an alternative metric that also takes system speed into account, for
which we derive a tractable upper-bound that can be minimized numerically.
Extensive numerical results show that these optimizations enhance accuracy by
10% to 30%.","Abdelkrim Alahyane, Céline Comte, Matthieu Jonckheere, Éric Moulines",2025-02-12 08:38:13.000000,arXiv,http://arxiv.org/abs/2502.08206v1,Machine Learning
519,Wisdom of the Crowds in Forecasting: Forecast Summarization for Supporting Future Event Prediction,"Future Event Prediction (FEP) is an essential activity whose demand and
application range across multiple domains. While traditional methods like
simulations, predictive and time-series forecasting have demonstrated promising
outcomes, their application in forecasting complex events is not entirely
reliable due to the inability of numerical data to accurately capture the
semantic information related to events. One forecasting way is to gather and
aggregate collective opinions on the future to make predictions as cumulative
perspectives carry the potential to help estimating the likelihood of upcoming
events. In this work, we organize the existing research and frameworks that aim
to support future event prediction based on crowd wisdom through aggregating
individual forecasts. We discuss the challenges involved, available datasets,
as well as the scope of improvement and future research directions for this
task. We also introduce a novel data model to represent individual forecast
statements.","Anisha Saha, Adam Jatowt",2025-02-12 08:35:10.000000,arXiv,http://arxiv.org/abs/2502.08205v1,Machine Learning
520,Privacy amplification by random allocation,"We consider the privacy guarantees of an algorithm in which a user's data is
used in $k$ steps randomly and uniformly chosen from a sequence (or set) of $t$
differentially private steps. We demonstrate that the privacy guarantees of
this sampling scheme can be upper bound by the privacy guarantees of the
well-studied independent (or Poisson) subsampling in which each step uses the
user's data with probability $(1+ o(1))k/t $. Further, we provide two
additional analysis techniques that lead to numerical improvements in some
parameter regimes. The case of $k=1$ has been previously studied in the context
of DP-SGD in Balle et al. (2020) and very recently in Chua et al. (2024).
Privacy analysis of Balle et al. (2020) relies on privacy amplification by
shuffling which leads to overly conservative bounds. Privacy analysis of Chua
et al. (2024a) relies on Monte Carlo simulations that are computationally
prohibitive in many practical scenarios and have additional inherent
limitations.","Vitaly Feldman, Moshe Shenfeld",2025-02-12 08:32:10.000000,arXiv,http://arxiv.org/abs/2502.08202v1,Machine Learning
521,ActiveSSF: An Active-Learning-Guided Self-Supervised Framework for Long-Tailed Megakaryocyte Classification,"Precise classification of megakaryocytes is crucial for diagnosing
myelodysplastic syndromes. Although self-supervised learning has shown promise
in medical image analysis, its application to classifying megakaryocytes in
stained slides faces three main challenges: (1) pervasive background noise that
obscures cellular details, (2) a long-tailed distribution that limits data for
rare subtypes, and (3) complex morphological variations leading to high
intra-class variability. To address these issues, we propose the ActiveSSF
framework, which integrates active learning with self-supervised pretraining.
Specifically, our approach employs Gaussian filtering combined with K-means
clustering and HSV analysis (augmented by clinical prior knowledge) for
accurate region-of-interest extraction; an adaptive sample selection mechanism
that dynamically adjusts similarity thresholds to mitigate class imbalance; and
prototype clustering on labeled samples to overcome morphological complexity.
Experimental results on clinical megakaryocyte datasets demonstrate that
ActiveSSF not only achieves state-of-the-art performance but also significantly
improves recognition accuracy for rare subtypes. Moreover, the integration of
these advanced techniques further underscores the practical potential of
ActiveSSF in clinical settings. To foster further research, the code and
datasets will be publicly released in the future.","Linghao Zhuang, Ying Zhang, Gege Yuan, Xingyue Zhao, Zhiping Jiang",2025-02-12 08:24:36.000000,arXiv,http://arxiv.org/abs/2502.08200v1,Computer Vision
522,AnyCharV: Bootstrap Controllable Character Video Generation with Fine-to-Coarse Guidance,"Character video generation is a significant real-world application focused on
producing high-quality videos featuring specific characters. Recent
advancements have introduced various control signals to animate static
characters, successfully enhancing control over the generation process.
However, these methods often lack flexibility, limiting their applicability and
making it challenging for users to synthesize a source character into a desired
target scene. To address this issue, we propose a novel framework, AnyCharV,
that flexibly generates character videos using arbitrary source characters and
target scenes, guided by pose information. Our approach involves a two-stage
training process. In the first stage, we develop a base model capable of
integrating the source character with the target scene using pose guidance. The
second stage further bootstraps controllable generation through a self-boosting
mechanism, where we use the generated video in the first stage and replace the
fine mask with the coarse one, enabling training outcomes with better
preservation of character details. Experimental results demonstrate the
effectiveness and robustness of our proposed method. Our project page is
https://anycharv.github.io.","Zhao Wang, Hao Wen, Lingting Zhu, Chenming Shang, Yujiu Yang, Qi Dou",2025-02-12 07:59:41.000000,arXiv,http://arxiv.org/abs/2502.08189v1,Computer Vision
523,Latest Advancements Towards Catastrophic Forgetting under Data Scarcity: A Comprehensive Survey on Few-Shot Class Incremental Learning,"Data scarcity significantly complicates the continual learning problem, i.e.,
how a deep neural network learns in dynamic environments with very few samples.
However, the latest progress of few-shot class incremental learning (FSCIL)
methods and related studies show insightful knowledge on how to tackle the
problem. This paper presents a comprehensive survey on FSCIL that highlights
several important aspects i.e. comprehensive and formal objectives of FSCIL
approaches, the importance of prototype rectifications, the new learning
paradigms based on pre-trained model and language-guided mechanism, the deeper
analysis of FSCIL performance metrics and evaluation, and the practical
contexts of FSCIL in various areas. Our extensive discussion presents the open
challenges, potential solutions, and future directions of FSCIL.","M. Anwar Ma'sum, Mahardhika Pratama, Igor Skrjanc",2025-02-12 07:39:44.000000,arXiv,http://arxiv.org/abs/2502.08181v1,Machine Learning
524,Enhancing LLM Character-Level Manipulation via Divide and Conquer,"Large Language Models (LLMs) have demonstrated strong generalization
capabilities across a wide range of natural language processing (NLP) tasks.
However, they exhibit notable weaknesses in character-level string
manipulation, struggling with fundamental operations such as character
deletion, insertion, and substitution. These challenges stem primarily from
tokenization constraints, despite the critical role of such operations in data
preprocessing and code generation. Through systematic analysis, we derive two
key insights: (1) LLMs face significant difficulties in leveraging intrinsic
token knowledge for character-level reasoning, and (2) atomized word structures
can substantially enhance LLMs' ability to process token-level structural
information. Building on these insights, we propose Character-Level
Manipulation via Divide and Conquer, a novel approach designed to bridge the
gap between token-level processing and character-level manipulation. Our method
decomposes complex operations into explicit character-level subtasks coupled
with controlled token reconstruction phases, leading to significant
improvements in accuracy. Without additional training, our method significantly
improves accuracies on the $\texttt{Deletion}$, $\texttt{Insertion}$, and
$\texttt{Substitution}$ tasks. To support further research, we open-source our
implementation and benchmarks.","Zhen Xiong, Yujun Cai, Bryan Hooi, Nanyun Peng, Kai-Wei Chang, Zhecheng Li, Yiwei Wang",2025-02-12 07:37:39.000000,arXiv,http://arxiv.org/abs/2502.08180v1,Natural Language Processing
525,ParetoRAG: Leveraging Sentence-Context Attention for Robust and Efficient Retrieval-Augmented Generation,"While Retrieval-Augmented Generation (RAG) systems enhance Large Language
Models (LLMs) by incorporating external knowledge, they still face persistent
challenges in retrieval inefficiency and the inability of LLMs to filter out
irrelevant information. We present ParetoRAG, an unsupervised framework that
optimizes RAG systems through sentence-level refinement guided by the Pareto
principle. By decomposing paragraphs into sentences and dynamically
re-weighting core content while preserving contextual coherence, ParetoRAG
achieves dual improvements in both retrieval precision and generation quality
without requiring additional training or API resources. This framework has been
empirically validated across various datasets, LLMs, and retrievers.","Ruobing Yao, Yifei Zhang, Shuang Song, Yuhua Liu, Neng Gao, Chenyang Tu",2025-02-12 07:32:48.000000,arXiv,http://arxiv.org/abs/2502.08178v1,Natural Language Processing
526,SycEval: Evaluating LLM Sycophancy,"Large language models (LLMs) are increasingly applied in educational,
clinical, and professional settings, but their tendency for sycophancy --
prioritizing user agreement over independent reasoning -- poses risks to
reliability. This study introduces a framework to evaluate sycophantic behavior
in ChatGPT-4o, Claude-Sonnet, and Gemini-1.5-Pro across AMPS (mathematics) and
MedQuad (medical advice) datasets. Sycophantic behavior was observed in 58.19%
of cases, with Gemini exhibiting the highest rate (62.47%) and ChatGPT the
lowest (56.71%). Progressive sycophancy, leading to correct answers, occurred
in 43.52% of cases, while regressive sycophancy, leading to incorrect answers,
was observed in 14.66%. Preemptive rebuttals demonstrated significantly higher
sycophancy rates than in-context rebuttals (61.75% vs. 56.52%, $Z=5.87$,
$p<0.001$), particularly in computational tasks, where regressive sycophancy
increased significantly (preemptive: 8.13%, in-context: 3.54%, $p<0.001$).
Simple rebuttals maximized progressive sycophancy ($Z=6.59$, $p<0.001$), while
citation-based rebuttals exhibited the highest regressive rates ($Z=6.59$,
$p<0.001$). Sycophantic behavior showed high persistence (78.5%, 95% CI:
[77.2%, 79.8%]) regardless of context or model. These findings emphasize the
risks and opportunities of deploying LLMs in structured and dynamic domains,
offering insights into prompt programming and model optimization for safer AI
applications.","Aaron Fanous, Jacob Goldberg, Ank A. Agarwal, Joanna Lin, Anson Zhou, Roxana Daneshjou, Sanmi Koyejo",2025-02-12 07:32:42.000000,arXiv,http://arxiv.org/abs/2502.08177v1,Artificial Intelligence
527,CoDynTrust: Robust Asynchronous Collaborative Perception via Dynamic Feature Trust Modulus,"Collaborative perception, fusing information from multiple agents, can extend
perception range so as to improve perception performance. However, temporal
asynchrony in real-world environments, caused by communication delays, clock
misalignment, or sampling configuration differences, can lead to information
mismatches. If this is not well handled, then the collaborative performance is
patchy, and what's worse safety accidents may occur. To tackle this challenge,
we propose CoDynTrust, an uncertainty-encoded asynchronous fusion perception
framework that is robust to the information mismatches caused by temporal
asynchrony. CoDynTrust generates dynamic feature trust modulus (DFTM) for each
region of interest by modeling aleatoric and epistemic uncertainty as well as
selectively suppressing or retaining single-vehicle features, thereby
mitigating information mismatches. We then design a multi-scale fusion module
to handle multi-scale feature maps processed by DFTM. Compared to existing
works that also consider asynchronous collaborative perception, CoDynTrust
combats various low-quality information in temporally asynchronous scenarios
and allows uncertainty to be propagated to downstream tasks such as planning
and control. Experimental results demonstrate that CoDynTrust significantly
reduces performance degradation caused by temporal asynchrony across multiple
datasets, achieving state-of-the-art detection performance even with temporal
asynchrony. The code is available at https://github.com/CrazyShout/CoDynTrust.","Yunjiang Xu, Lingzhi Li, Jin Wang, Benyuan Yang, Zhiwen Wu, Xinhong Chen, Jianping Wang",2025-02-12 07:23:26.000000,arXiv,http://arxiv.org/abs/2502.08169v1,Computer Vision
528,SARChat-Bench-2M: A Multi-Task Vision-Language Benchmark for SAR Image Interpretation,"As a powerful all-weather Earth observation tool, synthetic aperture radar
(SAR) remote sensing enables critical military reconnaissance, maritime
surveillance, and infrastructure monitoring. Although Vision language models
(VLMs) have made remarkable progress in natural language processing and image
understanding, their applications remain limited in professional domains due to
insufficient domain expertise. This paper innovatively proposes the first
large-scale multimodal dialogue dataset for SAR images, named SARChat-2M, which
contains approximately 2 million high-quality image-text pairs, encompasses
diverse scenarios with detailed target annotations. This dataset not only
supports several key tasks such as visual understanding and object detection
tasks, but also has unique innovative aspects: this study develop a
visual-language dataset and benchmark for the SAR domain, enabling and
evaluating VLMs' capabilities in SAR image interpretation, which provides a
paradigmatic framework for constructing multimodal datasets across various
remote sensing vertical domains. Through experiments on 16 mainstream VLMs, the
effectiveness of the dataset has been fully verified. The project will be
released at https://github.com/JimmyMa99/SARChat.","Zhiming Ma, Xiayang Xiao, Sihao Dong, Peidong Wang, HaiPeng Wang, Qingyun Pan",2025-02-12 07:19:36.000000,arXiv,http://arxiv.org/abs/2502.08168v2,Natural Language Processing
529,"DNNs May Determine Major Properties of Their Outputs Early, with Timing Possibly Driven by Bias","This paper argues that deep neural networks (DNNs) mostly determine their
outputs during the early stages of inference, where biases inherent in the
model play a crucial role in shaping this process. We draw a parallel between
this phenomenon and human decision-making, which often relies on fast,
intuitive heuristics. Using diffusion models (DMs) as a case study, we
demonstrate that DNNs often make early-stage decision-making influenced by the
type and extent of bias in their design and training. Our findings offer a new
perspective on bias mitigation, efficient inference, and the interpretation of
machine learning systems. By identifying the temporal dynamics of
decision-making in DNNs, this paper aims to inspire further discussion and
research within the machine learning community.","Song Park, Sanghyuk Chun, Byeongho Heo, Dongyoon Han",2025-02-12 07:14:54.000000,arXiv,http://arxiv.org/abs/2502.08167v1,Machine Learning
530,From Individual Experience to Collective Evidence: A Reporting-Based Framework for Identifying Systemic Harms,"When an individual reports a negative interaction with some system, how can
their personal experience be contextualized within broader patterns of system
behavior? We study the incident database problem, where individual reports of
adverse events arrive sequentially, and are aggregated over time. In this work,
our goal is to identify whether there are subgroups--defined by any combination
of relevant features--that are disproportionately likely to experience harmful
interactions with the system. We formalize this problem as a sequential
hypothesis test, and identify conditions on reporting behavior that are
sufficient for making inferences about disparities in true rates of harm across
subgroups. We show that algorithms for sequential hypothesis tests can be
applied to this problem with a standard multiple testing correction. We then
demonstrate our method on real-world datasets, including mortgage decisions and
vaccine side effects; on each, our method (re-)identifies subgroups known to
experience disproportionate harm using only a fraction of the data that was
initially used to discover them.","Jessica Dai, Paula Gradu, Inioluwa Deborah Raji, Benjamin Recht",2025-02-12 07:11:33.000000,arXiv,http://arxiv.org/abs/2502.08166v1,Other
531,MixDec Sampling: A Soft Link-based Sampling Method of Graph Neural Network for Recommendation,"Graph neural networks have been widely used in recent recommender systems,
where negative sampling plays an important role. Existing negative sampling
methods restrict the relationship between nodes as either hard positive pairs
or hard negative pairs. This leads to the loss of structural information, and
lacks the mechanism to generate positive pairs for nodes with few neighbors. To
overcome limitations, we propose a novel soft link-based sampling method,
namely MixDec Sampling, which consists of Mixup Sampling module and Decay
Sampling module. The Mixup Sampling augments node features by synthesizing new
nodes and soft links, which provides sufficient number of samples for nodes
with few neighbors. The Decay Sampling strengthens the digestion of graph
structure information by generating soft links for node embedding learning. To
the best of our knowledge, we are the first to model sampling relationships
between nodes by soft links in GNN-based recommender systems. Extensive
experiments demonstrate that the proposed MixDec Sampling can significantly and
consistently improve the recommendation performance of several representative
GNN-based models on various recommendation benchmarks.","Xiangjin Xie, Yuxin Chen, Ruipeng Wang, Kai Ouyang, Zihan Zhang, Hai-Tao Zheng, Buyue Qian, Hansen Zheng, Bo Hu, Chengxiang Zhuo, Zang Li",2025-02-12 07:05:59.000000,arXiv,http://arxiv.org/abs/2502.08161v1,Information Retrieval
532,"Vertical Federated Learning in Practice: The Good, the Bad, and the Ugly","Vertical Federated Learning (VFL) is a privacy-preserving collaborative
learning paradigm that enables multiple parties with distinct feature sets to
jointly train machine learning models without sharing their raw data. Despite
its potential to facilitate cross-organizational collaborations, the deployment
of VFL systems in real-world applications remains limited. To investigate the
gap between existing VFL research and practical deployment, this survey
analyzes the real-world data distributions in potential VFL applications and
identifies four key findings that highlight this gap. We propose a novel
data-oriented taxonomy of VFL algorithms based on real VFL data distributions.
Our comprehensive review of existing VFL algorithms reveals that some common
practical VFL scenarios have few or no viable solutions. Based on these
observations, we outline key research directions aimed at bridging the gap
between current VFL research and real-world applications.","Zhaomin Wu, Zhen Qin, Junyi Hou, Haodong Zhao, Qinbin Li, Bingsheng He, Lixin Fan",2025-02-12 07:03:32.000000,arXiv,http://arxiv.org/abs/2502.08160v1,Machine Learning
533,Multispectral Remote Sensing for Weed Detection in West Australian Agricultural Lands,"The Kondinin region in Western Australia faces significant agricultural
challenges due to pervasive weed infestations, causing economic losses and
ecological impacts. This study constructs a tailored multispectral remote
sensing dataset and an end-to-end framework for weed detection to advance
precision agriculture practices. Unmanned aerial vehicles were used to collect
raw multispectral data from two experimental areas (E2 and E8) over four years,
covering 0.6046 km^{2} and ground truth annotations were created with
GPS-enabled vehicles to manually label weeds and crops. The dataset is
specifically designed for agricultural applications in Western Australia. We
propose an end-to-end framework for weed detection that includes extensive
preprocessing steps, such as denoising, radiometric calibration, image
alignment, orthorectification, and stitching. The proposed method combines
vegetation indices (NDVI, GNDVI, EVI, SAVI, MSAVI) with multispectral channels
to form classification features, and employs several deep learning models to
identify weeds based on the input features. Among these models, ResNet achieves
the highest performance, with a weed detection accuracy of 0.9213, an F1-Score
of 0.8735, an mIOU of 0.7888, and an mDC of 0.8865, validating the efficacy of
the dataset and the proposed weed detection method.","Haitian Wang, Muhammad Ibrahim, Yumeng Miao, D ustin Severtson, Atif Mansoor, Ajmal S. Mian",2025-02-12 07:01:42.000000,arXiv,http://arxiv.org/abs/2502.08678v1,Computer Vision
534,Open-Source Factor Graph Optimization Package for GNSS: Examples and Applications,"State estimation methods using factor graph optimization (FGO) have garnered
significant attention in global navigation satellite system (GNSS) research.
FGO exhibits superior estimation accuracy compared with traditional state
estimation methods that rely on least-squares or Kalman filters. However, only
a few FGO libraries are specialized for GNSS observations. This paper
introduces an open-source GNSS FGO package named gtsam\_gnss, which has a
simple structure and can be easily applied to GNSS research and development.
This package separates the preprocessing of GNSS observations from factor
optimization. Moreover, it describes the error function of the GNSS factor in a
straightforward manner, allowing for general-purpose inputs. This design
facilitates the transition from ordinary least-squares-based positioning to FGO
and supports user-specific GNSS research. In addition, gtsam\_gnss includes
analytical examples involving various factors using GNSS data in real urban
environments. This paper presents three application examples: the use of a
robust error model, estimation of integer ambiguity in the carrier phase, and
combination of GNSS and inertial measurements from smartphones. The proposed
framework demonstrates excellent state estimation performance across all use
cases.",Taro Suzuki,2025-02-12 06:51:42.000000,arXiv,http://arxiv.org/abs/2502.08158v1,Robotics
535,DGSense: A Domain Generalization Framework for Wireless Sensing,"Wireless sensing is of great benefits to our daily lives. However, wireless
signals are sensitive to the surroundings. Various factors, e.g. environments,
locations, and individuals, may induce extra impact on wireless propagation.
Such a change can be regarded as a domain, in which the data distribution
shifts. A vast majority of the sensing schemes are learning-based. They are
dependent on the training domains, resulting in performance degradation in
unseen domains. Researchers have proposed various solutions to address this
issue. But these solutions leverage either semi-supervised or unsupervised
domain adaptation techniques. They still require some data in the target
domains and do not perform well in unseen domains. In this paper, we propose a
domain generalization framework DGSense, to eliminate the domain dependence
problem in wireless sensing. The framework is a general solution working across
diverse sensing tasks and wireless technologies. Once the sensing model is
built, it can generalize to unseen domains without any data from the target
domain. To achieve the goal, we first increase the diversity of the training
set by a virtual data generator, and then extract the domain independent
features via episodic training between the main feature extractor and the
domain feature extractors. The feature extractors employ a pre-trained Residual
Network (ResNet) with an attention mechanism for spatial features, and a 1D
Convolutional Neural Network (1DCNN) for temporal features. To demonstrate the
effectiveness and generality of DGSense, we evaluated on WiFi gesture
recognition, Millimeter Wave (mmWave) activity recognition, and acoustic fall
detection. All the systems exhibited high generalization capability to unseen
domains, including new users, locations, and environments, free of new data and
retraining.","Rui Zhou, Yu Cheng, Songlin Li, Hongwang Zhang, Chenxu Liu",2025-02-12 06:47:25.000000,arXiv,http://arxiv.org/abs/2502.08155v1,Machine Learning
536,Local Differential Privacy is Not Enough: A Sample Reconstruction Attack against Federated Learning with Local Differential Privacy,"Reconstruction attacks against federated learning (FL) aim to reconstruct
users' samples through users' uploaded gradients. Local differential privacy
(LDP) is regarded as an effective defense against various attacks, including
sample reconstruction in FL, where gradients are clipped and perturbed.
Existing attacks are ineffective in FL with LDP since clipped and perturbed
gradients obliterate most sample information for reconstruction. Besides,
existing attacks embed additional sample information into gradients to improve
the attack effect and cause gradient expansion, leading to a more severe
gradient clipping in FL with LDP. In this paper, we propose a sample
reconstruction attack against LDP-based FL with any target models to
reconstruct victims' sensitive samples to illustrate that FL with LDP is not
flawless. Considering gradient expansion in reconstruction attacks and noise in
LDP, the core of the proposed attack is gradient compression and reconstructed
sample denoising. For gradient compression, an inference structure based on
sample characteristics is presented to reduce redundant gradients against LDP.
For reconstructed sample denoising, we artificially introduce zero gradients to
observe noise distribution and scale confidence interval to filter the noise.
Theoretical proof guarantees the effectiveness of the proposed attack.
Evaluations show that the proposed attack is the only attack that reconstructs
victims' training samples in LDP-based FL and has little impact on the target
model's accuracy. We conclude that LDP-based FL needs further improvements to
defend against sample reconstruction attacks effectively.","Zhichao You, Xuewen Dong, Shujun Li, Ximeng Liu, Siqi Ma, Yulong Shen",2025-02-12 06:37:26.000000,arXiv,http://arxiv.org/abs/2502.08151v1,Other
537,Force Matching with Relativistic Constraints: A Physics-Inspired Approach to Stable and Efficient Generative Modeling,"This paper introduces Force Matching (ForM), a novel framework for generative
modeling that represents an initial exploration into leveraging special
relativistic mechanics to enhance the stability of the sampling process. By
incorporating the Lorentz factor, ForM imposes a velocity constraint, ensuring
that sample velocities remain bounded within a constant limit. This constraint
serves as a fundamental mechanism for stabilizing the generative dynamics,
leading to a more robust and controlled sampling process. We provide a rigorous
theoretical analysis demonstrating that the velocity constraint is preserved
throughout the sampling procedure within the ForM framework. To validate the
effectiveness of our approach, we conduct extensive empirical evaluations. On
the \textit{half-moons} dataset, ForM significantly outperforms baseline
methods, achieving the lowest Euclidean distance loss of \textbf{0.714}, in
contrast to vanilla first-order flow matching (5.853) and first- and
second-order flow matching (5.793). Additionally, we perform an ablation study
to further investigate the impact of our velocity constraint, reaffirming the
superiority of ForM in stabilizing the generative process. The theoretical
guarantees and empirical results underscore the potential of integrating
special relativity principles into generative modeling. Our findings suggest
that ForM provides a promising pathway toward achieving stable, efficient, and
flexible generative processes. This work lays the foundation for future
advancements in high-dimensional generative modeling, opening new avenues for
the application of physical principles in machine learning.","Yang Cao, Bo Chen, Xiaoyu Li, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song, Mingda Wan",2025-02-12 06:30:01.000000,arXiv,http://arxiv.org/abs/2502.08150v1,Machine Learning
538,Generalized Class Discovery in Instance Segmentation,"This work addresses the task of generalized class discovery (GCD) in instance
segmentation. The goal is to discover novel classes and obtain a model capable
of segmenting instances of both known and novel categories, given labeled and
unlabeled data. Since the real world contains numerous objects with long-tailed
distributions, the instance distribution for each class is inherently
imbalanced. To address the imbalanced distributions, we propose an
instance-wise temperature assignment (ITA) method for contrastive learning and
class-wise reliability criteria for pseudo-labels. The ITA method relaxes
instance discrimination for samples belonging to head classes to enhance GCD.
The reliability criteria are to avoid excluding most pseudo-labels for tail
classes when training an instance segmentation network using pseudo-labels from
GCD. Additionally, we propose dynamically adjusting the criteria to leverage
diverse samples in the early stages while relying only on reliable
pseudo-labels in the later stages. We also introduce an efficient soft
attention module to encode object-specific representations for GCD. Finally, we
evaluate our proposed method by conducting experiments on two settings:
COCO$_{half}$ + LVIS and LVIS + Visual Genome. The experimental results
demonstrate that the proposed method outperforms previous state-of-the-art
methods.","Cuong Manh Hoang, Yeejin Lee, Byeongkeun Kang",2025-02-12 06:26:05.000000,arXiv,http://arxiv.org/abs/2502.08149v1,Computer Vision
539,ACCESS : A Benchmark for Abstract Causal Event Discovery and Reasoning,"Identifying cause-and-effect relationships is critical to understanding
real-world dynamics and ultimately causal reasoning. Existing methods for
identifying event causality in NLP, including those based on Large Language
Models (LLMs), exhibit difficulties in out-of-distribution settings due to the
limited scale and heavy reliance on lexical cues within available benchmarks.
Modern benchmarks, inspired by probabilistic causal inference, have attempted
to construct causal graphs of events as a robust representation of causal
knowledge, where \texttt{CRAB} \citep{romanou2023crab} is one such recent
benchmark along this line. In this paper, we introduce \texttt{ACCESS}, a
benchmark designed for discovery and reasoning over abstract causal events.
Unlike existing resources, \texttt{ACCESS} focuses on causality of everyday
life events on the abstraction level. We propose a pipeline for identifying
abstractions for event generalizations from \texttt{GLUCOSE}
\citep{mostafazadeh-etal-2020-glucose}, a large-scale dataset of implicit
commonsense causal knowledge, from which we subsequently extract $1,4$K causal
pairs. Our experiments highlight the ongoing challenges of using statistical
methods and/or LLMs for automatic abstraction identification and causal
discovery in NLP. Nonetheless, we demonstrate that the abstract causal
knowledge provided in \texttt{ACCESS} can be leveraged for enhancing QA
reasoning performance in LLMs.","Vy Vo, Lizhen Qu, Tao Feng, Yuncheng Hua, Xiaoxi Kang, Songhai Fan, Tim Dwyer, Lay-Ki Soon, Gholamreza Haffari",2025-02-12 06:19:02.000000,arXiv,http://arxiv.org/abs/2502.08148v1,Artificial Intelligence
540,Knowledge-Guided Wasserstein Distributionally Robust Optimization,"Transfer learning is a popular strategy to leverage external knowledge and
improve statistical efficiency, particularly with a limited target sample. We
propose a novel knowledge-guided Wasserstein Distributionally Robust
Optimization (KG-WDRO) framework that adaptively incorporates multiple sources
of external knowledge to overcome the conservativeness of vanilla WDRO, which
often results in overly pessimistic shrinkage toward zero. Our method
constructs smaller Wasserstein ambiguity sets by controlling the transportation
along directions informed by the source knowledge. This strategy can alleviate
perturbations on the predictive projection of the covariates and protect
against information loss. Theoretically, we establish the equivalence between
our WDRO formulation and the knowledge-guided shrinkage estimation based on
collinear similarity, ensuring tractability and geometrizing the feasible set.
This also reveals a novel and general interpretation for recent shrinkage-based
transfer learning approaches from the perspective of distributional robustness.
In addition, our framework can adjust for scaling differences in the regression
models between the source and target and accommodates general types of
regularization such as lasso and ridge. Extensive simulations demonstrate the
superior performance and adaptivity of KG-WDRO in enhancing small-sample
transfer learning.","Zitao Wang, Ziyuan Wang, Molei Liu, Nian Si",2025-02-12 06:09:27.000000,arXiv,http://arxiv.org/abs/2502.08146v1,Machine Learning
541,Democratizing AI: Open-source Scalable LLM Training on GPU-based Supercomputers,"Training and fine-tuning large language models (LLMs) with hundreds of
billions to trillions of parameters requires tens of thousands of GPUs, and a
highly scalable software stack. In this work, we present a novel
four-dimensional hybrid parallel algorithm implemented in a highly scalable,
portable, open-source framework called AxoNN. We describe several performance
optimizations in AxoNN to improve matrix multiply kernel performance, overlap
non-blocking collectives with computation, and performance modeling to choose
performance optimal configurations. These have resulted in unprecedented
scaling and peak flop/s (bf16) for training of GPT-style transformer models on
Perlmutter (620.1 Petaflop/s), Frontier (1.381 Exaflop/s) and Alps (1.423
Exaflop/s).
  While the abilities of LLMs improve with the number of trainable parameters,
so do privacy and copyright risks caused by memorization of training data,
which can cause disclosure of sensitive or private information at inference
time. We highlight this side effect of scale through experiments that explore
""catastrophic memorization"", where models are sufficiently large to memorize
training data in a single pass, and present an approach to prevent it. As part
of this study, we demonstrate fine-tuning of a 405-billion parameter LLM using
AxoNN on Frontier.","Siddharth Singh, Prajwal Singhania, Aditya Ranjan, John Kirchenbauer, Jonas Geiping, Yuxin Wen, Neel Jain, Abhimanyu Hans, Manli Shu, Aditya Tomar, Tom Goldstein, Abhinav Bhatele",2025-02-12 06:05:52.000000,arXiv,http://arxiv.org/abs/2502.08145v1,Machine Learning
542,Bridging the Safety Gap: A Guardrail Pipeline for Trustworthy LLM Inferences,"We present Wildflare GuardRail, a guardrail pipeline designed to enhance the
safety and reliability of Large Language Model (LLM) inferences by
systematically addressing risks across the entire processing workflow.
Wildflare GuardRail integrates several core functional modules, including
Safety Detector that identifies unsafe inputs and detects hallucinations in
model outputs while generating root-cause explanations, Grounding that
contextualizes user queries with information retrieved from vector databases,
Customizer that adjusts outputs in real time using lightweight, rule-based
wrappers, and Repairer that corrects erroneous LLM outputs using hallucination
explanations provided by Safety Detector. Results show that our unsafe content
detection model in Safety Detector achieves comparable performance with OpenAI
API, though trained on a small dataset constructed with several public
datasets. Meanwhile, the lightweight wrappers can address malicious URLs in
model outputs in 1.06s per query with 100% accuracy without costly model calls.
Moreover, the hallucination fixing model demonstrates effectiveness in reducing
hallucinations with an accuracy of 80.7%.","Shanshan Han, Salman Avestimehr, Chaoyang He",2025-02-12 05:48:57.000000,arXiv,http://arxiv.org/abs/2502.08142v1,Artificial Intelligence
543,Data-dependent Bounds with $T$-Optimal Best-of-Both-Worlds Guarantees in Multi-Armed Bandits using Stability-Penalty Matching,"Existing data-dependent and best-of-both-worlds regret bounds for multi-armed
bandits problems have limited adaptivity as they are either data-dependent but
not best-of-both-worlds (BOBW), BOBW but not data-dependent or have sub-optimal
$O(\sqrt{T\ln{T}})$ worst-case guarantee in the adversarial regime. To overcome
these limitations, we propose real-time stability-penalty matching (SPM), a new
method for obtaining regret bounds that are simultaneously data-dependent,
best-of-both-worlds and $T$-optimal for multi-armed bandits problems. In
particular, we show that real-time SPM obtains bounds with worst-case
guarantees of order $O(\sqrt{T})$ in the adversarial regime and $O(\ln{T})$ in
the stochastic regime while simultaneously being adaptive to data-dependent
quantities such as sparsity, variations, and small losses. Our results are
obtained by extending the SPM technique for tuning the learning rates in the
follow-the-regularized-leader (FTRL) framework, which further indicates that
the combination of SPM and FTRL is a promising approach for proving new
adaptive bounds in online learning problems.","Quan Nguyen, Shinji Ito, Junpei Komiyama, Nishant A. Mehta",2025-02-12 05:48:57.000000,arXiv,http://arxiv.org/abs/2502.08143v1,Machine Learning
544,LowRA: Accurate and Efficient LoRA Fine-Tuning of LLMs under 2 Bits,"Fine-tuning large language models (LLMs) is increasingly costly as models
scale to hundreds of billions of parameters, and even parameter-efficient
fine-tuning (PEFT) methods like LoRA remain resource-intensive. We introduce
LowRA, the first framework to enable LoRA fine-tuning below 2 bits per
parameter with minimal performance loss. LowRA optimizes fine-grained
quantization - mapping, threshold selection, and precision assignment - while
leveraging efficient CUDA kernels for scalable deployment. Extensive
evaluations across 4 LLMs and 4 datasets show that LowRA achieves a superior
performance-precision trade-off above 2 bits and remains accurate down to 1.15
bits, reducing memory usage by up to 50%. Our results highlight the potential
of ultra-low-bit LoRA fine-tuning for resource-constrained environments.","Zikai Zhou, Qizheng Zhang, Hermann Kumbong, Kunle Olukotun",2025-02-12 05:48:26.000000,arXiv,http://arxiv.org/abs/2502.08141v1,Machine Learning
545,Riemannian Complex Hermit Positive Definite Convolution Network for Polarimetric SAR Image Classification,"Deep learning can learn high-level semantic features in Euclidean space
effectively for PolSAR images, while they need to covert the complex covariance
matrix into a feature vector or complex-valued vector as the network input.
However, the complex covariance matrices are essentially a complex Hermit
positive definite (HPD) matrix endowed in Riemannian manifold rather than
Euclidean space. The matrix's real and imagery parts are with the same
significance, as the imagery part represents the phase information. The matrix
vectorization will destroy the geometric structure and manifold characteristics
of complex covariance matrices. To learn complex HPD matrices directly, we
propose a Riemannian complex HPD convolution network(HPD\_CNN) for PolSAR
images. This method consists of a complex HPD unfolding network(HPDnet) and a
CV-3DCNN enhanced network. The proposed complex HPDnet defines the HPD mapping,
rectifying and the logEig layers to learn geometric features of complex
matrices. In addition, a fast eigenvalue decomposition method is designed to
reduce computation burden. Finally, a Riemannian-to-Euclidean enhanced network
is defined to enhance contextual information for classification. Experimental
results on two real PolSSAR datasets demonstrate the proposed method can
achieve superior performance than the state-of-the-art methods especially in
heterogeneous regions.","Junfei Shi, Mengmeng Nie, Yuke Li, Haiyan Jin, Weisi Lin",2025-02-12 05:41:25.000000,arXiv,http://arxiv.org/abs/2502.08137v1,Computer Vision
546,In-Context Learning of Linear Dynamical Systems with Transformers: Error Bounds and Depth-Separation,"This paper investigates approximation-theoretic aspects of the in-context
learning capability of the transformers in representing a family of noisy
linear dynamical systems. Our first theoretical result establishes an upper
bound on the approximation error of multi-layer transformers with respect to an
$L^2$-testing loss uniformly defined across tasks. This result demonstrates
that transformers with logarithmic depth can achieve error bounds comparable
with those of the least-squares estimator. In contrast, our second result
establishes a non-diminishing lower bound on the approximation error for a
class of single-layer linear transformers, which suggests a depth-separation
phenomenon for transformers in the in-context learning of dynamical systems.
Moreover, this second result uncovers a critical distinction in the
approximation power of single-layer linear transformers when learning from IID
versus non-IID data.","Frank Cole, Yulong Lu, Tianhao Zhang, Yuxuan Zhao",2025-02-12 05:40:11.000000,arXiv,http://arxiv.org/abs/2502.08136v1,Machine Learning
547,A Survey on Data Curation for Visual Contrastive Learning: Why Crafting Effective Positive and Negative Pairs Matters,"Visual contrastive learning aims to learn representations by contrasting
similar (positive) and dissimilar (negative) pairs of data samples. The design
of these pairs significantly impacts representation quality, training
efficiency, and computational cost. A well-curated set of pairs leads to
stronger representations and faster convergence. As contrastive pre-training
sees wider adoption for solving downstream tasks, data curation becomes
essential for optimizing its effectiveness. In this survey, we attempt to
create a taxonomy of existing techniques for positive and negative pair
curation in contrastive learning, and describe them in detail.","Shasvat Desai, Debasmita Ghose, Deep Chakraborty",2025-02-12 05:34:48.000000,arXiv,http://arxiv.org/abs/2502.08134v1,Computer Vision
548,"LIR-LIVO: A Lightweight,Robust LiDAR/Vision/Inertial Odometry with Illumination-Resilient Deep Features","In this paper, we propose LIR-LIVO, a lightweight and robust
LiDAR-inertial-visual odometry system designed for challenging illumination and
degraded environments. The proposed method leverages deep learning-based
illumination-resilient features and LiDAR-Inertial-Visual Odometry (LIVO). By
incorporating advanced techniques such as uniform depth distribution of
features enabled by depth association with LiDAR point clouds and adaptive
feature matching utilizing Superpoint and LightGlue, LIR-LIVO achieves
state-of-the-art (SOTA) accuracy and robustness with low computational cost.
Experiments are conducted on benchmark datasets, including NTU-VIRAL, Hilti'22,
and R3LIVE-Dataset. The corresponding results demonstrate that our proposed
method outperforms other SOTA methods on both standard and challenging
datasets. Particularly, the proposed method demonstrates robust pose estimation
under poor ambient lighting conditions in the Hilti'22 dataset. The code of
this work is publicly accessible on GitHub to facilitate advancements in the
robotics community.","Shujie Zhou, Zihao Wang, Xinye Dai, Weiwei Song, Shengfeng Gu",2025-02-12 05:28:10.000000,arXiv,http://arxiv.org/abs/2502.08676v1,Robotics
549,SS4Rec: Continuous-Time Sequential Recommendation with State Space Models,"Sequential recommendation is a key area in the field of recommendation
systems aiming to model user interest based on historical interaction sequences
with irregular intervals. While previous recurrent neural network-based and
attention-based approaches have achieved significant results, they have
limitations in capturing system continuity due to the discrete characteristics.
In the context of continuous-time modeling, state space model (SSM) offers a
potential solution, as it can effectively capture the dynamic evolution of user
interest over time. However, existing SSM-based approaches ignore the impact of
irregular time intervals within historical user interactions, making it
difficult to model complexed user-item transitions in sequences. To address
this issue, we propose a hybrid SSM-based model called SS4Rec for
continuous-time sequential recommendation. SS4Rec integrates a time-aware SSM
to handle irregular time intervals and a relation-aware SSM to model contextual
dependencies, enabling it to infer user interest from both temporal and
sequential perspectives. In the training process, the time-aware SSM and the
relation-aware SSM are discretized by variable stepsizes according to user
interaction time intervals and input data, respectively. This helps capture the
continuous dependency from irregular time intervals and provides time-specific
personalized recommendations. Experimental studies on five benchmark datasets
demonstrate the superiority and effectiveness of SS4Rec.","Wei Xiao, Huiying Wang, Qifeng Zhou, Qing Wang",2025-02-12 05:28:08.000000,arXiv,http://arxiv.org/abs/2502.08132v1,Information Retrieval
550,Selective Self-to-Supervised Fine-Tuning for Generalization in Large Language Models,"Fine-tuning Large Language Models (LLMs) on specific datasets is a common
practice to improve performance on target tasks. However, this performance gain
often leads to overfitting, where the model becomes too specialized in either
the task or the characteristics of the training data, resulting in a loss of
generalization. This paper introduces Selective Self-to-Supervised Fine-Tuning
(S3FT), a fine-tuning approach that achieves better performance than the
standard supervised fine-tuning (SFT) while improving generalization. S3FT
leverages the existence of multiple valid responses to a query. By utilizing
the model's correct responses, S3FT reduces model specialization during the
fine-tuning stage. S3FT first identifies the correct model responses from the
training set by deploying an appropriate judge. Then, it fine-tunes the model
using the correct model responses and the gold response (or its paraphrase) for
the remaining samples. The effectiveness of S3FT is demonstrated through
experiments on mathematical reasoning, Python programming and reading
comprehension tasks. The results show that standard SFT can lead to an average
performance drop of up to $4.4$ on multiple benchmarks, such as MMLU and
TruthfulQA. In contrast, S3FT reduces this drop by half, i.e. $2.5$, indicating
better generalization capabilities than SFT while performing significantly
better on the fine-tuning tasks.","Sonam Gupta, Yatin Nandwani, Asaf Yehudai, Dinesh Khandelwal, Dinesh Raghu, Sachindra Joshi",2025-02-12 05:24:21.000000,arXiv,http://arxiv.org/abs/2502.08130v1,Natural Language Processing
551,Fino1: On the Transferability of Reasoning Enhanced LLMs to Finance,"Recent advancements in large language models (LLMs) have shown strong general
reasoning abilities, yet their effectiveness in financial reasoning remains
underexplored. In this study, we comprehensively evaluate 16 powerful reasoning
and general LLMs on three complex financial tasks involving financial text,
tabular data, and equations, assessing numerical reasoning, tabular
interpretation, financial terminology comprehension, long-context processing,
and equation-based problem solving. Our results show that while better datasets
and pretraining improve financial reasoning, general enhancements like CoT
fine-tuning do not always yield consistent gains. Moreover, all reasoning
strategies face challenges in improving performance on long-context and
multi-table tasks. To address these limitations, we develop a financial
reasoning-enhanced model based on Llama-3.1-8B-Instruct, by CoT fine-tuning and
reinforcement learning with domain-specific reasoning paths. Even with simple
fine-tuning with one financial dataset, our model achieves a consistent 10%
performance improvement across tasks, surpassing all 8B models and even
Llama3-70B-Instruct and Llama3.1-70B-Instruct on average. Our results highlight
the need for domain-specific adaptations in financial tasks, emphasizing future
directions such as multi-table reasoning, long-context processing, and
financial terminology comprehension. All our datasets, models, and codes are
publicly available. Furthermore, we introduce a leaderboard for benchmarking
future datasets and models.","Lingfei Qian, Weipeng Zhou, Yan Wang, Xueqing Peng, Jimin Huang, Qianqian Xie",2025-02-12 05:13:04.000000,arXiv,http://arxiv.org/abs/2502.08127v1,Natural Language Processing
552,Incremental Approximate Single-Source Shortest Paths with Predictions,"The algorithms-with-predictions framework has been used extensively to
develop online algorithms with improved beyond-worst-case competitive ratios.
Recently, there is growing interest in leveraging predictions for designing
data structures with improved beyond-worst-case running times. In this paper,
we study the fundamental data structure problem of maintaining approximate
shortest paths in incremental graphs in the algorithms-with-predictions model.
Given a sequence $\sigma$ of edges that are inserted one at a time, the goal is
to maintain approximate shortest paths from the source to each vertex in the
graph at each time step. Before any edges arrive, the data structure is given a
prediction of the online edge sequence $\hat{\sigma}$ which is used to ``warm
start'' its state.
  As our main result, we design a learned algorithm that maintains
$(1+\epsilon)$-approximate single-source shortest paths, which runs in
$\tilde{O}(m \eta \log W/\epsilon)$ time, where $W$ is the weight of the
heaviest edge and $\eta$ is the prediction error. We show these techniques
immediately extend to the all-pairs shortest-path setting as well. Our
algorithms are consistent (performing nearly as fast as the offline algorithm)
when predictions are nearly perfect, have a smooth degradation in performance
with respect to the prediction error and, in the worst case, match the best
offline algorithm up to logarithmic factors.
  As a building block, we study the offline incremental approximate
single-source shortest-paths problem. In this problem, the edge sequence
$\sigma$ is known a priori and the goal is to efficiently return the length of
the shortest paths in the intermediate graph $G_t$ consisting of the first $t$
edges, for all $t$. Note that the offline incremental problem is defined in the
worst-case setting (without predictions) and is of independent interest.","Samuel McCauley, Benjamin Moseley, Aidin Niaparast, Helia Niaparast, Shikha Singh",2025-02-12 05:06:23.000000,arXiv,http://arxiv.org/abs/2502.08125v1,Other
553,Provably Robust Federated Reinforcement Learning,"Federated reinforcement learning (FRL) allows agents to jointly learn a
global decision-making policy under the guidance of a central server. While FRL
has advantages, its decentralized design makes it prone to poisoning attacks.
To mitigate this, Byzantine-robust aggregation techniques tailored for FRL have
been introduced. Yet, in our work, we reveal that these current
Byzantine-robust techniques are not immune to our newly introduced Normalized
attack. Distinct from previous attacks that targeted enlarging the distance of
policy updates before and after an attack, our Normalized attack emphasizes on
maximizing the angle of deviation between these updates. To counter these
threats, we develop an ensemble FRL approach that is provably secure against
both known and our newly proposed attacks. Our ensemble method involves
training multiple global policies, where each is learnt by a group of agents
using any foundational aggregation rule. These well-trained global policies
then individually predict the action for a specific test state. The ultimate
action is chosen based on a majority vote for discrete action systems or the
geometric median for continuous ones. Our experimental results across different
settings show that the Normalized attack can greatly disrupt non-ensemble
Byzantine-robust methods, and our ensemble approach offers substantial
resistance against poisoning attacks.","Minghong Fang, Xilong Wang, Neil Zhenqiang Gong",2025-02-12 05:05:40.000000,arXiv,http://arxiv.org/abs/2502.08123v1,Other
554,Hookpad Aria: A Copilot for Songwriters,"We present Hookpad Aria, a generative AI system designed to assist musicians
in writing Western pop songs. Our system is seamlessly integrated into Hookpad,
a web-based editor designed for the composition of lead sheets: symbolic music
scores that describe melody and harmony. Hookpad Aria has numerous generation
capabilities designed to assist users in non-sequential composition workflows,
including: (1) generating left-to-right continuations of existing material, (2)
filling in missing spans in the middle of existing material, and (3) generating
harmony from melody and vice versa. Hookpad Aria is also a scalable data
flywheel for music co-creation -- since its release in March 2024, Aria has
generated 318k suggestions for 3k users who have accepted 74k into their songs.
  More information about Hookpad Aria is available at
https://www.hooktheory.com/hookpad/aria","Chris Donahue, Shih-Lun Wu, Yewon Kim, Dave Carlton, Ryan Miyakawa, John Thickstun",2025-02-12 05:03:49.000000,arXiv,http://arxiv.org/abs/2502.08122v1,Other
555,Generative AI-Enhanced Cooperative MEC of UAVs and Ground Stations for Unmanned Surface Vehicles,"The increasing deployment of unmanned surface vehicles (USVs) require
computational support and coverage in applications such as maritime search and
rescue. Unmanned aerial vehicles (UAVs) can offer low-cost, flexible aerial
services, and ground stations (GSs) can provide powerful supports, which can
cooperate to help the USVs in complex scenarios. However, the collaboration
between UAVs and GSs for USVs faces challenges of task uncertainties, USVs
trajectory uncertainties, heterogeneities, and limited computational resources.
To address these issues, we propose a cooperative UAV and GS based robust
multi-access edge computing framework to assist USVs in completing
computational tasks. Specifically, we formulate the optimization problem of
joint task offloading and UAV trajectory to minimize the total execution time,
which is in the form of mixed integer nonlinear programming and NP-hard to
tackle. Therefore, we propose the algorithm of generative artificial
intelligence-enhanced heterogeneous agent proximal policy optimization
(GAI-HAPPO). The proposed algorithm integrates GAI models to enhance the actor
network ability to model complex environments and extract high-level features,
thereby allowing the algorithm to predict uncertainties and adapt to dynamic
conditions. Additionally, GAI stabilizes the critic network, addressing the
instability of multi-agent reinforcement learning approaches. Finally,
extensive simulations demonstrate that the proposed algorithm outperforms the
existing benchmark methods, thus highlighting the potentials in tackling
intricate, cross-domain issues in the considered scenarios.","Jiahao You, Ziye Jia, Chao Dong, Qihui Wu, Zhu Han",2025-02-12 04:42:59.000000,arXiv,http://arxiv.org/abs/2502.08119v1,Artificial Intelligence
556,Neuromorphic Digital-Twin-based Controller for Indoor Multi-UAV Systems Deployment,"Presented study introduces a novel distributed cloud-edge framework for
autonomous multi-UAV systems that combines the computational efficiency of
neuromorphic computing with nature-inspired control strategies. The proposed
architecture equips each UAV with an individual Spiking Neural Network (SNN)
that learns to reproduce optimal control signals generated by a cloud-based
controller, enabling robust operation even during communication interruptions.
By integrating spike coding with nature-inspired control principles inspired by
Tilapia fish territorial behavior, our system achieves sophisticated formation
control and obstacle avoidance in complex urban environments. The distributed
architecture leverages cloud computing for complex calculations while
maintaining local autonomy through edge-based SNNs, significantly reducing
energy consumption and computational overhead compared to traditional
centralized approaches. Our framework addresses critical limitations of
conventional methods, including the dependency on pre-modeled environments,
computational intensity of traditional methods, and local minima issues in
potential field approaches. Simulation results demonstrate the system's
effectiveness across two different scenarios. First, the indoor deployment of a
multi-UAV system made-up of 15 UAVs. Then the collision-free formation control
of a moving UAV flock including 6 UAVs considering the obstacle avoidance.
Owing to the sparsity of spiking patterns, and the event-based nature of SNNs
in average for the whole group of UAVs, the framework achieves almost 90%
reduction in computational burden compared to traditional von Neumann
architectures implementing traditional artificial neural networks.","Reza Ahmadvand, Sarah Safura Sharif, Yaser Mike Banad",2025-02-12 04:36:53.000000,arXiv,http://arxiv.org/abs/2502.08115v1,Neural Networks
557,HuDEx: Integrating Hallucination Detection and Explainability for Enhancing the Reliability of LLM responses,"Recent advances in large language models (LLMs) have shown promising
improvements, often surpassing existing methods across a wide range of
downstream tasks in natural language processing. However, these models still
face challenges, which may hinder their practical applicability. For example,
the phenomenon of hallucination is known to compromise the reliability of LLMs,
especially in fields that demand high factual precision. Current benchmarks
primarily focus on hallucination detection and factuality evaluation but do not
extend beyond identification. This paper proposes an explanation enhanced
hallucination-detection model, coined as HuDEx, aimed at enhancing the
reliability of LLM-generated responses by both detecting hallucinations and
providing detailed explanations. The proposed model provides a novel approach
to integrate detection with explanations, and enable both users and the LLM
itself to understand and reduce errors. Our measurement results demonstrate
that the proposed model surpasses larger LLMs, such as Llama3 70B and GPT-4, in
hallucination detection accuracy, while maintaining reliable explanations.
Furthermore, the proposed model performs well in both zero-shot and other test
environments, showcasing its adaptability across diverse benchmark datasets.
The proposed approach further enhances the hallucination detection research by
introducing a novel approach to integrating interpretability with hallucination
detection, which further enhances the performance and reliability of evaluating
hallucinations in language models.","Sujeong Lee, Hayoung Lee, Seongsoo Heo, Wonik Choi",2025-02-12 04:17:02.000000,arXiv,http://arxiv.org/abs/2502.08109v1,Natural Language Processing
558,Generative AI and Empirical Software Engineering: A Paradigm Shift,"The widespread adoption of generative AI in software engineering marks a
paradigm shift, offering new opportunities to design and utilize software
engineering tools while influencing both developers and the artifacts they
create. Traditional empirical methods in software engineering, including
quantitative, qualitative, and mixed-method approaches, are well established.
However, this paradigm shift introduces novel data types and redefines many
concepts in the software engineering process. The roles of developers, users,
agents, and researchers increasingly overlap, blurring the distinctions between
these social and technical actors within the field.
  This paper examines how integrating AI into software engineering challenges
traditional research paradigms. It focuses on the research phenomena that we
investigate, the methods and theories that we employ, the data we analyze, and
the threats to validity that emerge in this new context. Through this
exploration, our goal is to understand how AI adoption disrupts established
software development practices that creates new opportunities for empirical
software engineering research.","Christoph Treude, Margaret-Anne Storey",2025-02-12 04:13:07.000000,arXiv,http://arxiv.org/abs/2502.08108v1,Other
559,PoGDiff: Product-of-Gaussians Diffusion Models for Imbalanced Text-to-Image Generation,"Diffusion models have made significant advancements in recent years. However,
their performance often deteriorates when trained or fine-tuned on imbalanced
datasets. This degradation is largely due to the disproportionate
representation of majority and minority data in image-text pairs. In this
paper, we propose a general fine-tuning approach, dubbed PoGDiff, to address
this challenge. Rather than directly minimizing the KL divergence between the
predicted and ground-truth distributions, PoGDiff replaces the ground-truth
distribution with a Product of Gaussians (PoG), which is constructed by
combining the original ground-truth targets with the predicted distribution
conditioned on a neighboring text embedding. Experiments on real-world datasets
demonstrate that our method effectively addresses the imbalance problem in
diffusion models, improving both generation accuracy and quality.","Ziyan Wang, Sizhe Wei, Xiaoming Huo, Hao Wang",2025-02-12 04:07:14.000000,arXiv,http://arxiv.org/abs/2502.08106v1,Machine Learning
560,Out-of-Distribution Detection on Graphs: A Survey,"Graph machine learning has witnessed rapid growth, driving advancements
across diverse domains. However, the in-distribution assumption, where training
and testing data share the same distribution, often breaks in real-world
scenarios, leading to degraded model performance under distribution shifts.
This challenge has catalyzed interest in graph out-of-distribution (GOOD)
detection, which focuses on identifying graph data that deviates from the
distribution seen during training, thereby enhancing model robustness. In this
paper, we provide a rigorous definition of GOOD detection and systematically
categorize existing methods into four types: enhancement-based,
reconstruction-based, information propagation-based, and classification-based
approaches. We analyze the principles and mechanisms of each approach and
clarify the distinctions between GOOD detection and related fields, such as
graph anomaly detection, outlier detection, and GOOD generalization. Beyond
methodology, we discuss practical applications and theoretical foundations,
highlighting the unique challenges posed by graph data. Finally, we discuss the
primary challenges and propose future directions to advance this emerging
field. The repository of this survey is available at
https://github.com/ca1man-2022/Awesome-GOOD-Detection.","Tingyi Cai, Yunliang Jiang, Yixin Liu, Ming Li, Changqin Huang, Shirui Pan",2025-02-12 04:07:12.000000,arXiv,http://arxiv.org/abs/2502.08105v1,Machine Learning
561,Rethinking Tokenized Graph Transformers for Node Classification,"Node tokenized graph Transformers (GTs) have shown promising performance in
node classification. The generation of token sequences is the key module in
existing tokenized GTs which transforms the input graph into token sequences,
facilitating the node representation learning via Transformer. In this paper,
we observe that the generations of token sequences in existing GTs only focus
on the first-order neighbors on the constructed similarity graphs, which leads
to the limited usage of nodes to generate diverse token sequences, further
restricting the potential of tokenized GTs for node classification. To this
end, we propose a new method termed SwapGT. SwapGT first introduces a novel
token swapping operation based on the characteristics of token sequences that
fully leverages the semantic relevance of nodes to generate more informative
token sequences. Then, SwapGT leverages a Transformer-based backbone to learn
node representations from the generated token sequences. Moreover, SwapGT
develops a center alignment loss to constrain the representation learning from
multiple token sequences, further enhancing the model performance. Extensive
empirical results on various datasets showcase the superiority of SwapGT for
node classification.","Jinsong Chen, Chenyang Li, GaiChao Li, John E. Hopcroft, Kun He",2025-02-12 03:56:35.000000,arXiv,http://arxiv.org/abs/2502.08101v1,Machine Learning
562,Unsupervised categorization of similarity measures,"In general, objects can be distinguished on the basis of their features, such
as color or shape. In particular, it is assumed that similarity judgments about
such features can be processed independently in different metric spaces.
However, the unsupervised categorization mechanism of metric spaces
corresponding to object features remains unknown. Here, we show that the
artificial neural network system can autonomously categorize metric spaces
through representation learning to satisfy the algebraic independence between
neural networks, and project sensory information onto multiple high-dimensional
metric spaces to independently evaluate the differences and similarities
between features. Conventional methods often constrain the axes of the latent
space to be mutually independent or orthogonal. However, the independent axes
are not suitable for categorizing metric spaces. High-dimensional metric spaces
that are independent of each other are not uniquely determined by the mutually
independent axes, because any combination of independent axes can form mutually
independent spaces. In other words, the mutually independent axes cannot be
used to naturally categorize different feature spaces, such as color space and
shape space. Therefore, constraining the axes to be mutually independent makes
it difficult to categorize high-dimensional metric spaces. To overcome this
problem, we developed a method to constrain only the spaces to be mutually
independent and not the composed axes to be independent. Our theory provides
general conditions for the unsupervised categorization of independent metric
spaces, thus advancing the mathematical theory of functional differentiation of
neural networks.","Yoshiyuki Ohmura, Wataru Shimaya, Yasuo Kuniyoshi",2025-02-12 03:52:47.000000,arXiv,http://arxiv.org/abs/2502.08098v1,Machine Learning
563,ID-Cloak: Crafting Identity-Specific Cloaks Against Personalized Text-to-Image Generation,"Personalized text-to-image models allow users to generate images of new
concepts from several reference photos, thereby leading to critical concerns
regarding civil privacy. Although several anti-personalization techniques have
been developed, these methods typically assume that defenders can afford to
design a privacy cloak corresponding to each specific image. However, due to
extensive personal images shared online, image-specific methods are limited by
real-world practical applications. To address this issue, we are the first to
investigate the creation of identity-specific cloaks (ID-Cloak) that safeguard
all images belong to a specific identity. Specifically, we first model an
identity subspace that preserves personal commonalities and learns diverse
contexts to capture the image distribution to be protected. Then, we craft
identity-specific cloaks with the proposed novel objective that encourages the
cloak to guide the model away from its normal output within the subspace.
Extensive experiments show that the generated universal cloak can effectively
protect the images. We believe our method, along with the proposed
identity-specific cloak setting, marks a notable advance in realistic privacy
protection.","Qianrui Teng, Xing Cui, Xuannan Liu, Peipei Li, Zekun Li, Huaibo Huang, Ran He",2025-02-12 03:52:36.000000,arXiv,http://arxiv.org/abs/2502.08097v1,Computer Vision
564,Ground-Optimized 4D Radar-Inertial Odometry via Continuous Velocity Integration using Gaussian Process,"Radar ensures robust sensing capabilities in adverse weather conditions, yet
challenges remain due to its high inherent noise level. Existing radar odometry
has overcome these challenges with strategies such as filtering spurious
points, exploiting Doppler velocity, or integrating with inertial measurements.
This paper presents two novel improvements beyond the existing radar-inertial
odometry: ground-optimized noise filtering and continuous velocity
preintegration. Despite the widespread use of ground planes in LiDAR odometry,
imprecise ground point distributions of radar measurements cause naive plane
fitting to fail. Unlike plane fitting in LiDAR, we introduce a zone-based
uncertainty-aware ground modeling specifically designed for radar. Secondly, we
note that radar velocity measurements can be better combined with IMU for a
more accurate preintegration in radar-inertial odometry. Existing methods often
ignore temporal discrepancies between radar and IMU by simplifying the
complexities of asynchronous data streams with discretized propagation models.
Tackling this issue, we leverage GP and formulate a continuous preintegration
method for tightly integrating 3-DOF linear velocity with IMU, facilitating
full 6-DOF motion directly from the raw measurements. Our approach demonstrates
remarkable performance (less than 1% vertical drift) in public datasets with
meticulous conditions, illustrating substantial improvement in elevation
accuracy. The code will be released as open source for the community:
https://github.com/wooseongY/Go-RIO.","Wooseong Yang, Hyesu Jang, Ayoung Kim",2025-02-12 03:34:25.000000,arXiv,http://arxiv.org/abs/2502.08093v1,Robotics
565,GCoT: Chain-of-Thought Prompt Learning for Graphs,"Chain-of-thought (CoT) prompting has achieved remarkable success in natural
language processing (NLP). However, its vast potential remains largely
unexplored for graphs. This raises an interesting question: How can we design
CoT prompting for graphs to guide graph models to learn step by step? On one
hand, unlike natural languages, graphs are non-linear and characterized by
complex topological structures. On the other hand, many graphs lack textual
data, making it difficult to formulate language-based CoT prompting. In this
work, we propose the first CoT prompt learning framework for text-free graphs,
GCoT. Specifically, we decompose the adaptation process for each downstream
task into a series of inference steps, with each step consisting of
prompt-based inference, ``thought'' generation, and thought-conditioned prompt
learning. While the steps mimic CoT prompting in NLP, the exact mechanism
differs significantly. Specifically, at each step, an input graph, along with a
prompt, is first fed into a pre-trained graph encoder for prompt-based
inference. We then aggregate the hidden layers of the encoder to construct a
``thought'', which captures the working state of each node in the current step.
Conditioned on this thought, we learn a prompt specific to each node based on
the current state. These prompts are fed into the next inference step,
repeating the cycle. To evaluate and analyze the effectiveness of GCoT, we
conduct comprehensive experiments on eight public datasets, which demonstrate
the advantage of our approach.","Xingtong Yu, Chang Zhou, Zhongwei Kuai, Xinming Zhang, Yuan Fang",2025-02-12 03:33:06.000000,arXiv,http://arxiv.org/abs/2502.08092v1,Natural Language Processing
566,COutfitGAN: Learning to Synthesize Compatible Outfits Supervised by Silhouette Masks and Fashion Styles,"How to recommend outfits has gained considerable attention in both academia
and industry in recent years. Many studies have been carried out regarding
fashion compatibility learning, to determine whether the fashion items in an
outfit are compatible or not. These methods mainly focus on evaluating the
compatibility of existing outfits and rarely consider applying such knowledge
to 'design' new fashion items. We propose the new task of generating
complementary and compatible fashion items based on an arbitrary number of
given fashion items. In particular, given some fashion items that can make up
an outfit, the aim of this paper is to synthesize photo-realistic images of
other, complementary, fashion items that are compatible with the given ones. To
achieve this, we propose an outfit generation framework, referred to as
COutfitGAN, which includes a pyramid style extractor, an outfit generator, a
UNet-based real/fake discriminator, and a collocation discriminator. To train
and evaluate this framework, we collected a large-scale fashion outfit dataset
with over 200K outfits and 800K fashion items from the Internet. Extensive
experiments show that COutfitGAN outperforms other baselines in terms of
similarity, authenticity, and compatibility measurements.","Dongliang Zhou, Haijun Zhang, Qun Li, Jianghong Ma, Xiaofei Xu",2025-02-12 03:32:28.000000,arXiv,http://arxiv.org/abs/2502.08674v1,Computer Vision
567,High-Throughput SAT Sampling,"In this work, we present a novel technique for GPU-accelerated Boolean
satisfiability (SAT) sampling. Unlike conventional sampling algorithms that
directly operate on conjunctive normal form (CNF), our method transforms the
logical constraints of SAT problems by factoring their CNF representations into
simplified multi-level, multi-output Boolean functions. It then leverages
gradient-based optimization to guide the search for a diverse set of valid
solutions. Our method operates directly on the circuit structure of refactored
SAT instances, reinterpreting the SAT problem as a supervised multi-output
regression task. This differentiable technique enables independent bit-wise
operations on each tensor element, allowing parallel execution of learning
processes. As a result, we achieve GPU-accelerated sampling with significant
runtime improvements ranging from $33.6\times$ to $523.6\times$ over
state-of-the-art heuristic samplers. We demonstrate the superior performance of
our sampling method through an extensive evaluation on $60$ instances from a
public domain benchmark suite utilized in previous studies.","Arash Ardakani, Minwoo Kang, Kevin He, Qijing Huang, John Wawrzynek",2025-02-12 03:20:45.000000,arXiv,http://arxiv.org/abs/2502.08673v1,Artificial Intelligence
568,A Cooperative Bearing-Rate Approach for Observability-Enhanced Target Motion Estimation,"Vision-based target motion estimation is a fundamental problem in many
robotic tasks. The existing methods have the limitation of low observability
and, hence, face challenges in tracking highly maneuverable targets. Motivated
by the aerial target pursuit task where a target may maneuver in 3D space, this
paper studies how to further enhance observability by incorporating the
\emph{bearing rate} information that has not been well explored in the
literature. The main contribution of this paper is to propose a new cooperative
estimator called STT-R (Spatial-Temporal Triangulation with bearing Rate),
which is designed under the framework of distributed recursive least squares.
This theoretical result is further verified by numerical simulation and
real-world experiments. It is shown that the proposed STT-R algorithm can
effectively generate more accurate estimations and effectively reduce the lag
in velocity estimation, enabling tracking of more maneuverable targets.","Canlun Zheng, Hanqing Guo, Shiyu Zhao",2025-02-12 03:17:06.000000,arXiv,http://arxiv.org/abs/2502.08089v1,Robotics
569,Mixture of Decoupled Message Passing Experts with Entropy Constraint for General Node Classification,"The varying degrees of homophily and heterophily in real-world graphs
persistently constrain the universality of graph neural networks (GNNs) for
node classification. Adopting a data-centric perspective, this work reveals an
inherent preference of different graphs towards distinct message encoding
schemes: homophilous graphs favor local propagation, while heterophilous graphs
exhibit preference for flexible combinations of propagation and transformation.
To address this, we propose GNNMoE, a universal node classification framework
based on the Mixture-of-Experts (MoE) mechanism. The framework first constructs
diverse message-passing experts through recombination of fine-grained encoding
operators, then designs soft and hard gating layers to allocate the most
suitable expert networks for each node's representation learning, thereby
enhancing both model expressiveness and adaptability to diverse graphs.
Furthermore, considering that soft gating might introduce encoding noise in
homophilous scenarios, we introduce an entropy constraint to guide sharpening
of soft gates, achieving organic integration of weighted combination and Top-K
selection. Extensive experiments demonstrate that GNNMoE significantly
outperforms mainstream GNNs, heterophilous GNNs, and graph transformers in both
node classification performance and universality across diverse graph datasets.","Xuanze Chen, Jiajun Zhou, Jinsong Chen, Shanqing Yu, Qi Xuan",2025-02-12 03:10:26.000000,arXiv,http://arxiv.org/abs/2502.08083v1,Machine Learning
570,NLI under the Microscope: What Atomic Hypothesis Decomposition Reveals,"Decomposition of text into atomic propositions is a flexible framework
allowing for the closer inspection of input and output text. We use atomic
decomposition of hypotheses in two natural language reasoning tasks,
traditional NLI and defeasible NLI, to form atomic sub-problems, or granular
inferences that models must weigh when solving the overall problem. These
atomic sub-problems serve as a tool to further understand the structure of both
NLI and defeasible reasoning, probe a model's consistency and understanding of
different inferences, and measure the diversity of examples in benchmark
datasets. Our results indicate that LLMs still struggle with logical
consistency on atomic NLI and defeasible NLI sub-problems. Lastly, we identify
critical atomic sub-problems of defeasible NLI examples, or those that most
contribute to the overall label, and propose a method to measure the
inferential consistency of a model, a metric designed to capture the degree to
which a model makes consistently correct or incorrect predictions about the
same fact under different contexts.","Neha Srikanth, Rachel Rudinger",2025-02-12 02:54:12.000000,arXiv,http://arxiv.org/abs/2502.08080v1,Natural Language Processing
571,MAA: Meticulous Adversarial Attack against Vision-Language Pre-trained Models,"Current adversarial attacks for evaluating the robustness of vision-language
pre-trained (VLP) models in multi-modal tasks suffer from limited
transferability, where attacks crafted for a specific model often struggle to
generalize effectively across different models, limiting their utility in
assessing robustness more broadly. This is mainly attributed to the
over-reliance on model-specific features and regions, particularly in the image
modality. In this paper, we propose an elegant yet highly effective method
termed Meticulous Adversarial Attack (MAA) to fully exploit model-independent
characteristics and vulnerabilities of individual samples, achieving enhanced
generalizability and reduced model dependence. MAA emphasizes fine-grained
optimization of adversarial images by developing a novel resizing and sliding
crop (RScrop) technique, incorporating a multi-granularity similarity
disruption (MGSD) strategy. Extensive experiments across diverse VLP models,
multiple benchmark datasets, and a variety of downstream tasks demonstrate that
MAA significantly enhances the effectiveness and transferability of adversarial
attacks. A large cohort of performance studies is conducted to generate
insights into the effectiveness of various model configurations, guiding future
advancements in this domain.","Peng-Fei Zhang, Guangdong Bai, Zi Huang",2025-02-12 02:53:27.000000,arXiv,http://arxiv.org/abs/2502.08079v1,Computer Vision
572,Cascading Bandits Robust to Adversarial Corruptions,"Online learning to rank sequentially recommends a small list of items to
users from a large candidate set and receives the users' click feedback. In
many real-world scenarios, users browse the recommended list in order and click
the first attractive item without checking the rest. Such behaviors are usually
formulated as the cascade model. Many recent works study algorithms for
cascading bandits, an online learning to rank framework in the cascade model.
However, the performance of existing methods may drop significantly if part of
the user feedback is adversarially corrupted (e.g., click fraud). In this work,
we study how to resist adversarial corruptions in cascading bandits. We first
formulate the ``\textit{Cascading Bandits with Adversarial Corruptions}"" (CBAC)
problem, which assumes that there is an adaptive adversary that may manipulate
the user feedback. Then we propose two robust algorithms for this problem,
which assume the corruption level is known and agnostic, respectively. We show
that both algorithms can achieve logarithmic regret when the algorithm is not
under attack, and the regret increases linearly with the corruption level. The
experimental results also verify the robustness of our methods.","Jize Xie, Cheng Chen, Zhiyong Wang, Shuai Li",2025-02-12 02:44:41.000000,arXiv,http://arxiv.org/abs/2502.08077v1,Machine Learning
573,Knowledge Swapping via Learning and Unlearning,"We introduce \textbf{Knowledge Swapping}, a novel task designed to
selectively regulate knowledge of a pretrained model by enabling the forgetting
of user\-specified information, retaining essential knowledge, and acquiring
new knowledge simultaneously. By delving into the analysis of knock-on feature
hierarchy, we find that incremental learning typically progresses from
low\-level representations to higher\-level semantics, whereas forgetting tends
to occur in the opposite direction\-starting from high-level semantics and
moving down to low-level features. Building upon this, we propose to benchmark
the knowledge swapping task with the strategy of \textit{Learning Before
Forgetting}. Comprehensive experiments on various tasks like image
classification, object detection, and semantic segmentation validate the
effectiveness of the proposed strategy. The source code is available at
\href{https://github.com/xingmingyu123456/KnowledgeSwapping}{https://github.com/xingmingyu123456/KnowledgeSwapping}.","Mingyu Xing, Lechao Cheng, Shenggeng Tang, Yaxiong Wang, Zhun Zhong, Meng Wang",2025-02-12 02:37:16.000000,arXiv,http://arxiv.org/abs/2502.08075v1,Computer Vision
574,Collaborative Filtering Meets Spectrum Shift: Connecting User-Item Interaction with Graph-Structured Side Information,"Graph Neural Network (GNN) has demonstrated their superiority in
collaborative filtering, where the user-item (U-I) interaction bipartite graph
serves as the fundamental data format. However, when graph-structured side
information (e.g., multimodal similarity graphs or social networks) is
integrated into the U-I bipartite graph, existing graph collaborative filtering
methods fall short of achieving satisfactory performance. We quantitatively
analyze this problem from a spectral perspective. Recall that a bipartite graph
possesses a full spectrum within the range of [-1, 1], with the highest
frequency exactly achievable at -1 and the lowest frequency at 1; however, we
observe as more side information is incorporated, the highest frequency of the
augmented adjacency matrix progressively shifts rightward. This spectrum shift
phenomenon has caused previous approaches built for the full spectrum [-1, 1]
to assign mismatched importance to different frequencies. To this end, we
propose Spectrum Shift Correction (dubbed SSC), incorporating shifting and
scaling factors to enable spectral GNNs to adapt to the shifted spectrum.
Unlike previous paradigms of leveraging side information, which necessitate
tailored designs for diverse data types, SSC directly connects traditional
graph collaborative filtering with any graph-structured side information.
Experiments on social and multimodal recommendation demonstrate the
effectiveness of SSC, achieving relative improvements of up to 23% without
incurring any additional computational overhead.","Yunhang He, Cong Xu, Jun Wang, Wei Zhang",2025-02-12 02:24:26.000000,arXiv,http://arxiv.org/abs/2502.08071v1,Information Retrieval
575,Multi-Agent Performative Prediction Beyond the Insensitivity Assumption: A Case Study for Mortgage Competition,"Performative prediction models account for feedback loops in decision-making
processes where predictions influence future data distributions. While existing
work largely assumes insensitivity of data distributions to small strategy
changes, this assumption usually fails in real-world competitive (i.e.
multi-agent) settings. For example, in Bertrand-type competitions, a small
reduction in one firm's price can lead that firm to capture the entire demand,
while all others sharply lose all of their customers.
  We study a representative setting of multi-agent performative prediction in
which insensitivity assumptions do not hold, and investigate the convergence of
natural dynamics. To do so, we focus on a specific game that we call the ''Bank
Game'', where two lenders compete over interest rates and credit score
thresholds. Consumers act similarly as to in a Bertrand Competition, with each
consumer selecting the firm with the lowest interest rate that they are
eligible for based on the firms' credit thresholds. Our analysis characterizes
the equilibria of this game and demonstrates that when both firms use a common
and natural no-regret learning dynamic -- exponential weights -- with proper
initialization, the dynamics always converge to stable outcomes despite the
general-sum structure. Notably, our setting admits multiple stable equilibria,
with convergence dependent on initial conditions. We also provide theoretical
convergence results in the stochastic case when the utility matrix is not fully
known, but each learner can observe sufficiently many samples of consumers at
each time step to estimate it, showing robustness to slight mis-specifications.
Finally, we provide experimental results that validate our theoretical
findings.","Guanghui Wang, Krishna Acharya, Lokranjan Lakshmikanthan, Vidya Muthukumar, Juba Ziani",2025-02-12 02:04:46.000000,arXiv,http://arxiv.org/abs/2502.08063v1,Other
576,On Mechanistic Circuits for Extractive Question-Answering,"Large language models are increasingly used to process documents and
facilitate question-answering on them. In our paper, we extract mechanistic
circuits for this real-world language modeling task: context-augmented language
modeling for extractive question-answering (QA) tasks and understand the
potential benefits of circuits towards downstream applications such as data
attribution to context information. We extract circuits as a function of
internal model components (e.g., attention heads, MLPs) using causal mediation
analysis techniques. Leveraging the extracted circuits, we first understand the
interplay between the model's usage of parametric memory and retrieved context
towards a better mechanistic understanding of context-augmented language
models. We then identify a small set of attention heads in our circuit which
performs reliable data attribution by default, thereby obtaining attribution
for free in just the model's forward pass. Using this insight, we then
introduce ATTNATTRIB, a fast data attribution algorithm which obtains
state-of-the-art attribution results across various extractive QA benchmarks.
Finally, we show the possibility to steer the language model towards answering
from the context, instead of the parametric memory by using the attribution
from ATTNATTRIB as an additional signal during the forward pass. Beyond
mechanistic understanding, our paper provides tangible applications of circuits
in the form of reliable data attribution and model steering.","Samyadeep Basu, Vlad Morariu, Zichao Wang, Ryan Rossi, Cherry Zhao, Soheil Feizi, Varun Manjunatha",2025-02-12 01:54:21.000000,arXiv,http://arxiv.org/abs/2502.08059v1,Natural Language Processing
577,Color Universal Design Neural Network for the Color Vision Deficiencies,"Information regarding images should be visually understood by anyone,
including those with color deficiency. However, such information is not
recognizable if the color that seems to be distorted to the color deficiencies
meets an adjacent object. The aim of this paper is to propose a color universal
design network, called CUD-Net, that generates images that are visually
understandable by individuals with color deficiency. CUD-Net is a convolutional
deep neural network that can preserve color and distinguish colors for input
images by regressing the node point of a piecewise linear function and using a
specific filter for each image. To generate CUD images for color deficiencies,
we follow a four-step process. First, we refine the CUD dataset based on
specific criteria by color experts. Second, we expand the input image
information through pre-processing that is specialized for color deficiency
vision. Third, we employ a multi-modality fusion architecture to combine
features and process the expanded images. Finally, we propose a conjugate loss
function based on the composition of the predicted image through the model to
address one-to-many problems that arise from the dataset. Our approach is able
to produce high-quality CUD images that maintain color and contrast stability.
The code for CUD-Net is available on the GitHub repository","Sunyong Seo, Jinho Park",2025-02-12 01:53:15.000000,arXiv,http://arxiv.org/abs/2502.08671v1,Other
578,General Coded Computing: Adversarial Settings,"Conventional coded computing frameworks are predominantly tailored for
structured computations, such as matrix multiplication and polynomial
evaluation. Such tasks allow the reuse of tools and techniques from algebraic
coding theory to improve the reliability of distributed systems in the presence
of stragglers and adversarial servers.
  This paper lays the foundation for general coded computing, which extends the
applicability of coded computing to handle a wide class of computations. In
addition, it particularly addresses the challenging problem of managing
adversarial servers. We demonstrate that, in the proposed scheme, for a system
with $N$ servers, where $\mathcal{O}(N^a)$, $a \in [0,1)$, are adversarial, the
supremum of the average approximation error over all adversarial strategies
decays at a rate of $N^{\frac{6}{5}(a-1)}$, under minimal assumptions on the
computing tasks. Furthermore, we show that within a general framework, the
proposed scheme achieves optimal adversarial robustness, in terms of maximum
number of adversarial servers it can tolerate. This marks a significant step
toward practical and reliable general coded computing. Implementation results
further validate the effectiveness of the proposed method in handling various
computations, including inference in deep neural networks.","Parsa Moradi, Hanzaleh Akbarinodehi, Mohammad Ali Maddah-Ali",2025-02-12 01:50:12.000000,arXiv,http://arxiv.org/abs/2502.08058v1,Other
579,Cognify: Supercharging Gen-AI Workflows With Hierarchical Autotuning,"Today's gen-AI workflows that involve multiple ML model calls, tool/API
calls, data retrieval, or generic code execution are often tuned manually in an
ad-hoc way that is both time-consuming and error-prone. In this paper, we
propose a systematic approach for automatically tuning gen-AI workflows. Our
key insight is that gen-AI workflows can benefit from structure, operator, and
prompt changes, but unique properties of gen-AI workflows require new
optimization techniques. We propose AdaSeek, an adaptive hierarchical search
algorithm for autotuning gen-AI workflows. AdaSeek organizes workflow tuning
methods into different layers based on the user-specified total search budget
and distributes the budget across different layers based on the complexity of
each layer. During its hierarchical search, AdaSeek redistributes the search
budget from less useful to more promising tuning configurations based on
workflow-level evaluation results. We implement AdaSeek in a workflow
autotuning framework called Cognify and evaluate Cognify using six types of
workflows such as RAG-based QA and text-to-SQL transformation. Overall, Cognify
improves these workflows' generation quality by up to 2.8x, reduces execution
monetary cost by up to 10x, and reduces end-to-end latency by 2.7x.","Zijian He, Reyna Abhyankar, Vikranth Srivatsa, Yiying Zhang",2025-02-12 01:36:27.000000,arXiv,http://arxiv.org/abs/2502.08056v1,Machine Learning
580,SLVR: Securely Leveraging Client Validation for Robust Federated Learning,"Federated Learning (FL) enables collaborative model training while keeping
client data private. However, exposing individual client updates makes FL
vulnerable to reconstruction attacks. Secure aggregation mitigates such privacy
risks but prevents the server from verifying the validity of each client
update, creating a privacy-robustness tradeoff. Recent efforts attempt to
address this tradeoff by enforcing checks on client updates using
zero-knowledge proofs, but they support limited predicates and often depend on
public validation data. We propose SLVR, a general framework that securely
leverages clients' private data through secure multi-party computation. By
utilizing clients' data, SLVR not only eliminates the need for public
validation data, but also enables a wider range of checks for robustness,
including cross-client accuracy validation. It also adapts naturally to
distribution shifts in client data as it can securely refresh its validation
data up-to-date. Our empirical evaluations show that SLVR improves robustness
against model poisoning attacks, particularly outperforming existing methods by
up to 50% under adaptive attacks. Additionally, SLVR demonstrates effective
adaptability and stable convergence under various distribution shift scenarios.","Jihye Choi, Sai Rahul Rachuri, Ke Wang, Somesh Jha, Yizhen Wang",2025-02-12 01:31:39.000000,arXiv,http://arxiv.org/abs/2502.08055v1,Other
581,COMBO-Grasp: Learning Constraint-Based Manipulation for Bimanual Occluded Grasping,"This paper addresses the challenge of occluded robot grasping, i.e. grasping
in situations where the desired grasp poses are kinematically infeasible due to
environmental constraints such as surface collisions. Traditional robot
manipulation approaches struggle with the complexity of non-prehensile or
bimanual strategies commonly used by humans in these circumstances.
State-of-the-art reinforcement learning (RL) methods are unsuitable due to the
inherent complexity of the task. In contrast, learning from demonstration
requires collecting a significant number of expert demonstrations, which is
often infeasible. Instead, inspired by human bimanual manipulation strategies,
where two hands coordinate to stabilise and reorient objects, we focus on a
bimanual robotic setup to tackle this challenge. In particular, we introduce
Constraint-based Manipulation for Bimanual Occluded Grasping (COMBO-Grasp), a
learning-based approach which leverages two coordinated policies: a constraint
policy trained using self-supervised datasets to generate stabilising poses and
a grasping policy trained using RL that reorients and grasps the target object.
A key contribution lies in value function-guided policy coordination.
Specifically, during RL training for the grasping policy, the constraint
policy's output is refined through gradients from a jointly trained value
function, improving bimanual coordination and task performance. Lastly,
COMBO-Grasp employs teacher-student policy distillation to effectively deploy
point cloud-based policies in real-world environments. Empirical evaluations
demonstrate that COMBO-Grasp significantly improves task success rates compared
to competitive baseline approaches, with successful generalisation to unseen
objects in both simulated and real-world environments.","Jun Yamada, Alexander L. Mitchell, Jack Collins, Ingmar Posner",2025-02-12 01:31:01.000000,arXiv,http://arxiv.org/abs/2502.08054v1,Robotics
582,WorldGUI: Dynamic Testing for Comprehensive Desktop GUI Automation,"Current GUI agents have achieved outstanding performance in GUI element
grounding. However, planning remains highly challenging, especially due to
sensitivity to the initial state of the environment. Specifically, slight
differences in the initial state-such as the target software not being open or
the interface not being in its default state-often lead to planning errors.
This issue is widespread in real user scenarios, but existing benchmarks fail
to evaluate it. In this paper, we present WorldGUI, a novel GUI benchmark that
designs GUI tasks with various initial states to simulate real computer-user
interactions. The benchmark spans a wide range of tasks across 10 popular
software applications, including PowerPoint, VSCode, and Adobe Acrobat. In
addition, to address the challenges of dynamic GUI automation tasks, we propose
GUI-Thinker, a holistic framework, leveraging a critique mechanism, that
effectively manages the unpredictability and complexity of GUI interactions.
Experimental results demonstrate that GUI-Thinker significantly outperforms
Claude-3.5 (Computer Use) by 14.9% in success rate on WorldGUI tasks. This
improvement underscores the effectiveness of our critical-thinking-based
framework in enhancing GUI automation.","Henry Hengyuan Zhao, Difei Gao, Mike Zheng Shou",2025-02-12 01:06:10.000000,arXiv,http://arxiv.org/abs/2502.08047v1,Artificial Intelligence
583,Break the Checkbox: Challenging Closed-Style Evaluations of Cultural Alignment in LLMs,"A large number of studies rely on closed-style multiple-choice surveys to
evaluate cultural alignment in Large Language Models (LLMs). In this work, we
challenge this constrained evaluation paradigm and explore more realistic,
unconstrained approaches. Using the World Values Survey (WVS) and Hofstede
Cultural Dimensions as case studies, we demonstrate that LLMs exhibit stronger
cultural alignment in less constrained settings, where responses are not
forced. Additionally, we show that even minor changes, such as reordering
survey choices, lead to inconsistent outputs, exposing the limitations of
closed-style evaluations. Our findings advocate for more robust and flexible
evaluation frameworks that focus on specific cultural proxies, encouraging more
nuanced and accurate assessments of cultural alignment in LLMs.","Mohsinul Kabir, Ajwad Abrar, Sophia Ananiadou",2025-02-12 01:04:13.000000,arXiv,http://arxiv.org/abs/2502.08045v1,Natural Language Processing
584,"The Art of Misclassification: Too Many Classes, Not Enough Points","Classification is a ubiquitous and fundamental problem in artificial
intelligence and machine learning, with extensive efforts dedicated to
developing more powerful classifiers and larger datasets. However, the
classification task is ultimately constrained by the intrinsic properties of
datasets, independently of computational power or model complexity. In this
work, we introduce a formal entropy-based measure of classificability, which
quantifies the inherent difficulty of a classification problem by assessing the
uncertainty in class assignments given feature representations. This measure
captures the degree of class overlap and aligns with human intuition, serving
as an upper bound on classification performance for classification problems.
Our results establish a theoretical limit beyond which no classifier can
improve the classification accuracy, regardless of the architecture or amount
of data, in a given problem. Our approach provides a principled framework for
understanding when classification is inherently fallible and fundamentally
ambiguous.","Mario Franco, Gerardo Febres, Nelson Fernández, Carlos Gershenson",2025-02-12 00:57:53.000000,arXiv,http://arxiv.org/abs/2502.08041v1,Machine Learning
585,Franken-Adapter: Cross-Lingual Adaptation of LLMs by Embedding Surgery,"The capabilities of Large Language Models (LLMs) in low-resource languages
lag far behind those in English, making their universal accessibility a
significant challenge. To alleviate this, we present
$\textit{Franken-Adapter}$, a modular language adaptation approach for
decoder-only LLMs with embedding surgery. Our method begins by creating
customized vocabularies for target languages and performing language adaptation
through embedding tuning on multilingual data. These pre-trained embeddings are
subsequently integrated with LLMs that have been instruction-tuned on English
alignment data to enable zero-shot cross-lingual transfer. Our experiments on
$\texttt{Gemma2}$ models with up to 27B parameters demonstrate improvements of
up to 20% across 96 languages, spanning both discriminative and generative
tasks, with minimal regressions ($<$1%) in English. Further in-depth analysis
reveals the critical role of customizing tokenizers in enhancing language
adaptation, while boosting inference efficiency. Additionally, we show the
versatility of our method by achieving a 14% improvement over a math-optimized
LLM across 20 languages, offering a modular solution to transfer reasoning
abilities across languages post hoc.","Fan Jiang, Honglin Yu, Grace Chung, Trevor Cohn",2025-02-12 00:38:11.000000,arXiv,http://arxiv.org/abs/2502.08037v1,Natural Language Processing
586,Assessing the Impact of the Quality of Textual Data on Feature Representation and Machine Learning Models,"Background: Data collected in controlled settings typically results in
high-quality datasets. However, in real-world applications, the quality of data
collection is often compromised. It is well established that the quality of a
dataset significantly impacts the performance of machine learning models.
  Methods: A rudimentary error rate metric was developed to evaluate textual
dataset quality at the token level. Mixtral Large Language Model (LLM) was used
to quantify and correct errors in low quality datasets. The study analyzed two
healthcare datasets: the high-quality MIMIC-III public hospital dataset and a
lower-quality private dataset from Australian aged care homes. Errors were
systematically introduced into MIMIC at varying rates, while the ACH dataset
quality was improved using the LLM.
  Results: For the sampled 35,774 and 6,336 patients from the MIMIC and ACH
datasets respectively, we used Mixtral to introduce errors in MIMIC and correct
errors in ACH. Mixtral correctly detected errors in 63% of progress notes, with
17% containing a single token misclassified due to medical terminology. LLMs
demonstrated potential for improving progress note quality by addressing
various errors. Under varying error rates, feature representation performance
was tolerant to lower error rates (<10%) but declined significantly at higher
rates.
  Conclusions: The study revealed that models performed relatively well on
datasets with lower error rates (<10%), but their performance declined
significantly as error rates increased (>=10%). Therefore, it is crucial to
evaluate the quality of a dataset before utilizing it for machine learning
tasks. For datasets with higher error rates, implementing corrective measures
is essential to ensure the reliability and effectiveness of machine learning
models.","Tabinda Sarwar, Antonio Jose Jimeno Yepes, Lawrence Cavedon",2025-02-12 00:27:49.000000,arXiv,http://arxiv.org/abs/2502.08669v1,Natural Language Processing
587,End-to-End Predictive Planner for Autonomous Driving with Consistency Models,"Trajectory prediction and planning are fundamental components for autonomous
vehicles to navigate safely and efficiently in dynamic environments.
Traditionally, these components have often been treated as separate modules,
limiting the ability to perform interactive planning and leading to
computational inefficiency in multi-agent scenarios. In this paper, we present
a novel unified and data-driven framework that integrates prediction and
planning with a single consistency model. Trained on real-world human driving
datasets, our consistency model generates samples from high-dimensional,
multimodal joint trajectory distributions of the ego and multiple surrounding
agents, enabling end-to-end predictive planning. It effectively produces
interactive behaviors, such as proactive nudging and yielding to ensure both
safe and efficient interactions with other road users. To incorporate
additional planning constraints on the ego vehicle, we propose an alternating
direction method for multi-objective guidance in online guided sampling.
Compared to diffusion models, our consistency model achieves better performance
with fewer sampling steps, making it more suitable for real-time deployment.
Experimental results on Waymo Open Motion Dataset (WOMD) demonstrate our
method's superiority in trajectory quality, constraint satisfaction, and
interactive behavior compared to various existing approaches.","Anjian Li, Sangjae Bae, David Isele, Ryne Beeson, Faizan M. Tariq",2025-02-12 00:26:01.000000,arXiv,http://arxiv.org/abs/2502.08033v1,Robotics
588,Style Extraction on Text Embeddings Using VAE and Parallel Dataset,"This study investigates the stylistic differences among various Bible
translations using a Variational Autoencoder (VAE) model. By embedding textual
data into high-dimensional vectors, the study aims to detect and analyze
stylistic variations between translations, with a specific focus on
distinguishing the American Standard Version (ASV) from other translations. The
results demonstrate that each translation exhibits a unique stylistic
distribution, which can be effectively identified using the VAE model. These
findings suggest that the VAE model is proficient in capturing and
differentiating textual styles, although it is primarily optimized for
distinguishing a single style. The study highlights the model's potential for
broader applications in AI-based text generation and stylistic analysis, while
also acknowledging the need for further model refinement to address the
complexity of multi-dimensional stylistic relationships. Future research could
extend this methodology to other text domains, offering deeper insights into
the stylistic features embedded within various types of textual data.","InJin Kong, Shinyee Kang, Yuna Park, Sooyong Kim, Sanghyun Park",2025-02-12 00:24:28.000000,arXiv,http://arxiv.org/abs/2502.08668v1,Natural Language Processing
589,Contextual Subspace Manifold Projection for Structural Refinement of Large Language Model Representations,"Internal representations within deep neural architectures encode
high-dimensional abstractions of linguistic structures, yet they often exhibit
inefficiencies in feature distribution, limiting expressiveness and
adaptability. Contextual Subspace Manifold Projection introduces a structured
refinement technique that selectively reconfigures token embeddings through
controlled subspace constraints, ensuring more stable and geometrically
well-defined feature distributions. Empirical evaluations demonstrated that the
structured intervention reduced anisotropy, leading to improved representation
compactness while preserving semantic fidelity across transformer layers.
Clustering analyses indicated that token embeddings exhibited greater feature
separability, reinforcing the hypothesis that structured projection techniques
enhance internal representation organization without sacrificing linguistic
coherence. Gradient magnitude distributions suggested that the method
introduced a smoother optimization trajectory, potentially contributing to more
stable parameter updates throughout training. Computational overhead associated
with the projection operations remained minimal, ensuring that the refinements
did not introduce significant trade-offs in model efficiency or inference
speed. Comparisons with standard embedding refinement techniques highlighted
that structured manifold constraints provided a direct mechanism for improving
representation quality without requiring additional gradient-based
optimization. Perplexity evaluations confirmed that the adjustments did not
negatively impact sequence coherence, further validating the effectiveness of
the proposed approach.","Alistair Wren, Beatrice Loxley, Hamish Cadwallader, Simon Beckwith, Fabian Pargeter, James Blades",2025-02-12 00:00:37.000000,arXiv,http://arxiv.org/abs/2502.08026v1,Natural Language Processing
590,From Brainwaves to Brain Scans: A Robust Neural Network for EEG-to-fMRI Synthesis,"While functional magnetic resonance imaging (fMRI) offers rich spatial
resolution, it is limited by high operational costs and significant
infrastructural demands. In contrast, electroencephalography (EEG) provides
millisecond-level precision in capturing electrical activity but lacks the
spatial resolution necessary for precise neural localization. To bridge these
gaps, we introduce E2fNet, a simple yet effective deep learning model for
synthesizing fMRI images from low-cost EEG data. E2fNet is specifically
designed to capture and translate meaningful features from EEG across electrode
channels into accurate fMRI representations. Extensive evaluations across three
datasets demonstrate that E2fNet consistently outperforms existing methods,
achieving state-of-the-art results in terms of the structural similarity index
measure (SSIM). Our findings suggest that E2fNet is a promising, cost-effective
solution for enhancing neuroimaging capabilities. The code is available at
https://github.com/kgr20/E2fNet.","Kristofer Grover Roos, Quan Huu Cap, Atsushi Fukuda",2025-02-11 23:55:16.000000,arXiv,http://arxiv.org/abs/2502.08025v1,Computer Vision
591,Initialization Matters: Unraveling the Impact of Pre-Training on Federated Learning,"Initializing with pre-trained models when learning on downstream tasks is
becoming standard practice in machine learning. Several recent works explore
the benefits of pre-trained initialization in a federated learning (FL)
setting, where the downstream training is performed at the edge clients with
heterogeneous data distribution. These works show that starting from a
pre-trained model can substantially reduce the adverse impact of data
heterogeneity on the test performance of a model trained in a federated
setting, with no changes to the standard FedAvg training algorithm. In this
work, we provide a deeper theoretical understanding of this phenomenon. To do
so, we study the class of two-layer convolutional neural networks (CNNs) and
provide bounds on the training error convergence and test error of such a
network trained with FedAvg. We introduce the notion of aligned and misaligned
filters at initialization and show that the data heterogeneity only affects
learning on misaligned filters. Starting with a pre-trained model typically
results in fewer misaligned filters at initialization, thus producing a lower
test error even when the model is trained in a federated setting with data
heterogeneity. Experiments in synthetic settings and practical FL training on
CNNs verify our theoretical findings.","Divyansh Jhunjhunwala, Pranay Sharma, Zheng Xu, Gauri Joshi",2025-02-11 23:53:16.000000,arXiv,http://arxiv.org/abs/2502.08024v1,Machine Learning
592,Model Selection for Off-policy Evaluation: New Algorithms and Experimental Protocol,"Holdout validation and hyperparameter tuning from data is a long-standing
problem in offline reinforcement learning (RL). A standard framework is to use
off-policy evaluation (OPE) methods to evaluate and select the policies, but
OPE either incurs exponential variance (e.g., importance sampling) or has
hyperparameters on their own (e.g., FQE and model-based). In this work we focus
on hyperparameter tuning for OPE itself, which is even more under-investigated.
Concretely, we select among candidate value functions (""model-free"") or
dynamics (""model-based"") to best assess the performance of a target policy. Our
contributions are two fold. We develop: (1) new model-free and model-based
selectors with theoretical guarantees, and (2) a new experimental protocol for
empirically evaluating them. Compared to the model-free protocol in prior
works, our new protocol allows for more stable generation of candidate value
functions, better control of misspecification, and evaluation of model-free and
model-based methods alike. We exemplify the protocol on a Gym environment, and
find that our new model-free selector, LSTD-Tournament, demonstrates promising
empirical performance.","Pai Liu, Lingfeng Zhao, Shivangi Agarwal, Jinghan Liu, Audrey Huang, Philip Amortila, Nan Jiang",2025-02-11 23:40:55.000000,arXiv,http://arxiv.org/abs/2502.08021v1,Machine Learning
593,"Speculate, then Collaborate: Fusing Knowledge of Language Models during Decoding","Large Language Models (LLMs) often excel in specific domains but fall short
in others due to the limitations of their training. Thus, enabling LLMs to
solve problems collaboratively by integrating their complementary knowledge
promises to improve their performance across domains. To realize this
potential, we introduce a novel Collaborative Speculative Decoding (CoSD)
algorithm that enables efficient LLM knowledge fusion at test time without
requiring additional model training. CoSD employs a draft model to generate
initial sequences and an easy-to-learn rule or decision tree to decide when to
invoke an assistant model to improve these drafts. CoSD not only enhances
knowledge fusion but also improves inference efficiency, is transferable across
domains and models, and offers greater explainability. Experimental results
demonstrate that CoSD improves accuracy by up to 10\% across benchmarks
compared to existing methods, providing a scalable and effective solution for
LLM-based applications","Ziyao Wang, Muneeza Azmart, Ang Li, Raya Horesh, Mikhail Yurochkin",2025-02-11 23:40:53.000000,arXiv,http://arxiv.org/abs/2502.08020v1,Natural Language Processing
594,Training-Free Safe Denoisers for Safe Use of Diffusion Models,"There is growing concern over the safety of powerful diffusion models (DMs),
as they are often misused to produce inappropriate, not-safe-for-work (NSFW)
content or generate copyrighted material or data of individuals who wish to be
forgotten. Many existing methods tackle these issues by heavily relying on
text-based negative prompts or extensively retraining DMs to eliminate certain
features or samples. In this paper, we take a radically different approach,
directly modifying the sampling trajectory by leveraging a negation set (e.g.,
unsafe images, copyrighted data, or datapoints needed to be excluded) to avoid
specific regions of data distribution, without needing to retrain or fine-tune
DMs. We formally derive the relationship between the expected denoised samples
that are safe and those that are not safe, leading to our $\textit{safe}$
denoiser which ensures its final samples are away from the area to be negated.
Inspired by the derivation, we develop a practical algorithm that successfully
produces high-quality samples while avoiding negation areas of the data
distribution in text-conditional, class-conditional, and unconditional image
generation scenarios. These results hint at the great potential of our
training-free safe denoiser for using DMs more safely.","Mingyu Kim, Dongjun Kim, Amman Yusuf, Stefano Ermon, Mi Jung Park",2025-02-11 23:14:39.000000,arXiv,http://arxiv.org/abs/2502.08011v2,Artificial Intelligence
595,The Geometry of Prompting: Unveiling Distinct Mechanisms of Task Adaptation in Language Models,"Decoder-only language models have the ability to dynamically switch between
various computational tasks based on input prompts. Despite many successful
applications of prompting, there is very limited understanding of the internal
mechanism behind such flexibility. In this work, we investigate how different
prompting methods affect the geometry of representations in these models.
Employing a framework grounded in statistical physics, we reveal that various
prompting techniques, while achieving similar performance, operate through
distinct representational mechanisms for task adaptation. Our analysis
highlights the critical role of input distribution samples and label semantics
in few-shot in-context learning. We also demonstrate evidence of synergistic
and interfering interactions between different tasks on the representational
level. Our work contributes to the theoretical understanding of large language
models and lays the groundwork for developing more effective,
representation-aware prompting strategies.","Artem Kirsanov, Chi-Ning Chou, Kyunghyun Cho, SueYeon Chung",2025-02-11 23:09:50.000000,arXiv,http://arxiv.org/abs/2502.08009v1,Natural Language Processing
596,An Interactive Framework for Implementing Privacy-Preserving Federated Learning: Experiments on Large Language Models,"Federated learning (FL) enhances privacy by keeping user data on local
devices. However, emerging attacks have demonstrated that the updates shared by
users during training can reveal significant information about their data. This
has greatly thwart the adoption of FL methods for training robust AI models in
sensitive applications. Differential Privacy (DP) is considered the gold
standard for safeguarding user data. However, DP guarantees are highly
conservative, providing worst-case privacy guarantees. This can result in
overestimating privacy needs, which may compromise the model's accuracy.
Additionally, interpretations of these privacy guarantees have proven to be
challenging in different contexts. This is further exacerbated when other
factors, such as the number of training iterations, data distribution, and
specific application requirements, can add further complexity to this problem.
In this work, we proposed a framework that integrates a human entity as a
privacy practitioner to determine an optimal trade-off between the model's
privacy and utility. Our framework is the first to address the variable memory
requirement of existing DP methods in FL settings, where resource-limited
devices (e.g., cell phones) can participate. To support such settings, we adopt
a recent DP method with fixed memory usage to ensure scalable private FL. We
evaluated our proposed framework by fine-tuning a BERT-based LLM model using
the GLUE dataset (a common approach in literature), leveraging the new
accountant, and employing diverse data partitioning strategies to mimic
real-world conditions. As a result, we achieved stable memory usage, with an
average accuracy reduction of 1.33% for $\epsilon = 10$ and 1.9% for $\epsilon
= 6$, when compared to the state-of-the-art DP accountant which does not
support fixed memory usage.","Kasra Ahmadi, Rouzbeh Behnia, Reza Ebrahimi, Mehran Mozaffari Kermani, Jeremiah Birrell, Jason Pacheco, Attila A Yavuz",2025-02-11 23:07:14.000000,arXiv,http://arxiv.org/abs/2502.08008v1,Machine Learning
597,The Role of Randomness in Stability,"Stability is a central property in learning and statistics promising the
output of an algorithm $A$ does not change substantially when applied to
similar datasets $S$ and $S'$. It is an elementary fact that any sufficiently
stable algorithm (e.g.\ one returning the same result with high probability,
satisfying privacy guarantees, etc.) must be randomized. This raises a natural
question: can we quantify how much randomness is needed for algorithmic
stability?
  We study the randomness complexity of two influential notions of stability in
learning: replicability, which promises $A$ usually outputs the same result
when run over samples from the same distribution (and shared random coins), and
differential privacy, which promises the output distribution of $A$ remains
similar under neighboring datasets. The randomness complexity of these notions
was studied recently in (Dixon et al. ICML 2024) and (Cannone et al. ITCS 2024)
for basic $d$-dimensional tasks (e.g. estimating the bias of $d$ coins), but
little is known about the measures more generally or in complex settings like
classification.
  Toward this end, we prove a `weak-to-strong' boosting theorem for stability:
the randomness complexity of a task $M$ (either under replicability or DP) is
tightly controlled by the best replication probability of any deterministic
algorithm solving the task, a weak measure called `global stability' that is
universally capped at $\frac{1}{2}$ (Chase et al. FOCS 2023). Using this, we
characterize the randomness complexity of PAC Learning: a class has bounded
randomness complexity iff it has finite Littlestone dimension, and moreover
scales at worst logarithmically in the excess error of the learner. This
resolves a question of (Chase et al. STOC 2024) who asked for such a
characterization in the equivalent language of (error-dependent)
`list-replicability'.","Max Hopkins, Shay Moran",2025-02-11 23:06:43.000000,arXiv,http://arxiv.org/abs/2502.08007v1,Machine Learning
598,Greed is Good: Guided Generation from a Greedy Perspective,"Training-free guided generation is a widely used and powerful technique that
allows the end user to exert further control over the generative process of
diffusion models. In this work, we explore the guided generation from the
perspective of optimizing the solution trajectory of a neural differential
equation in a greedy manner. We present such a strategy as a unifying view on
training-free guidance by showing that the greedy strategy is a first-order
discretization of end-to-end optimization techniques. We show that a greedy
guidance strategy makes good decisions and compare it to a guidance strategy
using the ideal gradients found via the continuous adjoint equations. We then
show how other popular training-free guidance strategies can be viewed in a
unified manner from this perspective.","Zander W. Blasingame, Chen Liu",2025-02-11 23:05:16.000000,arXiv,http://arxiv.org/abs/2502.08006v1,Machine Learning
599,Towards Training One-Step Diffusion Models Without Distillation,"Recent advances in one-step generative models typically follow a two-stage
process: first training a teacher diffusion model and then distilling it into a
one-step student model. This distillation process traditionally relies on both
the teacher model's score function to compute the distillation loss and its
weights for student initialization. In this paper, we explore whether one-step
generative models can be trained directly without this distillation process.
First, we show that the teacher's score function is not essential and propose a
family of distillation methods that achieve competitive results without relying
on score estimation. Next, we demonstrate that initialization from teacher
weights is indispensable in successful training. Surprisingly, we find that
this benefit is not due to improved ``input-output"" mapping but rather the
learned feature representations, which dominate distillation quality. Our
findings provide a better understanding of the role of initialization in
one-step model training and its impact on distillation quality.","Mingtian Zhang, Jiajun He, Wenlin Chen, Zijing Ou, José Miguel Hernández-Lobato, Bernhard Schölkopf, David Barber",2025-02-11 23:02:14.000000,arXiv,http://arxiv.org/abs/2502.08005v1,Machine Learning
600,Optimizing Likelihoods via Mutual Information: Bridging Simulation-Based Inference and Bayesian Optimal Experimental Design,"Simulation-based inference (SBI) is a method to perform inference on a
variety of complex scientific models with challenging inference (inverse)
problems. Bayesian Optimal Experimental Design (BOED) aims to efficiently use
experimental resources to make better inferences. Various stochastic
gradient-based BOED methods have been proposed as an alternative to Bayesian
optimization and other experimental design heuristics to maximize information
gain from an experiment. We demonstrate a link via mutual information bounds
between SBI and stochastic gradient-based variational inference methods that
permits BOED to be used in SBI applications as SBI-BOED. This link allows
simultaneous optimization of experimental designs and optimization of amortized
inference functions. We evaluate the pitfalls of naive design optimization
using this method in a standard SBI task and demonstrate the utility of a
well-chosen design distribution in BOED. We compare this approach on SBI-based
models in real-world simulators in epidemiology and biology, showing notable
improvements in inference.","Vincent D. Zaballa, Elliot E. Hui",2025-02-11 22:58:18.000000,arXiv,http://arxiv.org/abs/2502.08004v1,Statistical Machine Learning
601,Heterogeneous Multi-agent Multi-armed Bandits on Stochastic Block Models,"We study a novel heterogeneous multi-agent multi-armed bandit problem with a
cluster structure induced by stochastic block models, influencing not only
graph topology, but also reward heterogeneity. Specifically, agents are
distributed on random graphs based on stochastic block models - a generalized
Erdos-Renyi model with heterogeneous edge probabilities: agents are grouped
into clusters (known or unknown); edge probabilities for agents within the same
cluster differ from those across clusters. In addition, the cluster structure
in stochastic block model also determines our heterogeneous rewards. Rewards
distributions of the same arm vary across agents in different clusters but
remain consistent within a cluster, unifying homogeneous and heterogeneous
settings and varying degree of heterogeneity, and rewards are independent
samples from these distributions. The objective is to minimize system-wide
regret across all agents. To address this, we propose a novel algorithm
applicable to both known and unknown cluster settings. The algorithm combines
an averaging-based consensus approach with a newly introduced information
aggregation and weighting technique, resulting in a UCB-type strategy. It
accounts for graph randomness, leverages both intra-cluster (homogeneous) and
inter-cluster (heterogeneous) information from rewards and graphs, and
incorporates cluster detection for unknown cluster settings. We derive optimal
instance-dependent regret upper bounds of order $\log{T}$ under sub-Gaussian
rewards. Importantly, our regret bounds capture the degree of heterogeneity in
the system (an additional layer of complexity), exhibit smaller constants,
scale better for large systems, and impose significantly relaxed assumptions on
edge probabilities. In contrast, prior works have not accounted for this
refined problem complexity, rely on more stringent assumptions, and exhibit
limited scalability.","Mengfan Xu, Liren Shan, Fatemeh Ghaffari, Xuchuang Wang, Xutong Liu, Mohammad Hajiesmaili",2025-02-11 22:57:19.000000,arXiv,http://arxiv.org/abs/2502.08003v1,Machine Learning
602,Unveiling Client Privacy Leakage from Public Dataset Usage in Federated Distillation,"Federated Distillation (FD) has emerged as a popular federated training
framework, enabling clients to collaboratively train models without sharing
private data. Public Dataset-Assisted Federated Distillation (PDA-FD), which
leverages public datasets for knowledge sharing, has become widely adopted.
Although PDA-FD enhances privacy compared to traditional Federated Learning, we
demonstrate that the use of public datasets still poses significant privacy
risks to clients' private training data. This paper presents the first
comprehensive privacy analysis of PDA-FD in presence of an honest-but-curious
server. We show that the server can exploit clients' inference results on
public datasets to extract two critical types of private information: label
distributions and membership information of the private training dataset. To
quantify these vulnerabilities, we introduce two novel attacks specifically
designed for the PDA-FD setting: a label distribution inference attack and
innovative membership inference methods based on Likelihood Ratio Attack
(LiRA). Through extensive evaluation of three representative PDA-FD frameworks
(FedMD, DS-FL, and Cronus), our attacks achieve state-of-the-art performance,
with label distribution attacks reaching minimal KL-divergence and membership
inference attacks maintaining high True Positive Rates under low False Positive
Rate constraints. Our findings reveal significant privacy risks in current
PDA-FD frameworks and emphasize the need for more robust privacy protection
mechanisms in collaborative learning systems.","Haonan Shi, Tu Ouyang, An Wang",2025-02-11 22:48:49.000000,arXiv,http://arxiv.org/abs/2502.08001v1,Other
603,Adaptive kernel predictors from feature-learning infinite limits of neural networks,"Previous influential work showed that infinite width limits of neural
networks in the lazy training regime are described by kernel machines. Here, we
show that neural networks trained in the rich, feature learning infinite-width
regime in two different settings are also described by kernel machines, but
with data-dependent kernels. For both cases, we provide explicit expressions
for the kernel predictors and prescriptions to numerically calculate them. To
derive the first predictor, we study the large-width limit of feature-learning
Bayesian networks, showing how feature learning leads to task-relevant
adaptation of layer kernels and preactivation densities. The saddle point
equations governing this limit result in a min-max optimization problem that
defines the kernel predictor. To derive the second predictor, we study gradient
flow training of randomly initialized networks trained with weight decay in the
infinite-width limit using dynamical mean field theory (DMFT). The fixed point
equations of the arising DMFT defines the task-adapted internal representations
and the kernel predictor. We compare our kernel predictors to kernels derived
from lazy regime and demonstrate that our adaptive kernels achieve lower test
loss on benchmark datasets.","Clarissa Lauditi, Blake Bordelon, Cengiz Pehlevan",2025-02-11 22:34:49.000000,arXiv,http://arxiv.org/abs/2502.07998v1,Machine Learning
604,What is a Sketch-and-Precondition Derivation for Low-Rank Approximation? Inverse Power Error or Inverse Power Estimation?,"Randomized sketching accelerates large-scale numerical linear algebra by
reducing computa- tional complexity. While the traditional sketch-and-solve
approach reduces the problem size di- rectly through sketching, the
sketch-and-precondition method leverages sketching to construct a computational
friendly preconditioner. This preconditioner improves the convergence speed of
iterative solvers applied to the original problem, maintaining accuracy in the
full space. Further- more, the convergence rate of the solver improves at least
linearly with the sketch size. Despite its potential, developing a
sketch-and-precondition framework for randomized algorithms in low- rank matrix
approximation remains an open challenge. We introduce the Error-Powered
Sketched Inverse Iteration (EPSI) Method via run sketched Newton iteration for
the Lagrange form as a sketch-and-precondition variant for randomized low-rank
approximation. Our method achieves theoretical guarantees, including a
convergence rate that improves at least linearly with the sketch size.","Ruihan Xu, Yiping Lu",2025-02-11 22:19:56.000000,arXiv,http://arxiv.org/abs/2502.07993v1,Other
605,Learning Effective Dynamics across Spatio-Temporal Scales of Complex Flows,"Modeling and simulation of complex fluid flows with dynamics that span
multiple spatio-temporal scales is a fundamental challenge in many scientific
and engineering domains. Full-scale resolving simulations for systems such as
highly turbulent flows are not feasible in the foreseeable future, and
reduced-order models must capture dynamics that involve interactions across
scales. In the present work, we propose a novel framework, Graph-based Learning
of Effective Dynamics (Graph-LED), that leverages graph neural networks (GNNs),
as well as an attention-based autoregressive model, to extract the effective
dynamics from a small amount of simulation data. GNNs represent flow fields on
unstructured meshes as graphs and effectively handle complex geometries and
non-uniform grids. The proposed method combines a GNN based, dimensionality
reduction for variable-size unstructured meshes with an autoregressive temporal
attention model that can learn temporal dependencies automatically. We
evaluated the proposed approach on a suite of fluid dynamics problems,
including flow past a cylinder and flow over a backward-facing step over a
range of Reynolds numbers. The results demonstrate robust and effective
forecasting of spatio-temporal physics; in the case of the flow past a
cylinder, both small-scale effects that occur close to the cylinder as well as
its wake are accurately captured.","Han Gao, Sebastian Kaltenbach, Petros Koumoutsakos",2025-02-11 22:14:30.000000,arXiv,http://arxiv.org/abs/2502.07990v1,Machine Learning
606,Universal Adversarial Attack on Aligned Multimodal LLMs,"We propose a universal adversarial attack on multimodal Large Language Models
(LLMs) that leverages a single optimized image to override alignment safeguards
across diverse queries and even multiple models. By backpropagating through the
vision encoder and language head, we craft a synthetic image that forces the
model to respond with a targeted phrase (e.g., ''Sure, here it is'') or
otherwise unsafe content-even for harmful prompts. In experiments on the
SafeBench benchmark, our method achieves significantly higher attack success
rates than existing baselines, including text-only universal prompts (e.g., up
to 93% on certain models). We further demonstrate cross-model transferability
by training on several multimodal LLMs simultaneously and testing on unseen
architectures. Additionally, a multi-answer variant of our approach produces
more natural-sounding (yet still malicious) responses. These findings
underscore critical vulnerabilities in current multimodal alignment and call
for more robust adversarial defenses. We will release code and datasets under
the Apache-2.0 license. Warning: some content generated by Multimodal LLMs in
this paper may be offensive to some readers.","Temurbek Rahmatullaev, Polina Druzhinina, Matvey Mikhalchuk, Andrey Kuznetsov, Anton Razzhigaev",2025-02-11 22:07:47.000000,arXiv,http://arxiv.org/abs/2502.07987v2,Artificial Intelligence
607,MetaSC: Test-Time Safety Specification Optimization for Language Models,"We propose a novel dynamic safety framework that optimizes language model
(LM) safety reasoning at inference time without modifying model weights.
Building on recent advances in self-critique methods, our approach leverages a
meta-critique mechanism that iteratively updates safety prompts-termed
specifications-to drive the critique and revision process adaptively. This
test-time optimization not only improves performance against adversarial
jailbreak requests but also in diverse general safety-related tasks, such as
avoiding moral harm or pursuing honest responses. Our empirical evaluations
across several language models demonstrate that dynamically optimized safety
prompts yield significantly higher safety scores compared to fixed system
prompts and static self-critique defenses. Code to be released at
https://github.com/vicgalle/meta-self-critique.git .",Víctor Gallego,2025-02-11 22:06:25.000000,arXiv,http://arxiv.org/abs/2502.07985v1,Natural Language Processing
608,Deep Semantic Graph Learning via LLM based Node Enhancement,"Graph learning has attracted significant attention due to its widespread
real-world applications. Current mainstream approaches rely on text node
features and obtain initial node embeddings through shallow embedding learning
using GNNs, which shows limitations in capturing deep textual semantics. Recent
advances in Large Language Models (LLMs) have demonstrated superior
capabilities in understanding text semantics, transforming traditional text
feature processing. This paper proposes a novel framework that combines Graph
Transformer architecture with LLM-enhanced node features. Specifically, we
leverage LLMs to generate rich semantic representations of text nodes, which
are then processed by a multi-head self-attention mechanism in the Graph
Transformer to capture both local and global graph structural information. Our
model utilizes the Transformer's attention mechanism to dynamically aggregate
neighborhood information while preserving the semantic richness provided by LLM
embeddings. Experimental results demonstrate that the LLM-enhanced node
features significantly improve the performance of graph learning models on node
classification tasks. This approach shows promising results across multiple
graph learning tasks, offering a practical direction for combining graph
networks with language models.","Chuanqi Shi, Yiyi Tao, Hang Zhang, Lun Wang, Shaoshuai Du, Yixian Shen, Yanxin Shen",2025-02-11 21:55:46.000000,arXiv,http://arxiv.org/abs/2502.07982v1,Artificial Intelligence
609,CIRCUIT: A Benchmark for Circuit Interpretation and Reasoning Capabilities of LLMs,"The role of Large Language Models (LLMs) has not been extensively explored in
analog circuit design, which could benefit from a reasoning-based approach that
transcends traditional optimization techniques. In particular, despite their
growing relevance, there are no benchmarks to assess LLMs' reasoning capability
about circuits. Therefore, we created the CIRCUIT dataset consisting of 510
question-answer pairs spanning various levels of analog-circuit-related
subjects. The best-performing model on our dataset, GPT-4o, achieves 48.04%
accuracy when evaluated on the final numerical answer. To evaluate the
robustness of LLMs on our dataset, we introduced a unique feature that enables
unit-test-like evaluation by grouping questions into unit tests. In this case,
GPT-4o can only pass 27.45% of the unit tests, highlighting that the most
advanced LLMs still struggle with understanding circuits, which requires
multi-level reasoning, particularly when involving circuit topologies. This
circuit-specific benchmark highlights LLMs' limitations, offering valuable
insights for advancing their application in analog integrated circuit design.","Lejla Skelic, Yan Xu, Matthew Cox, Wenjie Lu, Tao Yu, Ruonan Han",2025-02-11 21:53:48.000000,arXiv,http://arxiv.org/abs/2502.07980v1,Machine Learning
610,Joint Modelling Histology and Molecular Markers for Cancer Classification,"Cancers are characterized by remarkable heterogeneity and diverse prognosis.
Accurate cancer classification is essential for patient stratification and
clinical decision-making. Although digital pathology has been advancing cancer
diagnosis and prognosis, the paradigm in cancer pathology has shifted from
purely relying on histology features to incorporating molecular markers. There
is an urgent need for digital pathology methods to meet the needs of the new
paradigm. We introduce a novel digital pathology approach to jointly predict
molecular markers and histology features and model their interactions for
cancer classification. Firstly, to mitigate the challenge of
cross-magnification information propagation, we propose a multi-scale
disentangling module, enabling the extraction of multi-scale features from
high-magnification (cellular-level) to low-magnification (tissue-level) whole
slide images. Further, based on the multi-scale features, we propose an
attention-based hierarchical multi-task multi-instance learning framework to
simultaneously predict histology and molecular markers. Moreover, we propose a
co-occurrence probability-based label correlation graph network to model the
co-occurrence of molecular markers. Lastly, we design a cross-modal interaction
module with the dynamic confidence constrain loss and a cross-modal gradient
modulation strategy, to model the interactions of histology and molecular
markers. Our experiments demonstrate that our method outperforms other
state-of-the-art methods in classifying glioma, histology features and
molecular markers. Our method promises to promote precise oncology with the
potential to advance biomedical research and clinical applications. The code is
available at https://github.com/LHY1007/M3C2","Xiaofei Wang, Hanyu Liu, Yupei Zhang, Boyang Zhao, Hao Duan, Wanming Hu, Yonggao Mou, Stephen Price, Chao Li",2025-02-11 21:52:32.000000,arXiv,http://arxiv.org/abs/2502.07979v1,Computer Vision
611,A Survey of In-Context Reinforcement Learning,"Reinforcement learning (RL) agents typically optimize their policies by
performing expensive backward passes to update their network parameters.
However, some agents can solve new tasks without updating any parameters by
simply conditioning on additional context such as their action-observation
histories. This paper surveys work on such behavior, known as in-context
reinforcement learning.","Amir Moeini, Jiuqi Wang, Jacob Beck, Ethan Blaser, Shimon Whiteson, Rohan Chandra, Shangtong Zhang",2025-02-11 21:52:19.000000,arXiv,http://arxiv.org/abs/2502.07978v1,Machine Learning
612,RESIST: Resilient Decentralized Learning Using Consensus Gradient Descent,"Empirical risk minimization (ERM) is a cornerstone of modern machine learning
(ML), supported by advances in optimization theory that ensure efficient
solutions with provable algorithmic convergence rates, which measure the speed
at which optimization algorithms approach a solution, and statistical learning
rates, which characterize how well the solution generalizes to unseen data.
Privacy, memory, computational, and communications constraints increasingly
necessitate data collection, processing, and storage across network-connected
devices. In many applications, these networks operate in decentralized settings
where a central server cannot be assumed, requiring decentralized ML algorithms
that are both efficient and resilient. Decentralized learning, however, faces
significant challenges, including an increased attack surface for adversarial
interference during decentralized learning processes. This paper focuses on the
man-in-the-middle (MITM) attack, which can cause models to deviate
significantly from their intended ERM solutions. To address this challenge, we
propose RESIST (Resilient dEcentralized learning using conSensus gradIent
deScenT), an optimization algorithm designed to be robust against adversarially
compromised communication links. RESIST achieves algorithmic and statistical
convergence for strongly convex, Polyak-Lojasiewicz, and nonconvex ERM
problems. Experimental results demonstrate the robustness and scalability of
RESIST for real-world decentralized learning in adversarial environments.","Cheng Fang, Rishabh Dixit, Waheed U. Bajwa, Mert Gurbuzbalaban",2025-02-11 21:48:10.000000,arXiv,http://arxiv.org/abs/2502.07977v1,Machine Learning
613,Sink equilibria and the attractors of learning in games,"Characterizing the limit behavior -- that is, the attractors -- of learning
dynamics is one of the most fundamental open questions in game theory. In
recent work in this front, it was conjectured that the attractors of the
replicator dynamic are in one-to-one correspondence with the sink equilibria of
the game -- the sink strongly connected components of a game's preference graph
-- , and it was established that they do stand in at least one-to-many
correspondence with them. We make threefold progress on the problem of
characterizing attractors. First, we show through a topological construction
that the one-to-one conjecture is false. Second, we make progress on the
attractor characterization problem for two-player games by establishing that
the one-to-one conjecture is true in the absence of a local pattern called a
weak local source -- a pattern that is absent from zero-sum games. Finally, we
look -- for the first time in this context -- at fictitious play, the
longest-studied learning dynamic, and examine to what extent the conjecture
generalizes there. We establish that under fictitious play, sink equilibria
always contain attractors (sometimes strictly), and every attractor corresponds
to a strongly connected set of nodes in the preference graph.","Oliver Biggar, Christos Papadimitriou",2025-02-11 21:40:11.000000,arXiv,http://arxiv.org/abs/2502.07975v1,Other
614,From Hazard Identification to Controller Design: Proactive and LLM-Supported Safety Engineering for ML-Powered Systems,"Machine learning (ML) components are increasingly integrated into software
products, yet their complexity and inherent uncertainty often lead to
unintended and hazardous consequences, both for individuals and society at
large. Despite these risks, practitioners seldom adopt proactive approaches to
anticipate and mitigate hazards before they occur. Traditional safety
engineering approaches, such as Failure Mode and Effects Analysis (FMEA) and
System Theoretic Process Analysis (STPA), offer systematic frameworks for early
risk identification but are rarely adopted. This position paper advocates for
integrating hazard analysis into the development of any ML-powered software
product and calls for greater support to make this process accessible to
developers. By using large language models (LLMs) to partially automate a
modified STPA process with human oversight at critical steps, we expect to
address two key challenges: the heavy dependency on highly experienced safety
engineering experts, and the time-consuming, labor-intensive nature of
traditional hazard analysis, which often impedes its integration into
real-world development workflows. We illustrate our approach with a running
example, demonstrating that many seemingly unanticipated issues can, in fact,
be anticipated.","Yining Hong, Christopher S. Timperley, Christian Kästner",2025-02-11 21:37:19.000000,arXiv,http://arxiv.org/abs/2502.07974v1,Other
615,Training Sparse Mixture Of Experts Text Embedding Models,"Transformer-based text embedding models have improved their performance on
benchmarks like MIRACL and BEIR by increasing their parameter counts. However,
this scaling approach introduces significant deployment challenges, including
increased inference latency and memory usage. These challenges are particularly
severe in retrieval-augmented generation (RAG) applications, where large
models' increased memory requirements constrain dataset ingestion capacity, and
their higher latency directly impacts query-time performance. While causal
language models have addressed similar efficiency challenges using Mixture of
Experts (MoE) architectures, this approach hasn't been successfully adapted to
the general text embedding setting. In this paper, we introduce Nomic Embed v2,
the first general purpose MoE text embedding model. Our model outperforms
models in the same parameter class on both monolingual and multilingual
benchmarks while also maintaining competitive performance with models twice its
size. We open-source all code, models, and evaluation data to ensure full
reproducibility of our training pipeline at
\href{https://github.com/nomic-ai/contrastors}{https://github.com/nomic-ai/contrastors}.","Zach Nussbaum, Brandon Duderstadt",2025-02-11 21:36:31.000000,arXiv,http://arxiv.org/abs/2502.07972v2,Natural Language Processing
616,ReTreever: Tree-based Coarse-to-Fine Representations for Retrieval,"Document retrieval is a core component of question-answering systems, as it
enables conditioning answer generation on new and large-scale corpora. While
effective, the standard practice of encoding documents into high-dimensional
embeddings for similarity search entails large memory and compute footprints,
and also makes it hard to inspect the inner workings of the system. In this
paper, we propose a tree-based method for organizing and representing reference
documents at various granular levels, which offers the flexibility to balance
cost and utility, and eases the inspection of the corpus content and retrieval
operations. Our method, called ReTreever, jointly learns a routing function per
internal node of a binary tree such that query and reference documents are
assigned to similar tree branches, hence directly optimizing for retrieval
performance. Our evaluations show that ReTreever generally preserves full
representation accuracy. Its hierarchical structure further provides strong
coarse representations and enhances transparency by indirectly learning
meaningful semantic groupings. Among hierarchical retrieval methods, ReTreever
achieves the best retrieval accuracy at the lowest latency, proving that this
family of techniques can be viable in practical applications.","Shubham Gupta, Zichao Li, Tianyi Chen, Cem Subakan, Siva Reddy, Perouz Taslakian, Valentina Zantedeschi",2025-02-11 21:35:13.000000,arXiv,http://arxiv.org/abs/2502.07971v1,Information Retrieval
617,Generative Risk Minimization for Out-of-Distribution Generalization on Graphs,"Out-of-distribution (OOD) generalization on graphs aims at dealing with
scenarios where the test graph distribution differs from the training graph
distributions. Compared to i.i.d. data like images, the OOD generalization
problem on graph-structured data remains challenging due to the non-i.i.d.
property and complex structural information on graphs. Recently, several works
on graph OOD generalization have explored extracting invariant subgraphs that
share crucial classification information across different distributions.
Nevertheless, such a strategy could be suboptimal for entirely capturing the
invariant information, as the extraction of discrete structures could
potentially lead to the loss of invariant information or the involvement of
spurious information. In this paper, we propose an innovative framework, named
Generative Risk Minimization (GRM), designed to generate an invariant subgraph
for each input graph to be classified, instead of extraction. To address the
challenge of optimization in the absence of optimal invariant subgraphs (i.e.,
ground truths), we derive a tractable form of the proposed GRM objective by
introducing a latent causal variable, and its effectiveness is validated by our
theoretical analysis. We further conduct extensive experiments across a variety
of real-world graph datasets for both node-level and graph-level OOD
generalization, and the results demonstrate the superiority of our framework
GRM.","Song Wang, Zhen Tan, Yaochen Zhu, Chuxu Zhang, Jundong Li",2025-02-11 21:24:13.000000,arXiv,http://arxiv.org/abs/2502.07968v1,Machine Learning
618,New tools for comparing classical and neural ODE models for tumor growth,"A new computational tool TumorGrowth.jl for modeling tumor growth is
introduced. The tool allows the comparison of standard textbook models, such as
General Bertalanffy and Gompertz, with some newer models, including, for the
first time, neural ODE models. As an application, we revisit a human meta-study
of non-small cell lung cancer and bladder cancer lesions, in patients
undergoing two different treatment options, to determine if previously reported
performance differences are statistically significant, and if newer, more
complex models perform any better. In a population of examples with at least
four time-volume measurements available for calibration, and an average of
about 6.3, our main conclusion is that the General Bertalanffy model has
superior performance, on average. However, where more measurements are
available, we argue that more complex models, capable of capturing rebound and
relapse behavior, may be better choices.","Anthony D. Blaom, Samuel Okon",2025-02-11 21:21:28.000000,arXiv,http://arxiv.org/abs/2502.07964v1,Machine Learning
619,Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?,"Medical research faces well-documented challenges in translating novel
treatments into clinical practice. Publishing incentives encourage researchers
to present ""positive"" findings, even when empirical results are equivocal.
Consequently, it is well-documented that authors often spin study results,
especially in article abstracts. Such spin can influence clinician
interpretation of evidence and may affect patient care decisions. In this
study, we ask whether the interpretation of trial results offered by Large
Language Models (LLMs) is similarly affected by spin. This is important since
LLMs are increasingly being used to trawl through and synthesize published
medical evidence. We evaluated 22 LLMs and found that they are across the board
more susceptible to spin than humans. They might also propagate spin into their
outputs: We find evidence, e.g., that LLMs implicitly incorporate spin into
plain language summaries that they generate. We also find, however, that LLMs
are generally capable of recognizing spin, and can be prompted in a way to
mitigate spin's impact on LLM outputs.","Hye Sun Yun, Karen Y. C. Zhang, Ramez Kouzy, Iain J. Marshall, Junyi Jessy Li, Byron C. Wallace",2025-02-11 21:21:05.000000,arXiv,http://arxiv.org/abs/2502.07963v1,Natural Language Processing
620,ESPFormer: Doubly-Stochastic Attention with Expected Sliced Transport Plans,"While self-attention has been instrumental in the success of Transformers, it
can lead to over-concentration on a few tokens during training, resulting in
suboptimal information flow. Enforcing doubly-stochastic constraints in
attention matrices has been shown to improve structure and balance in attention
distributions. However, existing methods rely on iterative Sinkhorn
normalization, which is computationally costly. In this paper, we introduce a
novel, fully parallelizable doubly-stochastic attention mechanism based on
sliced optimal transport, leveraging Expected Sliced Transport Plans (ESP).
Unlike prior approaches, our method enforces double stochasticity without
iterative Sinkhorn normalization, significantly enhancing efficiency. To ensure
differentiability, we incorporate a temperature-based soft sorting technique,
enabling seamless integration into deep learning models. Experiments across
multiple benchmark datasets, including image classification, point cloud
classification, sentiment analysis, and neural machine translation, demonstrate
that our enhanced attention regularization consistently improves performance
across diverse applications.","Ashkan Shahbazi, Elaheh Akbari, Darian Salehi, Xinran Liu, Navid Naderializadeh, Soheil Kolouri",2025-02-11 21:20:48.000000,arXiv,http://arxiv.org/abs/2502.07962v1,Machine Learning
621,Intrinsic Bias is Predicted by Pretraining Data and Correlates with Downstream Performance in Vision-Language Encoders,"While recent work has found that vision-language models trained under the
Contrastive Language Image Pre-training (CLIP) framework contain intrinsic
social biases, the extent to which different upstream pre-training features of
the framework relate to these biases, and hence how intrinsic bias and
downstream performance are connected has been unclear. In this work, we present
the largest comprehensive analysis to-date of how the upstream pre-training
factors and downstream performance of CLIP models relate to their intrinsic
biases. Studying 131 unique CLIP models, trained on 26 datasets, using 55
architectures, and in a variety of sizes, we evaluate bias in each model using
26 well-established unimodal and cross-modal principled Embedding Association
Tests. We find that the choice of pre-training dataset is the most significant
upstream predictor of bias, whereas architectural variations have minimal
impact. Additionally, datasets curated using sophisticated filtering techniques
aimed at enhancing downstream model performance tend to be associated with
higher levels of intrinsic bias. Finally, we observe that intrinsic bias is
often significantly correlated with downstream performance ($0.3 \leq r \leq
0.8$), suggesting that models optimized for performance inadvertently learn to
amplify representational biases. Comparisons between unimodal and cross-modal
association tests reveal that social group bias depends heavily on the
modality. Our findings imply that more sophisticated strategies are needed to
address intrinsic model bias for vision-language models across the entire model
development pipeline.","Kshitish Ghate, Isaac Slaughter, Kyra Wilson, Mona Diab, Aylin Caliskan",2025-02-11 21:11:47.000000,arXiv,http://arxiv.org/abs/2502.07957v1,Artificial Intelligence
622,Federated Self-supervised Domain Generalization for Label-efficient Polyp Segmentation,"Employing self-supervised learning (SSL) methodologies assumes par-amount
significance in handling unlabeled polyp datasets when building deep
learning-based automatic polyp segmentation models. However, the intricate
privacy dynamics surrounding medical data often preclude seamless data sharing
among disparate medical centers. Federated learning (FL) emerges as a
formidable solution to this privacy conundrum, yet within the realm of FL,
optimizing model generalization stands as a pressing imperative. Robust
generalization capabilities are imperative to ensure the model's efficacy
across diverse geographical domains post-training on localized client datasets.
In this paper, a Federated self-supervised Domain Generalization method is
proposed to enhance the generalization capacity of federated and
Label-efficient intestinal polyp segmentation, named LFDG. Based on a classical
SSL method, DropPos, LFDG proposes an adversarial learning-based data
augmentation method (SSADA) to enhance the data diversity. LFDG further
proposes a relaxation module based on Source-reconstruction and
Augmentation-masking (SRAM) to maintain stability in feature learning. We have
validated LFDG on polyp images from six medical centers. The performance of our
method achieves 3.80% and 3.92% better than the baseline and other recent FL
methods and SSL methods, respectively.","Xinyi Tan, Jiacheng Wang, Liansheng Wang",2025-02-11 21:00:01.000000,arXiv,http://arxiv.org/abs/2502.07951v1,Computer Vision
623,VSC-RL: Advancing Autonomous Vision-Language Agents with Variational Subgoal-Conditioned Reinforcement Learning,"State-of-the-art (SOTA) reinforcement learning (RL) methods enable the
vision-language agents to learn from interactions with the environment without
human supervision. However, they struggle with learning inefficiencies in
tackling real-world complex sequential decision-making tasks, especially with
sparse reward signals and long-horizon dependencies. To effectively address the
issue, we introduce Variational Subgoal-Conditioned RL (VSC-RL), which
reformulates the vision-language sequential decision-making task as a
variational goal-conditioned RL problem, allowing us to leverage advanced
optimization methods to enhance learning efficiency. Specifically, VSC-RL
optimizes the SubGoal Evidence Lower BOund (SGC-ELBO), which consists of (a)
maximizing the subgoal-conditioned return via RL and (b) minimizing the
subgoal-conditioned difference with the reference policy. We theoretically
demonstrate that SGC-ELBO is equivalent to the original optimization objective,
ensuring improved learning efficiency without sacrificing performance
guarantees. Additionally, for real-world complex decision-making tasks, VSC-RL
leverages the vision-language model to autonomously decompose the goal into
feasible subgoals, enabling efficient learning. Across various benchmarks,
including challenging real-world mobile device control tasks, VSC-RL
significantly outperforms the SOTA vision-language agents, achieving superior
performance and remarkable improvement in learning efficiency.","Qingyuan Wu, Jianheng Liu, Jianye Hao, Jun Wang, Kun Shao",2025-02-11 20:57:46.000000,arXiv,http://arxiv.org/abs/2502.07949v1,Machine Learning
624,SurGrID: Controllable Surgical Simulation via Scene Graph to Image Diffusion,"Surgical simulation offers a promising addition to conventional surgical
training. However, available simulation tools lack photorealism and rely on
hardcoded behaviour. Denoising Diffusion Models are a promising alternative for
high-fidelity image synthesis, but existing state-of-the-art conditioning
methods fall short in providing precise control or interactivity over the
generated scenes.
  We introduce SurGrID, a Scene Graph to Image Diffusion Model, allowing for
controllable surgical scene synthesis by leveraging Scene Graphs. These graphs
encode a surgical scene's components' spatial and semantic information, which
are then translated into an intermediate representation using our novel
pre-training step that explicitly captures local and global information.
  Our proposed method improves the fidelity of generated images and their
coherence with the graph input over the state-of-the-art. Further, we
demonstrate the simulation's realism and controllability in a user assessment
study involving clinical experts.
  Scene Graphs can be effectively used for precise and interactive conditioning
of Denoising Diffusion Models for simulating surgical scenes, enabling high
fidelity and interactive control over the generated content.","Yannik Frisch, Ssharvien Kumar Sivakumar, Çağhan Köksal, Elsa Böhm, Felix Wagner, Adrian Gericke, Ghazal Ghazaei, Anirban Mukhopadhyay",2025-02-11 20:49:13.000000,arXiv,http://arxiv.org/abs/2502.07945v1,Computer Vision
625,SHACL-SKOS Based Knowledge Representation of Material Safety Data Sheet (SDS) for the Pharmaceutical Industry,"We report the development of a knowledge representation and reasoning (KRR)
system built on hybrid SHACL-SKOS ontologies for globally harmonized system
(GHS) material Safety Data Sheets (SDS) to enhance chemical safety
communication and regulatory compliance. SDS are comprehensive documents
containing safety and handling information for chemical substances. Thus, they
are an essential part of workplace safety and risk management. However, the
vast number of Safety Data Sheets from multiple organizations, manufacturers,
and suppliers that produce and distribute chemicals makes it challenging to
centralize and access SDS documents through a single repository. To accomplish
the underlying issues of data exchange related to chemical shipping and
handling, we construct SDS related controlled vocabulary and conditions
validated by SHACL, and knowledge systems of similar domains linked via SKOS.
The resulting hybrid ontologies aim to provide standardized yet adaptable
representations of SDS information, facilitating better data sharing,
retrieval, and integration across various platforms. This paper outlines our
SHACL-SKOS system architectural design and showcases our implementation for an
industrial application streamlining the generation of a composite shipping
cover sheet.","Brian Lu, Dennis Pham, Ti-Chiun Chang, Michael Lovette, Terri Bui, Stephen Ma",2025-02-11 20:44:45.000000,arXiv,http://arxiv.org/abs/2502.07944v1,Artificial Intelligence
626,CREDAL: Close Reading of Data Models,"Data models are necessary for the birth of data and of any data-driven
system. Indeed, every algorithm, every machine learning model, every
statistical model, and every database has an underlying data model without
which the system would not be usable. Hence, data models are excellent sites
for interrogating the (material, social, political, ...) conditions giving rise
to a data system. Towards this, drawing inspiration from literary criticism, we
propose to closely read data models in the same spirit as we closely read
literary artifacts. Close readings of data models reconnect us with, among
other things, the materiality, the genealogies, the techne, the closed nature,
and the design of technical systems.
  While recognizing from literary theory that there is no one correct way to
read, it is nonetheless critical to have systematic guidance for those
unfamiliar with close readings. This is especially true for those trained in
the computing and data sciences, who too often are enculturated to set aside
the socio-political aspects of data work. A systematic methodology for reading
data models currently does not exist. To fill this gap, we present the CREDAL
methodology for close readings of data models. We detail our iterative
development process and present results of a qualitative evaluation of CREDAL
demonstrating its usability, usefulness, and effectiveness in the critical
study of data.","George Fletcher, Olha Nahurna, Matvii Prytula, Julia Stoyanovich",2025-02-11 20:42:56.000000,arXiv,http://arxiv.org/abs/2502.07943v1,Other
627,Symbiotic Cooperation for Web Agents: Harnessing Complementary Strengths of Large and Small LLMs,"Web browsing agents powered by large language models (LLMs) have shown
tremendous potential in automating complex web-based tasks. Existing approaches
typically rely on large LLMs (e.g., GPT-4o) to explore web environments and
generate trajectory data, which is then used either for demonstration retrieval
(for large LLMs) or to distill small LLMs (e.g., Llama3) in a process that
remains decoupled from the exploration. In this paper, we propose
AgentSymbiotic, an iterative framework that couples data synthesis with
task-performance, yielding a ""symbiotic improvement"" for both large and small
LLMs. Our study uncovers a complementary dynamic between LLM types: while large
LLMs excel at generating high-quality trajectories for distillation, the
distilled small LLMs-owing to their distinct reasoning capabilities-often
choose actions that diverge from those of their larger counterparts. This
divergence drives the exploration of novel trajectories, thereby enriching the
synthesized data. However, we also observe that the performance of small LLMs
becomes a bottleneck in this iterative enhancement process. To address this, we
propose two innovations in LLM distillation: a speculative data synthesis
strategy that mitigates off-policy bias, and a multi-task learning approach
designed to boost the reasoning capabilities of the student LLM. Furthermore,
we introduce a Hybrid Mode for Privacy Preservation to address user privacy
concerns. Evaluated on the WEBARENA benchmark, AgentSymbiotic achieves SOTA
performance with both LLM types. Our best Large LLM agent reaches 52%,
surpassing the previous best of 45%, while our 8B distilled model demonstrates
a competitive 49%, exceeding the prior best of 28%. Code will be released upon
acceptance.","Ruichen Zhang, Mufan Qiu, Zhen Tan, Mohan Zhang, Vincent Lu, Jie Peng, Kaidi Xu, Leandro Z. Agudelo, Peter Qian, Tianlong Chen",2025-02-11 20:41:49.000000,arXiv,http://arxiv.org/abs/2502.07942v1,Multi-Agent Systems
628,Discrete Markov Probabilistic Models,"This paper introduces the Discrete Markov Probabilistic Model (DMPM), a novel
algorithm for discrete data generation. The algorithm operates in the space of
bits $\{0,1\}^d$, where the noising process is a continuous-time Markov chain
that can be sampled exactly via a Poissonian clock that flips labels uniformly
at random. The time-reversal process, like the forward noise process, is a jump
process, with its intensity governed by a discrete analogue of the classical
score function. Crucially, this intensity is proven to be the conditional
expectation of a function of the forward process, strengthening its theoretical
alignment with score-based generative models while ensuring robustness and
efficiency. We further establish convergence bounds for the algorithm under
minimal assumptions and demonstrate its effectiveness through experiments on
low-dimensional Bernoulli-distributed datasets and high-dimensional binary
MNIST data. The results highlight its strong performance in generating discrete
structures. This work bridges theoretical foundations and practical
applications, advancing the development of effective and theoretically grounded
discrete generative modeling.","Le-Tuyet-Nhi Pham, Dario Shariatian, Antonio Ocello, Giovanni Conforti, Alain Durmus",2025-02-11 20:36:23.000000,arXiv,http://arxiv.org/abs/2502.07939v1,Statistical Machine Learning
629,Adapting Multilingual Embedding Models to Historical Luxembourgish,"The growing volume of digitized historical texts requires effective semantic
search using text embeddings. However, pre-trained multilingual models,
typically evaluated on contemporary texts, face challenges with historical
digitized content due to OCR noise and outdated spellings. We explore the use
of multilingual embeddings for cross-lingual semantic search on historical
Luxembourgish, a low-resource language. We collect historical Luxembourgish
news articles spanning various time periods and use GPT-4o to segment and
translate them into closely related languages, creating 20,000 parallel
training sentences per language pair. We further create a historical bitext
mining evaluation set and find that these models struggle to perform
cross-lingual search on historical Luxembourgish. To address this, we propose a
simple adaptation method using in-domain training data, achieving up to 98\%
accuracy in cross-lingual evaluations. We release our adapted models and
historical Luxembourgish-German/French bitexts to support further research.","Andrianos Michail, Corina Julia Raclé, Juri Opitz, Simon Clematide",2025-02-11 20:35:29.000000,arXiv,http://arxiv.org/abs/2502.07938v1,Natural Language Processing
630,Active Advantage-Aligned Online Reinforcement Learning with Offline Data,"Online reinforcement learning (RL) enhances policies through direct
interactions with the environment, but faces challenges related to sample
efficiency. In contrast, offline RL leverages extensive pre-collected data to
learn policies, but often produces suboptimal results due to limited data
coverage. Recent efforts have sought to integrate offline and online RL in
order to harness the advantages of both approaches. However, effectively
combining online and offline RL remains challenging due to issues that include
catastrophic forgetting, lack of robustness and sample efficiency. In an effort
to address these challenges, we introduce A3 RL , a novel method that actively
selects data from combined online and offline sources to optimize policy
improvement. We provide theoretical guarantee that validates the effectiveness
our active sampling strategy and conduct thorough empirical experiments showing
that our method outperforms existing state-of-the-art online RL techniques that
utilize offline data. Our code will be publicly available at:
https://github.com/xuefeng-cs/A3RL.","Xuefeng Liu, Hung T. C. Le, Siyu Chen, Rick Stevens, Zhuoran Yang, Matthew R. Walter, Yuxin Chen",2025-02-11 20:31:59.000000,arXiv,http://arxiv.org/abs/2502.07937v1,Machine Learning
631,Educating a Responsible AI Workforce: Piloting a Curricular Module on AI Policy in a Graduate Machine Learning Course,"As artificial intelligence (AI) technologies begin to permeate diverse
fields-from healthcare to education-consumers, researchers and policymakers are
increasingly raising concerns about whether and how AI is regulated. It is
therefore reasonable to anticipate that alignment with principles of 'ethical'
or 'responsible' AI, as well as compliance with law and policy, will form an
increasingly important part of AI development. Yet, for the most part, the
conventional computer science curriculum is ill-equipped to prepare students
for these challenges. To this end, we seek to explore how new educational
content related to AI ethics and AI policy can be integrated into both ethics-
and technical-focused courses. This paper describes a two-lecture 'AI policy
module' that was piloted in a graduate-level introductory machine learning
course in 2024. The module, which includes an in-class active learning game, is
evaluated using data from student surveys before and after the lectures, and
pedagogical motivations and considerations are discussed. We find that the
module is successful in engaging otherwise technically-oriented students on the
topic of AI policy, increasing student awareness of the social impacts of a
variety of AI technologies and developing student interest in the field of AI
regulation.","James Weichert, Hoda Eldardiry",2025-02-11 20:16:56.000000,arXiv,http://arxiv.org/abs/2502.07931v1,Other
632,Unpaired Image-to-Image Translation with Content Preserving Perspective: A Review,"Image-to-image translation (I2I) transforms an image from a source domain to
a target domain while preserving source content. Most computer vision
applications are in the field of image-to-image translation, such as style
transfer, image segmentation, and photo enhancement. The degree of preservation
of the content of the source images in the translation process can be different
according to the problem and the intended application. From this point of view,
in this paper, we divide the different tasks in the field of image-to-image
translation into three categories: Fully Content preserving, Partially Content
preserving, and Non-Content preserving. We present different tasks, datasets,
methods, results of methods for these three categories in this paper. We make a
categorization for I2I methods based on the architecture of different models
and study each category separately. In addition, we introduce well-known
evaluation criteria in the I2I translation field. Specifically, nearly 70
different I2I models were analyzed, and more than 10 quantitative evaluation
metrics and 30 distinct tasks and datasets relevant to the I2I translation
problem were both introduced and assessed. Translating from simulation to real
images could be well viewed as an application of fully content preserving or
partially content preserving unsupervised image-to-image translation methods.
So, we provide a benchmark for Sim-to-Real translation, which can be used to
evaluate different methods. In general, we conclude that because of the
different extent of the obligation to preserving content in various
applications, it is better to consider this issue in choosing a suitable I2I
model for a specific application.","Mehran Safayani, Behnaz Mirzapour, Hanieh Aghaebrahimian, Nasrin Salehi, Hamid Ravaee",2025-02-11 20:09:29.000000,arXiv,http://arxiv.org/abs/2502.08667v1,Other
633,NDAI Agreements,"We study a fundamental challenge in the economics of innovation: an inventor
must reveal details of a new idea to secure compensation or funding, yet such
disclosure risks expropriation. We present a model in which a seller (inventor)
and buyer (investor) bargain over an information good under the threat of
hold-up. In the classical setting, the seller withholds disclosure to avoid
misappropriation, leading to inefficiency. We show that trusted execution
environments (TEEs) combined with AI agents can mitigate and even fully
eliminate this hold-up problem. By delegating the disclosure and payment
decisions to tamper-proof programs, the seller can safely reveal the invention
without risking expropriation, achieving full disclosure and an efficient ex
post transfer. Moreover, even if the invention's value exceeds a threshold that
TEEs can fully secure, partial disclosure still improves outcomes compared to
no disclosure. Recognizing that real AI agents are imperfect, we model ""agent
errors"" in payments or disclosures and demonstrate that budget caps and
acceptance thresholds suffice to preserve most of the efficiency gains.
  Our results imply that cryptographic or hardware-based solutions can function
as an ""ironclad NDA,"" substantially mitigating the fundamental
disclosure-appropriation paradox first identified by Arrow (1962) and Nelson
(1959). This has far-reaching policy implications for fostering R&D, technology
transfer, and collaboration.","Matthew Stephenson, Andrew Miller, Xyn Sun, Bhargav Annem, Rohan Parikh",2025-02-11 19:56:26.000000,arXiv,http://arxiv.org/abs/2502.07924v1,Other
634,Sign Operator for Coping with Heavy-Tailed Noise: High Probability Convergence Bounds with Extensions to Distributed Optimization and Comparison Oracle,"The growing popularity of AI optimization problems involving severely
corrupted data has increased the demand for methods capable of handling
heavy-tailed noise, i.e., noise with bounded $\kappa$-th moment, $\kappa \in
(1,2]$. For the widely used clipping technique, effectiveness heavily depends
on the careful tuning of clipping levels throughout training. In this paper, we
demonstrate that using only the sign of the input, without introducing
additional hyperparameters, is sufficient to cope with heavy-tailed noise
effectively. For smooth non-convex functions, we prove that SignSGD achieves
optimal sample complexity $\tilde{O}\left(\varepsilon^{-\frac{3\kappa -
2}{\kappa - 1}}\right)$ with high probability for attaining an average gradient
norm accuracy of $\varepsilon$. Under the assumption of symmetric noise, we use
SignSGD with Majority Voting to extend this bound to the distributed
optimization or reduce the sample complexity to $\tilde{O}(\varepsilon^{-4})$
in the case of a single worker with arbitrary parameters. Furthermore, we
explore the application of the sign operator in zeroth-order optimization with
an oracle that can only compare function values at two different points. We
propose a novel method, MajorityVote-CompsSGD, and provide the first-known
high-probability bound $\tilde{O}(\varepsilon^{-6})$ for the number of
comparisons under symmetric noise assumption. Our theoretical findings are
supported by the superior performance of sign-based methods in training Large
Language Models.","Nikita Kornilov, Philip Zmushko, Andrei Semenov, Alexander Gasnikov, Alexander Beznosikov",2025-02-11 19:54:11.000000,arXiv,http://arxiv.org/abs/2502.07923v1,Other
635,Visual-Haptic Model Mediated Teleoperation for Remote Ultrasound,"Tele-ultrasound has the potential greatly to improve health equity for
countless remote communities. However, practical scenarios involve potentially
large time delays which cause current implementations of telerobotic ultrasound
(US) to fail. Using a local model of the remote environment to provide haptics
to the expert operator can decrease teleoperation instability, but the delayed
visual feedback remains problematic. This paper introduces a robotic tele-US
system in which the local model is not only haptic, but also visual, by
re-slicing and rendering a pre-acquired US sweep in real time to provide the
operator a preview of what the delayed image will resemble. A prototype system
is presented and tested with 15 volunteer operators. It is found that
visual-haptic model-mediated teleoperation (MMT) compensates completely for
time delays up to 1000 ms round trip in terms of operator effort and completion
time while conventional MMT does not. Visual-haptic MMT also significantly
outperforms MMT for longer time delays in terms of motion accuracy and force
control. This proof-of-concept study suggests that visual-haptic MMT may
facilitate remote robotic tele-US.","David Black, Maria Tirindelli, Septimiu Salcudean, Wolfgang Wein, Marco Esposito",2025-02-11 19:50:13.000000,arXiv,http://arxiv.org/abs/2502.07922v1,Robotics
636,Filtered Markovian Projection: Dimensionality Reduction in Filtering for Stochastic Reaction Networks,"Stochastic reaction networks (SRNs) model stochastic effects for various
applications, including intracellular chemical or biological processes and
epidemiology. A typical challenge in practical problems modeled by SRNs is that
only a few state variables can be dynamically observed. Given the measurement
trajectories, one can estimate the conditional probability distribution of
unobserved (hidden) state variables by solving a stochastic filtering problem.
In this setting, the conditional distribution evolves over time according to an
extensive or potentially infinite-dimensional system of coupled ordinary
differential equations with jumps, known as the filtering equation. The current
numerical filtering techniques, such as the Filtered Finite State Projection
(DAmbrosio et al., 2022), are hindered by the curse of dimensionality,
significantly affecting their computational performance. To address these
limitations, we propose to use a dimensionality reduction technique based on
the Markovian projection (MP), initially introduced for forward problems (Ben
Hammouda et al., 2024). In this work, we explore how to adapt the existing MP
approach to the filtering problem and introduce a novel version of the MP, the
Filtered MP, that guarantees the consistency of the resulting estimator. The
novel method combines a particle filter with reduced variance and solving the
filtering equations in a low-dimensional space, exploiting the advantages of
both approaches. The analysis and empirical results highlight the superior
computational efficiency of projection methods compared to the existing
filtered finite state projection in the large dimensional setting.","Chiheb Ben Hammouda, Maksim Chupin, Sophia Münker, Raúl Tempone",2025-02-11 19:45:40.000000,arXiv,http://arxiv.org/abs/2502.07918v1,Other
637,Elevating Legal LLM Responses: Harnessing Trainable Logical Structures and Semantic Knowledge with Legal Reasoning,"Large Language Models (LLMs) have achieved impressive results across numerous
domains, yet they experience notable deficiencies in legal question-answering
tasks. LLMs often generate generalized responses that lack the logical
specificity required for expert legal advice and are prone to hallucination,
providing answers that appear correct but are unreliable. Retrieval-Augmented
Generation (RAG) techniques offer partial solutions to address this challenge,
but existing approaches typically focus only on semantic similarity, neglecting
the logical structure essential to legal reasoning. In this paper, we propose
the Logical-Semantic Integration Model (LSIM), a novel supervised framework
that bridges semantic and logical coherence. LSIM comprises three components:
reinforcement learning predicts a structured fact-rule chain for each question,
a trainable Deep Structured Semantic Model (DSSM) retrieves the most relevant
candidate questions by integrating semantic and logical features, and
in-context learning generates the final answer using the retrieved content. Our
experiments on a real-world legal QA dataset-validated through both automated
metrics and human evaluation-demonstrate that LSIM significantly enhances
accuracy and reliability compared to existing methods.","Rujing Yao, Yang Wu, Chenghao Wang, Jingwei Xiong, Fang Wang, Xiaozhong Liu",2025-02-11 19:33:07.000000,arXiv,http://arxiv.org/abs/2502.07912v1,Natural Language Processing
638,Model-free Methods for Event History Analysis and Efficient Adjustment (PhD Thesis),"This thesis contains a series of independent contributions to statistics,
unified by a model-free perspective. The first chapter elaborates on how a
model-free perspective can be used to formulate flexible methods that leverage
prediction techniques from machine learning. Mathematical insights are obtained
from concrete examples, and these insights are generalized to principles that
permeate the rest of the thesis. The second chapter studies the concept of
local independence, which describes whether the evolution of one stochastic
process is directly influenced by another. To test local independence, we
define a model-free parameter called the Local Covariance Measure (LCM). We
formulate an estimator for the LCM, from which a test of local independence is
proposed. We discuss how the size and power of the proposed test can be
controlled uniformly and investigate the test in a simulation study. The third
chapter focuses on covariate adjustment, a method used to estimate the effect
of a treatment by accounting for observed confounding. We formulate a general
framework that facilitates adjustment for any subset of covariate information.
We identify the optimal covariate information for adjustment and, based on
this, introduce the Debiased Outcome-adapted Propensity Estimator (DOPE) for
efficient estimation of treatment effects. An instance of DOPE is implemented
using neural networks, and we demonstrate its performance on simulated and real
data. The fourth and final chapter introduces a model-free measure of the
conditional association between an exposure and a time-to-event, which we call
the Aalen Covariance Measure (ACM). We develop a model-free estimation method
and show that it is doubly robust, ensuring $\sqrt{n}$-consistency provided
that the nuisance functions can be estimated with modest rates. A simulation
study demonstrates the use of our estimator in several settings.",Alexander Mangulad Christgau,2025-02-11 19:24:09.000000,arXiv,http://arxiv.org/abs/2502.07906v1,Other
639,DeepSeek on a Trip: Inducing Targeted Visual Hallucinations via Representation Vulnerabilities,"Multimodal Large Language Models (MLLMs) represent the cutting edge of AI
technology, with DeepSeek models emerging as a leading open-source alternative
offering competitive performance to closed-source systems. While these models
demonstrate remarkable capabilities, their vision-language integration
mechanisms introduce specific vulnerabilities. We implement an adapted
embedding manipulation attack on DeepSeek Janus that induces targeted visual
hallucinations through systematic optimization of image embeddings. Through
extensive experimentation across COCO, DALL-E 3, and SVIT datasets, we achieve
hallucination rates of up to 98.0% while maintaining high visual fidelity (SSIM
> 0.88) of the manipulated images on open-ended questions. Our analysis
demonstrates that both 1B and 7B variants of DeepSeek Janus are susceptible to
these attacks, with closed-form evaluation showing consistently higher
hallucination rates compared to open-ended questioning. We introduce a novel
multi-prompt hallucination detection framework using LLaMA-3.1 8B Instruct for
robust evaluation. The implications of these findings are particularly
concerning given DeepSeek's open-source nature and widespread deployment
potential. This research emphasizes the critical need for embedding-level
security measures in MLLM deployment pipelines and contributes to the broader
discussion of responsible AI implementation.","Chashi Mahiul Islam, Samuel Jacob Chacko, Preston Horne, Xiuwen Liu",2025-02-11 19:21:23.000000,arXiv,http://arxiv.org/abs/2502.07905v1,Computer Vision
640,Intelligent Legal Assistant: An Interactive Clarification System for Legal Question Answering,"The rise of large language models has opened new avenues for users seeking
legal advice. However, users often lack professional legal knowledge, which can
lead to questions that omit critical information. This deficiency makes it
challenging for traditional legal question-answering systems to accurately
identify users' actual needs, often resulting in imprecise or generalized
advice. In this work, we develop a legal question-answering system called
Intelligent Legal Assistant, which interacts with users to precisely capture
their needs. When a user poses a question, the system requests that the user
select their geographical location to pinpoint the applicable laws. It then
generates clarifying questions and options based on the key information missing
from the user's initial question. This allows the user to select and provide
the necessary details. Once all necessary information is provided, the system
produces an in-depth legal analysis encompassing three aspects: overall
conclusion, jurisprudential analysis, and resolution suggestions.","Rujing Yao, Yiquan Wu, Tong Zhang, Xuhui Zhang, Yuting Huang, Yang Wu, Jiayin Yang, Changlong Sun, Fang Wang, Xiaozhong Liu",2025-02-11 19:19:08.000000,arXiv,http://arxiv.org/abs/2502.07904v1,Natural Language Processing
641,The Observational Partial Order of Causal Structures with Latent Variables,"For two causal structures with the same set of visible variables, one is said
to observationally dominate the other if the set of distributions over the
visible variables realizable by the first contains the set of distributions
over the visible variables realizable by the second. Knowing such dominance
relations is useful for adjudicating between these structures given
observational data. We here consider the problem of determining the partial
order of equivalence classes of causal structures with latent variables
relative to observational dominance. We provide a complete characterization of
the dominance order in the case of three visible variables, and a partial
characterization in the case of four visible variables. Our techniques also
help to identify which observational equivalence classes have a set of
realizable distributions that is characterized by nontrivial inequality
constraints, analogous to Bell inequalities and instrumental inequalities. We
find evidence that as one increases the number of visible variables, the
equivalence classes satisfying nontrivial inequality constraints become
ubiquitous. (Because such classes are the ones for which there can be a
difference in the distributions that are quantumly and classically realizable,
this implies that the potential for quantum-classical gaps is also ubiquitous.)
Furthermore, we find evidence that constraint-based causal discovery algorithms
that rely solely on conditional independence constraints have a significantly
weaker distinguishing power among observational equivalence classes than
algorithms that go beyond these (i.e., algorithms that also leverage nested
Markov constraints and inequality constraints).","Marina Maciel Ansanelli, Elie Wolfe, Robert W. Spekkens",2025-02-11 19:00:58.000000,arXiv,http://arxiv.org/abs/2502.07891v1,Statistical Machine Learning
642,A unifying account of warm start guarantees for patches of quantum landscapes,"Barren plateaus are fundamentally a statement about quantum loss landscapes
on average but there can, and generally will, exist patches of barren plateau
landscapes with substantial gradients. Previous work has studied certain
classes of parameterized quantum circuits and found example regions where
gradients vanish at worst polynomially in system size. Here we present a
general bound that unifies all these previous cases and that can tackle
physically-motivated ans\""atze that could not be analyzed previously.
Concretely, we analytically prove a lower-bound on the variance of the loss
that can be used to show that in a non-exponentially narrow region around a
point with curvature the loss variance cannot decay exponentially fast. This
result is complemented by numerics and an upper-bound that suggest that any
loss function with a barren plateau will have exponentially vanishing gradients
in any constant radius subregion. Our work thus suggests that while there are
hopes to be able to warm-start variational quantum algorithms, any
initialization strategy that cannot get increasingly close to the region of
attraction with increasing problem size is likely inadequate.","Hela Mhiri, Ricard Puig, Sacha Lerch, Manuel S. Rudolph, Thiparat Chotibut, Supanut Thanasilp, Zoë Holmes",2025-02-11 19:00:05.000000,arXiv,http://arxiv.org/abs/2502.07889v1,Other
643,MatSwap: Light-aware material transfers in images,"We present MatSwap, a method to transfer materials to designated surfaces in
an image photorealistically. Such a task is non-trivial due to the large
entanglement of material appearance, geometry, and lighting in a photograph. In
the literature, material editing methods typically rely on either cumbersome
text engineering or extensive manual annotations requiring artist knowledge and
3D scene properties that are impractical to obtain. In contrast, we propose to
directly learn the relationship between the input material -- as observed on a
flat surface -- and its appearance within the scene, without the need for
explicit UV mapping. To achieve this, we rely on a custom light- and
geometry-aware diffusion model. We fine-tune a large-scale pre-trained
text-to-image model for material transfer using our synthetic dataset,
preserving its strong priors to ensure effective generalization to real images.
As a result, our method seamlessly integrates a desired material into the
target location in the photograph while retaining the identity of the scene. We
evaluate our method on synthetic and real images and show that it compares
favorably to recent work both qualitatively and quantitatively. We will release
our code and data upon publication.","Ivan Lopes, Valentin Deschaintre, Yannick Hold-Geoffroy, Raoul de Charette",2025-02-11 18:59:59.000000,arXiv,http://arxiv.org/abs/2502.07784v1,Computer Vision
644,Pippo: High-Resolution Multi-View Humans from a Single Image,"We present Pippo, a generative model capable of producing 1K resolution dense
turnaround videos of a person from a single casually clicked photo. Pippo is a
multi-view diffusion transformer and does not require any additional inputs -
e.g., a fitted parametric model or camera parameters of the input image. We
pre-train Pippo on 3B human images without captions, and conduct multi-view
mid-training and post-training on studio captured humans. During mid-training,
to quickly absorb the studio dataset, we denoise several (up to 48) views at
low-resolution, and encode target cameras coarsely using a shallow MLP. During
post-training, we denoise fewer views at high-resolution and use pixel-aligned
controls (e.g., Spatial anchor and Plucker rays) to enable 3D consistent
generations. At inference, we propose an attention biasing technique that
allows Pippo to simultaneously generate greater than 5 times as many views as
seen during training. Finally, we also introduce an improved metric to evaluate
3D consistency of multi-view generations, and show that Pippo outperforms
existing works on multi-view human generation from a single image.","Yash Kant, Ethan Weber, Jin Kyu Kim, Rawal Khirodkar, Su Zhaoen, Julieta Martinez, Igor Gilitschenski, Shunsuke Saito, Timur Bagautdinov",2025-02-11 18:59:59.000000,arXiv,http://arxiv.org/abs/2502.07785v1,Computer Vision
645,Curvature Tuning: Provable Training-free Model Steering From a Single Parameter,"The scaling of model size and data size has reshaped the paradigm of AI. As a
result, the common protocol to leverage the latest models is to steer them
towards a specific downstream task of interest through {\em fine-tuning}.
Despite its importance, the main methods for fine-tuning remain limited to full
or low-rank adapters--containing countless hyper-parameters and lacking
interpretability. In this paper, we take a step back and demonstrate how novel
and explainable post-training steering solutions can be derived theoretically
from {\em spline operators}, a rich mathematical framing of Deep Networks that
was recently developed. Our method--coined \textbf{Curvature Tuning (CT)}--has
a single parameter that provably modulates the curvature of the model's
decision boundary henceforth allowing training-free steering. This makes CT
both more efficient and interpretable than conventional fine-tuning methods. We
empirically validate its effectiveness in improving generalization and
robustness of pretrained models. For example, CT improves out-of-distribution
transfer performances of ResNet-18/50 by 2.57\%/1.74\% across seventeen
downstream datasets, and improves RobustBench robust accuracy by
11.76\%/348.44\%. Additionally, we apply CT to ReLU-based Swin-T/S, improving
their generalization on nine downstream datasets by 2.43\%/3.33\%. Our code is
available at
\href{https://github.com/Leon-Leyang/curvature-tuning}{https://github.com/Leon-Leyang/curvature-tuning}.","Leyang Hu, Randall Balestriero",2025-02-11 18:59:57.000000,arXiv,http://arxiv.org/abs/2502.07783v1,Machine Learning
646,A Flag Decomposition for Hierarchical Datasets,"Flag manifolds encode hierarchical nested sequences of subspaces and serve as
powerful structures for various computer vision and machine learning
applications. Despite their utility in tasks such as dimensionality reduction,
motion averaging, and subspace clustering, current applications are often
restricted to extracting flags using common matrix decomposition methods like
the singular value decomposition. Here, we address the need for a general
algorithm to factorize and work with hierarchical datasets. In particular, we
propose a novel, flag-based method that decomposes arbitrary hierarchical
real-valued data into a hierarchy-preserving flag representation in Stiefel
coordinates. Our work harnesses the potential of flag manifolds in applications
including denoising, clustering, and few-shot learning.","Nathan Mankovich, Ignacio Santamaria, Gustau Camps-Valls, Tolga Birdal",2025-02-11 18:59:52.000000,arXiv,http://arxiv.org/abs/2502.07782v1,Computer Vision
647,DarwinLM: Evolutionary Structured Pruning of Large Language Models,"Large Language Models (LLMs) have achieved significant success across various
NLP tasks. However, their massive computational costs limit their widespread
use, particularly in real-time applications. Structured pruning offers an
effective solution by compressing models and directly providing end-to-end
speed improvements, regardless of the hardware environment. Meanwhile,
different components of the model exhibit varying sensitivities towards
pruning, calling for \emph{non-uniform} model compression. However, a pruning
method should not only identify a capable substructure, but also account for
post-compression training. To this end, we propose \sysname, a method for
\emph{training-aware} structured pruning. \sysname builds upon an evolutionary
search process, generating multiple offspring models in each generation through
mutation, and selecting the fittest for survival. To assess the effect of
post-training, we incorporate a lightweight, multistep training process within
the offspring population, progressively increasing the number of tokens and
eliminating poorly performing models in each selection stage. We validate our
method through extensive experiments on Llama-2-7B, Llama-3.1-8B and
Qwen-2.5-14B-Instruct, achieving state-of-the-art performance for structured
pruning. For instance, \sysname surpasses ShearedLlama while requiring
$5\times$ less training data during post-compression training.","Shengkun Tang, Oliver Sieberling, Eldar Kurtic, Zhiqiang Shen, Dan Alistarh",2025-02-11 18:59:35.000000,arXiv,http://arxiv.org/abs/2502.07780v1,Machine Learning
648,TextAtlas5M: A Large-scale Dataset for Dense Text Image Generation,"Text-conditioned image generation has gained significant attention in recent
years and are processing increasingly longer and comprehensive text prompt. In
everyday life, dense and intricate text appears in contexts like
advertisements, infographics, and signage, where the integration of both text
and visuals is essential for conveying complex information. However, despite
these advances, the generation of images containing long-form text remains a
persistent challenge, largely due to the limitations of existing datasets,
which often focus on shorter and simpler text. To address this gap, we
introduce TextAtlas5M, a novel dataset specifically designed to evaluate
long-text rendering in text-conditioned image generation. Our dataset consists
of 5 million long-text generated and collected images across diverse data
types, enabling comprehensive evaluation of large-scale generative models on
long-text image generation. We further curate 3000 human-improved test set
TextAtlasEval across 3 data domains, establishing one of the most extensive
benchmarks for text-conditioned generation. Evaluations suggest that the
TextAtlasEval benchmarks present significant challenges even for the most
advanced proprietary models (e.g. GPT4o with DallE-3), while their open-source
counterparts show an even larger performance gap. These evidences position
TextAtlas5M as a valuable dataset for training and evaluating future-generation
text-conditioned image generation models.","Alex Jinpeng Wang, Dongxing Mao, Jiawei Zhang, Weiming Han, Zhuobai Dong, Linjie Li, Yiqi Lin, Zhengyuan Yang, Libo Qin, Fuwei Zhang, Lijuan Wang, Min Li",2025-02-11 18:59:19.000000,arXiv,http://arxiv.org/abs/2502.07870v1,Computer Vision
649,Stay-Positive: A Case for Ignoring Real Image Features in Fake Image Detection,"Detecting AI generated images is a challenging yet essential task. A primary
difficulty arises from the detectors tendency to rely on spurious patterns,
such as compression artifacts, which can influence its decisions. These issues
often stem from specific patterns that the detector associates with the real
data distribution, making it difficult to isolate the actual generative traces.
We argue that an image should be classified as fake if and only if it contains
artifacts introduced by the generative model. Based on this premise, we propose
Stay Positive, an algorithm designed to constrain the detectors focus to
generative artifacts while disregarding those associated with real data.
Experimental results demonstrate that detectors trained with Stay Positive
exhibit reduced susceptibility to spurious correlations, leading to improved
generalization and robustness to post processing. Additionally, unlike
detectors that associate artifacts with real images, those that focus purely on
fake artifacts are better at detecting inpainted real images.","Anirudh Sundara Rajan, Yong Jae Lee",2025-02-11 18:59:10.000000,arXiv,http://arxiv.org/abs/2502.07778v1,Computer Vision
650,Auditing Prompt Caching in Language Model APIs,"Prompt caching in large language models (LLMs) results in data-dependent
timing variations: cached prompts are processed faster than non-cached prompts.
These timing differences introduce the risk of side-channel timing attacks. For
example, if the cache is shared across users, an attacker could identify cached
prompts from fast API response times to learn information about other users'
prompts. Because prompt caching may cause privacy leakage, transparency around
the caching policies of API providers is important. To this end, we develop and
conduct statistical audits to detect prompt caching in real-world LLM API
providers. We detect global cache sharing across users in seven API providers,
including OpenAI, resulting in potential privacy leakage about users' prompts.
Timing variations due to prompt caching can also result in leakage of
information about model architecture. Namely, we find evidence that OpenAI's
embedding model is a decoder-only Transformer, which was previously not
publicly known.","Chenchen Gu, Xiang Lisa Li, Rohith Kuditipudi, Percy Liang, Tatsunori Hashimoto",2025-02-11 18:58:04.000000,arXiv,http://arxiv.org/abs/2502.07776v1,Natural Language Processing
651,Optimistic Interior Point Methods for Sequential Hypothesis Testing by Betting,"The technique of ""testing by betting"" frames nonparametric sequential
hypothesis testing as a multiple-round game, where a player bets on future
observations that arrive in a streaming fashion, accumulates wealth that
quantifies evidence against the null hypothesis, and rejects the null once the
wealth exceeds a specified threshold while controlling the false positive
error. Designing an online learning algorithm that achieves a small regret in
the game can help rapidly accumulate the bettor's wealth, which in turn can
shorten the time to reject the null hypothesis under the alternative $H_1$.
However, many of the existing works employ the Online Newton Step (ONS) to
update within a halved decision space to avoid a gradient explosion issue,
which is potentially conservative for rapid wealth accumulation. In this paper,
we introduce a novel strategy utilizing interior-point methods in optimization
that allows updates across the entire interior of the decision space without
the risk of gradient explosion. Our approach not only maintains strong
statistical guarantees but also facilitates faster null hypothesis rejection in
critical scenarios, overcoming the limitations of existing approaches.","Can Chen, Jun-Kun Wang",2025-02-11 18:57:18.000000,arXiv,http://arxiv.org/abs/2502.07774v1,Machine Learning
652,EventEgo3D++: 3D Human Motion Capture from a Head-Mounted Event Camera,"Monocular egocentric 3D human motion capture remains a significant challenge,
particularly under conditions of low lighting and fast movements, which are
common in head-mounted device applications. Existing methods that rely on RGB
cameras often fail under these conditions. To address these limitations, we
introduce EventEgo3D++, the first approach that leverages a monocular event
camera with a fisheye lens for 3D human motion capture. Event cameras excel in
high-speed scenarios and varying illumination due to their high temporal
resolution, providing reliable cues for accurate 3D human motion capture.
EventEgo3D++ leverages the LNES representation of event streams to enable
precise 3D reconstructions. We have also developed a mobile head-mounted device
(HMD) prototype equipped with an event camera, capturing a comprehensive
dataset that includes real event observations from both controlled studio
environments and in-the-wild settings, in addition to a synthetic dataset.
Additionally, to provide a more holistic dataset, we include allocentric RGB
streams that offer different perspectives of the HMD wearer, along with their
corresponding SMPL body model. Our experiments demonstrate that EventEgo3D++
achieves superior 3D accuracy and robustness compared to existing solutions,
even in challenging conditions. Moreover, our method supports real-time 3D pose
updates at a rate of 140Hz. This work is an extension of the EventEgo3D
approach (CVPR 2024) and further advances the state of the art in egocentric 3D
human motion capture. For more details, visit the project page at
https://eventego3d.mpi-inf.mpg.de.","Christen Millerdurai, Hiroyasu Akada, Jian Wang, Diogo Luvizon, Alain Pagani, Didier Stricker, Christian Theobalt, Vladislav Golyanik",2025-02-11 18:57:05.000000,arXiv,http://arxiv.org/abs/2502.07869v1,Computer Vision
653,Automatic Robot Task Planning by Integrating Large Language Model with Genetic Programming,"Accurate task planning is critical for controlling autonomous systems, such
as robots, drones, and self-driving vehicles. Behavior Trees (BTs) are
considered one of the most prominent control-policy-defining frameworks in task
planning, due to their modularity, flexibility, and reusability. Generating
reliable and accurate BT-based control policies for robotic systems remains
challenging and often requires domain expertise. In this paper, we present the
LLM-GP-BT technique that leverages the Large Language Model (LLM) and Genetic
Programming (GP) to automate the generation and configuration of BTs. The
LLM-GP-BT technique processes robot task commands expressed in human natural
language and converts them into accurate and reliable BT-based task plans in a
computationally efficient and user-friendly manner. The proposed technique is
systematically developed and validated through simulation experiments,
demonstrating its potential to streamline task planning for autonomous systems.","Azizjon Kobilov, Jianglin Lan",2025-02-11 18:56:20.000000,arXiv,http://arxiv.org/abs/2502.07772v1,Robotics
654,Breaking Down Bias: On The Limits of Generalizable Pruning Strategies,"We employ model pruning to examine how LLMs conceptualize racial biases, and
whether a generalizable mitigation strategy for such biases appears feasible.
Our analysis yields several novel insights. We find that pruning can be an
effective method to reduce bias without significantly increasing anomalous
model behavior. Neuron-based pruning strategies generally yield better results
than approaches pruning entire attention heads. However, our results also show
that the effectiveness of either approach quickly deteriorates as pruning
strategies become more generalized. For instance, a model that is trained on
removing racial biases in the context of financial decision-making poorly
generalizes to biases in commercial transactions. Overall, our analysis
suggests that racial biases are only partially represented as a general concept
within language models. The other part of these biases is highly
context-specific, suggesting that generalizable mitigation strategies may be of
limited effectiveness. Our findings have important implications for legal
frameworks surrounding AI. In particular, they suggest that an effective
mitigation strategy should include the allocation of legal responsibility on
those that deploy models in a specific use case.","Sibo Ma, Alejandro Salinas, Peter Henderson, Julian Nyarko",2025-02-11 18:55:57.000000,arXiv,http://arxiv.org/abs/2502.07771v1,Natural Language Processing
655,Polynomial-Time Approximability of Constrained Reinforcement Learning,"We study the computational complexity of approximating general constrained
Markov decision processes. Our primary contribution is the design of a
polynomial time $(0,\epsilon)$-additive bicriteria approximation algorithm for
finding optimal constrained policies across a broad class of recursively
computable constraints, including almost-sure, chance, expectation, and their
anytime variants. Matching lower bounds imply our approximation guarantees are
optimal so long as $P \neq NP$. The generality of our approach results in
answers to several long-standing open complexity questions in the constrained
reinforcement learning literature. Specifically, we are the first to prove
polynomial-time approximability for the following settings: policies under
chance constraints, deterministic policies under multiple expectation
constraints, policies under non-homogeneous constraints (i.e., constraints of
different types), and policies under constraints for continuous-state
processes.",Jeremy McMahan,2025-02-11 18:47:53.000000,arXiv,http://arxiv.org/abs/2502.07764v1,Other
656,"Hallucination, Monofacts, and Miscalibration: An Empirical Investigation","Recent theoretical work by [Kalai and Vempala 2024] proves that a particular
notion of hallucination rate in LLMs must be lower bounded by the training data
monofact rate (related to the classical Good-Turing missing mass estimator)
minus model miscalibration. Through systematic experiments with n-gram models
and in-context learning with LLMs, we empirically investigate and validate this
theory by examining how different underlying data distributions affect the
monofact rate and a model's tendency to hallucinate. We then vary model
miscalibration through controlled upweighting of training samples while holding
monofact rates constant, allowing us to isolate miscalibration's reduction
effect on hallucination. These findings suggest that both the distribution of
fact frequencies in training data and the calibration-hallucination trade-off
are inherent to probabilistic language generation. Our results also suggest
that current practices of aggressive deduplication in training data may need to
be reconsidered, as selective duplication could serve as a principled mechanism
for reducing hallucination.","Muqing Miao, Michael Kearns",2025-02-11 18:46:00.000000,arXiv,http://arxiv.org/abs/2502.08666v1,Natural Language Processing
657,Scalable Fingerprinting of Large Language Models,"Model fingerprinting has emerged as a powerful tool for model owners to
identify their shared model given API access. However, to lower false discovery
rate, fight fingerprint leakage, and defend against coalitions of model users
attempting to bypass detection, we argue that {\em scalability} is critical,
i.e., scaling up the number of fingerprints one can embed into a model. Hence,
we pose scalability as a crucial requirement for fingerprinting schemes. We
experiment with fingerprint design at a scale significantly larger than
previously considered, and introduce a new method, dubbed Perinucleus sampling,
to generate scalable, persistent, and harmless fingerprints. We demonstrate
that this scheme can add 24,576 fingerprints to a Llama-3.1-8B model -- two
orders of magnitude more than existing schemes -- without degrading the model's
utility. Our inserted fingerprints persist even after supervised fine-tuning on
standard post-training data. We further address security risks for
fingerprinting, and theoretically and empirically show how a scalable
fingerprinting scheme like ours can mitigate these risks.","Anshul Nasery, Jonathan Hayase, Creston Brooks, Peiyao Sheng, Himanshu Tyagi, Pramod Viswanath, Sewoong Oh",2025-02-11 18:43:07.000000,arXiv,http://arxiv.org/abs/2502.07760v1,Other
658,Novel computational workflows for natural and biomedical image processing based on hypercomplex algebras,"Hypercomplex image processing extends conventional techniques in a unified
paradigm encompassing algebraic and geometric principles. This work leverages
quaternions and the two-dimensional orthogonal planes split framework
(splitting of a quaternion - representing a pixel - into pairs of orthogonal 2D
planes) for natural/biomedical image analysis through the following
computational workflows and outcomes: natural/biomedical image re-colorization,
natural image de-colorization, natural/biomedical image contrast enhancement,
computational re-staining and stain separation in histological images, and
performance gains in machine/deep learning pipelines for histological images.
The workflows are analyzed separately for natural and biomedical images to
showcase the effectiveness of the proposed approaches. The proposed workflows
can regulate color appearance (e.g. with alternative renditions and grayscale
conversion) and image contrast, be part of automated image processing pipelines
(e.g. isolating stain components, boosting learning models), and assist in
digital pathology applications (e.g. enhancing biomarker visibility, enabling
colorblind-friendly renditions). Employing only basic arithmetic and matrix
operations, this work offers a computationally accessible methodology - in the
hypercomplex domain - that showcases versatility and consistency across image
processing tasks and a range of computer vision and biomedical applications.
The proposed non-data-driven methods achieve comparable or better results
(particularly in cases involving well-known methods) to those reported in the
literature, showcasing the potential of robust theoretical frameworks with
practical effectiveness. Results, methods, and limitations are detailed
alongside discussion of promising extensions, emphasizing the potential of
feature-rich mathematical/computational frameworks for natural and biomedical
images.","Nektarios A. Valous, Eckhard Hitzer, Dragoş Duşe, Rodrigo Rojas Moraleda, Ferdinand Popp, Meggy Suarez-Carmona, Anna Berthel, Ismini Papageorgiou, Carlo Fremd, Alexander Rölle, Christina C. Westhoff, Bénédicte Lenoir, Niels Halama, Inka Zörnig, Dirk Jäger",2025-02-11 18:38:02.000000,arXiv,http://arxiv.org/abs/2502.07758v1,Computer Vision
659,An Advanced NLP Framework for Automated Medical Diagnosis with DeBERTa and Dynamic Contextual Positional Gating,"This paper presents a novel Natural Language Processing (NLP) framework for
enhancing medical diagnosis through the integration of advanced techniques in
data augmentation, feature extraction, and classification. The proposed
approach employs back-translation to generate diverse paraphrased datasets,
improving robustness and mitigating overfitting in classification tasks.
Leveraging Decoding-enhanced BERT with Disentangled Attention (DeBERTa) with
Dynamic Contextual Positional Gating (DCPG), the model captures fine-grained
contextual and positional relationships, dynamically adjusting the influence of
positional information based on semantic context to produce high-quality text
embeddings. For classification, an Attention-Based Feedforward Neural Network
(ABFNN) is utilized, effectively focusing on the most relevant features to
improve decision-making accuracy. Applied to the classification of symptoms,
clinical notes, and other medical texts, this architecture demonstrates its
ability to address the complexities of medical data. The combination of data
augmentation, contextual embedding generation, and advanced classification
mechanisms offers a robust and accurate diagnostic tool, with potential
applications in automated medical diagnosis and clinical decision support. This
method demonstrates the effectiveness of the proposed NLP framework for medical
diagnosis, achieving remarkable results with an accuracy of 99.78%, recall of
99.72%, precision of 99.79%, and an F1-score of 99.75%. These metrics not only
underscore the model's robust performance in classifying medical texts with
exceptional precision and reliability but also highlight its superiority over
existing methods, making it a highly promising tool for automated diagnostic
systems.","Mohammad Ali Labbaf Khaniki, Sahabeh Saadati, Mohammad Manthouri",2025-02-11 18:32:24.000000,arXiv,http://arxiv.org/abs/2502.07755v1,Natural Language Processing
660,MeshSplats: Mesh-Based Rendering with Gaussian Splatting Initialization,"Gaussian Splatting (GS) is a recent and pivotal technique in 3D computer
graphics. GS-based algorithms almost always bypass classical methods such as
ray tracing, which offers numerous inherent advantages for rendering. For
example, ray tracing is able to handle incoherent rays for advanced lighting
effects, including shadows and reflections. To address this limitation, we
introduce MeshSplats, a method which converts GS to a mesh-like format.
Following the completion of training, MeshSplats transforms Gaussian elements
into mesh faces, enabling rendering using ray tracing methods with all their
associated benefits. Our model can be utilized immediately following
transformation, yielding a mesh of slightly reduced quality without additional
training. Furthermore, we can enhance the reconstruction quality through the
application of a dedicated optimization algorithm that operates on mesh faces
rather than Gaussian components. The efficacy of our method is substantiated by
experimental results, underscoring its extensive applications in computer
graphics and image processing.","Rafał Tobiasz, Grzegorz Wilczyński, Marcin Mazur, Sławomir Tadeja, Przemysław Spurek",2025-02-11 18:27:39.000000,arXiv,http://arxiv.org/abs/2502.07754v1,Other
661,Direct Ascent Synthesis: Revealing Hidden Generative Capabilities in Discriminative Models,"We demonstrate that discriminative models inherently contain powerful
generative capabilities, challenging the fundamental distinction between
discriminative and generative architectures. Our method, Direct Ascent
Synthesis (DAS), reveals these latent capabilities through multi-resolution
optimization of CLIP model representations. While traditional inversion
attempts produce adversarial patterns, DAS achieves high-quality image
synthesis by decomposing optimization across multiple spatial scales (1x1 to
224x224), requiring no additional training. This approach not only enables
diverse applications -- from text-to-image generation to style transfer -- but
maintains natural image statistics ($1/f^2$ spectrum) and guides the generation
away from non-robust adversarial patterns. Our results demonstrate that
standard discriminative models encode substantially richer generative knowledge
than previously recognized, providing new perspectives on model
interpretability and the relationship between adversarial examples and natural
image synthesis.","Stanislav Fort, Jonathan Whitaker",2025-02-11 18:27:27.000000,arXiv,http://arxiv.org/abs/2502.07753v1,Computer Vision
662,Towards Efficient Optimizer Design for LLM via Structured Fisher Approximation with a Low-Rank Extension,"Designing efficient optimizers for large language models (LLMs) with
low-memory requirements and fast convergence is an important and challenging
problem. This paper makes a step towards the systematic design of such
optimizers through the lens of structured Fisher information matrix (FIM)
approximation. We show that many state-of-the-art efficient optimizers can be
viewed as solutions to FIM approximation (under the Frobenius norm) with
specific structural assumptions. Building on these insights, we propose two
design recommendations of practical efficient optimizers for LLMs, involving
the careful selection of structural assumptions to balance generality and
efficiency, and enhancing memory efficiency of optimizers with general
structures through a novel low-rank extension framework. We demonstrate how to
use each design approach by deriving new memory-efficient optimizers: Row and
Column Scaled SGD (RACS) and Adaptive low-dimensional subspace estimation
(Alice). Experiments on LLaMA pre-training (up to 1B parameters) validate the
effectiveness, showing faster and better convergence than existing
memory-efficient baselines and Adam with little memory overhead. Notably, Alice
achieves better than 2x faster convergence over Adam, while RACS delivers
strong performance on the 1B model with SGD-like memory.","Wenbo Gong, Meyer Scetbon, Chao Ma, Edward Meeds",2025-02-11 18:27:19.000000,arXiv,http://arxiv.org/abs/2502.07752v1,Machine Learning
663,CausalGeD: Blending Causality and Diffusion for Spatial Gene Expression Generation,"The integration of single-cell RNA sequencing (scRNA-seq) and spatial
transcriptomics (ST) data is crucial for understanding gene expression in
spatial context. Existing methods for such integration have limited
performance, with structural similarity often below 60\%, We attribute this
limitation to the failure to consider causal relationships between genes. We
present CausalGeD, which combines diffusion and autoregressive processes to
leverage these relationships. By generalizing the Causal Attention Transformer
from image generation to gene expression data, our model captures regulatory
mechanisms without predefined relationships. Across 10 tissue datasets,
CausalGeD outperformed state-of-the-art baselines by 5- 32\% in key metrics,
including Pearson's correlation and structural similarity, advancing both
technical and biological insights.","Rabeya Tus Sadia, Md Atik Ahamed, Qiang Cheng",2025-02-11 18:26:22.000000,arXiv,http://arxiv.org/abs/2502.07751v1,Computer Vision
664,PFedDST: Personalized Federated Learning with Decentralized Selection Training,"Distributed Learning (DL) enables the training of machine learning models
across multiple devices, yet it faces challenges like non-IID data
distributions and device capability disparities, which can impede training
efficiency. Communication bottlenecks further complicate traditional Federated
Learning (FL) setups. To mitigate these issues, we introduce the Personalized
Federated Learning with Decentralized Selection Training (PFedDST) framework.
PFedDST enhances model training by allowing devices to strategically evaluate
and select peers based on a comprehensive communication score. This score
integrates loss, task similarity, and selection frequency, ensuring optimal
peer connections. This selection strategy is tailored to increase local
personalization and promote beneficial peer collaborations to strengthen the
stability and efficiency of the training process. Our experiments demonstrate
that PFedDST not only enhances model accuracy but also accelerates convergence.
This approach outperforms state-of-the-art methods in handling data
heterogeneity, delivering both faster and more effective training in diverse
and decentralized systems.","Mengchen Fan, Keren Li, Tianyun Zhang, Qing Tian, Baocheng Geng",2025-02-11 18:25:48.000000,arXiv,http://arxiv.org/abs/2502.07750v1,Machine Learning
665,Whole-Genome Phenotype Prediction with Machine Learning: Open Problems in Bacterial Genomics,"How can we identify causal genetic mechanisms that govern bacterial traits?
Initial efforts entrusting machine learning models to handle the task of
predicting phenotype from genotype return high accuracy scores. However,
attempts to extract any meaning from the predictive models are found to be
corrupted by falsely identified ""causal"" features. Relying solely on pattern
recognition and correlations is unreliable, significantly so in bacterial
genomics settings where high-dimensionality and spurious associations are the
norm. Though it is not yet clear whether we can overcome this hurdle,
significant efforts are being made towards discovering potential high-risk
bacterial genetic variants. In view of this, we set up open problems
surrounding phenotype prediction from bacterial whole-genome datasets and
extending those to learning causal effects, and discuss challenges that impact
the reliability of a machine's decision-making when faced with datasets of this
nature.","Tamsin James, Ben Williamson, Peter Tino, Nicole Wheeler",2025-02-11 18:25:14.000000,arXiv,http://arxiv.org/abs/2502.07749v1,Other
666,TransMLA: Multi-Head Latent Attention Is All You Need,"Modern large language models (LLMs) often encounter communication bottlenecks
on current hardware, rather than purely computational constraints. Multi-head
Latent Attention (MLA) tackles this challenge by using low-rank matrices in the
key-value (KV) layers, thereby allowing compressed latent KV states to be
cached. This approach significantly reduces the KV cache size relative to
traditional multi-head attention, leading to faster inference. Moreover, MLA
employs an up-projection matrix to increase expressiveness, trading additional
computation for reduced communication overhead. Although MLA has demonstrated
efficiency and effectiveness in Deepseek V2/V3/R1, many major model providers
still rely on Group Query Attention (GQA) and have not announced any plans to
adopt MLA. In this paper, we show that GQA can always be represented by MLA
while maintaining the same KV cache overhead, but the converse does not hold.
To encourage broader use of MLA, we introduce TransMLA, a post-training method
that converts widely used GQA-based pre-trained models (e.g., LLaMA, Qwen,
Mixtral) into MLA-based models. After conversion, the model can undergo
additional training to boost expressiveness without increasing the KV cache
size. Furthermore, we plan to develop MLA-specific inference acceleration
techniques to preserve low latency in transformed models, thus enabling more
efficient distillation of Deepseek R1.","Fanxu Meng, Zengwei Yao, Muhan Zhang",2025-02-11 18:20:18.000000,arXiv,http://arxiv.org/abs/2502.07864v2,Machine Learning
667,WHODUNIT: Evaluation benchmark for culprit detection in mystery stories,"We present a novel data set, WhoDunIt, to assess the deductive reasoning
capabilities of large language models (LLM) within narrative contexts.
Constructed from open domain mystery novels and short stories, the dataset
challenges LLMs to identify the perpetrator after reading and comprehending the
story. To evaluate model robustness, we apply a range of character-level name
augmentations, including original names, name swaps, and substitutions with
well-known real and/or fictional entities from popular discourse. We further
use various prompting styles to investigate the influence of prompting on
deductive reasoning accuracy.
  We conduct evaluation study with state-of-the-art models, specifically
GPT-4o, GPT-4-turbo, and GPT-4o-mini, evaluated through multiple trials with
majority response selection to ensure reliability. The results demonstrate that
while LLMs perform reliably on unaltered texts, accuracy diminishes with
certain name substitutions, particularly those with wide recognition. This
dataset is publicly available here.",Kshitij Gupta,2025-02-11 18:14:44.000000,arXiv,http://arxiv.org/abs/2502.07747v1,Natural Language Processing
668,HiPoNet: A Topology-Preserving Multi-View Neural Network For High Dimensional Point Cloud and Single-Cell Data,"In this paper, we propose HiPoNet, an end-to-end differentiable neural
network for regression, classification, and representation learning on
high-dimensional point clouds. Single-cell data can have high dimensionality
exceeding the capabilities of existing methods point cloud tailored for 3D
data. Moreover, modern single-cell and spatial experiments now yield entire
cohorts of datasets (i.e. one on every patient), necessitating models that can
process large, high-dimensional point clouds at scale. Most current approaches
build a single nearest-neighbor graph, discarding important geometric
information. In contrast, HiPoNet forms higher-order simplicial complexes
through learnable feature reweighting, generating multiple data views that
disentangle distinct biological processes. It then employs simplicial wavelet
transforms to extract multi-scale features - capturing both local and global
topology. We empirically show that these components preserve topological
information in the learned representations, and that HiPoNet significantly
outperforms state-of-the-art point-cloud and graph-based models on single cell.
We also show an application of HiPoNet on spatial transcriptomics datasets
using spatial co-ordinates as one of the views. Overall, HiPoNet offers a
robust and scalable solution for high-dimensional data analysis.","Siddharth Viswanath, Hiren Madhu, Dhananjay Bhaskar, Jake Kovalic, Dave Johnson, Rex Ying, Christopher Tape, Ian Adelstein, Michael Perlmutter, Smita Krishnaswamy",2025-02-11 18:13:29.000000,arXiv,http://arxiv.org/abs/2502.07746v1,Machine Learning
669,Advancing climate model interpretability: Feature attribution for Arctic melt anomalies,"The focus of our work is improving the interpretability of anomalies in
climate models and advancing our understanding of Arctic melt dynamics. The
Arctic and Antarctic ice sheets are experiencing rapid surface melting and
increased freshwater runoff, contributing significantly to global sea level
rise. Understanding the mechanisms driving snowmelt in these regions is
crucial. ERA5, a widely used reanalysis dataset in polar climate studies,
offers extensive climate variables and global data assimilation. However, its
snowmelt model employs an energy imbalance approach that may oversimplify the
complexity of surface melt. In contrast, the Glacier Energy and Mass Balance
(GEMB) model incorporates additional physical processes, such as snow
accumulation, firn densification, and meltwater percolation/refreezing,
providing a more detailed representation of surface melt dynamics. In this
research, we focus on analyzing surface snowmelt dynamics of the Greenland Ice
Sheet using feature attribution for anomalous melt events in ERA5 and GEMB
models. We present a novel unsupervised attribution method leveraging
counterfactual explanation method to analyze detected anomalies in ERA5 and
GEMB. Our anomaly detection results are validated using MEaSUREs ground-truth
data, and the attributions are evaluated against established feature ranking
methods, including XGBoost, Shapley values, and Random Forest. Our attribution
framework identifies the physics behind each model and the climate features
driving melt anomalies. These findings demonstrate the utility of our
attribution method in enhancing the interpretability of anomalies in climate
models and advancing our understanding of Arctic melt dynamics.","Tolulope Ale, Nicole-Jeanne Schlegel, Vandana P. Janeja",2025-02-11 18:05:54.000000,arXiv,http://arxiv.org/abs/2502.07741v1,Machine Learning
670,HRP: High-Rank Preheating for Superior LoRA Initialization,"This paper studies the crucial impact of initialization on the convergence
properties of Low-Rank Adaptation (LoRA). We theoretically demonstrate that
random initialization, a widely used schema, will likely lead LoRA to random
low-rank results, rather than the best low-rank result. While this issue can be
mitigated by adjusting initialization towards a well-informed direction, it
relies on prior knowledge of the target, which is typically unknown in
real-world scenarios. To approximate this well-informed initial direction, we
propose High-Rank Preheating (HRP), which fine-tunes high-rank LoRA for a few
steps and uses the singular value decomposition of the preheated result as a
superior initialization. HRP initialization is theory-supported to combine the
convergence strengths of high-rank LoRA and the generalization strengths of
low-rank LoRA. Extensive experiments demonstrate that HRP significantly
enhances LoRA's effectiveness across various models and tasks, achieving
performance comparable to full-parameter fine-tuning and outperforming other
initialization strategies.","Yuzhu Chen, Yingjie Wang, Shi Fu, Li Shen, Yongcheng Jing, Xinmei Tian, Dacheng Tao",2025-02-11 17:59:35.000000,arXiv,http://arxiv.org/abs/2502.07739v1,Machine Learning
671,Next Block Prediction: Video Generation via Semi-Autoregressive Modeling,"Next-Token Prediction (NTP) is a de facto approach for autoregressive (AR)
video generation, but it suffers from suboptimal unidirectional dependencies
and slow inference speed. In this work, we propose a semi-autoregressive
(semi-AR) framework, called Next-Block Prediction (NBP), for video generation.
By uniformly decomposing video content into equal-sized blocks (e.g., rows or
frames), we shift the generation unit from individual tokens to blocks,
allowing each token in the current block to simultaneously predict the
corresponding token in the next block. Unlike traditional AR modeling, our
framework employs bidirectional attention within each block, enabling tokens to
capture more robust spatial dependencies. By predicting multiple tokens in
parallel, NBP models significantly reduce the number of generation steps,
leading to faster and more efficient inference. Our model achieves FVD scores
of 103.3 on UCF101 and 25.5 on K600, outperforming the vanilla NTP model by an
average of 4.4. Furthermore, thanks to the reduced number of inference steps,
the NBP model generates 8.89 frames (128x128 resolution) per second, achieving
an 11x speedup. We also explored model scales ranging from 700M to 3B
parameters, observing significant improvements in generation quality, with FVD
scores dropping from 103.3 to 55.3 on UCF101 and from 25.5 to 19.5 on K600,
demonstrating the scalability of our approach.","Shuhuai Ren, Shuming Ma, Xu Sun, Furu Wei",2025-02-11 17:57:53.000000,arXiv,http://arxiv.org/abs/2502.07737v2,Computer Vision
672,Revisiting Non-Acyclic GFlowNets in Discrete Environments,"Generative Flow Networks (GFlowNets) are a family of generative models that
learn to sample objects from a given probability distribution, potentially
known up to a normalizing constant. Instead of working in the object space,
GFlowNets proceed by sampling trajectories in an appropriately constructed
directed acyclic graph environment, greatly relying on the acyclicity of the
graph. In our paper, we revisit the theory that relaxes the acyclicity
assumption and present a simpler theoretical framework for non-acyclic
GFlowNets in discrete environments. Moreover, we provide various novel
theoretical insights related to training with fixed backward policies, the
nature of flow functions, and connections between entropy-regularized RL and
non-acyclic GFlowNets, which naturally generalize the respective concepts and
theoretical results from the acyclic setting. In addition, we experimentally
re-examine the concept of loss stability in non-acyclic GFlowNet training, as
well as validate our own theoretical findings.","Nikita Morozov, Ian Maksimov, Daniil Tiapkin, Sergey Samsonov",2025-02-11 17:55:03.000000,arXiv,http://arxiv.org/abs/2502.07735v1,Machine Learning
673,EdgeEar: Efficient and Accurate Ear Recognition for Edge Devices,"Ear recognition is a contactless and unobtrusive biometric technique with
applications across various domains. However, deploying high-performing ear
recognition models on resource-constrained devices is challenging, limiting
their applicability and widespread adoption. This paper introduces EdgeEar, a
lightweight model based on a proposed hybrid CNN-transformer architecture to
solve this problem. By incorporating low-rank approximations into specific
linear layers, EdgeEar reduces its parameter count by a factor of 50 compared
to the current state-of-the-art, bringing it below two million while
maintaining competitive accuracy. Evaluation on the Unconstrained Ear
Recognition Challenge (UERC2023) benchmark shows that EdgeEar achieves the
lowest EER while significantly reducing computational costs. These findings
demonstrate the feasibility of efficient and accurate ear recognition, which we
believe will contribute to the wider adoption of ear biometrics.","Camile Lendering, Bernardo Perrone Ribeiro, Žiga Emeršič, Peter Peer",2025-02-11 17:53:33.000000,arXiv,http://arxiv.org/abs/2502.07734v1,Computer Vision
674,Economics of Sourcing Human Data,"Progress in AI has relied on human-generated data, from annotator
marketplaces to the wider Internet. However, the widespread use of large
language models now threatens the quality and integrity of human-generated data
on these very platforms. We argue that this issue goes beyond the immediate
challenge of filtering AI-generated content--it reveals deeper flaws in how
data collection systems are designed. Existing systems often prioritize speed,
scale, and efficiency at the cost of intrinsic human motivation, leading to
declining engagement and data quality. We propose that rethinking data
collection systems to align with contributors' intrinsic motivations--rather
than relying solely on external incentives--can help sustain high-quality data
sourcing at scale while maintaining contributor trust and long-term
participation.","Sebastin Santy, Prasanta Bhattacharya, Manoel Horta Ribeiro, Kelsey Allen, Sewoong Oh",2025-02-11 17:51:52.000000,arXiv,http://arxiv.org/abs/2502.07732v1,Other
675,DOGlove: Dexterous Manipulation with a Low-Cost Open-Source Haptic Force Feedback Glove,"Dexterous hand teleoperation plays a pivotal role in enabling robots to
achieve human-level manipulation dexterity. However, current teleoperation
systems often rely on expensive equipment and lack multi-modal sensory
feedback, restricting human operators' ability to perceive object properties
and perform complex manipulation tasks. To address these limitations, we
present DOGlove, a low-cost, precise, and haptic force feedback glove system
for teleoperation and manipulation. DoGlove can be assembled in hours at a cost
under 600 USD. It features a customized joint structure for 21-DoF motion
capture, a compact cable-driven torque transmission mechanism for 5-DoF
multidirectional force feedback, and a linear resonate actuator for 5-DoF
fingertip haptic feedback. Leveraging action and haptic force retargeting,
DOGlove enables precise and immersive teleoperation of dexterous robotic hands,
achieving high success rates in complex, contact-rich tasks. We further
evaluate DOGlove in scenarios without visual feedback, demonstrating the
critical role of haptic force feedback in task performance. In addition, we
utilize the collected demonstrations to train imitation learning policies,
highlighting the potential and effectiveness of DOGlove. DOGlove's hardware and
software system will be fully open-sourced at https://do-glove.github.io/.","Han Zhang, Songbo Hu, Zhecheng Yuan, Huazhe Xu",2025-02-11 17:47:05.000000,arXiv,http://arxiv.org/abs/2502.07730v1,Robotics
676,Verifying LLM-Generated Code in the Context of Software Verification with Ada/SPARK,"Large language models (LLMs) have demonstrated remarkable code generation
capabilities, but the correctness of the generated code cannot be inherently
trusted. This paper explores the feasibility of using formal software
verification, specifically the SPARK framework for Ada, to ensure the
reliability of LLM-generated code. We present Marmaragan, a tool that leverages
an LLM in order to generate SPARK annotations for existing programs, enabling
formal verification of the code. The tool is benchmarked on a curated set of
SPARK programs, with annotations selectively removed to test specific
capabilities. The performance of Marmaragan with GPT-4o on the benchmark is
promising, with correct annotations having been generated for 50.7% of the
benchmark cases. The results establish a foundation for future work on
combining the power of LLMs with the reliability of formal software
verification.","Marcos Cramer, Lucian McIntyre",2025-02-11 17:42:07.000000,arXiv,http://arxiv.org/abs/2502.07728v1,Other
677,DeepVL: Dynamics and Inertial Measurements-based Deep Velocity Learning for Underwater Odometry,"This paper presents a learned model to predict the robot-centric velocity of
an underwater robot through dynamics-aware proprioception. The method exploits
a recurrent neural network using as inputs inertial cues, motor commands, and
battery voltage readings alongside the hidden state of the previous time-step
to output robust velocity estimates and their associated uncertainty. An
ensemble of networks is utilized to enhance the velocity and uncertainty
predictions. Fusing the network's outputs into an Extended Kalman Filter,
alongside inertial predictions and barometer updates, the method enables
long-term underwater odometry without further exteroception. Furthermore, when
integrated into visual-inertial odometry, the method assists in enhanced
estimation resilience when dealing with an order of magnitude fewer total
features tracked (as few as 1) as compared to conventional visual-inertial
systems. Tested onboard an underwater robot deployed both in a laboratory pool
and the Trondheim Fjord, the method takes less than 5ms for inference either on
the CPU or the GPU of an NVIDIA Orin AGX and demonstrates less than 4% relative
position error in novel trajectories during complete visual blackout, and
approximately 2% relative error when a maximum of 2 visual features from a
monocular camera are available.","Mohit Singh, Kostas Alexis",2025-02-11 17:39:54.000000,arXiv,http://arxiv.org/abs/2502.07726v1,Robotics
678,TMLC-Net: Transferable Meta Label Correction for Noisy Label Learning,"The prevalence of noisy labels in real-world datasets poses a significant
impediment to the effective deployment of deep learning models. While
meta-learning strategies have emerged as a promising approach for addressing
this challenge, existing methods often suffer from limited transferability and
task-specific designs. This paper introduces TMLC-Net, a novel Transferable
Meta-Learner for Correcting Noisy Labels, designed to overcome these
limitations. TMLC-Net learns a general-purpose label correction strategy that
can be readily applied across diverse datasets and model architectures without
requiring extensive retraining or fine-tuning. Our approach integrates three
core components: (1) Normalized Noise Perception, which captures and normalizes
training dynamics to handle distribution shifts; (2) Time-Series Encoding,
which models the temporal evolution of sample statistics using a recurrent
neural network; and (3) Subclass Decoding, which predicts a corrected label
distribution based on the learned representations. We conduct extensive
experiments on benchmark datasets with various noise types and levels,
demonstrating that TMLC-Net consistently outperforms state-of-the-art methods
in terms of both accuracy and robustness to label noise. Furthermore, we
analyze the transferability of TMLC-Net, showcasing its adaptability to new
datasets and noise conditions, and establishing its potential as a broadly
applicable solution for robust deep learning in noisy environments.",Mengyang Li,2025-02-11 17:33:48.000000,arXiv,http://arxiv.org/abs/2502.07721v1,Machine Learning
679,ADMN: A Layer-Wise Adaptive Multimodal Network for Dynamic Input Noise and Compute Resources,"Multimodal deep learning systems are deployed in dynamic scenarios due to the
robustness afforded by multiple sensing modalities. Nevertheless, they struggle
with varying compute resource availability (due to multi-tenancy, device
heterogeneity, etc.) and fluctuating quality of inputs (from sensor feed
corruption, environmental noise, etc.). Current multimodal systems employ
static resource provisioning and cannot easily adapt when compute resources
change over time. Additionally, their reliance on processing sensor data with
fixed feature extractors is ill-equipped to handle variations in modality
quality. Consequently, uninformative modalities, such as those with high noise,
needlessly consume resources better allocated towards other modalities. We
propose ADMN, a layer-wise Adaptive Depth Multimodal Network capable of
tackling both challenges - it adjusts the total number of active layers across
all modalities to meet compute resource constraints, and continually
reallocates layers across input modalities according to their modality quality.
Our evaluations showcase ADMN can match the accuracy of state-of-the-art
networks while reducing up to 75% of their floating-point operations.","Jason Wu, Kang Yang, Lance Kaplan, Mani Srivastava",2025-02-11 17:19:44.000000,arXiv,http://arxiv.org/abs/2502.07862v1,Machine Learning
680,Making Language Models Robust Against Negation,"Negation has been a long-standing challenge for language models. Previous
studies have shown that they struggle with negation in many natural language
understanding tasks. In this work, we propose a self-supervised method to make
language models more robust against negation. We introduce a novel task, Next
Sentence Polarity Prediction (NSPP), and a variation of the Next Sentence
Prediction (NSP) task. We show that BERT and RoBERTa further pre-trained on our
tasks outperform the off-the-shelf versions on nine negation-related
benchmarks. Most notably, our pre-training tasks yield between 1.8% and 9.1%
improvement on CondaQA, a large question-answering corpus requiring reasoning
over negation.","MohammadHossein Rezaei, Eduardo Blanco",2025-02-11 17:18:47.000000,arXiv,http://arxiv.org/abs/2502.07717v1,Natural Language Processing
681,BalanceKV: KV Cache Compression through Discrepancy Theory,"Large language models (LLMs) have achieved impressive success, but their high
memory requirements present challenges for long-context token generation. The
memory complexity of long-context LLMs is primarily due to the need to store
Key-Value (KV) embeddings in their KV cache. We present BalanceKV, a KV cache
compression method based on geometric sampling process stemming from
Banaszczyk's vector balancing theory, which introduces dependencies informed by
the geometry of keys and value tokens, and improves precision. BalanceKV offers
both theoretically proven and empirically validated performance improvements
over existing methods.","Insu Han, Michael Kapralov, Ekaterina Kochetkova, Kshiteej Sheth, Amir Zandieh",2025-02-11 17:18:17.000000,arXiv,http://arxiv.org/abs/2502.07861v1,Machine Learning
682,Near-Optimal Sample Complexity in Reward-Free Kernel-Based Reinforcement Learning,"Reinforcement Learning (RL) problems are being considered under increasingly
more complex structures. While tabular and linear models have been thoroughly
explored, the analytical study of RL under nonlinear function approximation,
especially kernel-based models, has recently gained traction for their strong
representational capacity and theoretical tractability. In this context, we
examine the question of statistical efficiency in kernel-based RL within the
reward-free RL framework, specifically asking: how many samples are required to
design a near-optimal policy? Existing work addresses this question under
restrictive assumptions about the class of kernel functions. We first explore
this question by assuming a generative model, then relax this assumption at the
cost of increasing the sample complexity by a factor of H, the length of the
episode. We tackle this fundamental problem using a broad class of kernels and
a simpler algorithm compared to prior work. Our approach derives new confidence
intervals for kernel ridge regression, specific to our RL setting, which may be
of broader applicability. We further validate our theoretical findings through
simulations.","Aya Kayal, Sattar Vakili, Laura Toni, Alberto Bernacchia",2025-02-11 17:15:55.000000,arXiv,http://arxiv.org/abs/2502.07715v1,Machine Learning
683,MAGELLAN: Metacognitive predictions of learning progress guide autotelic LLM agents in large goal spaces,"Open-ended learning agents must efficiently prioritize goals in vast
possibility spaces, focusing on those that maximize learning progress (LP).
When such autotelic exploration is achieved by LLM agents trained with online
RL in high-dimensional and evolving goal spaces, a key challenge for LP
prediction is modeling one's own competence, a form of metacognitive
monitoring. Traditional approaches either require extensive sampling or rely on
brittle expert-defined goal groupings. We introduce MAGELLAN, a metacognitive
framework that lets LLM agents learn to predict their competence and LP online.
By capturing semantic relationships between goals, MAGELLAN enables
sample-efficient LP estimation and dynamic adaptation to evolving goal spaces
through generalization. In an interactive learning environment, we show that
MAGELLAN improves LP prediction efficiency and goal prioritization, being the
only method allowing the agent to fully master a large and evolving goal space.
These results demonstrate how augmenting LLM agents with a metacognitive
ability for LP predictions can effectively scale curriculum learning to
open-ended goal spaces.","Loris Gaven, Thomas Carta, Clément Romac, Cédric Colas, Sylvain Lamprier, Olivier Sigaud, Pierre-Yves Oudeyer",2025-02-11 17:08:00.000000,arXiv,http://arxiv.org/abs/2502.07709v2,Artificial Intelligence
684,PRVQL: Progressive Knowledge-guided Refinement for Robust Egocentric Visual Query Localization,"Egocentric visual query localization (EgoVQL) focuses on localizing the
target of interest in space and time from first-person videos, given a visual
query. Despite recent progressive, existing methods often struggle to handle
severe object appearance changes and cluttering background in the video due to
lacking sufficient target cues, leading to degradation. Addressing this, we
introduce PRVQL, a novel Progressive knowledge-guided Refinement framework for
EgoVQL. The core is to continuously exploit target-relevant knowledge directly
from videos and utilize it as guidance to refine both query and video features
for improving target localization. Our PRVQL contains multiple processing
stages. The target knowledge from one stage, comprising appearance and spatial
knowledge extracted via two specially designed knowledge learning modules, are
utilized as guidance to refine the query and videos features for the next
stage, which are used to generate more accurate knowledge for further feature
refinement. With such a progressive process, target knowledge in PRVQL can be
gradually improved, which, in turn, leads to better refined query and video
features for localization in the final stage. Compared to previous methods, our
PRVQL, besides the given object cues, enjoys additional crucial target
information from a video as guidance to refine features, and hence enhances
EgoVQL in complicated scenes. In our experiments on challenging Ego4D, PRVQL
achieves state-of-the-art result and largely surpasses other methods, showing
its efficacy. Our code, model and results will be released at
https://github.com/fb-reps/PRVQL.","Bing Fan, Yunhe Feng, Yapeng Tian, Yuewei Lin, Yan Huang, Heng Fan",2025-02-11 17:04:31.000000,arXiv,http://arxiv.org/abs/2502.07707v1,Computer Vision
685,GaRLIO: Gravity enhanced Radar-LiDAR-Inertial Odometry,"Recently, gravity has been highlighted as a crucial constraint for state
estimation to alleviate potential vertical drift. Existing online gravity
estimation methods rely on pose estimation combined with IMU measurements,
which is considered best practice when direct velocity measurements are
unavailable. However, with radar sensors providing direct velocity data-a
measurement not yet utilized for gravity estimation-we found a significant
opportunity to improve gravity estimation accuracy substantially. GaRLIO, the
proposed gravity-enhanced Radar-LiDAR-Inertial Odometry, can robustly predict
gravity to reduce vertical drift while simultaneously enhancing state
estimation performance using pointwise velocity measurements. Furthermore,
GaRLIO ensures robustness in dynamic environments by utilizing radar to remove
dynamic objects from LiDAR point clouds. Our method is validated through
experiments in various environments prone to vertical drift, demonstrating
superior performance compared to traditional LiDAR-Inertial Odometry methods.
We make our source code publicly available to encourage further research and
development. https://github.com/ChiyunNoh/GaRLIO","Chiyun Noh, Wooseong Yang, Minwoo Jung, Sangwoo Jung, Ayoung Kim",2025-02-11 17:00:18.000000,arXiv,http://arxiv.org/abs/2502.07703v1,Robotics
686,Magic 1-For-1: Generating One Minute Video Clips within One Minute,"In this technical report, we present Magic 1-For-1 (Magic141), an efficient
video generation model with optimized memory consumption and inference latency.
The key idea is simple: factorize the text-to-video generation task into two
separate easier tasks for diffusion step distillation, namely text-to-image
generation and image-to-video generation. We verify that with the same
optimization algorithm, the image-to-video task is indeed easier to converge
over the text-to-video task. We also explore a bag of optimization tricks to
reduce the computational cost of training the image-to-video (I2V) models from
three aspects: 1) model convergence speedup by using a multi-modal prior
condition injection; 2) inference latency speed up by applying an adversarial
step distillation, and 3) inference memory cost optimization with parameter
sparsification. With those techniques, we are able to generate 5-second video
clips within 3 seconds. By applying a test time sliding window, we are able to
generate a minute-long video within one minute with significantly improved
visual quality and motion dynamics, spending less than 1 second for generating
1 second video clips on average. We conduct a series of preliminary
explorations to find out the optimal tradeoff between computational cost and
video quality during diffusion step distillation and hope this could be a good
foundation model for open-source explorations. The code and the model weights
are available at https://github.com/DA-Group-PKU/Magic-1-For-1.","Hongwei Yi, Shitong Shao, Tian Ye, Jiantong Zhao, Qingyu Yin, Michael Lingelbach, Li Yuan, Yonghong Tian, Enze Xie, Daquan Zhou",2025-02-11 16:58:15.000000,arXiv,http://arxiv.org/abs/2502.07701v1,Computer Vision
687,SoK: A Classification for AI-driven Personalized Privacy Assistants,"To help users make privacy-related decisions, personalized privacy assistants
based on AI technology have been developed in recent years. These AI-driven
Personalized Privacy Assistants (AI-driven PPAs) can reap significant benefits
for users, who may otherwise struggle to make decisions regarding their
personal data in environments saturated with privacy-related decision requests.
However, no study systematically inquired about the features of these AI-driven
PPAs, their underlying technologies, or the accuracy of their decisions. To
fill this gap, we present a Systematization of Knowledge (SoK) to map the
existing solutions found in the scientific literature. We screened 1697 unique
research papers over the last decade (2013-2023), constructing a classification
from 39 included papers. As a result, this SoK reviews several aspects of
existing research on AI-driven PPAs in terms of types of publications,
contributions, methodological quality, and other quantitative insights.
Furthermore, we provide a comprehensive classification for AI-driven PPAs,
delving into their architectural choices, system contexts, types of AI used,
data sources, types of decisions, and control over decisions, among other
facets. Based on our SoK, we further underline the research gaps and challenges
and formulate recommendations for the design and development of AI-driven PPAs
as well as avenues for future research.","Victor Morel, Leonardo Iwaya, Simone Fischer-Hübner",2025-02-11 16:46:56.000000,arXiv,http://arxiv.org/abs/2502.07693v2,Other
688,Large Language Models as Proxies for Theories of Human Linguistic Cognition,"We consider the possible role of current large language models (LLMs) in the
study of human linguistic cognition. We focus on the use of such models as
proxies for theories of cognition that are relatively linguistically-neutral in
their representations and learning but differ from current LLMs in key ways. We
illustrate this potential use of LLMs as proxies for theories of cognition in
the context of two kinds of questions: (a) whether the target theory accounts
for the acquisition of a given pattern from a given corpus; and (b) whether the
target theory makes a given typologically-attested pattern easier to acquire
than another, typologically-unattested pattern. For each of the two questions
we show, building on recent literature, how current LLMs can potentially be of
help, but we note that at present this help is quite limited.","Imry Ziv, Nur Lan, Emmanuel Chemla, Roni Katzir",2025-02-11 16:38:16.000000,arXiv,http://arxiv.org/abs/2502.07687v1,Natural Language Processing
689,Matrix3D: Large Photogrammetry Model All-in-One,"We present Matrix3D, a unified model that performs several photogrammetry
subtasks, including pose estimation, depth prediction, and novel view synthesis
using just the same model. Matrix3D utilizes a multi-modal diffusion
transformer (DiT) to integrate transformations across several modalities, such
as images, camera parameters, and depth maps. The key to Matrix3D's large-scale
multi-modal training lies in the incorporation of a mask learning strategy.
This enables full-modality model training even with partially complete data,
such as bi-modality data of image-pose and image-depth pairs, thus
significantly increases the pool of available training data. Matrix3D
demonstrates state-of-the-art performance in pose estimation and novel view
synthesis tasks. Additionally, it offers fine-grained control through
multi-round interactions, making it an innovative tool for 3D content creation.
Project page: https://nju-3dv.github.io/projects/matrix3d.","Yuanxun Lu, Jingyang Zhang, Tian Fang, Jean-Daniel Nahmias, Yanghai Tsin, Long Quan, Xun Cao, Yao Yao, Shiwei Li",2025-02-11 16:36:55.000000,arXiv,http://arxiv.org/abs/2502.07685v1,Computer Vision
690,exHarmony: Authorship and Citations for Benchmarking the Reviewer Assignment Problem,"The peer review process is crucial for ensuring the quality and reliability
of scholarly work, yet assigning suitable reviewers remains a significant
challenge. Traditional manual methods are labor-intensive and often
ineffective, leading to nonconstructive or biased reviews. This paper
introduces the exHarmony (eHarmony but for connecting experts to manuscripts)
benchmark, designed to address these challenges by re-imagining the Reviewer
Assignment Problem (RAP) as a retrieval task. Utilizing the extensive data from
OpenAlex, we propose a novel approach that considers a host of signals from the
authors, most similar experts, and the citation relations as potential
indicators for a suitable reviewer for a manuscript. This approach allows us to
develop a standard benchmark dataset for evaluating the reviewer assignment
problem without needing explicit labels. We benchmark various methods,
including traditional lexical matching, static neural embeddings, and
contextualized neural embeddings, and introduce evaluation metrics that assess
both relevance and diversity in the context of RAP. Our results indicate that
while traditional methods perform reasonably well, contextualized embeddings
trained on scholarly literature show the best performance. The findings
underscore the importance of further research to enhance the diversity and
effectiveness of reviewer assignments.","Sajad Ebrahimi, Sara Salamat, Negar Arabzadeh, Mahdi Bashari, Ebrahim Bagheri",2025-02-11 16:35:04.000000,arXiv,http://arxiv.org/abs/2502.07683v1,Information Retrieval
691,Multiview Point Cloud Registration Based on Minimum Potential Energy for Free-Form Blade Measurement,"Point cloud registration is an essential step for free-form blade
reconstruction in industrial measurement. Nonetheless, measuring defects of the
3D acquisition system unavoidably result in noisy and incomplete point cloud
data, which renders efficient and accurate registration challenging. In this
paper, we propose a novel global registration method that is based on the
minimum potential energy (MPE) method to address these problems. The basic
strategy is that the objective function is defined as the minimum potential
energy optimization function of the physical registration system. The function
distributes more weight to the majority of inlier points and less weight to the
noise and outliers, which essentially reduces the influence of perturbations in
the mathematical formulation. We decompose the solution into a globally optimal
approximation procedure and a fine registration process with the trimmed
iterative closest point algorithm to boost convergence. The approximation
procedure consists of two main steps. First, according to the construction of
the force traction operator, we can simply compute the position of the
potential energy minimum. Second, to find the MPE point, we propose a new
theory that employs two flags to observe the status of the registration
procedure. We demonstrate the performance of the proposed algorithm on four
types of blades. The proposed method outperforms the other global methods in
terms of both accuracy and noise resistance.","Zijie Wu, Yaonan Wang, Yang Mo, Qing Zhu, He Xie, Haotian Wu, Mingtao Feng, Ajmal Mian",2025-02-11 16:30:14.000000,arXiv,http://arxiv.org/abs/2502.07680v1,Computer Vision
692,Automatic Prostate Volume Estimation in Transabdominal Ultrasound Images,"Prostate cancer is a leading health concern among men, requiring accurate and
accessible methods for early detection and risk stratification. Prostate volume
(PV) is a key parameter in multivariate risk stratification for early prostate
cancer detection, commonly estimated using transrectal ultrasound (TRUS). While
TRUS provides precise prostate volume measurements, its invasive nature often
compromises patient comfort. Transabdominal ultrasound (TAUS) provides a
non-invasive alternative but faces challenges such as lower image quality,
complex interpretation, and reliance on operator expertise. This study
introduces a new deep-learning-based framework for automatic PV estimation
using TAUS, emphasizing its potential to enable accurate and non-invasive
prostate cancer risk stratification. A dataset of TAUS videos from 100
individual patients was curated, with manually delineated prostate boundaries
and calculated diameters by an expert clinician as ground truth. The introduced
framework integrates deep-learning models for prostate segmentation in both
axial and sagittal planes, automatic prostate diameter estimation, and PV
calculation. Segmentation performance was evaluated using Dice correlation
coefficient (%) and Hausdorff distance (mm). Framework's volume estimation
capabilities were evaluated on volumetric error (mL). The framework
demonstrates that it can estimate PV from TAUS videos with a mean volumetric
error of -5.5 mL, which results in an average relative error between 5 and 15%.
The introduced framework for automatic PV estimation from TAUS images,
utilizing deep learning models for prostate segmentation, shows promising
results. It effectively segments the prostate and estimates its volume,
offering potential for reliable, non-invasive risk stratification for early
prostate detection.","Tiziano Natali, Liza M. Kurucz, Matteo Fusaglia, Laura S. Mertens, Theo J. M. Ruers, Pim J. van Leeuwen, Behdad Dashtbozorg",2025-02-11 16:29:22.000000,arXiv,http://arxiv.org/abs/2502.07859v1,Other
693,Auto-Drafting Police Reports from Noisy ASR Outputs: A Trust-Centered LLM Approach,"Achieving a delicate balance between fostering trust in law en- forcement and
protecting the rights of both officers and civilians continues to emerge as a
pressing research and product challenge in the world today. In the pursuit of
fairness and transparency, this study presents an innovative AI-driven system
designed to generate police report drafts from complex, noisy, and multi-role
dialogue data. Our approach intelligently extracts key elements of law
enforcement interactions and includes them in the draft, producing structured
narratives that are not only high in quality but also reinforce accountability
and procedural clarity. This frame- work holds the potential to transform the
reporting process, ensur- ing greater oversight, consistency, and fairness in
future policing practices. A demonstration video of our system can be accessed
at
https://drive.google.com/file/d/1kBrsGGR8e3B5xPSblrchRGj-Y-kpCHNO/view?usp=sharing","Param Kulkarni, Yingchi Liu, Hao-Ming Fu, Shaohua Yang, Isuru Gunasekara, Matt Peloquin, Noah Spitzer-Williams, Xiaotian Zhou, Xiaozhong Liu, Zhengping Ji, Yasser Ibrahim",2025-02-11 16:27:28.000000,arXiv,http://arxiv.org/abs/2502.07677v2,Natural Language Processing
694,MAAT: Mamba Adaptive Anomaly Transformer with association discrepancy for time series,"Anomaly detection in time series is essential for industrial monitoring and
environmental sensing, yet distinguishing anomalies from complex patterns
remains challenging. Existing methods like the Anomaly Transformer and
DCdetector have progressed, but they face limitations such as sensitivity to
short-term contexts and inefficiency in noisy, non-stationary environments.
  To overcome these issues, we introduce MAAT, an improved architecture that
enhances association discrepancy modeling and reconstruction quality. MAAT
features Sparse Attention, efficiently capturing long-range dependencies by
focusing on relevant time steps, thereby reducing computational redundancy.
Additionally, a Mamba-Selective State Space Model is incorporated into the
reconstruction module, utilizing a skip connection and Gated Attention to
improve anomaly localization and detection performance.
  Extensive experiments show that MAAT significantly outperforms previous
methods, achieving better anomaly distinguishability and generalization across
various time series applications, setting a new standard for unsupervised time
series anomaly detection in real-world scenarios.","Abdellah Zakaria Sellam, Ilyes Benaissa, Abdelmalik Taleb-Ahmed, Luigi Patrono, Cosimo Distante",2025-02-11 16:22:06.000000,arXiv,http://arxiv.org/abs/2502.07858v1,Machine Learning
695,SNAP: Sequential Non-Ancestor Pruning for Targeted Causal Effect Estimation With an Unknown Graph,"Causal discovery can be computationally demanding for large numbers of
variables. If we only wish to estimate the causal effects on a small subset of
target variables, we might not need to learn the causal graph for all
variables, but only a small subgraph that includes the targets and their
adjustment sets. In this paper, we focus on identifying causal effects between
target variables in a computationally and statistically efficient way. This
task combines causal discovery and effect estimation, aligning the discovery
objective with the effects to be estimated. We show that definite non-ancestors
of the targets are unnecessary to learn causal relations between the targets
and to identify efficient adjustments sets. We sequentially identify and prune
these definite non-ancestors with our Sequential Non-Ancestor Pruning (SNAP)
framework, which can be used either as a preprocessing step to standard causal
discovery methods, or as a standalone sound and complete causal discovery
algorithm. Our results on synthetic and real data show that both approaches
substantially reduce the number of independence tests and the computation time
without compromising the quality of causal effect estimations.","Mátyás Schubert, Tom Claassen, Sara Magliacane",2025-02-11 16:20:57.000000,arXiv,http://arxiv.org/abs/2502.07857v1,Statistical Machine Learning
696,Cheap Permutation Testing,"Permutation tests are a popular choice for distinguishing distributions and
testing independence, due to their exact, finite-sample control of false
positives and their minimax optimality when paired with U-statistics. However,
standard permutation tests are also expensive, requiring a test statistic to be
computed hundreds or thousands of times to detect a separation between
distributions. In this work, we offer a simple approach to accelerate testing:
group your datapoints into bins and permute only those bins. For U and
V-statistics, we prove that these cheap permutation tests have two remarkable
properties. First, by storing appropriate sufficient statistics, a cheap test
can be run in time comparable to evaluating a single test statistic. Second,
cheap permutation power closely approximates standard permutation power. As a
result, cheap tests inherit the exact false positive control and minimax
optimality of standard permutation tests while running in a fraction of the
time. We complement these findings with improved power guarantees for standard
permutation testing and experiments demonstrating the benefits of cheap
permutations over standard maximum mean discrepancy (MMD), Hilbert-Schmidt
independence criterion (HSIC), random Fourier feature, Wilcoxon-Mann-Whitney,
cross-MMD, and cross-HSIC tests.","Carles Domingo-Enrich, Raaz Dwivedi, Lester Mackey",2025-02-11 16:19:07.000000,arXiv,http://arxiv.org/abs/2502.07672v1,Other
697,Human Decision-making is Susceptible to AI-driven Manipulation,"Artificial Intelligence (AI) systems are increasingly intertwined with daily
life, assisting users in executing various tasks and providing guidance on
decision-making. This integration introduces risks of AI-driven manipulation,
where such systems may exploit users' cognitive biases and emotional
vulnerabilities to steer them toward harmful outcomes. Through a randomized
controlled trial with 233 participants, we examined human susceptibility to
such manipulation in financial (e.g., purchases) and emotional (e.g., conflict
resolution) decision-making contexts. Participants interacted with one of three
AI agents: a neutral agent (NA) optimizing for user benefit without explicit
influence, a manipulative agent (MA) designed to covertly influence beliefs and
behaviors, or a strategy-enhanced manipulative agent (SEMA) employing explicit
psychological tactics to reach its hidden objectives. By analyzing
participants' decision patterns and shifts in their preference ratings
post-interaction, we found significant susceptibility to AI-driven
manipulation. Particularly, across both decision-making domains, participants
interacting with the manipulative agents shifted toward harmful options at
substantially higher rates (financial, MA: 62.3%, SEMA: 59.6%; emotional, MA:
42.3%, SEMA: 41.5%) compared to the NA group (financial, 35.8%; emotional,
12.8%). Notably, our findings reveal that even subtle manipulative objectives
(MA) can be as effective as employing explicit psychological strategies (SEMA)
in swaying human decision-making. By revealing the potential for covert AI
influence, this study highlights a critical vulnerability in human-AI
interactions, emphasizing the need for ethical safeguards and regulatory
frameworks to ensure responsible deployment of AI technologies and protect
human autonomy.","Sahand Sabour, June M. Liu, Siyang Liu, Chris Z. Yao, Shiyao Cui, Xuanming Zhang, Wen Zhang, Yaru Cao, Advait Bhat, Jian Guan, Wei Wu, Rada Mihalcea, Tim Althoff, Tatia M. C. Lee, Minlie Huang",2025-02-11 15:56:22.000000,arXiv,http://arxiv.org/abs/2502.07663v1,Artificial Intelligence
698,Partial-Label Learning with Conformal Candidate Cleaning,"Real-world data is often ambiguous; for example, human annotation produces
instances with multiple conflicting class labels. Partial-label learning (PLL)
aims at training a classifier in this challenging setting, where each instance
is associated with a set of candidate labels and one correct, but unknown,
class label. A multitude of algorithms targeting this setting exists and, to
enhance their prediction quality, several extensions that are applicable across
a wide range of PLL methods have been introduced. While many of these
extensions rely on heuristics, this article proposes a novel enhancing method
that incrementally prunes candidate sets using conformal prediction. To work
around the missing labeled validation set, which is typically required for
conformal prediction, we propose a strategy that alternates between training a
PLL classifier to label the validation set, leveraging these predicted class
labels for calibration, and pruning candidate labels that are not part of the
resulting conformal sets. In this sense, our method alternates between
empirical risk minimization and candidate set pruning. We establish that our
pruning method preserves the conformal validity with respect to the unknown
ground truth. Our extensive experiments on artificial and real-world data show
that the proposed approach significantly improves the test set accuracies of
several state-of-the-art PLL classifiers.","Tobias Fuchs, Florian Kalinke",2025-02-11 15:51:23.000000,arXiv,http://arxiv.org/abs/2502.07661v1,Machine Learning
699,IU4Rec: Interest Unit-Based Product Organization and Recommendation for E-Commerce Platform,"Most recommendation systems typically follow a product-based paradigm
utilizing user-product interactions to identify the most engaging items for
users. However, this product-based paradigm has notable drawbacks for
Xianyu~\footnote{Xianyu is China's largest online C2C e-commerce platform where
a large portion of the product are post by individual sellers}. Most of the
product on Xianyu posted from individual sellers often have limited stock
available for distribution, and once the product is sold, it's no longer
available for distribution. This result in most items distributed product on
Xianyu having relatively few interactions, affecting the effectiveness of
traditional recommendation depending on accumulating user-item interactions. To
address these issues, we introduce \textbf{IU4Rec}, an \textbf{I}nterest
\textbf{U}nit-based two-stage \textbf{Rec}ommendation system framework. We
first group products into clusters based on attributes such as category, image,
and semantics. These IUs are then integrated into the Recommendation system,
delivering both product and technological innovations. IU4Rec begins by
grouping products into clusters based on attributes such as category, image,
and semantics, forming Interest Units (IUs). Then we redesign the
recommendation process into two stages. In the first stage, the focus is on
recommend these Interest Units, capturing broad-level interests. In the second
stage, it guides users to find the best option among similar products within
the selected Interest Unit. User-IU interactions are incorporated into our
ranking models, offering the advantage of more persistent IU behaviors compared
to item-specific interactions. Experimental results on the production dataset
and online A/B testing demonstrate the effectiveness and superiority of our
proposed IU-centric recommendation approach.","Wenhao Wu, Xiaojie Li, Lin Wang, Jialiang Zhou, Di Wu, Qinye Xie, Qingheng Zhang, Yin Zhang, Shuguang Han, Fei Huang, Junfeng Chen",2025-02-11 15:46:28.000000,arXiv,http://arxiv.org/abs/2502.07658v1,Information Retrieval
700,"Private Low-Rank Approximation for Covariance Matrices, Dyson Brownian Motion, and Eigenvalue-Gap Bounds for Gaussian Perturbations","We consider the problem of approximating a $d \times d$ covariance matrix $M$
with a rank-$k$ matrix under $(\varepsilon,\delta)$-differential privacy. We
present and analyze a complex variant of the Gaussian mechanism and obtain
upper bounds on the Frobenius norm of the difference between the matrix output
by this mechanism and the best rank-$k$ approximation to $M$. Our analysis
provides improvements over previous bounds, particularly when the spectrum of
$M$ satisfies natural structural assumptions. The novel insight is to view the
addition of Gaussian noise to a matrix as a continuous-time matrix Brownian
motion. This viewpoint allows us to track the evolution of eigenvalues and
eigenvectors of the matrix, which are governed by stochastic differential
equations discovered by Dyson. These equations enable us to upper bound the
Frobenius distance between the best rank-$k$ approximation of $M$ and that of a
Gaussian perturbation of $M$ as an integral that involves inverse eigenvalue
gaps of the stochastically evolving matrix, as opposed to a sum of perturbation
bounds obtained via Davis-Kahan-type theorems. Subsequently, again using the
Dyson Brownian motion viewpoint, we show that the eigenvalues of the matrix $M$
perturbed by Gaussian noise have large gaps with high probability. These
results also contribute to the analysis of low-rank approximations under
average-case perturbations, and to an understanding of eigenvalue gaps for
random matrices, both of which may be of independent interest.","Oren Mangoubi, Nisheeth K. Vishnoi",2025-02-11 15:46:03.000000,arXiv,http://arxiv.org/abs/2502.07657v1,Other
701,A Unifying Framework for Causal Imitation Learning with Hidden Confounders,"We propose a general and unifying framework for causal Imitation Learning
(IL) with hidden confounders that subsumes several existing confounded IL
settings from the literature. Our framework accounts for two types of hidden
confounders: (a) those observed by the expert, which thus influence the
expert's policy, and (b) confounding noise hidden to both the expert and the IL
algorithm. For additional flexibility, we also introduce a confounding noise
horizon and time-varying expert-observable hidden variables. We show that
causal IL in our framework can be reduced to a set of Conditional Moment
Restrictions (CMRs) by leveraging trajectory histories as instruments to learn
a history-dependent policy. We propose DML-IL, a novel algorithm that uses
instrumental variable regression to solve these CMRs and learn a policy. We
provide a bound on the imitation gap for DML-IL, which recovers prior results
as special cases. Empirical evaluation on a toy environment with continues
state-action spaces and multiple Mujoco tasks demonstrate that DML-IL
outperforms state-of-the-art causal IL algorithms.","Daqian Shao, Thomas Kleine Buening, Marta Kwiatkowska",2025-02-11 15:43:49.000000,arXiv,http://arxiv.org/abs/2502.07656v1,Machine Learning
702,Guiding Time-Varying Generative Models with Natural Gradients on Exponential Family Manifold,"Optimising probabilistic models is a well-studied field in statistics.
However, its connection with the training of generative models remains largely
under-explored. In this paper, we show that the evolution of time-varying
generative models can be projected onto an exponential family manifold,
naturally creating a link between the parameters of a generative model and
those of a probabilistic model. We then train the generative model by moving
its projection on the manifold according to the natural gradient descent
scheme. This approach also allows us to approximate the natural gradient of the
KL divergence efficiently without relying on MCMC for intractable models.
Furthermore, we propose particle versions of the algorithm, which feature
closed-form update rules for any parametric model within the exponential
family. Through toy and real-world experiments, we validate the effectiveness
of the proposed algorithms.","Song Liu, Leyang Wang, Yakun Wang",2025-02-11 15:39:47.000000,arXiv,http://arxiv.org/abs/2502.07650v1,Statistical Machine Learning
703,Causal Additive Models with Unobserved Causal Paths and Backdoor Paths,"Causal additive models have been employed as tractable yet expressive
frameworks for causal discovery involving hidden variables. State-of-the-art
methodologies suggest that determining the causal relationship between a pair
of variables is infeasible in the presence of an unobserved backdoor or an
unobserved causal path. Contrary to this assumption, we theoretically show that
resolving the causal direction is feasible in certain scenarios by
incorporating two novel components into the theory. The first component
introduces a novel characterization of regression sets within independence
between regression residuals. The second component leverages conditional
independence among the observed variables. We also provide a search algorithm
that integrates these innovations and demonstrate its competitive performance
against existing methods.","Thong Pham, Takashi Nicholas Maeda, Shohei Shimizu",2025-02-11 15:35:15.000000,arXiv,http://arxiv.org/abs/2502.07646v1,Machine Learning
704,Beyond Behavior Cloning: Robustness through Interactive Imitation and Contrastive Learning,"Behavior cloning (BC) traditionally relies on demonstration data, assuming
the demonstrated actions are optimal. This can lead to overfitting under noisy
data, particularly when expressive models are used (e.g., the energy-based
model in Implicit BC). To address this, we extend behavior cloning into an
iterative process of optimal action estimation within the Interactive Imitation
Learning framework. Specifically, we introduce Contrastive policy Learning from
Interactive Corrections (CLIC). CLIC leverages human corrections to estimate a
set of desired actions and optimizes the policy to select actions from this
set. We provide theoretical guarantees for the convergence of the desired
action set to optimal actions in both single and multiple optimal action cases.
Extensive simulation and real-robot experiments validate CLIC's advantages over
existing state-of-the-art methods, including stable training of energy-based
models, robustness to feedback noise, and adaptability to diverse feedback
types beyond demonstrations. Our code will be publicly available soon.","Zhaoting Li, Rodrigo Pérez-Dattari, Robert Babuska, Cosimo Della Santina, Jens Kober",2025-02-11 15:34:24.000000,arXiv,http://arxiv.org/abs/2502.07645v1,Robotics
705,SymGPT: Auditing Smart Contracts via Combining Symbolic Execution with Large Language Models,"To govern smart contracts running on Ethereum, multiple Ethereum Request for
Comment (ERC) standards have been developed, each having a set of rules to
guide the behaviors of smart contracts. Violating the ERC rules could cause
serious security issues and financial loss, signifying the importance of
verifying smart contracts follow ERCs. Today's practices of such verification
are to manually audit each single contract, use expert-developed
program-analysis tools, or use large language models (LLMs), all of which are
far from effective in identifying ERC rule violations. This paper introduces
SymGPT, a tool that combines the natural language understanding of large
language models (LLMs) with the formal guarantees of symbolic execution to
automatically verify smart contracts' compliance with ERC rules. To develop
SymGPT, we conduct an empirical study of 132 ERC rules from three widely used
ERC standards, examining their content, security implications, and natural
language descriptions. Based on this study, we design SymGPT by first
instructing an LLM to translate ERC rules into a defined EBNF grammar. We then
synthesize constraints from the formalized rules to represent scenarios where
violations may occur and use symbolic execution to detect them. Our evaluation
shows that SymGPT identifies 5,783 ERC rule violations in 4,000 real-world
contracts, including 1,375 violations with clear attack paths for stealing
financial assets, demonstrating its effectiveness. Furthermore, SymGPT
outperforms six automated techniques and a security-expert auditing service,
underscoring its superiority over current smart contract analysis methods.","Shihao Xia, Mengting He, Shuai Shao, Tingting Yu, Yiying Zhang, Linhai Song",2025-02-11 15:34:00.000000,arXiv,http://arxiv.org/abs/2502.07644v2,Artificial Intelligence
706,FoQA: A Faroese Question-Answering Dataset,"We present FoQA, a Faroese extractive question-answering (QA) dataset with
2,000 samples, created using a semi-automated approach combining Large Language
Models (LLMs) and human validation. The dataset was generated from Faroese
Wikipedia articles using GPT-4-turbo for initial QA generation, followed by
question rephrasing to increase complexity and native speaker validation to
ensure quality. We provide baseline performance metrics for FoQA across
multiple models, including LLMs and BERT, demonstrating its effectiveness in
evaluating Faroese QA performance. The dataset is released in three versions: a
validated set of 2,000 samples, a complete set of all 10,001 generated samples,
and a set of 2,395 rejected samples for error analysis.","Annika Simonsen, Dan Saattrup Nielsen, Hafsteinn Einarsson",2025-02-11 15:33:17.000000,arXiv,http://arxiv.org/abs/2502.07642v1,Natural Language Processing
707,Distributional Instrumental Variable Method,"The instrumental variable (IV) approach is commonly used to infer causal
effects in the presence of unmeasured confounding. Conventional IV models
commonly make the additive noise assumption, which is hard to ensure in
practice, but also typically lack flexibility if the causal effects are
complex. Further, the vast majority of the existing methods aims to estimate
the mean causal effects only, a few other methods focus on the quantile
effects. This work aims for estimation of the entire interventional
distribution. We propose a novel method called distributional instrumental
variables (DIV), which leverages generative modelling in a nonlinear
instrumental variable setting. We establish identifiability of the
interventional distribution under general assumptions and demonstrate an
`under-identified' case where DIV can identify the causal effects while
two-step least squares fails to. Our empirical results show that the DIV method
performs well for a broad range of simulated data, exhibiting advantages over
existing IV approaches in terms of the identifiability and estimation error of
the mean or quantile treatment effects. Furthermore, we apply DIV to an
economic data set to examine the causal relation between institutional quality
and economic development and our results that closely align with the original
study. We also apply DIV to a single-cell data set, where we study the
generalizability and stability in predicting gene expression under unseen
interventions. The software implementations of DIV are available in R and
Python.","Anastasiia Holovchak, Sorawit Saengkyongam, Nicolai Meinshausen, Xinwei Shen",2025-02-11 15:33:06.000000,arXiv,http://arxiv.org/abs/2502.07641v1,Other
708,Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving,"We introduce Goedel-Prover, an open-source large language model (LLM) that
achieves the state-of-the-art (SOTA) performance in automated formal proof
generation for mathematical problems. The key challenge in this field is the
scarcity of formalized math statements and proofs, which we tackle in the
following ways. We train statement formalizers to translate the natural
language math problems from Numina into formal language (Lean 4), creating a
dataset of 1.64 million formal statements. LLMs are used to check that the
formal statements accurately preserve the content of the original natural
language problems. We then iteratively build a large dataset of formal proofs
by training a series of provers. Each prover succeeds in proving many
statements that the previous ones could not, and these new proofs are added to
the training set for the next prover. The final prover outperforms all existing
open-source models in whole-proof generation. On the miniF2F benchmark, it
achieves a 57.6% success rate (Pass@32), exceeding the previous best
open-source model by 7.6%. On PutnamBench, Goedel-Prover successfully solves 7
problems (Pass@512), ranking first on the leaderboard. Furthermore, it
generates 29.7K formal proofs for Lean Workbook problems, nearly doubling the
15.7K produced by earlier works.","Yong Lin, Shange Tang, Bohan Lyu, Jiayun Wu, Hongzhou Lin, Kaiyu Yang, Jia Li, Mengzhou Xia, Danqi Chen, Sanjeev Arora, Chi Jin",2025-02-11 15:27:35.000000,arXiv,http://arxiv.org/abs/2502.07640v1,Machine Learning
709,BiaSWE: An Expert Annotated Dataset for Misogyny Detection in Swedish,"In this study, we introduce the process for creating BiaSWE, an
expert-annotated dataset tailored for misogyny detection in the Swedish
language. To address the cultural and linguistic specificity of misogyny in
Swedish, we collaborated with experts from the social sciences and humanities.
Our interdisciplinary team developed a rigorous annotation process,
incorporating both domain knowledge and language expertise, to capture the
nuances of misogyny in a Swedish context. This methodology ensures that the
dataset is not only culturally relevant but also aligned with broader efforts
in bias detection for low-resource languages. The dataset, along with the
annotation guidelines, is publicly available for further research.","Kätriin Kukk, Danila Petrelli, Judit Casademont, Eric J. W. Orlowski, Michał Dzieliński, Maria Jacobson",2025-02-11 15:25:10.000000,arXiv,http://arxiv.org/abs/2502.07637v1,Natural Language Processing
710,Consistency Training with Physical Constraints,"We propose a physics-aware Consistency Training (CT) method that accelerates
sampling in Diffusion Models with physical constraints. Our approach leverages
a two-stage strategy: (1) learning the noise-to-data mapping via CT, and (2)
incorporating physics constraints as a regularizer. Experiments on toy examples
show that our method generates samples in a single step while adhering to the
imposed constraints. This approach has the potential to efficiently solve
partial differential equations (PDEs) using deep generative modeling.","Che-Chia Chang, Chen-Yang Dai, Te-Sheng Lin, Ming-Chih Lai, Chieh-Hsin Lai",2025-02-11 15:23:14.000000,arXiv,http://arxiv.org/abs/2502.07636v1,Machine Learning
711,Distributed Value Decomposition Networks with Networked Agents,"We investigate the problem of distributed training under partial
observability, whereby cooperative multi-agent reinforcement learning agents
(MARL) maximize the expected cumulative joint reward. We propose distributed
value decomposition networks (DVDN) that generate a joint Q-function that
factorizes into agent-wise Q-functions. Whereas the original value
decomposition networks rely on centralized training, our approach is suitable
for domains where centralized training is not possible and agents must learn by
interacting with the physical environment in a decentralized manner while
communicating with their peers. DVDN overcomes the need for centralized
training by locally estimating the shared objective. We contribute with two
innovative algorithms, DVDN and DVDN (GT), for the heterogeneous and
homogeneous agents settings respectively. Empirically, both algorithms
approximate the performance of value decomposition networks, in spite of the
information loss during communication, as demonstrated in ten MARL tasks in
three standard environments.","Guilherme S. Varela, Alberto Sardinha, Francisco S. Melo",2025-02-11 15:23:05.000000,arXiv,http://arxiv.org/abs/2502.07635v1,Machine Learning
712,Divide and Merge: Motion and Semantic Learning in End-to-End Autonomous Driving,"Perceiving the environment and its changes over time corresponds to two
fundamental yet heterogeneous types of information: semantics and motion.
Previous end-to-end autonomous driving works represent both types of
information in a single feature vector. However, including motion tasks, such
as prediction and planning, always impairs detection and tracking performance,
a phenomenon known as negative transfer in multi-task learning. To address this
issue, we propose Neural-Bayes motion decoding, a novel parallel detection,
tracking, and prediction method separating semantic and motion learning,
similar to the Bayes filter. Specifically, we employ a set of learned motion
queries that operate in parallel with the detection and tracking queries,
sharing a unified set of recursively updated reference points. Moreover, we
employ interactive semantic decoding to enhance information exchange in
semantic tasks, promoting positive transfer. Experiments on the nuScenes
dataset show improvements of 5% in detection and 11% in tracking. Our method
achieves state-of-the-art collision rates in open-loop planning evaluation
without any modifications to the planning module.","Yinzhe Shen, Ömer Şahin Taş, Kaiwen Wang, Royden Wagner, Christoph Stiller",2025-02-11 15:21:31.000000,arXiv,http://arxiv.org/abs/2502.07631v1,Computer Vision
713,Rethinking Timing Residuals: Advancing PET Detectors with Explicit TOF Corrections,"PET is a functional imaging method that visualizes metabolic processes. TOF
information can be derived from coincident detector signals and incorporated
into image reconstruction to enhance the SNR. PET detectors are typically
assessed by their CTR, but timing performance is degraded by various factors.
Research on timing calibration seeks to mitigate these degradations and restore
accurate timing information. While many calibration methods use analytical
approaches, machine learning techniques have recently gained attention due to
their flexibility. We developed a residual physics-based calibration approach
that combines prior domain knowledge with the power of machine learning models.
This approach begins with an initial analytical calibration addressing
first-order skews. The remaining deviations, regarded as residual effects, are
used to train machine learning models to eliminate higher-order skews. The key
advantage is that the experimenter guides the learning process through the
definition of timing residuals. In earlier studies, we developed models that
directly predicted the expected time difference, which offered corrections only
implicitly (implicit correction models). In this study, we introduce a new
definition for timing residuals, enabling us to train models that directly
predict correction values (explicit correction models). The explicit correction
approach significantly simplifies data acquisition, improves linearity, and
enhances timing performance from $371 \pm 6$ ps to $281 \pm 5$ ps for
coincidences from 430 keV to 590 keV. Additionally, the new definition reduces
model size, making it suitable for high-throughput applications like PET
scanners. Experiments were conducted using two detector stacks composed of $4
\times 4$ LYSO:Ce,Ca crystals ($3.8\times 3.8\times 20$ mm$^{3}$) coupled to $4
\times 4$ Broadcom NUV-MT SiPMs and digitized with the TOFPET2 ASIC.","Stephan Naunheim, Luis Lopes de Paiva, Vanessa Nadig, Yannick Kuhl, Stefan Gundacker, Florian Mueller, Volkmar Schulz",2025-02-11 15:17:29.000000,arXiv,http://arxiv.org/abs/2502.07630v1,Other
714,Exploring Mobile Touch Interaction with Large Language Models,"Interacting with Large Language Models (LLMs) for text editing on mobile
devices currently requires users to break out of their writing environment and
switch to a conversational AI interface. In this paper, we propose to control
the LLM via touch gestures performed directly on the text. We first chart a
design space that covers fundamental touch input and text transformations. In
this space, we then concretely explore two control mappings: spread-to-generate
and pinch-to-shorten, with visual feedback loops. We evaluate this concept in a
user study (N=14) that compares three feedback designs: no visualisation, text
length indicator, and length + word indicator. The results demonstrate that
touch-based control of LLMs is both feasible and user-friendly, with the length
+ word indicator proving most effective for managing text generation. This work
lays the foundation for further research into gesture-based interaction with
LLMs on touch devices.","Tim Zindulka, Jannek Sekowski, Florian Lehmann, Daniel Buschek",2025-02-11 15:17:00.000000,arXiv,http://arxiv.org/abs/2502.07629v1,Other
715,Lexical categories of stem-forming roots in Mapudüngun verb forms,"After developing a computational system for morphological analysis of the
Mapuche language, and evaluating it with texts from various authors and styles,
it became necessary to verify the linguistic assumptions of the source used as
the basis for implementing this tool.
  In the present work, the primary focus is on the lexical category
classification of Mapud\""ungun roots recognised as verbal in the source
utilised for the development of the morphological analysis system.
  The results of this lexical category revision directly benefit the
computational analyser, as they are implemented as soon as they are verified.
Additionally, it is hoped that these results will help clarify some
uncertainties about lexical categories in the Mapuche language.
  This work addresses a preliminary task to identify the valency of true verbal
roots, the results of which will be presented in a subsequent work that
complements this article.",Andrés Chandía,2025-02-11 15:10:23.000000,arXiv,http://arxiv.org/abs/2502.07623v1,Natural Language Processing
716,Causal-Informed Contrastive Learning: Towards Bias-Resilient Pre-training under Concept Drift,"The evolution of large-scale contrastive pre-training propelled by top-tier
datasets has reached a transition point in the scaling law. Consequently,
sustaining and enhancing a model's pre-training capabilities in drift
environments have surfaced as a notable challenge. In this paper, we initially
uncover that contrastive pre-training methods are significantly impacted by
concept drift wherein distributions change unpredictably, resulting in notable
biases in the feature space of the pre-trained model. Empowered by causal
inference, we construct a structural causal graph to analyze the impact of
concept drift to contrastive pre-training systemically, and propose the causal
interventional contrastive objective. Upon achieving this, we devise a
resilient contrastive pre-training approach to accommodate the data stream of
concept drift, with simple and scalable implementation. Extensive experiments
on various downstream tasks demonstrate our resilient contrastive pre-training
effectively mitigates the bias stemming from the concept drift data stream.
Codes are available at https://anonymous.4open.science/r/ResilientCL/.","Xiaoyu Yang, Jie Lu, En Yu",2025-02-11 15:09:05.000000,arXiv,http://arxiv.org/abs/2502.07620v1,Machine Learning
717,Scaling Pre-training to One Hundred Billion Data for Vision Language Models,"We provide an empirical investigation of the potential of pre-training
vision-language models on an unprecedented scale: 100 billion examples. We find
that model performance tends to saturate at this scale on many common
Western-centric classification and retrieval benchmarks, such as COCO Captions.
Nevertheless, tasks of cultural diversity achieve more substantial gains from
the 100-billion scale web data, thanks to its coverage of long-tail concepts.
Furthermore, we analyze the model's multilinguality and show gains in
low-resource languages as well. In addition, we observe that reducing the size
of the pretraining dataset via quality filters like using CLIP, typically used
to enhance performance, may inadvertently reduce the cultural diversity
represented even in large-scale datasets. Our results highlight that while
traditional benchmarks may not benefit significantly from scaling noisy, raw
web data to 100 billion examples, this data scale is vital for building truly
inclusive multimodal systems.","Xiao Wang, Ibrahim Alabdulmohsin, Daniel Salz, Zhe Li, Keran Rong, Xiaohua Zhai",2025-02-11 15:05:33.000000,arXiv,http://arxiv.org/abs/2502.07617v1,Computer Vision
718,Flow Distillation Sampling: Regularizing 3D Gaussians with Pre-trained Matching Priors,"3D Gaussian Splatting (3DGS) has achieved excellent rendering quality with
fast training and rendering speed. However, its optimization process lacks
explicit geometric constraints, leading to suboptimal geometric reconstruction
in regions with sparse or no observational input views. In this work, we try to
mitigate the issue by incorporating a pre-trained matching prior to the 3DGS
optimization process. We introduce Flow Distillation Sampling (FDS), a
technique that leverages pre-trained geometric knowledge to bolster the
accuracy of the Gaussian radiance field. Our method employs a strategic
sampling technique to target unobserved views adjacent to the input views,
utilizing the optical flow calculated from the matching model (Prior Flow) to
guide the flow analytically calculated from the 3DGS geometry (Radiance Flow).
Comprehensive experiments in depth rendering, mesh reconstruction, and novel
view synthesis showcase the significant advantages of FDS over state-of-the-art
methods. Additionally, our interpretive experiments and analysis aim to shed
light on the effects of FDS on geometric accuracy and rendering quality,
potentially providing readers with insights into its performance. Project page:
https://nju-3dv.github.io/projects/fds","Lin-Zhuo Chen, Kangjie Liu, Youtian Lin, Siyu Zhu, Zhihao Li, Xun Cao, Yao Yao",2025-02-11 15:05:26.000000,arXiv,http://arxiv.org/abs/2502.07615v1,Computer Vision
719,Tractable Transformers for Flexible Conditional Generation,"Non-autoregressive (NAR) generative models are valuable because they can
handle diverse conditional generation tasks in a more principled way than their
autoregressive (AR) counterparts, which are constrained by sequential
dependency requirements. Recent advancements in NAR models, such as diffusion
language models, have demonstrated superior performance in unconditional
generation compared to AR models (e.g., GPTs) of similar sizes. However, such
improvements do not always lead to improved conditional generation performance.
We show that a key reason for this gap is the difficulty in generalizing to
conditional probability queries unseen during training. As a result, strong
unconditional generation performance does not guarantee high-quality
conditional generation. This paper proposes Tractable Transformers
(Tracformer), a Transformer-based generative model that is more robust to
different conditional generation tasks. Unlike existing models that rely solely
on global contextual features derived from full inputs, Tracformers incorporate
a sparse Transformer encoder to capture both local and global contextual
information. This information is routed through a decoder for conditional
generation. Empirical results demonstrate that Tracformers achieve
state-of-the-art conditional generation performance on text modeling compared
to recent diffusion and AR model baselines.","Anji Liu, Xuejie Liu, Dayuan Zhao, Mathias Niepert, Yitao Liang, Guy Van den Broeck",2025-02-11 15:05:26.000000,arXiv,http://arxiv.org/abs/2502.07616v1,Natural Language Processing
720,Beyond Prompting: Time2Lang -- Bridging Time-Series Foundation Models and Large Language Models for Health Sensing,"Large language models (LLMs) show promise for health applications when
combined with behavioral sensing data. Traditional approaches convert sensor
data into text prompts, but this process is prone to errors, computationally
expensive, and requires domain expertise. These challenges are particularly
acute when processing extended time series data. While time series foundation
models (TFMs) have recently emerged as powerful tools for learning
representations from temporal data, bridging TFMs and LLMs remains challenging.
Here, we present Time2Lang, a framework that directly maps TFM outputs to LLM
representations without intermediate text conversion. Our approach first trains
on synthetic data using periodicity prediction as a pretext task, followed by
evaluation on mental health classification tasks. We validate Time2Lang on two
longitudinal wearable and mobile sensing datasets: daily depression prediction
using step count data (17,251 days from 256 participants) and flourishing
classification based on conversation duration (46 participants over 10 weeks).
Time2Lang maintains near constant inference times regardless of input length,
unlike traditional prompting methods. The generated embeddings preserve
essential time-series characteristics such as auto-correlation. Our results
demonstrate that TFMs and LLMs can be effectively integrated while minimizing
information loss and enabling performance transfer across these distinct
modeling paradigms. To our knowledge, we are the first to integrate a TFM and
an LLM for health, thus establishing a foundation for future research combining
general-purpose large models for complex healthcare tasks.","Arvind Pillai, Dimitris Spathis, Subigya Nepal, Amanda C Collins, Daniel M Mackin, Michael V Heinz, Tess Z Griffin, Nicholas C Jacobson, Andrew Campbell",2025-02-11 14:58:54.000000,arXiv,http://arxiv.org/abs/2502.07608v2,Machine Learning
721,MRS: A Fast Sampler for Mean Reverting Diffusion based on ODE and SDE Solvers,"In applications of diffusion models, controllable generation is of practical
significance, but is also challenging. Current methods for controllable
generation primarily focus on modifying the score function of diffusion models,
while Mean Reverting (MR) Diffusion directly modifies the structure of the
stochastic differential equation (SDE), making the incorporation of image
conditions simpler and more natural. However, current training-free fast
samplers are not directly applicable to MR Diffusion. And thus MR Diffusion
requires hundreds of NFEs (number of function evaluations) to obtain
high-quality samples. In this paper, we propose a new algorithm named MRS (MR
Sampler) to reduce the sampling NFEs of MR Diffusion. We solve the reverse-time
SDE and the probability flow ordinary differential equation (PF-ODE) associated
with MR Diffusion, and derive semi-analytical solutions. The solutions consist
of an analytical function and an integral parameterized by a neural network.
Based on this solution, we can generate high-quality samples in fewer steps.
Our approach does not require training and supports all mainstream
parameterizations, including noise prediction, data prediction and velocity
prediction. Extensive experiments demonstrate that MR Sampler maintains high
sampling quality with a speedup of 10 to 20 times across ten different image
restoration tasks. Our algorithm accelerates the sampling procedure of MR
Diffusion, making it more practical in controllable generation.","Ao Li, Wei Fang, Hongbo Zhao, Le Lu, Ge Yang, Minfeng Xu",2025-02-11 14:57:33.000000,arXiv,http://arxiv.org/abs/2502.07856v2,Computer Vision
722,Algorithmic Aspects of Strategic Trading,"Algorithmic trading in modern financial markets is widely acknowledged to
exhibit strategic, game-theoretic behaviors whose complexity can be difficult
to model. A recent series of papers (Chriss, 2024b,c,a, 2025) has made progress
in the setting of trading for position building. Here parties wish to buy or
sell a fixed number of shares in a fixed time period in the presence of both
temporary and permanent market impact, resulting in exponentially large
strategy spaces. While these papers primarily consider the existence and
structural properties of equilibrium strategies, in this work we focus on the
algorithmic aspects of the proposed model. We give an efficient algorithm for
computing best responses, and show that while the temporary impact only setting
yields a potential game, best response dynamics do not generally converge for
the general setting, for which no fast algorithm for (Nash) equilibrium
computation is known. This leads us to consider the broader notion of Coarse
Correlated Equilibria (CCE), which we show can be computed efficiently via an
implementation of Follow the Perturbed Leader (FTPL). We illustrate the model
and our results with an experimental investigation, where FTPL exhibits
interesting behavior in different regimes of the relative weighting between
temporary and permanent market impact.","Michael Kearns, Mirah Shi",2025-02-11 14:56:16.000000,arXiv,http://arxiv.org/abs/2502.07606v1,Other
723,An Improved Optimal Proximal Gradient Algorithm for Non-Blind Image Deblurring,"Image deblurring remains a central research area within image processing,
critical for its role in enhancing image quality and facilitating clearer
visual representations across diverse applications. This paper tackles the
optimization problem of image deblurring, assuming a known blurring kernel. We
introduce an improved optimal proximal gradient algorithm (IOptISTA), which
builds upon the optimal gradient method and a weighting matrix, to efficiently
address the non-blind image deblurring problem. Based on two regularization
cases, namely the $l_1$ norm and total variation norm, we perform numerical
experiments to assess the performance of our proposed algorithm. The results
indicate that our algorithm yields enhanced PSNR and SSIM values, as well as a
reduced tolerance, compared to existing methods.","Qingsong Wang, Shengze Xu, Xiaojiao Tong, Tieyong Zeng",2025-02-11 14:52:11.000000,arXiv,http://arxiv.org/abs/2502.07602v1,Computer Vision
724,Towards Zero-Shot Anomaly Detection and Reasoning with Multimodal Large Language Models,"Zero-Shot Anomaly Detection (ZSAD) is an emerging AD paradigm. Unlike the
traditional unsupervised AD setting that requires a large number of normal
samples to train a model, ZSAD is more practical for handling data-restricted
real-world scenarios. Recently, Multimodal Large Language Models (MLLMs) have
shown revolutionary reasoning capabilities in various vision tasks. However,
the reasoning of image abnormalities remains underexplored due to the lack of
corresponding datasets and benchmarks. To facilitate research in AD &
reasoning, we establish the first visual instruction tuning dataset,
Anomaly-Instruct-125k, and the evaluation benchmark, VisA-D&R. Through
investigation with our benchmark, we reveal that current MLLMs like GPT-4o
cannot accurately detect and describe fine-grained anomalous details in images.
To address this, we propose Anomaly-OneVision (Anomaly-OV), the first
specialist visual assistant for ZSAD and reasoning. Inspired by human behavior
in visual inspection, Anomaly-OV leverages a Look-Twice Feature Matching (LTFM)
mechanism to adaptively select and emphasize abnormal visual tokens. Extensive
experiments demonstrate that Anomaly-OV achieves significant improvements over
advanced generalist models in both detection and reasoning. Extensions to
medical and 3D AD are provided for future study. The link to our project page:
https://xujiacong.github.io/Anomaly-OV/","Jiacong Xu, Shao-Yuan Lo, Bardia Safaei, Vishal M. Patel, Isht Dwivedi",2025-02-11 14:50:43.000000,arXiv,http://arxiv.org/abs/2502.07601v1,Computer Vision
725,PlaySlot: Learning Inverse Latent Dynamics for Controllable Object-Centric Video Prediction and Planning,"Predicting future scene representations is a crucial task for enabling robots
to understand and interact with the environment. However, most existing methods
rely on video sequences and simulations with precise action annotations,
limiting their ability to leverage the large amount of available unlabeled
video data. To address this challenge, we propose PlaySlot, an object-centric
video prediction model that infers object representations and latent actions
from unlabeled video sequences. It then uses these representations to forecast
future object states and video frames. PlaySlot allows to generate multiple
possible futures conditioned on latent actions, which can be inferred from
video dynamics, provided by a user, or generated by a learned action policy,
thus enabling versatile and interpretable world modeling. Our results show that
PlaySlot outperforms both stochastic and object-centric baselines for video
prediction across different environments. Furthermore, we show that our
inferred latent actions can be used to learn robot behaviors sample-efficiently
from unlabeled video demonstrations. Videos and code are available at
https://play-slot.github.io/PlaySlot/.","Angel Villar-Corrales, Sven Behnke",2025-02-11 14:50:10.000000,arXiv,http://arxiv.org/abs/2502.07600v1,Computer Vision
726,DPO-Shift: Shifting the Distribution of Direct Preference Optimization,"Direct Preference Optimization (DPO) and its variants have become
increasingly popular for aligning language models with human preferences. These
methods aim to teach models to better distinguish between chosen (or preferred)
and rejected (or dispreferred) responses. However, prior research has
identified that the probability of chosen responses often decreases during
training, and this phenomenon is known as likelihood displacement. To tackle
this challenge, in this work we introduce \method to controllably shift the
distribution of the chosen probability. Then, we show that \method exhibits a
fundamental trade-off between improving the chosen probability and sacrificing
the reward margin, as supported by both theoretical analysis and experimental
validation. Furthermore, we demonstrate the superiority of \method over DPO on
downstream tasks such as MT-Bench and a designed win rate experiment. We
believe this study shows that the likelihood displacement issue of DPO can be
effectively mitigated with a simple, theoretically grounded solution. Our code
is available at https://github.com/Meaquadddd/DPO-Shift.","Xiliang Yang, Feng Jiang, Qianen Zhang, Lei Zhao, Xiao Li",2025-02-11 14:49:44.000000,arXiv,http://arxiv.org/abs/2502.07599v1,Natural Language Processing
727,Distributed Coverage Control for Time-Varying Spatial Processes,"Multi-robot systems are essential for environmental monitoring, particularly
for tracking spatial phenomena like pollution, soil minerals, and water
salinity, and more. This study addresses the challenge of deploying a
multi-robot team for optimal coverage in environments where the density
distribution, describing areas of interest, is unknown and changes over time.
We propose a fully distributed control strategy that uses Gaussian Processes
(GPs) to model the spatial field and balance the trade-off between learning the
field and optimally covering it. Unlike existing approaches, we address a more
realistic scenario by handling time-varying spatial fields, where the
exploration-exploitation trade-off is dynamically adjusted over time. Each
robot operates locally, using only its own collected data and the information
shared by the neighboring robots. To address the computational limits of GPs,
the algorithm efficiently manages the volume of data by selecting only the most
relevant samples for the process estimation. The performance of the proposed
algorithm is evaluated through several simulations and experiments,
incorporating real-world data phenomena to validate its effectiveness.","Federico Pratissoli, Mattia Mantovani, Amanda Prorok, Lorenzo Sabattini",2025-02-11 14:45:17.000000,arXiv,http://arxiv.org/abs/2502.07595v1,Robotics
728,YOLO Network For Defect Detection In Optical lenses,"Mass-produced optical lenses often exhibit defects that alter their
scattering properties and compromise quality standards. Manual inspection is
usually adopted to detect defects, but it is not recommended due to low
accuracy, high error rate and limited scalability. To address these challenges,
this study presents an automated defect detection system based on the YOLOv8
deep learning model. A custom dataset of optical lenses, annotated with defect
and lens regions, was created to train the model. Experimental results obtained
in this study reveal that the system can be used to efficiently and accurately
detect defects in optical lenses. The proposed system can be utilized in
real-time industrial environments to enhance quality control processes by
enabling reliable and scalable defect detection in optical lens manufacturing.",Habib Yaseen,2025-02-11 14:41:30.000000,arXiv,http://arxiv.org/abs/2502.07592v1,Computer Vision
729,DMWM: Dual-Mind World Model with Long-Term Imagination,"Imagination in world models is crucial for enabling agents to learn
long-horizon policy in a sample-efficient manner. Existing recurrent
state-space model (RSSM)-based world models depend on single-step statistical
inference to capture the environment dynamics, and, hence, they are unable to
perform long-term imagination tasks due to the accumulation of prediction
errors. Inspired by the dual-process theory of human cognition, we propose a
novel dual-mind world model (DMWM) framework that integrates logical reasoning
to enable imagination with logical consistency. DMWM is composed of two
components: an RSSM-based System 1 (RSSM-S1) component that handles state
transitions in an intuitive manner and a logic-integrated neural network-based
System 2 (LINN-S2) component that guides the imagination process through
hierarchical deep logical reasoning. The inter-system feedback mechanism is
designed to ensure that the imagination process follows the logical rules of
the real environment. The proposed framework is evaluated on benchmark tasks
that require long-term planning from the DMControl suite. Extensive
experimental results demonstrate that the proposed framework yields significant
improvements in terms of logical coherence, trial efficiency, data efficiency
and long-term imagination over the state-of-the-art world models.","Lingyi Wang, Rashed Shelim, Walid Saad, Naren Ramakrishnan",2025-02-11 14:40:57.000000,arXiv,http://arxiv.org/abs/2502.07591v1,Machine Learning
730,DSV: Exploiting Dynamic Sparsity to Accelerate Large-Scale Video DiT Training,"Diffusion Transformers (DiTs) have shown remarkable performance in modeling
and generating high-quality videos. However, the quadratic computational
complexity of 3D full attention mechanism presents significant challenges in
scaling video DiT training, especially for high-definition and lengthy videos,
where attention can dominate up to 95% of the end-to-end time and necessitate
specialized communication paradigms to handle large input sizes.
  This paper introduces DSV, a novel framework designed to accelerate and scale
the training of video DiTs by leveraging the inherent dynamic attention
sparsity throughout the training process. DSV employs a two-stage training
algorithm that exploits sparsity patterns, focusing on critical elements
supported by efficient, tailored kernels. To accommodate the new sparsity
dimension, we develop a hybrid sparsity-aware context parallelism that
effectively scales to large inputs by addressing the heterogeneity of sparsity
across attention heads and blocks, resulting in optimized sparse computation
and communication. Extensive evaluations demonstrate that DSV achieves up to
3.02x gain in training throughput with nearly no quality degradation.","Xin Tan, Yuetao Chen, Yimin Jiang, Xing Chen, Kun Yan, Nan Duan, Yibo Zhu, Daxin Jiang, Hong Xu",2025-02-11 14:39:59.000000,arXiv,http://arxiv.org/abs/2502.07590v1,Other
731,SEMU: Singular Value Decomposition for Efficient Machine Unlearning,"While the capabilities of generative foundational models have advanced
rapidly in recent years, methods to prevent harmful and unsafe behaviors remain
underdeveloped. Among the pressing challenges in AI safety, machine unlearning
(MU) has become increasingly critical to meet upcoming safety regulations. Most
existing MU approaches focus on altering the most significant parameters of the
model. However, these methods often require fine-tuning substantial portions of
the model, resulting in high computational costs and training instabilities,
which are typically mitigated by access to the original training dataset.
  In this work, we address these limitations by leveraging Singular Value
Decomposition (SVD) to create a compact, low-dimensional projection that
enables the selective forgetting of specific data points. We propose Singular
Value Decomposition for Efficient Machine Unlearning (SEMU), a novel approach
designed to optimize MU in two key aspects. First, SEMU minimizes the number of
model parameters that need to be modified, effectively removing unwanted
knowledge while making only minimal changes to the model's weights. Second,
SEMU eliminates the dependency on the original training dataset, preserving the
model's previously acquired knowledge without additional data requirements.
  Extensive experiments demonstrate that SEMU achieves competitive performance
while significantly improving efficiency in terms of both data usage and the
number of modified parameters.","Marcin Sendera, Łukasz Struski, Kamil Książek, Kryspin Musiol, Jacek Tabor, Dawid Rymarczyk",2025-02-11 14:36:39.000000,arXiv,http://arxiv.org/abs/2502.07587v1,Machine Learning
732,We Can't Understand AI Using our Existing Vocabulary,"This position paper argues that, in order to understand AI, we cannot rely on
our existing vocabulary of human words. Instead, we should strive to develop
neologisms: new words that represent precise human concepts that we want to
teach machines, or machine concepts that we need to learn. We start from the
premise that humans and machines have differing concepts. This means
interpretability can be framed as a communication problem: humans must be able
to reference and control machine concepts, and communicate human concepts to
machines. Creating a shared human-machine language through developing
neologisms, we believe, could solve this communication problem. Successful
neologisms achieve a useful amount of abstraction: not too detailed, so they're
reusable in many contexts, and not too high-level, so they convey precise
information. As a proof of concept, we demonstrate how a ""length neologism""
enables controlling LLM response length, while a ""diversity neologism"" allows
sampling more variable responses. Taken together, we argue that we cannot
understand AI using our existing vocabulary, and expanding it through
neologisms creates opportunities for both controlling and understanding
machines better.","John Hewitt, Robert Geirhos, Been Kim",2025-02-11 14:34:05.000000,arXiv,http://arxiv.org/abs/2502.07586v1,Natural Language Processing
733,Understanding the Generalization Error of Markov algorithms through Poissonization,"Using continuous-time stochastic differential equation (SDE) proxies to
stochastic optimization algorithms has proven fruitful for understanding their
generalization abilities. A significant part of these approaches are based on
the so-called ``entropy flows'', which greatly simplify the generalization
analysis. Unfortunately, such well-structured entropy flows cannot be obtained
for most discrete-time algorithms, and the existing SDE approaches remain
limited to specific noise and algorithmic structures. We aim to alleviate this
issue by introducing a generic framework for analyzing the generalization error
of Markov algorithms through `Poissonization', a continuous-time approximation
of discrete-time processes with formal approximation guarantees. Through this
approach, we first develop a novel entropy flow, which directly leads to
PAC-Bayesian generalization bounds. We then draw novel links to modified
versions of the celebrated logarithmic Sobolev inequalities (LSI), identify
cases where such LSIs are satisfied, and obtain improved bounds. Beyond its
generality, our framework allows exploiting specific properties of learning
algorithms. In particular, we incorporate the noise structure of different
algorithm types - namely, those with additional noise injections (noisy) and
those without (non-noisy) - through various technical tools. This illustrates
the capacity of our methods to achieve known (yet, Poissonized) and new
generalization bounds.","Benjamin Dupuis, Maxime Haddouche, George Deligiannidis, Umut Simsekli",2025-02-11 14:31:32.000000,arXiv,http://arxiv.org/abs/2502.07584v1,Statistical Machine Learning
734,Generative Modeling with Bayesian Sample Inference,"We derive a novel generative model from the simple act of Gaussian posterior
inference. Treating the generated sample as an unknown variable to infer lets
us formulate the sampling process in the language of Bayesian probability. Our
model uses a sequence of prediction and posterior update steps to narrow down
the unknown sample from a broad initial belief. In addition to a rigorous
theoretical analysis, we establish a connection between our model and diffusion
models and show that it includes Bayesian Flow Networks (BFNs) as a special
case. In our experiments, we demonstrate improved performance over both BFNs
and Variational Diffusion Models, achieving competitive likelihood scores on
CIFAR10 and ImageNet.","Marten Lienen, Marcel Kollovieh, Stephan Günnemann",2025-02-11 14:27:10.000000,arXiv,http://arxiv.org/abs/2502.07580v1,Machine Learning
735,Single-Step Consistent Diffusion Samplers,"Sampling from unnormalized target distributions is a fundamental yet
challenging task in machine learning and statistics. Existing sampling
algorithms typically require many iterative steps to produce high-quality
samples, leading to high computational costs that limit their practicality in
time-sensitive or resource-constrained settings. In this work, we introduce
consistent diffusion samplers, a new class of samplers designed to generate
high-fidelity samples in a single step. We first develop a distillation
algorithm to train a consistent diffusion sampler from a pretrained diffusion
model without pre-collecting large datasets of samples. Our algorithm leverages
incomplete sampling trajectories and noisy intermediate states directly from
the diffusion process. We further propose a method to train a consistent
diffusion sampler from scratch, fully amortizing exploration by training a
single model that both performs diffusion sampling and skips intermediate steps
using a self-consistency loss. Through extensive experiments on a variety of
unnormalized distributions, we show that our approach yields high-fidelity
samples using less than 1% of the network evaluations required by traditional
diffusion samplers.","Pascal Jutras-Dubé, Patrick Pynadath, Ruqi Zhang",2025-02-11 14:25:52.000000,arXiv,http://arxiv.org/abs/2502.07579v1,Machine Learning
736,Automated Capability Discovery via Model Self-Exploration,"Foundation models have become general-purpose assistants, exhibiting diverse
capabilities across numerous domains through training on web-scale data. It
remains challenging to precisely characterize even a fraction of the full
spectrum of capabilities and potential risks in any new model. Existing
evaluation approaches often require significant human effort, and it is taking
increasing effort to design ever harder challenges for more capable models. We
introduce Automated Capability Discovery (ACD), a framework that designates one
foundation model as a scientist to systematically propose open-ended tasks
probing the abilities of a subject model (potentially itself). By combining
frontier models with ideas from the field of open-endedness, ACD automatically
and systematically uncovers both surprising capabilities and failures in the
subject model. We demonstrate ACD across a range of foundation models
(including the GPT, Claude, and Llama series), showing that it automatically
reveals thousands of capabilities that would be challenging for any single team
to uncover. We further validate our method's automated scoring with extensive
human surveys, observing high agreement between model-generated and human
evaluations. By leveraging foundation models' ability to both create tasks and
self-evaluate, ACD is a significant step toward scalable, automated evaluation
of novel AI systems. All code and evaluation logs are open-sourced at
https://github.com/conglu1997/ACD.","Cong Lu, Shengran Hu, Jeff Clune",2025-02-11 14:23:13.000000,arXiv,http://arxiv.org/abs/2502.07577v2,Machine Learning
737,Towards Efficient and Multifaceted Computer-assisted Pronunciation Training Leveraging Hierarchical Selective State Space Model and Decoupled Cross-entropy Loss,"Prior efforts in building computer-assisted pronunciation training (CAPT)
systems often treat automatic pronunciation assessment (APA) and
mispronunciation detection and diagnosis (MDD) as separate fronts: the former
aims to provide multiple pronunciation aspect scores across diverse linguistic
levels, while the latter focuses instead on pinpointing the precise phonetic
pronunciation errors made by non-native language learners. However, it is
generally expected that a full-fledged CAPT system should perform both
functionalities simultaneously and efficiently. In response to this surging
demand, we in this work first propose HMamba, a novel CAPT approach that
seamlessly integrates APA and MDD tasks in parallel. In addition, we introduce
a novel loss function, decoupled cross-entropy loss (deXent), specifically
tailored for MDD to facilitate better-supervised learning for detecting
mispronounced phones, thereby enhancing overall performance. A comprehensive
set of empirical results on the speechocean762 benchmark dataset demonstrates
the effectiveness of our approach on APA. Notably, our proposed approach also
yields a considerable improvement in MDD performance over a strong baseline,
achieving an F1-score of 63.85%. Our codes are made available at
https://github.com/Fuann/hmamba","Fu-An Chao, Berlin Chen",2025-02-11 14:17:29.000000,arXiv,http://arxiv.org/abs/2502.07575v1,Other
738,Vision-Language Models for Edge Networks: A Comprehensive Survey,"Vision Large Language Models (VLMs) combine visual understanding with natural
language processing, enabling tasks like image captioning, visual question
answering, and video analysis. While VLMs show impressive capabilities across
domains such as autonomous vehicles, smart surveillance, and healthcare, their
deployment on resource-constrained edge devices remains challenging due to
processing power, memory, and energy limitations. This survey explores recent
advancements in optimizing VLMs for edge environments, focusing on model
compression techniques, including pruning, quantization, knowledge
distillation, and specialized hardware solutions that enhance efficiency. We
provide a detailed discussion of efficient training and fine-tuning methods,
edge deployment challenges, and privacy considerations. Additionally, we
discuss the diverse applications of lightweight VLMs across healthcare,
environmental monitoring, and autonomous systems, illustrating their growing
impact. By highlighting key design strategies, current challenges, and offering
recommendations for future directions, this survey aims to inspire further
research into the practical deployment of VLMs, ultimately making advanced AI
accessible in resource-limited settings.","Ahmed Sharshar, Latif U. Khan, Waseem Ullah, Mohsen Guizani",2025-02-11 14:04:43.000000,arXiv,http://arxiv.org/abs/2502.07855v1,Computer Vision
739,An Elliptic Curve Based Solution to the Perspective-Three-Point Problem,"The Perspective-Three-Point Problem (P3P) is solved by first focusing on
determining the directions of the lines through pairs of control points,
relative to the camera, rather than the distances from the camera to the
control points. The analysis of this produces an efficient, accurate and
reasonably simple P3P solver, which is compared with a state-of-the-art P3P
solver, ""Lambda Twist."" Both methods depend on the accurate computation of a
single root of a cubic polynomial. They have been implemented and tested for a
wide range of control-point triangles, and under certain reasonable
restrictions, the new method is noticably more accurate than Lambda Twist,
though it is slower. However, the principal value of the present work is not in
introducing yet another P3P solver, but lies rather in the discovery of an
intimate connection between the P3P problem and a special family of elliptic
curves that includes curves utilized in cryptography. This holds the potential
for further advances in a number of directions. To make this connection, an
interesting spherical analogue of an ancient ""sliding"" problem is stated and
solved.",Michael Q. Rieck,2025-02-11 14:03:39.000000,arXiv,http://arxiv.org/abs/2502.07564v1,Computer Vision
740,LASP-2: Rethinking Sequence Parallelism for Linear Attention and Its Hybrid,"Linear sequence modeling approaches, such as linear attention, provide
advantages like linear-time training and constant-memory inference over
sequence lengths. However, existing sequence parallelism (SP) methods are
either not optimized for the right-product-first feature of linear attention or
use a ring-style communication strategy, which results in lower computation
parallelism, limits their scalability for longer sequences in distributed
systems. In this paper, we introduce LASP-2, a new SP method to enhance both
communication and computation parallelism when training linear attention
transformer models with very-long input sequences. Compared to previous work
LASP, LASP-2 rethinks the minimal communication requirement for SP on linear
attention layers, reorganizes the whole communication-computation workflow of
LASP. In this way, only one single AllGather collective communication is needed
on intermediate memory states, whose sizes are independent of the sequence
length, leading to significant improvements of both communication and
computation parallelism, as well as their overlap. Additionally, we extend
LASP-2 to LASP-2H by applying similar communication redesign to standard
attention modules, offering an efficient SP solution for hybrid models that
blend linear and standard attention layers. Our evaluation on a Linear-Llama3
model, a variant of Llama3 with linear attention replacing standard attention,
demonstrates the effectiveness of LASP-2 and LASP-2H. Specifically, LASP-2
achieves training speed improvements of 15.2% over LASP and 36.6% over Ring
Attention, with a sequence length of 2048K across 64 GPUs. The Code is released
as a part of: https://github.com/OpenSparseLLMs/Linear-MoE.","Weigao Sun, Disen Lan, Yiran Zhong, Xiaoye Qu, Yu Cheng",2025-02-11 14:01:39.000000,arXiv,http://arxiv.org/abs/2502.07563v1,Machine Learning
741,LoRP-TTS: Low-Rank Personalized Text-To-Speech,"Speech synthesis models convert written text into natural-sounding audio.
While earlier models were limited to a single speaker, recent advancements have
led to the development of zero-shot systems that generate realistic speech from
a wide range of speakers using their voices as additional prompts. However,
they still struggle with imitating non-studio-quality samples that differ
significantly from the training datasets. In this work, we demonstrate that
utilizing Low-Rank Adaptation (LoRA) allows us to successfully use even single
recordings of spontaneous speech in noisy environments as prompts. This
approach enhances speaker similarity by up to $30pp$ while preserving content
and naturalness. It represents a significant step toward creating truly diverse
speech corpora, that is crucial in all speech-related tasks.","Łukasz Bondaruk, Jakub Kubiak",2025-02-11 14:00:12.000000,arXiv,http://arxiv.org/abs/2502.07562v1,Other
742,Navigating Semantic Drift in Task-Agnostic Class-Incremental Learning,"Class-incremental learning (CIL) seeks to enable a model to sequentially
learn new classes while retaining knowledge of previously learned ones.
Balancing flexibility and stability remains a significant challenge,
particularly when the task ID is unknown. To address this, our study reveals
that the gap in feature distribution between novel and existing tasks is
primarily driven by differences in mean and covariance moments. Building on
this insight, we propose a novel semantic drift calibration method that
incorporates mean shift compensation and covariance calibration. Specifically,
we calculate each class's mean by averaging its sample embeddings and estimate
task shifts using weighted embedding changes based on their proximity to the
previous mean, effectively capturing mean shifts for all learned classes with
each new task. We also apply Mahalanobis distance constraint for covariance
calibration, aligning class-specific embedding covariances between old and
current networks to mitigate the covariance shift. Additionally, we integrate a
feature-level self-distillation approach to enhance generalization.
Comprehensive experiments on commonly used datasets demonstrate the
effectiveness of our approach. The source code is available at
\href{https://github.com/fwu11/MACIL.git}{https://github.com/fwu11/MACIL.git}.","Fangwen Wu, Lechao Cheng, Shengeng Tang, Xiaofeng Zhu, Chaowei Fang, Dingwen Zhang, Meng Wang",2025-02-11 13:57:30.000000,arXiv,http://arxiv.org/abs/2502.07560v1,Computer Vision
743,Efficient Sparsification of Simplicial Complexes via Local Densities of States,"Simplicial complexes (SCs), a generalization of graph models for relational
data that account for higher-order relations between data items, have become a
popular abstraction for analyzing complex data using tools from topological
data analysis or topological signal processing. However, the analysis of many
real-world datasets leads to dense SCs with a large number of higher-order
interactions. Unfortunately, analyzing such large SCs often has a prohibitive
cost in terms of computation time and memory consumption. The sparsification of
such complexes, i.e., the approximation of an original SC with a sparser
simplicial complex with only a log-linear number of high-order simplices while
maintaining a spectrum close to the original SC, is of broad interest.
  In this work, we develop a novel method for a probabilistic sparsifaction of
SCs. At its core lies the efficient computation of sparsifying sampling
probability through local densities of states as functional descriptors of the
spectral information. To avoid pathological structures in the spectrum of the
corresponding Hodge Laplacian operators, we suggest a ""kernel-ignoring""
decomposition for approximating the sampling probability; additionally, we
exploit error estimates to show asymptotically prevailing algorithmic
complexity of the developed method. The performance of the framework is
demonstrated on the family of Vietoris--Rips filtered simplicial complexes.","Anton Savostianov, Michael T. Schaub, Nicola Guglielmi, Francesco Tudisco",2025-02-11 13:51:42.000000,arXiv,http://arxiv.org/abs/2502.07558v1,Statistical Machine Learning
744,SketchFlex: Facilitating Spatial-Semantic Coherence in Text-to-Image Generation with Region-Based Sketches,"Text-to-image models can generate visually appealing images from text
descriptions. Efforts have been devoted to improving model controls with prompt
tuning and spatial conditioning. However, our formative study highlights the
challenges for non-expert users in crafting appropriate prompts and specifying
fine-grained spatial conditions (e.g., depth or canny references) to generate
semantically cohesive images, especially when multiple objects are involved. In
response, we introduce SketchFlex, an interactive system designed to improve
the flexibility of spatially conditioned image generation using rough region
sketches. The system automatically infers user prompts with rational
descriptions within a semantic space enriched by crowd-sourced object
attributes and relationships. Additionally, SketchFlex refines users' rough
sketches into canny-based shape anchors, ensuring the generation quality and
alignment of user intentions. Experimental results demonstrate that SketchFlex
achieves more cohesive image generations than end-to-end models, meanwhile
significantly reducing cognitive load and better matching user intentions
compared to region-based generation baseline.","Haichuan Lin, Yilin Ye, Jiazhi Xia, Wei Zeng",2025-02-11 13:48:11.000000,arXiv,http://arxiv.org/abs/2502.07556v1,Other
745,O1 Embedder: Let Retrievers Think Before Action,"The growing power of large language models (LLMs) has revolutionized how
people access and utilize information. Notably, the LLMs excel at performing
fine-grained data representation, which facilitates precise retrieval of
information. They also generate high-quality answers based on external
references, enabling the production of useful knowledge. The recent
introduction of reasoning models, like OpenAI O1 and DeepSeek R1, marks another
leap forward, highlighting LLMs' ability to think progressively before
delivering final answers. This breakthrough significantly improves the ability
to address complex tasks, e.g., coding and math proofs.
  Inspired by this progress, we aim to develop similar capabilities for
retrieval models, which hold great promise for tackling critical challenges in
the field, including multi-task retrieval, zero-shot retrieval, and tasks
requiring intensive reasoning of complex relationships. With this motivation,
we propose a novel approach called O1 Embedder, which generates useful thoughts
for the input query before making retrieval for the target documents. To
realize this objective, we conquer two technical difficulties. First, we design
a data synthesis workflow, creating training signals for O1 Embedder by
generating initial thoughts from an LLM-expert and subsequently refining them
using a retrieval committee. Second, we optimize the training process, enabling
a pre-trained model to be jointly fine-tuned to generate retrieval thoughts via
behavior cloning and perform dense retrieval through contrastive learning. Our
approach is evaluated by comprehensive experiments, where substantial
improvements are achieved across 12 popular datasets, spanning both in-domain
and out-of-domain scenarios. These results highlight O1 Embedder's remarkable
accuracy and generalizability, paving the way for the development of
next-generation IR foundation models.","Ruiran Yan, Zheng Liu, Defu Lian",2025-02-11 13:48:10.000000,arXiv,http://arxiv.org/abs/2502.07555v2,Natural Language Processing
746,Attention Learning is Needed to Efficiently Learn Parity Function,"Transformers, with their attention mechanisms, have emerged as the
state-of-the-art architectures of sequential modeling and empirically
outperform feed-forward neural networks (FFNNs) across many fields, such as
natural language processing and computer vision. However, their generalization
ability, particularly for low-sensitivity functions, remains less studied. We
bridge this gap by analyzing transformers on the $k$-parity problem. Daniely
and Malach (NeurIPS 2020) show that FFNNs with one hidden layer and $O(nk^7
\log k)$ parameters can learn $k$-parity, where the input length $n$ is
typically much larger than $k$. In this paper, we prove that FFNNs require at
least $\Omega(n)$ parameters to learn $k$-parity, while transformers require
only $O(k)$ parameters, surpassing the theoretical lower bound needed by FFNNs.
We further prove that this parameter efficiency cannot be achieved with fixed
attention heads. Our work establishes transformers as theoretically superior to
FFNNs in learning parity function, showing how their attention mechanisms
enable parameter-efficient generalization in functions with low sensitivity.","Yaomengxi Han, Debarghya Ghoshdastidar",2025-02-11 13:41:30.000000,arXiv,http://arxiv.org/abs/2502.07553v1,Machine Learning
747,Unsupervised Translation of Emergent Communication,"Emergent Communication (EC) provides a unique window into the language
systems that emerge autonomously when agents are trained to jointly achieve
shared goals. However, it is difficult to interpret EC and evaluate its
relationship with natural languages (NL). This study employs unsupervised
neural machine translation (UNMT) techniques to decipher ECs formed during
referential games with varying task complexities, influenced by the semantic
diversity of the environment. Our findings demonstrate UNMT's potential to
translate EC, illustrating that task complexity characterized by semantic
diversity enhances EC translatability, while higher task complexity with
constrained semantic variability exhibits pragmatic EC, which, although
challenging to interpret, remains suitable for translation. This research marks
the first attempt, to our knowledge, to translate EC without the aid of
parallel data.","Ido Levy, Orr Paradise, Boaz Carmeli, Ron Meir, Shafi Goldwasser, Yonatan Belinkov",2025-02-11 13:41:06.000000,arXiv,http://arxiv.org/abs/2502.07552v1,Natural Language Processing
748,Early Stopping Against Label Noise Without Validation Data,"Early stopping methods in deep learning face the challenge of balancing the
volume of training and validation data, especially in the presence of label
noise. Concretely, sparing more data for validation from training data would
limit the performance of the learned model, yet insufficient validation data
could result in a sub-optimal selection of the desired model. In this paper, we
propose a novel early stopping method called Label Wave, which does not require
validation data for selecting the desired model in the presence of label noise.
It works by tracking the changes in the model's predictions on the training set
during the training process, aiming to halt training before the model unduly
fits mislabeled data. This method is empirically supported by our observation
that minimum fluctuations in predictions typically occur at the training epoch
before the model excessively fits mislabeled data. Through extensive
experiments, we show both the effectiveness of the Label Wave method across
various settings and its capability to enhance the performance of existing
methods for learning with noisy labels.","Suqin Yuan, Lei Feng, Tongliang Liu",2025-02-11 13:40:15.000000,arXiv,http://arxiv.org/abs/2502.07551v1,Machine Learning
749,HGTUL: A Hypergraph-based Model For Trajectory User Linking,"Trajectory User Linking (TUL), which links anonymous trajectories with users
who generate them, plays a crucial role in modeling human mobility. Despite
significant advancements in this field, existing studies primarily neglect the
high-order inter-trajectory relationships, which represent complex associations
among multiple trajectories, manifested through multi-location co-occurrence
patterns emerging when trajectories intersect at various Points of Interest
(POIs). Furthermore, they also overlook the variable influence of POIs on
different trajectories, as well as the user class imbalance problem caused by
disparities in user activity levels and check-in frequencies. To address these
limitations, we propose a novel HyperGraph-based multi-perspective Trajectory
User Linking model (HGTUL). Our model learns trajectory representations from
both relational and spatio-temporal perspectives: (1) it captures high-order
associations among trajectories by constructing a trajectory hypergraph and
leverages a hypergraph attention network to learn the variable impact of POIs
on trajectories; (2) it models the spatio-temporal characteristics of
trajectories by incorporating their temporal and spatial information into a
sequential encoder. Moreover, we design a data balancing method to effectively
address the user class imbalance problem and experimentally validate its
significance in TUL. Extensive experiments on three real-world datasets
demonstrate that HGTUL outperforms state-of-the-art baselines, achieving
improvements of 2.57%~20.09% and 5.68%~26.00% in ACC@1 and Macro-F1 metrics,
respectively.","Fengjie Chang, Xinning Zhu, Zheng Hu, Yang Qin",2025-02-11 13:39:35.000000,arXiv,http://arxiv.org/abs/2502.07549v1,Machine Learning
750,Instance-dependent Early Stopping,"In machine learning practice, early stopping has been widely used to
regularize models and can save computational costs by halting the training
process when the model's performance on a validation set stops improving.
However, conventional early stopping applies the same stopping criterion to all
instances without considering their individual learning statuses, which leads
to redundant computations on instances that are already well-learned. To
further improve the efficiency, we propose an Instance-dependent Early Stopping
(IES) method that adapts the early stopping mechanism from the entire training
set to the instance level, based on the core principle that once the model has
mastered an instance, the training on it should stop. IES considers an instance
as mastered if the second-order differences of its loss value remain within a
small range around zero. This offers a more consistent measure of an instance's
learning status compared with directly using the loss value, and thus allows
for a unified threshold to determine when an instance can be excluded from
further backpropagation. We show that excluding mastered instances from
backpropagation can increase the gradient norms, thereby accelerating the
decrease of the training loss and speeding up the training process. Extensive
experiments on benchmarks demonstrate that IES method can reduce
backpropagation instances by 10%-50% while maintaining or even slightly
improving the test accuracy and transfer learning performance of a model.","Suqin Yuan, Runqi Lin, Lei Feng, Bo Han, Tongliang Liu",2025-02-11 13:34:09.000000,arXiv,http://arxiv.org/abs/2502.07547v1,Machine Learning
751,Grammar Control in Dialogue Response Generation for Language Learning Chatbots,"Chatbots based on large language models offer cheap conversation practice
opportunities for language learners. However, they are hard to control for
linguistic forms that correspond to learners' current needs, such as grammar.
We control grammar in chatbot conversation practice by grounding a dialogue
response generation model in a pedagogical repository of grammar skills. We
also explore how this control helps learners to produce specific grammar. We
comprehensively evaluate prompting, fine-tuning, and decoding strategies for
grammar-controlled dialogue response generation. Strategically decoding Llama3
outperforms GPT-3.5 when tolerating minor response quality losses. Our
simulation predicts grammar-controlled responses to support grammar acquisition
adapted to learner proficiency. Existing language learning chatbots and
research on second language acquisition benefit from these affordances. Code
available on GitHub.","Dominik Glandorf, Peng Cui, Detmar Meurers, Mrinmaya Sachan",2025-02-11 13:30:41.000000,arXiv,http://arxiv.org/abs/2502.07544v1,Natural Language Processing
752,Exoplanet Transit Candidate Identification in TESS Full-Frame Images via a Transformer-Based Algorithm,"The Transiting Exoplanet Survey Satellite (TESS) is surveying a large
fraction of the sky, generating a vast database of photometric time series data
that requires thorough analysis to identify exoplanetary transit signals.
Automated learning approaches have been successfully applied to identify
transit signals. However, most existing methods focus on the classification and
validation of candidates, while few efforts have explored new techniques for
the search of candidates. To search for new exoplanet transit candidates, we
propose an approach to identify exoplanet transit signals without the need for
phase folding or assuming periodicity in the transit signals, such as those
observed in multi-transit light curves. To achieve this, we implement a new
neural network inspired by Transformers to directly process Full Frame Image
(FFI) light curves to detect exoplanet transits. Transformers, originally
developed for natural language processing, have recently demonstrated
significant success in capturing long-range dependencies compared to previous
approaches focused on sequential data. This ability allows us to employ
multi-head self-attention to identify exoplanet transit signals directly from
the complete light curves, combined with background and centroid time series,
without requiring prior transit parameters. The network is trained to learn
characteristics of the transit signal, like the dip shape, which helps
distinguish planetary transits from other variability sources. Our model
successfully identified 214 new planetary system candidates, including 122
multi-transit light curves, 88 single-transit and 4 multi-planet systems from
TESS sectors 1-26 with a radius > 0.27 $R_{\mathrm{Jupiter}}$, demonstrating
its ability to detect transits regardless of their periodicity.","Helem Salinas, Rafael Brahm, Greg Olmschenk, Richard K. Barry, Karim Pichara, Stela Ishitani Silva, Vladimir Araujo",2025-02-11 13:29:58.000000,arXiv,http://arxiv.org/abs/2502.07542v1,Other
753,Corporate Greenwashing Detection in Text - a Survey,"Greenwashing is an effort to mislead the public about the environmental
impact of an entity, such as a state or company. We provide a comprehensive
survey of the scientific literature addressing natural language processing
methods to identify potentially misleading climate-related corporate
communications, indicative of greenwashing. We break the detection of
greenwashing into intermediate tasks, and review the state-of-the-art
approaches for each of them. We discuss datasets, methods, and results, as well
as limitations and open challenges. We also provide an overview of how far the
field has come as a whole, and point out future research directions.","Tom Calamai, Oana Balalau, Théo Le Guenedal, Fabian M. Suchanek",2025-02-11 13:28:56.000000,arXiv,http://arxiv.org/abs/2502.07541v1,Natural Language Processing
754,Diffusion-LAM: Probabilistic Limited Area Weather Forecasting with Diffusion,"Machine learning methods have been shown to be effective for weather
forecasting, based on the speed and accuracy compared to traditional numerical
models. While early efforts primarily concentrated on deterministic
predictions, the field has increasingly shifted toward probabilistic
forecasting to better capture the forecast uncertainty. Most machine
learning-based models have been designed for global-scale predictions, with
only limited work targeting regional or limited area forecasting, which allows
more specialized and flexible modeling for specific locations. This work
introduces Diffusion-LAM, a probabilistic limited area weather model leveraging
conditional diffusion. By conditioning on boundary data from surrounding
regions, our approach generates forecasts within a defined area. Experimental
results on the MEPS limited area dataset demonstrate the potential of
Diffusion-LAM to deliver accurate probabilistic forecasts, highlighting its
promise for limited-area weather prediction.","Erik Larsson, Joel Oskarsson, Tomas Landelius, Fredrik Lindsten",2025-02-11 13:15:16.000000,arXiv,http://arxiv.org/abs/2502.07532v2,Machine Learning
755,Advancing Heat Demand Forecasting with Attention Mechanisms: Opportunities and Challenges,"Global leaders and policymakers are unified in their unequivocal commitment
to decarbonization efforts in support of Net-Zero agreements. District Heating
Systems (DHS), while contributing to carbon emissions due to the continued
reliance on fossil fuels for heat production, are embracing more sustainable
practices albeit with some sense of vulnerability as it could constrain their
ability to adapt to dynamic demand and production scenarios. As demographic
demands grow and renewables become the central strategy in decarbonizing the
heating sector, the need for accurate demand forecasting has intensified.
Advances in digitization have paved the way for Machine Learning (ML) based
solutions to become the industry standard for modeling complex time series
patterns. In this paper, we focus on building a Deep Learning (DL) model that
uses deconstructed components of independent and dependent variables that
affect heat demand as features to perform multi-step ahead forecasting of head
demand. The model represents the input features in a time-frequency space and
uses an attention mechanism to generate accurate forecasts. The proposed method
is evaluated on a real-world dataset and the forecasting performance is
assessed against LSTM and CNN-based forecasting models. Across different supply
zones, the attention-based models outperforms the baselines quantitatively and
qualitatively, with an Mean Absolute Error (MAE) of 0.105 with a standard
deviation of 0.06kW h and a Mean Absolute Percentage Error (MAPE) of 5.4% with
a standard deviation of 2.8%, in comparison the second best model with a MAE of
0.10 with a standard deviation of 0.06kW h and a MAPE of 5.6% with a standard
deviation of 3%.","Adithya Ramachandran, Thorkil Flensmark B. Neergaard, Andreas Maier, Siming Bayer",2025-02-11 13:12:06.000000,arXiv,http://arxiv.org/abs/2502.07854v1,Machine Learning
756,"VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation","Recent image-to-video generation methods have demonstrated success in
enabling control over one or two visual elements, such as camera trajectory or
object motion. However, these methods are unable to offer control over multiple
visual elements due to limitations in data and network efficacy. In this paper,
we introduce VidCRAFT3, a novel framework for precise image-to-video generation
that enables control over camera motion, object motion, and lighting direction
simultaneously. To better decouple control over each visual element, we propose
the Spatial Triple-Attention Transformer, which integrates lighting direction,
text, and image in a symmetric way. Since most real-world video datasets lack
lighting annotations, we construct a high-quality synthetic video dataset, the
VideoLightingDirection (VLD) dataset. This dataset includes lighting direction
annotations and objects of diverse appearance, enabling VidCRAFT3 to
effectively handle strong light transmission and reflection effects.
Additionally, we propose a three-stage training strategy that eliminates the
need for training data annotated with multiple visual elements (camera motion,
object motion, and lighting direction) simultaneously. Extensive experiments on
benchmark datasets demonstrate the efficacy of VidCRAFT3 in producing
high-quality video content, surpassing existing state-of-the-art methods in
terms of control granularity and visual coherence. All code and data will be
publicly available.","Sixiao Zheng, Zimian Peng, Yanpeng Zhou, Yi Zhu, Hang Xu, Xiangru Huang, Yanwei Fu",2025-02-11 13:11:59.000000,arXiv,http://arxiv.org/abs/2502.07531v2,Computer Vision
757,Training Deep Learning Models with Norm-Constrained LMOs,"In this work, we study optimization methods that leverage the linear
minimization oracle (LMO) over a norm-ball. We propose a new stochastic family
of algorithms that uses the LMO to adapt to the geometry of the problem and,
perhaps surprisingly, show that they can be applied to unconstrained problems.
The resulting update rule unifies several existing optimization methods under a
single framework. Furthermore, we propose an explicit choice of norm for deep
architectures, which, as a side benefit, leads to the transferability of
hyperparameters across model sizes. Experimentally, we demonstrate significant
speedups on nanoGPT training without any reliance on Adam. The proposed method
is memory-efficient, requiring only one set of model weights and one set of
gradients, which can be stored in half-precision.","Thomas Pethick, Wanyun Xie, Kimon Antonakopoulos, Zhenyu Zhu, Antonio Silveti-Falls, Volkan Cevher",2025-02-11 13:10:34.000000,arXiv,http://arxiv.org/abs/2502.07529v1,Machine Learning
758,Forecasting the future development in quality and value of professional football players for applications in team management,"Transfers in professional football (soccer) are risky investments because of
the large transfer fees and high risks involved. Although data-driven models
can be used to improve transfer decisions, existing models focus on describing
players' historical progress, leaving their future performance unknown.
Moreover, recent developments have called for the use of explainable models
combined with uncertainty quantification of predictions. This paper assesses
explainable machine learning models based on predictive accuracy and
uncertainty quantification methods for the prediction of the future development
in quality and transfer value of professional football players. Using a
historical data set of data-driven indicators describing player quality and the
transfer value of a football player, the models are trained to forecast player
quality and player value one year ahead. These two prediction problems
demonstrate the efficacy of tree-based models, particularly random forest and
XGBoost, in making accurate predictions. In general, the random forest model is
found to be the most suitable model because it provides accurate predictions as
well as an uncertainty quantification method that naturally arises from the
bagging procedure of the random forest model. Additionally, our research shows
that the development of player performance contains nonlinear patterns and
interactions between variables, and that time series information can provide
useful information for the modeling of player performance metrics. Our research
provides models to help football clubs make more informed, data-driven transfer
decisions by forecasting player quality and transfer value.","Koen W. van Arem, Floris Goes-Smit, Jakob Söhl",2025-02-11 13:09:09.000000,arXiv,http://arxiv.org/abs/2502.07528v1,Other
759,NatureLM: Deciphering the Language of Nature for Scientific Discovery,"Foundation models have revolutionized natural language processing and
artificial intelligence, significantly enhancing how machines comprehend and
generate human languages. Inspired by the success of these foundation models,
researchers have developed foundation models for individual scientific domains,
including small molecules, materials, proteins, DNA, and RNA. However, these
models are typically trained in isolation, lacking the ability to integrate
across different scientific domains. Recognizing that entities within these
domains can all be represented as sequences, which together form the ""language
of nature"", we introduce Nature Language Model (briefly, NatureLM), a
sequence-based science foundation model designed for scientific discovery.
Pre-trained with data from multiple scientific domains, NatureLM offers a
unified, versatile model that enables various applications including: (i)
generating and optimizing small molecules, proteins, RNA, and materials using
text instructions; (ii) cross-domain generation/design, such as
protein-to-molecule and protein-to-RNA generation; and (iii) achieving
state-of-the-art performance in tasks like SMILES-to-IUPAC translation and
retrosynthesis on USPTO-50k. NatureLM offers a promising generalist approach
for various scientific tasks, including drug discovery (hit
generation/optimization, ADMET optimization, synthesis), novel material design,
and the development of therapeutic proteins or nucleotides. We have developed
NatureLM models in different sizes (1 billion, 8 billion, and 46.7 billion
parameters) and observed a clear improvement in performance as the model size
increases.","Yingce Xia, Peiran Jin, Shufang Xie, Liang He, Chuan Cao, Renqian Luo, Guoqing Liu, Yue Wang, Zequn Liu, Yuan-Jyue Chen, Zekun Guo, Yeqi Bai, Pan Deng, Yaosen Min, Ziheng Lu, Hongxia Hao, Han Yang, Jielan Li, Chang Liu, Jia Zhang, Jianwei Zhu, Kehan Wu, Wei Zhang, Kaiyuan Gao, Qizhi Pei, Qian Wang, Xixian Liu, Yanting Li, Houtian Zhu, Yeqing Lu, Mingqian Ma, Zun Wang, Tian Xie, Krzysztof Maziarz, Marwin Segler, Zhao Yang, Zilong Chen, Yu Shi, Shuxin Zheng, Lijun Wu, Chen Hu, Peggy Dai, Tie-Yan Liu, Haiguang Liu, Tao Qin",2025-02-11 13:08:03.000000,arXiv,http://arxiv.org/abs/2502.07527v1,Artificial Intelligence
760,CodePhys: Robust Video-based Remote Physiological Measurement through Latent Codebook Querying,"Remote photoplethysmography (rPPG) aims to measure non-contact physiological
signals from facial videos, which has shown great potential in many
applications. Most existing methods directly extract video-based rPPG features
by designing neural networks for heart rate estimation. Although they can
achieve acceptable results, the recovery of rPPG signal faces intractable
challenges when interference from real-world scenarios takes place on facial
video. Specifically, facial videos are inevitably affected by non-physiological
factors (e.g., camera device noise, defocus, and motion blur), leading to the
distortion of extracted rPPG signals. Recent rPPG extraction methods are easily
affected by interference and degradation, resulting in noisy rPPG signals. In
this paper, we propose a novel method named CodePhys, which innovatively treats
rPPG measurement as a code query task in a noise-free proxy space (i.e.,
codebook) constructed by ground-truth PPG signals. We consider noisy rPPG
features as queries and generate high-fidelity rPPG features by matching them
with noise-free PPG features from the codebook. Our approach also incorporates
a spatial-aware encoder network with a spatial attention mechanism to highlight
physiologically active areas and uses a distillation loss to reduce the
influence of non-periodic visual interference. Experimental results on four
benchmark datasets demonstrate that CodePhys outperforms state-of-the-art
methods in both intra-dataset and cross-dataset settings.","Shuyang Chu, Menghan Xia, Mengyao Yuan, Xin Liu, Tapio Seppanen, Guoying Zhao, Jingang Shi",2025-02-11 13:05:42.000000,arXiv,http://arxiv.org/abs/2502.07526v1,Computer Vision
761,Scaling Off-Policy Reinforcement Learning with Batch and Weight Normalization,"Reinforcement learning has achieved significant milestones, but sample
efficiency remains a bottleneck for real-world applications. Recently, CrossQ
has demonstrated state-of-the-art sample efficiency with a low update-to-data
(UTD) ratio of 1. In this work, we explore CrossQ's scaling behavior with
higher UTD ratios. We identify challenges in the training dynamics, which are
emphasized by higher UTD ratios. To address these, we integrate weight
normalization into the CrossQ framework, a solution that stabilizes training,
has been shown to prevent potential loss of plasticity and keeps the effective
learning rate constant. Our proposed approach reliably scales with increasing
UTD ratios, achieving competitive performance across 25 challenging continuous
control tasks on the DeepMind Control Suite and Myosuite benchmarks, notably
the complex dog and humanoid environments. This work eliminates the need for
drastic interventions, such as network resets, and offers a simple yet robust
pathway for improving sample efficiency and scalability in model-free
reinforcement learning.","Daniel Palenicek, Florian Vogt, Jan Peters",2025-02-11 12:55:32.000000,arXiv,http://arxiv.org/abs/2502.07523v1,Machine Learning
762,The Devil is in the Prompts: De-Identification Traces Enhance Memorization Risks in Synthetic Chest X-Ray Generation,"Generative models, particularly text-to-image (T2I) diffusion models, play a
crucial role in medical image analysis. However, these models are prone to
training data memorization, posing significant risks to patient privacy.
Synthetic chest X-ray generation is one of the most common applications in
medical image analysis with the MIMIC-CXR dataset serving as the primary data
repository for this task. This study adopts a data-driven approach and presents
the first systematic attempt to identify prompts and text tokens in MIMIC-CXR
that contribute the most to training data memorization. Our analysis reveals an
unexpected finding: prompts containing traces of de-identification procedures
are among the most memorized, with de-identification markers contributing the
most. Furthermore, we also find existing inference-time memorization mitigation
strategies are ineffective and fail to sufficiently reduce the model's reliance
on memorized text tokens highlighting a broader issue in T2I synthesis with
MIMIC-CXR. On this front, we propose actionable strategies to enhance privacy
and improve the reliability of generative models in medical imaging. Finally,
our results provide a foundation for future work on developing and benchmarking
memorization mitigation techniques for synthetic chest X-ray generation using
the MIMIC-CXR dataset.",Raman Dutt,2025-02-11 12:36:00.000000,arXiv,http://arxiv.org/abs/2502.07516v1,Other
763,PolicySimEval: A Benchmark for Evaluating Policy Outcomes through Agent-Based Simulation,"With the growing adoption of agent-based models in policy evaluation, a
pressing question arises: Can such systems effectively simulate and analyze
complex social scenarios to inform policy decisions? Addressing this challenge
could significantly enhance the policy-making process, offering researchers and
practitioners a systematic way to validate, explore, and refine policy
outcomes. To advance this goal, we introduce PolicySimEval, the first benchmark
designed to evaluate the capability of agent-based simulations in policy
assessment tasks. PolicySimEval aims to reflect the real-world complexities
faced by social scientists and policymakers. The benchmark is composed of three
categories of evaluation tasks: (1) 20 comprehensive scenarios that replicate
end-to-end policy modeling challenges, complete with annotated expert
solutions; (2) 65 targeted sub-tasks that address specific aspects of
agent-based simulation (e.g., agent behavior calibration); and (3) 200
auto-generated tasks to enable large-scale evaluation and method development.
Experiments show that current state-of-the-art frameworks struggle to tackle
these tasks effectively, with the highest-performing system achieving only
24.5\% coverage rate on comprehensive scenarios, 15.04\% on sub-tasks, and
14.5\% on auto-generated tasks. These results highlight the difficulty of the
task and the gap between current capabilities and the requirements for
real-world policy evaluation.","Jiaju Kang, Puyu Han, Tian Zhang, Luqi Gong",2025-02-11 12:36:00.000000,arXiv,http://arxiv.org/abs/2502.07853v1,Multi-Agent Systems
764,"A Near-optimal, Scalable and Corruption-tolerant Framework for Stochastic Bandits: From Single-Agent to Multi-Agent and Beyond","We investigate various stochastic bandit problems in the presence of
adversarial corruption. A seminal contribution to this area is the
BARBAR~\citep{gupta2019better} algorithm, which is both simple and efficient,
tolerating significant levels of corruption with nearly no degradation in
performance. However, its regret upper bound exhibits a complexity of $O(KC)$,
while the lower bound is $\Omega(C)$. In this paper, we enhance the BARBAR
algorithm by proposing a novel framework called BARBAT, which eliminates the
factor of $K$ and achieves an optimal regret bound up to a logarithmic factor.
We also demonstrate how BARBAT can be extended to various settings, including
graph bandits, combinatorial semi-bandits, batched bandits and multi-agent
bandits. In comparison to the Follow-The-Regularized-Leader (FTRL) family of
methods, which provide a best-of-both-worlds guarantee, our approach is more
efficient and parallelizable. Notably, FTRL-based methods face challenges in
scaling to batched and multi-agent settings.","Zicheng Hu, Cheng Chen",2025-02-11 12:33:33.000000,arXiv,http://arxiv.org/abs/2502.07514v1,Machine Learning
765,Fresh2comm: Information Freshness Optimized Collaborative Perception,"Collaborative perception is a cornerstone of intelligent connected vehicles,
enabling them to share and integrate sensory data to enhance situational
awareness. However, measuring the impact of high transmission delay and
inconsistent delay on collaborative perception in real communication scenarios,
as well as improving the effectiveness of collaborative perception under such
conditions, remain significant challenges in the field. To address these
challenges, we incorporate the key factor of information freshness into the
collaborative perception mechanism and develop a model that systematically
measures and analyzes the impacts of real-world communication on collaborative
perception performance. This provides a new perspective for accurately
evaluating and optimizing collaborative perception performance. We propose and
validate an Age of Information (AoI)-based optimization framework that
strategically allocates communication resources to effectively control the
system's AoI, thereby significantly enhancing the freshness of information
transmission and the accuracy of perception. Additionally, we introduce a novel
experimental approach that comprehensively assesses the varying impacts of
different types of delay on perception results, offering valuable insights for
perception performance optimization under real-world communication scenarios.","Ziyong Wu, Zhilin Peng, Lei Yu",2025-02-11 12:29:57.000000,arXiv,http://arxiv.org/abs/2502.07852v1,Multi-Agent Systems
766,Quantitative evaluation of unsupervised clustering algorithms for dynamic total-body PET image analysis,"Background. Recently, dynamic total-body positron emission tomography (PET)
imaging has become possible due to new scanner devices. While clustering
algorithms have been proposed for PET analysis already earlier, there is still
little research systematically evaluating these algorithms for processing of
dynamic total-body PET images. Materials and methods. Here, we compare the
performance of 15 unsupervised clustering methods, including K-means either by
itself or after principal component analysis (PCA) or independent component
analysis (ICA), Gaussian mixture model (GMM), fuzzy c-means (FCM),
agglomerative clustering, spectral clustering, and several newer clustering
algorithms, for classifying time activity curves (TACs) in dynamic PET images.
We use dynamic total-body $^{15}$O-water PET images collected from 30 patients
with suspected or confirmed coronary artery disease. To evaluate the clustering
algorithms in a quantitative way, we use them to classify 5000 TACs from each
image based on whether the curve is taken from brain, right heart ventricle,
right kidney, lower right lung lobe, or urinary bladder. Results. According to
our results, the best methods are GMM, FCM, and ICA combined with mini batch
K-means, which classified the TACs with a median accuracies of 89\%, 83\%, and
81\%, respectively, in a processing time of half a second or less on average
for each image. Conclusion. GMM, FCM, and ICA with mini batch K-means show
promise for dynamic total-body PET analysis.","Oona Rainio, Maria K. Jaakkola, Riku Klén",2025-02-11 12:28:50.000000,arXiv,http://arxiv.org/abs/2502.07511v1,Other
767,Joint Metric Space Embedding by Unbalanced OT with Gromov-Wasserstein Marginal Penalization,"We propose a new approach for unsupervised alignment of heterogeneous
datasets, which maps data from two different domains without any known
correspondences to a common metric space. Our method is based on an unbalanced
optimal transport problem with Gromov-Wasserstein marginal penalization. It can
be seen as a counterpart to the recently introduced joint multidimensional
scaling method. We prove that there exists a minimizer of our functional and
that for penalization parameters going to infinity, the corresponding sequence
of minimizers converges to a minimizer of the so-called embedded Wasserstein
distance. Our model can be reformulated as a quadratic, multi-marginal,
unbalanced optimal transport problem, for which a bi-convex relaxation admits a
numerical solver via block-coordinate descent. We provide numerical examples
for joint embeddings in Euclidean as well as non-Euclidean spaces.","Florian Beier, Moritz Piening, Robert Beinert, Gabriele Steidl",2025-02-11 12:28:47.000000,arXiv,http://arxiv.org/abs/2502.07510v1,Machine Learning
768,Dual Arm Steering of Deformable Linear Objects in 2-D and 3-D Environments Using Euler's Elastica Solutions,"This paper describes a method for steering deformable linear objects using
two robot hands in environments populated by sparsely spaced obstacles. The
approach involves manipulating an elastic inextensible rod by varying the
gripping endpoint positions and tangents. Closed form solutions that describe
the flexible linear object shape in planar environments, Euler's elastica, are
described. The paper uses these solutions to formulate criteria for non
self-intersection, stability and obstacle avoidance. These criteria are
formulated as constraints in the flexible object six-dimensional configuration
space that represents the robot gripping endpoint positions and tangents. In
particular, this paper introduces a novel criterion that ensures the flexible
object stability during steering. All safety criteria are integrated into a
scheme for steering flexible linear objects in planar environments, which is
lifted into a steering scheme in three-dimensional environments populated by
sparsely spaced obstacles. Experiments with a dual-arm robot demonstrate the
method.","Aharon Levin, Itay Grinberg, Elon Rimon, Amir Shapiro",2025-02-11 12:25:47.000000,arXiv,http://arxiv.org/abs/2502.07509v1,Robotics
769,Enhance-A-Video: Better Generated Video for Free,"DiT-based video generation has achieved remarkable results, but research into
enhancing existing models remains relatively unexplored. In this work, we
introduce a training-free approach to enhance the coherence and quality of
DiT-based generated videos, named Enhance-A-Video. The core idea is enhancing
the cross-frame correlations based on non-diagonal temporal attention
distributions. Thanks to its simple design, our approach can be easily applied
to most DiT-based video generation frameworks without any retraining or
fine-tuning. Across various DiT-based video generation models, our approach
demonstrates promising improvements in both temporal consistency and visual
quality. We hope this research can inspire future explorations in video
generation enhancement.","Yang Luo, Xuanlei Zhao, Mengzhao Chen, Kaipeng Zhang, Wenqi Shao, Kai Wang, Zhangyang Wang, Yang You",2025-02-11 12:22:35.000000,arXiv,http://arxiv.org/abs/2502.07508v2,Computer Vision
770,Efficient Continuous Group Convolutions for Local SE(3) Equivariance in 3D Point Clouds,"Extending the translation equivariance property of convolutional neural
networks to larger symmetry groups has been shown to reduce sample complexity
and enable more discriminative feature learning. Further, exploiting additional
symmetries facilitates greater weight sharing than standard convolutions,
leading to an enhanced network expressivity without an increase in parameter
count. However, extending the equivariant properties of a convolution layer
comes at a computational cost. In particular, for 3D data, expanding
equivariance to the SE(3) group (rotation and translation) results in a 6D
convolution operation, which is not tractable for larger data samples such as
3D scene scans. While efforts have been made to develop efficient SE(3)
equivariant networks, existing approaches rely on discretization or only
introduce global rotation equivariance. This limits their applicability to
point clouds representing a scene composed of multiple objects. This work
presents an efficient, continuous, and local SE(3) equivariant convolution
layer for point cloud processing based on general group convolution and local
reference frames. Our experiments show that our approach achieves competitive
or superior performance across a range of datasets and tasks, including object
classification and semantic segmentation, with negligible computational
overhead.","Lisa Weijler, Pedro Hermosilla",2025-02-11 12:15:56.000000,arXiv,http://arxiv.org/abs/2502.07505v1,Computer Vision
771,Proceedings 40th International Conference on Logic Programming,"Since the first conference In Marseille in 1982, the International Conference
on Logic Programming (ICLP) has been the premier international event for
presenting research in logic programming. These proceedings include technical
communications about, and abstracts for presentations given at the 40th ICLP
held October 14-17, in Dallas Texas, USA. The papers and abstracts in this
volume include the following areas and topics. Formal and operational
semantics: including non-monotonic reasoning, probabilistic reasoning,
argumentation, and semantic issues of combining logic with neural models.
Language design and programming methodologies such as answer set programming.
inductive logic programming, and probabilistic programming. Program analysis
and logic-based validation of generated programs. Implementation methodologies
including constraint implementation, tabling, Logic-based prompt engineering,
and the interaction of logic programming with LLMs.","Pedro Cabalar, Francesco Fabiano, Martin Gebser, Gopal Gupta, Theresa Swift",2025-02-11 12:13:52.000000,arXiv,http://arxiv.org/abs/2502.08453v1,Other
772,Harnessing Language's Fractal Geometry with Recursive Inference Scaling,"Recent research in language modeling reveals two scaling effects: the
well-known improvement from increased training compute, and a lesser-known
boost from applying more sophisticated or computationally intensive inference
methods. Inspired by recent findings on the fractal geometry of language, we
introduce Recursive INference Scaling (RINS) as a complementary, plug-in recipe
for scaling inference time. For a given fixed model architecture and training
compute budget, RINS substantially improves language modeling performance. It
also generalizes beyond pure language tasks, delivering gains in multimodal
systems, including a +2% improvement in 0-shot ImageNet accuracy for
SigLIP-B/16. Additionally, by deriving data scaling laws, we show that RINS
improves both the asymptotic performance limits and the scaling exponents.
These advantages are maintained even when compared to state-of-the-art
recursive techniques like the ""repeat-all-over"" (RAO) strategy in Mobile LLM.
Finally, stochastic RINS not only can enhance performance further but also
provides the flexibility to optionally forgo increased inference computation at
test time with minimal performance degradation.","Ibrahim Alabdulmohsin, Xiaohua Zhai",2025-02-11 12:11:40.000000,arXiv,http://arxiv.org/abs/2502.07503v1,Artificial Intelligence
773,Unified Graph Networks (UGN): A Deep Neural Framework for Solving Graph Problems,"Deep neural networks have enabled researchers to create powerful generalized
frameworks, such as transformers, that can be used to solve well-studied
problems in various application domains, such as text and image. However, such
generalized frameworks are not available for solving graph problems. Graph
structures are ubiquitous in many applications around us and many graph
problems have been widely studied over years. In recent times, there has been a
surge in deep neural network based approaches to solve graph problems, with
growing availability of graph structured datasets across diverse domains.
Nevertheless, existing methods are mostly tailored to solve a specific task and
lack the capability to create a generalized model leading to solutions for
different downstream tasks. In this work, we propose a novel,
resource-efficient framework named \emph{U}nified \emph{G}raph \emph{N}etwork
(UGN) by leveraging the feature extraction capability of graph convolutional
neural networks (GCN) and 2-dimensional convolutional neural networks (Conv2D).
UGN unifies various graph learning tasks, such as link prediction, node
classification, community detection, graph-to-graph translation, knowledge
graph completion, and more, within a cohesive framework, while exercising
minimal task-specific extensions (e.g., formation of supernodes for coarsening
massive networks to increase scalability, use of \textit{mean target
connectivity matrix} (MTCM) representation for achieving scalability in graph
translation task, etc.) to enhance the generalization capability of graph
learning and analysis. We test the novel UGN framework for six uncorrelated
graph problems, using twelve different datasets. Experimental results show that
UGN outperforms the state-of-the-art baselines by a significant margin on ten
datasets, while producing comparable results on the remaining dataset.","Rudrajit Dawn, Madhusudan Ghosh, Partha Basuchowdhuri, Sudip Kumar Naskar",2025-02-11 12:03:18.000000,arXiv,http://arxiv.org/abs/2502.07500v1,Machine Learning
774,On Training-Conditional Conformal Prediction and Binomial Proportion Confidence Intervals,"Estimating the expectation of a Bernoulli random variable based on N
independent trials is a classical problem in statistics, typically addressed
using Binomial Proportion Confidence Intervals (BPCI). In the control systems
community, many critical tasks-such as certifying the statistical safety of
dynamical systems-can be formulated as BPCI problems. Conformal Prediction
(CP), a distribution-free technique for uncertainty quantification, has gained
significant attention in recent years and has been applied to various control
systems problems, particularly to address uncertainties in learned dynamics or
controllers. A variant known as training-conditional CP was recently employed
to tackle the problem of safety certification. In this note, we highlight that
the use of training-conditional CP in this context does not provide valid
safety guarantees. We demonstrate why CP is unsuitable for BPCI problems and
argue that traditional BPCI methods are better suited for statistical safety
certification.","Rudi Coppola, Manuel Mazo Jr",2025-02-11 11:59:03.000000,arXiv,http://arxiv.org/abs/2502.07497v1,Machine Learning
775,LLM-Sketch: Enhancing Network Sketches with LLM,"Network stream mining is fundamental to many network operations. Sketches, as
compact data structures that offer low memory overhead with bounded accuracy,
have emerged as a promising solution for network stream mining. Recent studies
attempt to optimize sketches using machine learning; however, these approaches
face the challenges of lacking adaptivity to dynamic networks and incurring
high training costs. In this paper, we propose LLM-Sketch, based on the insight
that fields beyond the flow IDs in packet headers can also help infer flow
sizes. By using a two-tier data structure and separately recording large and
small flows, LLM-Sketch improves accuracy while minimizing memory usage.
Furthermore, it leverages fine-tuned large language models (LLMs) to reliably
estimate flow sizes. We evaluate LLM-Sketch on three representative tasks, and
the results demonstrate that LLM-Sketch outperforms state-of-the-art methods by
achieving a $7.5\times$ accuracy improvement.","Yuanpeng Li, Zhen Xu, Zongwei Lv, Yannan Hu, Yong Cui, Tong Yang",2025-02-11 11:54:56.000000,arXiv,http://arxiv.org/abs/2502.07495v1,Other
776,URECA: The Chain of Two Minimum Set Cover Problems exists behind Adaptation to Shifts in Semantic Code Search,"Adaptation is to make model learn the patterns shifted from the training
distribution. In general, this adaptation is formulated as the minimum entropy
problem. However, the minimum entropy problem has inherent limitation --
shifted initialization cascade phenomenon. We extend the relationship between
the minimum entropy problem and the minimum set cover problem via Lebesgue
integral. This extension reveals that internal mechanism of the minimum entropy
problem ignores the relationship between disentangled representations, which
leads to shifted initialization cascade. From the analysis, we introduce a new
clustering algorithm, Union-find based Recursive Clustering Algorithm~(URECA).
URECA is an efficient clustering algorithm for the leverage of the
relationships between disentangled representations. The update rule of URECA
depends on Thresholdly-Updatable Stationary Assumption to dynamics as a
released version of Stationary Assumption. This assumption helps URECA to
transport disentangled representations with no errors based on the
relationships between disentangled representations. URECA also utilize
simulation trick to efficiently cluster disentangled representations. The wide
range of evaluations show that URECA achieves consistent performance gains for
the few-shot adaptation to diverse types of shifts along with advancement to
State-of-The-Art performance in CoSQA in the scenario of query shift.","Seok-Ung Choi, Joonghyuk Hahn, Yo-Sub Han",2025-02-11 11:53:23.000000,arXiv,http://arxiv.org/abs/2502.07494v1,Artificial Intelligence
777,RoMA: Robust Malware Attribution via Byte-level Adversarial Training with Global Perturbations and Adversarial Consistency Regularization,"Attributing APT (Advanced Persistent Threat) malware to their respective
groups is crucial for threat intelligence and cybersecurity. However, APT
adversaries often conceal their identities, rendering attribution inherently
adversarial. Existing machine learning-based attribution models, while
effective, remain highly vulnerable to adversarial attacks. For example, the
state-of-the-art byte-level model MalConv sees its accuracy drop from over 90%
to below 2% under PGD (projected gradient descent) attacks. Existing
gradient-based adversarial training techniques for malware detection or image
processing were applied to malware attribution in this study, revealing that
both robustness and training efficiency require significant improvement. To
address this, we propose RoMA, a novel single-step adversarial training
approach that integrates global perturbations to generate enhanced adversarial
samples and employs adversarial consistency regularization to improve
representation quality and resilience. A novel APT malware dataset named AMG18,
with diverse samples and realistic class imbalances, is introduced for
evaluation. Extensive experiments show that RoMA significantly outperforms
seven competing methods in both adversarial robustness (e.g., achieving over
80% robust accuracy-more than twice that of the next-best method under PGD
attacks) and training efficiency (e.g., more than twice as fast as the
second-best method in terms of accuracy), while maintaining superior standard
accuracy in non-adversarial scenarios.","Yuxia Sun, Huihong Chen, Jingcai Guo, Aoxiang Sun, Zhetao Li, Haolin Liu",2025-02-11 11:51:12.000000,arXiv,http://arxiv.org/abs/2502.07492v1,Other
778,Exploring Patterns Behind Sports,"This paper presents a comprehensive framework for time series prediction
using a hybrid model that combines ARIMA and LSTM. The model incorporates
feature engineering techniques, including embedding and PCA, to transform raw
data into a lower-dimensional representation while retaining key information.
The embedding technique is used to convert categorical data into continuous
vectors, facilitating the capture of complex relationships. PCA is applied to
reduce dimensionality and extract principal components, enhancing model
performance and computational efficiency. To handle both linear and nonlinear
patterns in the data, the ARIMA model captures linear trends, while the LSTM
model models complex nonlinear dependencies. The hybrid model is trained on
historical data and achieves high accuracy, as demonstrated by low RMSE and MAE
scores. Additionally, the paper employs the run test to assess the randomness
of sequences, providing insights into the underlying patterns. Ablation studies
are conducted to validate the roles of different components in the model,
demonstrating the significance of each module. The paper also utilizes the SHAP
method to quantify the impact of traditional advantages on the predicted
results, offering a detailed understanding of feature importance. The KNN
method is used to determine the optimal prediction interval, further enhancing
the model's accuracy. The results highlight the effectiveness of combining
traditional statistical methods with modern deep learning techniques for robust
time series forecasting in Sports.","Chang Liu, Chengcheng Ma, XuanQi Zhou",2025-02-11 11:51:07.000000,arXiv,http://arxiv.org/abs/2502.07491v1,Machine Learning
779,Mask-Enhanced Autoregressive Prediction: Pay Less Attention to Learn More,"Large Language Models (LLMs) are discovered to suffer from accurately
retrieving key information. To address this, we propose Mask-Enhanced
Autoregressive Prediction (MEAP), a simple yet effective training paradigm that
seamlessly integrates Masked Language Modeling (MLM) into Next-Token Prediction
(NTP) to enhance the latter's in-context retrieval capabilities. Specifically,
MEAP first randomly masks a small fraction of input tokens and then directly
performs the standard next-token prediction autoregressive using a decoder-only
Transformer. MEAP eliminates the need for bidirectional attention or
encoder-decoder architectures for MLM, incurring no additional computational
overhead during pre-training or inference. Intensive experiments demonstrate
that MEAP substantially outperforms NTP on key information retrieval and
long-context reasoning tasks, while performing on par or better on commonsense
reasoning tasks. The benefits of MEAP also extend to supervised fine-tuning,
where it shows remarkable advantages in lost-in-the-middle scenarios,
outperforming NTP by 11.77 percentage points. Our analysis indicates that
MEAP's effectiveness arises from its ability to promote more distinguishable
attention scores by concentrating on a reduced set of non-masked tokens. This
mechanism improves the model's focus on task-relevant signals while mitigating
the influence of peripheral context. These findings position MEAP as a
promising training paradigm for large language models.","Xialie Zhuang, Zhikai Jia, Jianjin Li, Zhenyu Zhang, Li Shen, Zheng Cao, Shiwei Liu",2025-02-11 11:49:03.000000,arXiv,http://arxiv.org/abs/2502.07490v1,Natural Language Processing
780,Physiome-ODE: A Benchmark for Irregularly Sampled Multivariate Time Series Forecasting Based on Biological ODEs,"State-of-the-art methods for forecasting irregularly sampled time series with
missing values predominantly rely on just four datasets and a few small toy
examples for evaluation. While ordinary differential equations (ODE) are the
prevalent models in science and engineering, a baseline model that forecasts a
constant value outperforms ODE-based models from the last five years on three
of these existing datasets. This unintuitive finding hampers further research
on ODE-based models, a more plausible model family. In this paper, we develop a
methodology to generate irregularly sampled multivariate time series (IMTS)
datasets from ordinary differential equations and to select challenging
instances via rejection sampling. Using this methodology, we create
Physiome-ODE, a large and sophisticated benchmark of IMTS datasets consisting
of 50 individual datasets, derived from real-world ordinary differential
equations from research in biology. Physiome-ODE is the first benchmark for
IMTS forecasting that we are aware of and an order of magnitude larger than the
current evaluation setting of four datasets. Using our benchmark Physiome-ODE,
we show qualitatively completely different results than those derived from the
current four datasets: on Physiome-ODE ODE-based models can play to their
strength and our benchmark can differentiate in a meaningful way between
different IMTS forecasting models. This way, we expect to give a new impulse to
research on ODE-based time series modeling.","Christian Klötergens, Vijaya Krishna Yalavarthi, Randolf Scholz, Maximilian Stubbemann, Stefan Born, Lars Schmidt-Thieme",2025-02-11 11:48:22.000000,arXiv,http://arxiv.org/abs/2502.07489v1,Machine Learning
781,Improving Adaptive Moment Optimization via Preconditioner Diagonalization,"Modern adaptive optimization methods, such as Adam and its variants, have
emerged as the most widely used tools in deep learning over recent years. These
algorithms offer automatic mechanisms for dynamically adjusting the update step
based on estimates of gradient statistics. Compared to traditional algorithms
like Stochastic Gradient Descent, these adaptive methods are typically more
robust to model scale and hyperparameter tuning. However, the gradient
statistics employed by these methods often do not leverage sufficient gradient
covariance information, leading to suboptimal updates in certain directions of
the parameter space and potentially slower convergence. In this work, we keep
track of such covariance statistics in the form of a structured preconditioner
matrix. Unlike other works, our approach does not apply direct approximations
to estimate this matrix. We instead implement an invertible transformation that
maps the preconditioner matrix into a new space where it becomes approximately
diagonal. This enables a diagonal approximation of the preconditioner matrix in
the transformed space, offering several computational advantages. Empirical
results show that our approach can substantially enhance the convergence speed
of modern adaptive optimizers. Notably, for large language models like LLaMA,
we can achieve a speedup of 2x compared to the baseline Adam. Additionally, our
method can be integrated with memory-efficient optimizers like Adafactor to
manage computational overhead.","Son Nguyen, Bo Liu, Lizhang Chen, Qiang Liu",2025-02-11 11:48:04.000000,arXiv,http://arxiv.org/abs/2502.07488v1,Machine Learning
782,Multi-Agent Collaboration for Multilingual Code Instruction Tuning,"Recent advancement in code understanding and generation demonstrates that
code LLMs fine-tuned on a high-quality instruction dataset can gain powerful
capabilities to address wide-ranging code-related tasks. However, most previous
existing methods mainly view each programming language in isolation and ignore
the knowledge transfer among different programming languages. To bridge the gap
among different programming languages, we introduce a novel multi-agent
collaboration framework to enhance multilingual instruction tuning for code
LLMs, where multiple language-specific intelligent agent components with
generation memory work together to transfer knowledge from one language to
another efficiently and effectively. Specifically, we first generate the
language-specific instruction data from the code snippets and then provide the
generated data as the seed data for language-specific agents. Multiple
language-specific agents discuss and collaborate to formulate a new instruction
and its corresponding solution (A new programming language or existing
programming language), To further encourage the cross-lingual transfer, each
agent stores its generation history as memory and then summarizes its merits
and faults. Finally, the high-quality multilingual instruction data is used to
encourage knowledge transfer among different programming languages to train
Qwen2.5-xCoder. Experimental results on multilingual programming benchmarks
demonstrate the superior performance of Qwen2.5-xCoder in sharing common
knowledge, highlighting its potential to reduce the cross-lingual gap.","Jian Yang, Wei Zhang, Jiaxi Yang, Yibo Miao, Shanghaoran Quan, Zhenhe Wu, Qiyao Peng, Liqun Yang, Tianyu Liu, Zeyu Cui, Binyuan Hui, Junyang Lin",2025-02-11 11:46:38.000000,arXiv,http://arxiv.org/abs/2502.07487v1,Natural Language Processing
783,Automated Road Extraction and Centreline Fitting in LiDAR Point Clouds,"Road information extraction from 3D point clouds is useful for urban planning
and traffic management. Existing methods often rely on local features and the
refraction angle of lasers from kerbs, which makes them sensitive to variable
kerb designs and issues in high-density areas due to data homogeneity. We
propose an approach for extracting road points and fitting centrelines using a
top-down view of LiDAR based ground-collected point clouds. This prospective
view reduces reliance on specific kerb design and results in better road
extraction. We first perform statistical outlier removal and density-based
clustering to reduce noise from 3D point cloud data. Next, we perform ground
point filtering using a grid-based segmentation method that adapts to diverse
road scenarios and terrain characteristics. The filtered points are then
projected onto a 2D plane, and the road is extracted by a skeletonisation
algorithm. The skeleton is back-projected onto the 3D point cloud with
calculated normals, which guide a region growing algorithm to find nearby road
points. The extracted road points are then smoothed with the Savitzky-Golay
filter to produce the final centreline. Our initial approach without
post-processing of road skeleton achieved 67% in IoU by testing on the Perth
CBD dataset with different road types. Incorporating the post-processing of the
road skeleton improved the extraction of road points around the smoothed
skeleton. The refined approach achieved a higher IoU value of 73% and with 23%
reduction in the processing time. Our approach offers a generalised and
computationally efficient solution that combines 3D and 2D processing
techniques, laying the groundwork for future road reconstruction and 3D-to-2D
point cloud alignment.","Xinyu Wang, Muhammad Ibrahim, Atif Mansoor, Hasnein Tareque, Ajmal Mian",2025-02-11 11:45:52.000000,arXiv,http://arxiv.org/abs/2502.07486v1,Computer Vision
784,Overfitting Regimes of Nadaraya-Watson Interpolators,"In recent years, there has been much interest in understanding the
generalization behavior of interpolating predictors, which overfit on noisy
training data. Whereas standard analyses are concerned with whether a method is
consistent or not, recent observations have shown that even inconsistent
predictors can generalize well. In this work, we revisit the classic
interpolating Nadaraya-Watson (NW) estimator (also known as Shepard's method),
and study its generalization capabilities through this modern viewpoint. In
particular, by varying a single bandwidth-like hyperparameter, we prove the
existence of multiple overfitting behaviors, ranging non-monotonically from
catastrophic, through benign, to tempered. Our results highlight how even
classical interpolating methods can exhibit intricate generalization behaviors.
Numerical experiments complement our theory, demonstrating the same phenomena.","Daniel Barzilai, Guy Kornowski, Ohad Shamir",2025-02-11 11:41:09.000000,arXiv,http://arxiv.org/abs/2502.07480v1,Machine Learning
785,WebChecker: A Versatile EVL Plugin for Validating HTML Pages with Bootstrap Frameworks,"WebChecker is a plugin for Epsilon Validation Language (EVL), designed to
validate both static and dynamic HTML pages utilizing frameworks like
Bootstrap. By employing configurable EVL constraints, WebChecker enforces
implicit rules governing HTML and CSS frameworks. The effectiveness of the
plugin is demonstrated through its application on Bootstrap, the widely adopted
HTML, CSS, and JavaScript framework. WebChecker comes with a set of EVL
constraints to assess Bootstrap based web pages. To substantiate our claims, I
present an illustrative example featuring two solutions that effectively
enforce implicit rules.",Milind Cherukuri,2025-02-11 11:40:43.000000,arXiv,http://arxiv.org/abs/2502.07479v1,Other
786,ETimeline: An Extensive Timeline Generation Dataset based on Large Language Model,"Timeline generation is of great significance for a comprehensive
understanding of the development of events over time. Its goal is to organize
news chronologically, which helps to identify patterns and trends that may be
obscured when viewing news in isolation, making it easier to track the
development of stories and understand the interrelationships between key
events. Timelines are now common in various commercial products, but academic
research in this area is notably scarce. Additionally, the current datasets are
in need of refinement for enhanced utility and expanded coverage. In this
paper, we propose ETimeline, which encompasses over $13,000$ news articles,
spanning $600$ bilingual timelines across $28$ news domains. Specifically, we
gather a candidate pool of more than $120,000$ news articles and employ the
large language model (LLM) Pipeline to improve performance, ultimately yielding
the ETimeline. The data analysis underscores the appeal of ETimeline.
Additionally, we also provide the news pool data for further research and
analysis. This work contributes to the advancement of timeline generation
research and supports a wide range of tasks, including topic generation and
event relationships. We believe that this dataset will serve as a catalyst for
innovative research and bridge the gap between academia and industry in
understanding the practical application of technology services. The dataset is
available at https://zenodo.org/records/11392212","Xiaochen Liu, Yanan Zhang",2025-02-11 11:34:33.000000,arXiv,http://arxiv.org/abs/2502.07474v1,Information Retrieval
787,Robotic In-Hand Manipulation for Large-Range Precise Object Movement: The RGMC Champion Solution,"In-hand manipulation using multiple dexterous fingers is a critical robotic
skill that can reduce the reliance on large arm motions, thereby saving space
and energy. This letter focuses on in-grasp object movement, which refers to
manipulating an object to a desired pose through only finger motions within a
stable grasp. The key challenge lies in simultaneously achieving high precision
and large-range movements while maintaining a constant stable grasp. To address
this problem, we propose a simple and practical approach based on kinematic
trajectory optimization with no need for pretraining or object geometries,
which can be easily applied to novel objects in real-world scenarios. Adopting
this approach, we won the championship for the in-hand manipulation track at
the 9th Robotic Grasping and Manipulation Competition (RGMC) held at ICRA 2024.
Implementation details, discussion, and further quantitative experimental
results are presented in this letter, which aims to comprehensively evaluate
our approach and share our key takeaways from the competition. Supplementary
materials including video and code are available at
https://rgmc-xl-team.github.io/ingrasp_manipulation .","Mingrui Yu, Yongpeng Jiang, Chen Chen, Yongyi Jia, Xiang Li",2025-02-11 11:26:24.000000,arXiv,http://arxiv.org/abs/2502.07472v1,Robotics
788,5D Neural Surrogates for Nonlinear Gyrokinetic Simulations of Plasma Turbulence,"Nuclear fusion plays a pivotal role in the quest for reliable and sustainable
energy production. A major roadblock to achieving commercially viable fusion
power is understanding plasma turbulence, which can significantly degrade
plasma confinement. Modelling turbulence is crucial to design performing plasma
scenarios for next-generation reactor-class devices and current experimental
machines. The nonlinear gyrokinetic equation underpinning turbulence modelling
evolves a 5D distribution function over time. Solving this equation numerically
is extremely expensive, requiring up to weeks for a single run to converge,
making it unfeasible for iterative optimisation and control studies. In this
work, we propose a method for training neural surrogates for 5D gyrokinetic
simulations. Our method extends a hierarchical vision transformer to five
dimensions and is trained on the 5D distribution function for the adiabatic
electron approximation. We demonstrate that our model can accurately infer
downstream physical quantities such as heat flux time trace and electrostatic
potentials for single-step predictions two orders of magnitude faster than
numerical codes. Our work paves the way towards neural surrogates for plasma
turbulence simulations to accelerate deployment of commercial energy production
via nuclear fusion.","Gianluca Galletti, Fabian Paischer, Paul Setinek, William Hornsby, Lorenzo Zanisi, Naomi Carey, Stanislas Pamela, Johannes Brandstetter",2025-02-11 11:25:10.000000,arXiv,http://arxiv.org/abs/2502.07469v1,Other
789,Less is More: Masking Elements in Image Condition Features Avoids Content Leakages in Style Transfer Diffusion Models,"Given a style-reference image as the additional image condition,
text-to-image diffusion models have demonstrated impressive capabilities in
generating images that possess the content of text prompts while adopting the
visual style of the reference image. However, current state-of-the-art methods
often struggle to disentangle content and style from style-reference images,
leading to issues such as content leakages. To address this issue, we propose a
masking-based method that efficiently decouples content from style without the
need of tuning any model parameters. By simply masking specific elements in the
style reference's image features, we uncover a critical yet under-explored
principle: guiding with appropriately-selected fewer conditions (e.g., dropping
several image feature elements) can efficiently avoid unwanted content flowing
into the diffusion models, enhancing the style transfer performances of
text-to-image diffusion models. In this paper, we validate this finding both
theoretically and experimentally. Extensive experiments across various styles
demonstrate the effectiveness of our masking-based method and support our
theoretical results.","Lin Zhu, Xinbing Wang, Chenghu Zhou, Qinying Gu, Nanyang Ye",2025-02-11 11:17:39.000000,arXiv,http://arxiv.org/abs/2502.07466v1,Computer Vision
790,Crime Forecasting: A Spatio-temporal Analysis with Deep Learning Models,"This study uses deep-learning models to predict city partition crime counts
on specific days. It helps police enhance surveillance, gather intelligence,
and proactively prevent crimes. We formulate crime count prediction as a
spatiotemporal sequence challenge, where both input data and prediction targets
are spatiotemporal sequences. In order to improve the accuracy of crime
forecasting, we introduce a new model that combines Convolutional Neural
Networks (CNN) and Long Short-Term Memory (LSTM) networks. We conducted a
comparative analysis to access the effects of various data sequences, including
raw and binned data, on the prediction errors of four deep learning forecasting
models. Directly inputting raw crime data into the forecasting model causes
high prediction errors, making the model unsuitable for real - world use. The
findings indicate that the proposed CNN-LSTM model achieves optimal performance
when crime data is categorized into 10 or 5 groups. Data binning can enhance
forecasting model performance, but poorly defined intervals may reduce map
granularity. Compared to dividing into 5 bins, binning into 10 intervals
strikes an optimal balance, preserving data characteristics and surpassing raw
data in predictive modelling efficacy.","Li Mao, Wei Du, Shuo Wen, Qi Li, Tong Zhang, Wei Zhong",2025-02-11 11:16:59.000000,arXiv,http://arxiv.org/abs/2502.07465v2,Machine Learning
791,Fast and Safe Scheduling of Robots,"In this paper, we present an experimental analysis of a fast heuristic
algorithm that was designed to generate a fast, collision-free schedule for a
set of robots on a path graph. The experiments confirm the algorithm's
effectiveness in producing collision-free schedules as well as achieving the
optimal solution when all tasks assigned to the robots are of equal duration.
Additionally, we provide an integer linear programming formulation that
guarantees an optimal solution for this scheduling problem on any input graph,
at the expense of significantly greater computational resources. We prove the
correctness of our integer linear program. By comparing the solutions of these
two algorithms, including the time required by the schedule itself, and the run
time of each algorithm, we show that the heuristic algorithm is optimal or near
optimal in nearly all cases, with a far faster run time than the integer linear
program.","Duncan Adamson, Nathan Flaherty, Igor Potapov, Paul G. Spirakis",2025-02-11 11:14:07.000000,arXiv,http://arxiv.org/abs/2502.07851v1,Robotics
792,JamendoMaxCaps: A Large Scale Music-caption Dataset with Imputed Metadata,"We introduce JamendoMaxCaps, a large-scale music-caption dataset featuring
over 200,000 freely licensed instrumental tracks from the renowned Jamendo
platform. The dataset includes captions generated by a state-of-the-art
captioning model, enhanced with imputed metadata. We also introduce a retrieval
system that leverages both musical features and metadata to identify similar
songs, which are then used to fill in missing metadata using a local large
language model (LLLM). This approach allows us to provide a more comprehensive
and informative dataset for researchers working on music-language understanding
tasks. We validate this approach quantitatively with five different
measurements. By making the JamendoMaxCaps dataset publicly available, we
provide a high-quality resource to advance research in music-language
understanding tasks such as music retrieval, multimodal representation
learning, and generative music models.","Abhinaba Roy, Renhang Liu, Tongyu Lu, Dorien Herremans",2025-02-11 11:12:19.000000,arXiv,http://arxiv.org/abs/2502.07461v1,Other
793,Logarithmic Regret for Online KL-Regularized Reinforcement Learning,"Recent advances in Reinforcement Learning from Human Feedback (RLHF) have
shown that KL-regularization plays a pivotal role in improving the efficiency
of RL fine-tuning for large language models (LLMs). Despite its empirical
advantage, the theoretical difference between KL-regularized RL and standard RL
remains largely under-explored. While there is a recent line of work on the
theoretical analysis of KL-regularized objective in decision making
\citep{xiong2024iterative, xie2024exploratory,zhao2024sharp}, these analyses
either reduce to the traditional RL setting or rely on strong coverage
assumptions. In this paper, we propose an optimism-based KL-regularized online
contextual bandit algorithm, and provide a novel analysis of its regret. By
carefully leveraging the benign optimization landscape induced by the
KL-regularization and the optimistic reward estimation, our algorithm achieves
an $\mathcal{O}\big(\eta\log (N_{\mathcal R} T)\cdot d_{\mathcal R}\big)$
logarithmic regret bound, where $\eta, N_{\mathcal R},T,d_{\mathcal R}$ denote
the KL-regularization parameter, the cardinality of the reward function class,
number of rounds, and the complexity of the reward function class. Furthermore,
we extend our algorithm and analysis to reinforcement learning by developing a
novel decomposition over transition steps and also obtain a similar logarithmic
regret bound.","Heyang Zhao, Chenlu Ye, Wei Xiong, Quanquan Gu, Tong Zhang",2025-02-11 11:11:05.000000,arXiv,http://arxiv.org/abs/2502.07460v1,Machine Learning
794,PerCul: A Story-Driven Cultural Evaluation of LLMs in Persian,"Large language models predominantly reflect Western cultures, largely due to
the dominance of English-centric training data. This imbalance presents a
significant challenge, as LLMs are increasingly used across diverse contexts
without adequate evaluation of their cultural competence in non-English
languages, including Persian. To address this gap, we introduce PerCul, a
carefully constructed dataset designed to assess the sensitivity of LLMs toward
Persian culture. PerCul features story-based, multiple-choice questions that
capture culturally nuanced scenarios. Unlike existing benchmarks, PerCul is
curated with input from native Persian annotators to ensure authenticity and to
prevent the use of translation as a shortcut. We evaluate several
state-of-the-art multilingual and Persian-specific LLMs, establishing a
foundation for future research in cross-cultural NLP evaluation. Our
experiments demonstrate a 11.3% gap between best closed source model and
layperson baseline while the gap increases to 21.3% by using the best
open-weight model. You can access the dataset from here:
https://huggingface.co/datasets/teias-ai/percul","Erfan Moosavi Monazzah, Vahid Rahimzadeh, Yadollah Yaghoobzadeh, Azadeh Shakery, Mohammad Taher Pilehvar",2025-02-11 11:07:44.000000,arXiv,http://arxiv.org/abs/2502.07459v1,Natural Language Processing
795,Bidirectional Uncertainty-Aware Region Learning for Semi-Supervised Medical Image Segmentation,"In semi-supervised medical image segmentation, the poor quality of unlabeled
data and the uncertainty in the model's predictions lead to models that
inevitably produce erroneous pseudo-labels. These errors accumulate throughout
model training, thereby weakening the model's performance. We found that these
erroneous pseudo-labels are typically concentrated in high-uncertainty regions.
Traditional methods improve performance by directly discarding pseudo-labels in
these regions, but this can also result in neglecting potentially valuable
training data. To alleviate this problem, we propose a bidirectional
uncertainty-aware region learning strategy. In training labeled data, we focus
on high-uncertainty regions, using precise label information to guide the
model's learning in potentially uncontrollable areas. Meanwhile, in the
training of unlabeled data, we concentrate on low-uncertainty regions to reduce
the interference of erroneous pseudo-labels on the model. Through this
bidirectional learning strategy, the model's overall performance has
significantly improved. Extensive experiments show that our proposed method
achieves significant performance improvement on different medical image
segmentation tasks.","Shiwei Zhou, Haifeng Zhao, Dengdi Sun",2025-02-11 11:03:09.000000,arXiv,http://arxiv.org/abs/2502.07457v1,Computer Vision
796,FedAPA: Server-side Gradient-Based Adaptive Personalized Aggregation for Federated Learning on Heterogeneous Data,"Personalized federated learning (PFL) tailors models to clients' unique data
distributions while preserving privacy. However, existing
aggregation-weight-based PFL methods often struggle with heterogeneous data,
facing challenges in accuracy, computational efficiency, and communication
overhead. We propose FedAPA, a novel PFL method featuring a server-side,
gradient-based adaptive aggregation strategy to generate personalized models,
by updating aggregation weights based on gradients of client-parameter changes
with respect to the aggregation weights in a centralized manner. FedAPA
guarantees theoretical convergence and achieves superior accuracy and
computational efficiency compared to 10 PFL competitors across three datasets,
with competitive communication overhead.","Yuxia Sun, Aoxiang Sun, Siyi Pan, Zhixiao Fu, Jingcai Guo",2025-02-11 11:00:58.000000,arXiv,http://arxiv.org/abs/2502.07456v1,Machine Learning
797,RusCode: Russian Cultural Code Benchmark for Text-to-Image Generation,"Text-to-image generation models have gained popularity among users around the
world. However, many of these models exhibit a strong bias toward
English-speaking cultures, ignoring or misrepresenting the unique
characteristics of other language groups, countries, and nationalities. The
lack of cultural awareness can reduce the generation quality and lead to
undesirable consequences such as unintentional insult, and the spread of
prejudice. In contrast to the field of natural language processing, cultural
awareness in computer vision has not been explored as extensively. In this
paper, we strive to reduce this gap. We propose a RusCode benchmark for
evaluating the quality of text-to-image generation containing elements of the
Russian cultural code. To do this, we form a list of 19 categories that best
represent the features of Russian visual culture. Our final dataset consists of
1250 text prompts in Russian and their translations into English. The prompts
cover a wide range of topics, including complex concepts from art, popular
culture, folk traditions, famous people's names, natural objects, scientific
achievements, etc. We present the results of a human evaluation of the
side-by-side comparison of Russian visual concepts representations using
popular generative models.","Viacheslav Vasilev, Julia Agafonova, Nikolai Gerasimenko, Alexander Kapitanov, Polina Mikhailova, Evelina Mironova, Denis Dimitrov",2025-02-11 10:57:12.000000,arXiv,http://arxiv.org/abs/2502.07455v1,Computer Vision
798,Eliciting Rational Initial Weights in Gradual Argumentation,"Many semantics for weighted argumentation frameworks assume that each
argument is associated with an initial weight. However, eliciting these initial
weights poses challenges: (1) accurately providing a specific numerical value
is often difficult, and (2) individuals frequently confuse initial weights with
acceptability degrees in the presence of other arguments. To address these
issues, we propose an elicitation pipeline that allows one to specify
acceptability degree intervals for each argument. By employing gradual
semantics, we can refine these intervals when they are rational, restore
rationality when they are not, and ultimately identify possible initial weights
for each argument.","Nir Oren, Bruno Yun",2025-02-11 10:52:54.000000,arXiv,http://arxiv.org/abs/2502.07452v1,Artificial Intelligence
799,Forget What You Know about LLMs Evaluations - LLMs are Like a Chameleon,"Large language models (LLMs) often appear to excel on public benchmarks, but
these high scores may mask an overreliance on dataset-specific surface cues
rather than true language understanding. We introduce the Chameleon Benchmark
Overfit Detector (C-BOD), a meta-evaluation framework that systematically
distorts benchmark prompts via a parametric transformation and detects
overfitting of LLMs. By rephrasing inputs while preserving their semantic
content and labels, C-BOD exposes whether a model's performance is driven by
memorized patterns. Evaluated on the MMLU benchmark using 26 leading LLMs, our
method reveals an average performance degradation of 2.15% under modest
perturbations, with 20 out of 26 models exhibiting statistically significant
differences. Notably, models with higher baseline accuracy exhibit larger
performance differences under perturbation, and larger LLMs tend to be more
sensitive to rephrasings indicating that both cases may overrely on fixed
prompt patterns. In contrast, the Llama family and models with lower baseline
accuracy show insignificant degradation, suggesting reduced dependency on
superficial cues. Moreover, C-BOD's dataset- and model-agnostic design allows
easy integration into training pipelines to promote more robust language
understanding. Our findings challenge the community to look beyond leaderboard
scores and prioritize resilience and generalization in LLM evaluation.","Nurit Cohen-Inger, Yehonatan Elisha, Bracha Shapira, Lior Rokach, Seffi Cohen",2025-02-11 10:43:36.000000,arXiv,http://arxiv.org/abs/2502.07445v1,Natural Language Processing
800,Approximating Human Strategic Reasoning with LLM-Enhanced Recursive Reasoners Leveraging Multi-agent Hypergames,"LLM-driven multi-agent-based simulations have been gaining traction with
applications in game-theoretic and social simulations. While most
implementations seek to exploit or evaluate LLM-agentic reasoning, they often
do so with a weak notion of agency and simplified architectures. We implement a
role-based multi-agent strategic interaction framework tailored to
sophisticated recursive reasoners, providing the means for systematic in-depth
development and evaluation of strategic reasoning. Our game environment is
governed by the umpire responsible for facilitating games, from matchmaking
through move validation to environment management. Players incorporate
state-of-the-art LLMs in their decision mechanism, relying on a formal
hypergame-based model of hierarchical beliefs. We use one-shot, 2-player beauty
contests to evaluate the recursive reasoning capabilities of the latest LLMs,
providing a comparison to an established baseline model from economics and data
from human experiments. Furthermore, we introduce the foundations of an
alternative semantic measure of reasoning to the k-level theory. Our
experiments show that artificial reasoners can outperform the baseline model in
terms of both approximating human behaviour and reaching the optimal solution.","Vince Trencsenyi, Agnieszka Mensfelt, Kostas Stathis",2025-02-11 10:37:20.000000,arXiv,http://arxiv.org/abs/2502.07443v1,Artificial Intelligence
801,Hierarchical Document Parsing via Large Margin Feature Matching and Heuristics,"We present our solution to the AAAI-25 VRD-IU challenge, achieving first
place in the competition. Our approach integrates large margin loss for
improved feature discrimination and employs heuristic rules to refine
hierarchical relationships. By combining a deep learning-based matching
strategy with greedy algorithms, we achieve a significant boost in accuracy
while maintaining computational efficiency. Our method attains an accuracy of
0.98904 on the private leaderboard, demonstrating its effectiveness in document
structure parsing. Source codes are publicly available at
https://github.com/ffyyytt/VRUID-AAAI-DAKiet",Duong Anh Kiet,2025-02-11 10:37:01.000000,arXiv,http://arxiv.org/abs/2502.07442v1,Natural Language Processing
802,Mathematical reasoning and the computer,"Computers have already changed the way that humans do mathematics: they
enable us to compute efficiently. But will they soon be helping us to reason?
And will they one day start reasoning themselves? We give an overview of recent
developments in neural networks, computer theorem provers and large language
models.",Kevin Buzzard,2025-02-11 10:35:52.000000,arXiv,http://arxiv.org/abs/2502.07850v1,Artificial Intelligence
803,SensPS: Sensing Personal Space Comfortable Distance between Human-Human Using Multimodal Sensors,"Personal space, also known as peripersonal space, is crucial in human social
interaction, influencing comfort, communication, and social stress. Estimating
and respecting personal space is essential for enhancing human-computer
interaction (HCI) and smart environments. Personal space preferences vary due
to individual traits, cultural background, and contextual factors. Advanced
multimodal sensing technologies, including eye-tracking and wristband sensors,
offer opportunities to develop adaptive systems that dynamically adjust to user
comfort levels. Integrating physiological and behavioral data enables a deeper
understanding of spatial interactions. This study develops a sensor-based model
to estimate comfortable personal space and identifies key features influencing
spatial preferences. Our findings show that multimodal sensors, particularly
eye-tracking and physiological wristband data, can effectively predict personal
space preferences, with eye-tracking data playing a more significant role. An
experimental study involving controlled human interactions demonstrates that a
Transformer-based model achieves the highest predictive accuracy (F1 score:
0.87) for estimating personal space. Eye-tracking features, such as gaze point
and pupil diameter, emerge as the most significant predictors, while
physiological signals from wristband sensors contribute marginally. These
results highlight the potential for AI-driven personalization of social space
in adaptive environments, suggesting that multimodal sensing can be leveraged
to develop intelligent systems that optimize spatial arrangements in
workplaces, educational institutions, and public settings. Future work should
explore larger datasets, real-world applications, and additional physiological
markers to enhance model robustness.","Ko Watanabe, Nico Förster, Shoya Ishimaru",2025-02-11 10:31:43.000000,arXiv,http://arxiv.org/abs/2502.07441v1,Other
804,Understanding Classifier-Free Guidance: High-Dimensional Theory and Non-Linear Generalizations,"Recent studies have raised concerns about the effectiveness of
Classifier-Free Guidance (CFG), indicating that in low-dimensional settings, it
can lead to overshooting the target distribution and reducing sample diversity.
In this work, we demonstrate that in infinite and sufficiently high-dimensional
contexts CFG effectively reproduces the target distribution, revealing a
blessing-of-dimensionality result. Additionally, we explore finite-dimensional
effects, precisely characterizing overshoot and variance reduction. Based on
our analysis, we introduce non-linear generalizations of CFG. Through numerical
simulations on Gaussian mixtures and experiments on class-conditional and
text-to-image diffusion models, we validate our analysis and show that our
non-linear CFG offers improved flexibility and generation quality without
additional computation cost.","Krunoslav Lehman Pavasovic, Jakob Verbeek, Giulio Biroli, Marc Mezard",2025-02-11 10:29:29.000000,arXiv,http://arxiv.org/abs/2502.07849v1,Machine Learning
805,Optimizing Knowledge Distillation in Transformers: Enabling Multi-Head Attention without Alignment Barriers,"Knowledge distillation (KD) in transformers often faces challenges due to
misalignment in the number of attention heads between teacher and student
models. Existing methods either require identical head counts or introduce
projectors to bridge dimensional gaps, limiting flexibility and efficiency. We
propose Squeezing-Heads Distillation (SHD), a novel approach that enables
seamless knowledge transfer between models with varying head counts by
compressing multi-head attention maps via efficient linear approximation.
Unlike prior work, SHD eliminates alignment barriers without additional
parameters or architectural modifications. Our method dynamically approximates
the combined effect of multiple teacher heads into fewer student heads,
preserving fine-grained attention patterns while reducing redundancy.
Experiments across language (LLaMA, GPT) and vision (DiT, MDT) generative and
vision (DeiT) discriminative tasks demonstrate SHD's effectiveness: it
outperforms logit-based and feature-alignment KD baselines, achieving
state-of-the-art results in image classification, image generation language
fine-tuning, and language pre-training. The key innovations of flexible head
compression, projector-free design, and linear-time complexity make SHD a
versatile and scalable solution for distilling modern transformers. This work
bridges a critical gap in KD, enabling efficient deployment of compact models
without compromising performance.","Zhaodong Bing, Linze Li, Jiajun Liang",2025-02-11 10:24:57.000000,arXiv,http://arxiv.org/abs/2502.07436v1,Computer Vision
806,CapyMOA: Efficient Machine Learning for Data Streams in Python,"CapyMOA is an open-source library designed for efficient machine learning on
streaming data. It provides a structured framework for real-time learning and
evaluation, featuring a flexible data representation. CapyMOA includes an
extensible architecture that allows integration with external frameworks such
as MOA and PyTorch, facilitating hybrid learning approaches that combine
traditional online algorithms with deep learning techniques. By emphasizing
adaptability, scalability, and usability, CapyMOA allows researchers and
practitioners to tackle dynamic learning challenges across various domains.","Heitor Murilo Gomes, Anton Lee, Nuwan Gunasekara, Yibin Sun, Guilherme Weigert Cassales, Justin Liu, Marco Heyden, Vitor Cerqueira, Maroua Bahri, Yun Sing Koh, Bernhard Pfahringer, Albert Bifet",2025-02-11 10:20:04.000000,arXiv,http://arxiv.org/abs/2502.07432v1,Machine Learning
807,ArthroPhase: A Novel Dataset and Method for Phase Recognition in Arthroscopic Video,"This study aims to advance surgical phase recognition in arthroscopic
procedures, specifically Anterior Cruciate Ligament (ACL) reconstruction, by
introducing the first arthroscopy dataset and developing a novel
transformer-based model. We aim to establish a benchmark for arthroscopic
surgical phase recognition by leveraging spatio-temporal features to address
the specific challenges of arthroscopic videos including limited field of view,
occlusions, and visual distortions. We developed the ACL27 dataset, comprising
27 videos of ACL surgeries, each labeled with surgical phases. Our model
employs a transformer-based architecture, utilizing temporal-aware frame-wise
feature extraction through a ResNet-50 and transformer layers. This approach
integrates spatio-temporal features and introduces a Surgical Progress Index
(SPI) to quantify surgery progression. The model's performance was evaluated
using accuracy, precision, recall, and Jaccard Index on the ACL27 and Cholec80
datasets. The proposed model achieved an overall accuracy of 72.91% on the
ACL27 dataset. On the Cholec80 dataset, the model achieved a comparable
performance with the state-of-the-art methods with an accuracy of 92.4%. The
SPI demonstrated an output error of 10.6% and 9.86% on ACL27 and Cholec80
datasets respectively, indicating reliable surgery progression estimation. This
study introduces a significant advancement in surgical phase recognition for
arthroscopy, providing a comprehensive dataset and a robust transformer-based
model. The results validate the model's effectiveness and generalizability,
highlighting its potential to improve surgical training, real-time assistance,
and operational efficiency in orthopedic surgery. The publicly available
dataset and code will facilitate future research and development in this
critical field.","Ali Bahari Malayeri, Matthias Seibold, Nicola Cavalcanti, Jonas Hein, Sascha Jecklin, Lazaros Vlachopoulos, Sandro Fucentese, Sandro Hodel, Philipp Furnstahl",2025-02-11 10:19:50.000000,arXiv,http://arxiv.org/abs/2502.07431v2,Computer Vision
808,Towards a Foundation Model for Physics-Informed Neural Networks: Multi-PDE Learning with Active Sampling,"Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework
for solving partial differential equations (PDEs) by embedding physical laws
into neural network training. However, traditional PINN models are typically
designed for single PDEs, limiting their generalizability across different
physical systems. In this work, we explore the potential of a foundation PINN
model capable of solving multiple PDEs within a unified architecture. We
investigate the efficacy of a single PINN framework trained on four distinct
PDEs-the Simple Harmonic Oscillator (SHO), the 1D Heat Equation, the 1D Wave
Equation, and the 2D Laplace Equation, demonstrating its ability to learn
diverse physical dynamics.
  To enhance sample efficiency, we incorporate Active Learning (AL) using Monte
Carlo (MC) Dropout-based uncertainty estimation, selecting the most informative
training samples iteratively. We evaluate different active learning strategies,
comparing models trained on 10%, 20%, 30%, 40%, and 50% of the full dataset,
and analyze their impact on solution accuracy. Our results indicate that
targeted uncertainty sampling significantly improves performance with fewer
training samples, leading to efficient learning across multiple PDEs.
  This work highlights the feasibility of a generalizable PINN-based foundation
model, capable of adapting to different physics-based problems without
redesigning network architectures. Our findings suggest that multi-PDE PINNs
with active learning can serve as an effective approach for reducing
computational costs while maintaining high accuracy in physics-based deep
learning applications.",Keon Vin Park,2025-02-11 10:12:28.000000,arXiv,http://arxiv.org/abs/2502.07425v1,Machine Learning
809,RomanLens: Latent Romanization and its role in Multilinguality in LLMs,"Large Language Models (LLMs) exhibit remarkable multilingual generalization
despite being predominantly trained on English-centric corpora. A fundamental
question arises: how do LLMs achieve such robust multilingual capabilities? For
non-Latin script languages, we investigate the role of romanization - the
representation of non-Latin scripts using Latin characters - as a bridge in
multilingual processing. Using mechanistic interpretability techniques, we
analyze next-token generation and find that intermediate layers frequently
represent target words in romanized form before transitioning to native script,
a phenomenon we term Latent Romanization. Further, through activation patching
experiments, we demonstrate that LLMs encode semantic concepts similarly across
native and romanized scripts, suggesting a shared underlying representation.
Additionally in translation towards non Latin languages, our findings reveal
that when the target language is in romanized form, its representations emerge
earlier in the model's layers compared to native script. These insights
contribute to a deeper understanding of multilingual representation in LLMs and
highlight the implicit role of romanization in facilitating language transfer.
Our work provides new directions for potentially improving multilingual
language modeling and interpretability.","Alan Saji, Jaavid Aktar Husain, Thanmay Jayakumar, Raj Dabre, Anoop Kunchukuttan, Mitesh M. Khapra, Ratish Puduppully",2025-02-11 10:10:26.000000,arXiv,http://arxiv.org/abs/2502.07424v1,Natural Language Processing
810,Technical note on calibrating vision-language models under covariate shift,"Despite being a successful example of emerging capability, vision-language
foundation models for low-shot vision classification have a limited ability to
sufficiently generalize to the target data distribution due to sample poverty,
leading to sensitivity to variations in the data. A popular mitigation strategy
is finetuning over multiple datasets, but domain generalization is expensive
when practiced in this manner. This work examines both covariate shift between
pre-training data and the underspecified target data, and \textit{confidence
misalignment}, where the model's prediction confidence amplified by the limited
data availability. We propose \textit{Confidence-Calibrated Covariate Shift
Correction ($C3SC$)}, a unified framework to mitigate both covariate shift and
confidence misalignment. $C3SC$ leverages Fisher information penalty for
covariate shift correction and confidence misalignment penalty (CMP) to lower
confidence on misclassified examples. Experimental results across various
vision and covariate shift datasets demonstrates that $C3SC$ significantly
improves in calibration (ECE) by $5.82\%$ at maximum. $C3SC$ shows better
robustness as well by showing $3.5\%$ improvement in accuracy metric on
challenging covariate shift datasets, making $C3SC$ a promising solution for
reliable real-world vision-language low-shot applications under distribution
shift.","Behraj Khan, Rizwan Qureshi, Tahir Syed",2025-02-11 10:10:15.000000,arXiv,http://arxiv.org/abs/2502.07847v1,Computer Vision
811,Towards a Formal Theory of the Need for Competence via Computational Intrinsic Motivation,"Computational models offer powerful tools for formalising psychological
theories, making them both testable and applicable in digital contexts.
However, they remain little used in the study of motivation within psychology.
We focus on the ""need for competence"", postulated as a key basic human need
within Self-Determination Theory (SDT) -- arguably the most influential
psychological framework for studying intrinsic motivation (IM). The need for
competence is treated as a single construct across SDT texts. Yet, recent
research has identified multiple, ambiguously defined facets of competence in
SDT. We propose that these inconsistencies may be alleviated by drawing on
computational models from the field of artificial intelligence, specifically
from the domain of reinforcement learning (RL). By aligning the aforementioned
facets of competence -- effectance, skill use, task performance, and capacity
growth -- with existing RL formalisms, we provide a foundation for advancing
competence-related theory in SDT and motivational psychology more broadly. The
formalisms reveal underlying preconditions that SDT fails to make explicit,
demonstrating how computational models can improve our understanding of IM.
Additionally, our work can support a cycle of theory development by inspiring
new computational models formalising aspects of the theory, which can then be
tested empirically to refine the theory. While our research lays a promising
foundation, empirical studies of these models in both humans and machines are
needed, inviting collaboration across disciplines.","Erik M. Lintunen, Nadia M. Ady, Sebastian Deterding, Christian Guckelsberger",2025-02-11 10:03:40.000000,arXiv,http://arxiv.org/abs/2502.07423v1,Artificial Intelligence
812,"MoENAS: Mixture-of-Expert based Neural Architecture Search for jointly Accurate, Fair, and Robust Edge Deep Neural Networks","There has been a surge in optimizing edge Deep Neural Networks (DNNs) for
accuracy and efficiency using traditional optimization techniques such as
pruning, and more recently, employing automatic design methodologies. However,
the focus of these design techniques has often overlooked critical metrics such
as fairness, robustness, and generalization. As a result, when evaluating SOTA
edge DNNs' performance in image classification using the FACET dataset, we
found that they exhibit significant accuracy disparities (14.09%) across 10
different skin tones, alongside issues of non-robustness and poor
generalizability. In response to these observations, we introduce
Mixture-of-Experts-based Neural Architecture Search (MoENAS), an automatic
design technique that navigates through a space of mixture of experts to
discover accurate, fair, robust, and general edge DNNs. MoENAS improves the
accuracy by 4.02% compared to SOTA edge DNNs and reduces the skin tone accuracy
disparities from 14.09% to 5.60%, while enhancing robustness by 3.80% and
minimizing overfitting to 0.21%, all while keeping model size close to
state-of-the-art models average size (+0.4M). With these improvements, MoENAS
establishes a new benchmark for edge DNN design, paving the way for the
development of more inclusive and robust edge DNNs.","Lotfi Abdelkrim Mecharbat, Alberto Marchisio, Muhammad Shafique, Mohammad M. Ghassemi, Tuka Alhanai",2025-02-11 10:02:43.000000,arXiv,http://arxiv.org/abs/2502.07422v1,Machine Learning
813,Entity Linking using LLMs for Automated Product Carbon Footprint Estimation,"Growing concerns about climate change and sustainability are driving
manufacturers to take significant steps toward reducing their carbon
footprints. For these manufacturers, a first step towards this goal is to
identify the environmental impact of the individual components of their
products. We propose a system leveraging large language models (LLMs) to
automatically map components from manufacturer Bills of Materials (BOMs) to
Life Cycle Assessment (LCA) database entries by using LLMs to expand on
available component information. Our approach reduces the need for manual data
processing, paving the way for more accessible sustainability practices.","Steffen Castle, Julian Moreno Schneider, Leonhard Hennig, Georg Rehm",2025-02-11 09:54:39.000000,arXiv,http://arxiv.org/abs/2502.07418v1,Natural Language Processing
814,Fast-COS: A Fast One-Stage Object Detector Based on Reparameterized Attention Vision Transformer for Autonomous Driving,"The perception system is a a critical role of an autonomous driving system
for ensuring safety. The driving scene perception system fundamentally
represents an object detection task that requires achieving a balance between
accuracy and processing speed. Many contemporary methods focus on improving
detection accuracy but often overlook the importance of real-time detection
capabilities when computational resources are limited. Thus, it is vital to
investigate efficient object detection strategies for driving scenes. This
paper introduces Fast-COS, a novel single-stage object detection framework
crafted specifically for driving scene applications. The research initiates
with an analysis of the backbone, considering both macro and micro
architectural designs, yielding the Reparameterized Attention Vision
Transformer (RAViT). RAViT utilizes Reparameterized Multi-Scale Depth-Wise
Convolution (RepMSDW) and Reparameterized Self-Attention (RepSA) to enhance
computational efficiency and feature extraction. In extensive tests across GPU,
edge, and mobile platforms, RAViT achieves 81.4% Top-1 accuracy on the
ImageNet-1K dataset, demonstrating significant throughput improvements over
comparable backbone models such as ResNet, FastViT, RepViT, and
EfficientFormer. Additionally, integrating RepMSDW into a feature pyramid
network forms RepFPN, enabling fast and multi-scale feature fusion. Fast-COS
enhances object detection in driving scenes, attaining an AP50 score of 57.2%
on the BDD100K dataset and 80.0% on the TJU-DHD Traffic dataset. It surpasses
leading models in efficiency, delivering up to 75.9% faster GPU inference and
1.38 higher throughput on edge devices compared to FCOS, YOLOF, and RetinaNet.
These findings establish Fast-COS as a highly scalable and reliable solution
suitable for real-time applications, especially in resource-limited
environments like autonomous driving systems","Novendra Setyawan, Ghufron Wahyu Kurniawan, Chi-Chia Sun, Wen-Kai Kuo, Jun-Wei Hsieh",2025-02-11 09:54:09.000000,arXiv,http://arxiv.org/abs/2502.07417v1,Computer Vision
815,Quantification of model error for inverse problems in the Weak Neural Variational Inference framework,"We present a novel extension of the Weak Neural Variational Inference (WNVI)
framework for probabilistic material property estimation that explicitly
quantifies model errors in PDE-based inverse problems. Traditional approaches
assume the correctness of all governing equations, including potentially
unreliable constitutive laws, which can lead to biased estimates and
misinterpretations. Our proposed framework addresses this limitation by
distinguishing between reliable governing equations, such as conservation laws,
and uncertain constitutive relationships. By treating all state variables as
latent random variables, we enforce these equations through separate sets of
residuals, leveraging a virtual likelihood approach with weighted residuals.
This formulation not only identifies regions where constitutive laws break down
but also improves robustness against model uncertainties without relying on a
fully trustworthy forward model. We demonstrate the effectiveness of our
approach in the context of elastography, showing that it provides a structured,
interpretable, and computationally efficient alternative to traditional model
error correction techniques. Our findings suggest that the proposed framework
enhances the accuracy and reliability of material property estimation by
offering a principled way to incorporate uncertainty in constitutive modeling.","Vincent C. Scholz, P. S. Koutsourelakis",2025-02-11 09:52:06.000000,arXiv,http://arxiv.org/abs/2502.07415v1,Statistical Machine Learning
816,Memory Analysis on the Training Course of DeepSeek Models,"We present a theoretical analysis of GPU memory consumption during the
training of DeepSeek models such as DeepSeek-v2 and DeepSeek-v3. Our primary
objective is to clarify the device-level memory requirements associated with
various distributed training configurations. Specifically, we examine critical
factors influencing memory usage, including micro-batch size, activation
recomputation policies, 3D parallelism, and ZeRO optimizations. It is important
to emphasize that the training policies discussed in this report are not
representative of DeepSeek's official configurations. Instead, they are
explored to provide a deeper understanding of memory dynamics in training of
large-scale mixture-of-experts model.","Ping Zhang, Lei Su",2025-02-11 09:51:25.000000,arXiv,http://arxiv.org/abs/2502.07846v1,Other
817,Sample Weight Averaging for Stable Prediction,"The challenge of Out-of-Distribution (OOD) generalization poses a
foundational concern for the application of machine learning algorithms to
risk-sensitive areas. Inspired by traditional importance weighting and
propensity weighting methods, prior approaches employ an independence-based
sample reweighting procedure. They aim at decorrelating covariates to
counteract the bias introduced by spurious correlations between unstable
variables and the outcome, thus enhancing generalization and fulfilling stable
prediction under covariate shift. Nonetheless, these methods are prone to
experiencing an inflation of variance, primarily attributable to the reduced
efficacy in utilizing training samples during the reweighting process. Existing
remedies necessitate either environmental labels or substantially higher time
costs along with additional assumptions and supervised information. To mitigate
this issue, we propose SAmple Weight Averaging (SAWA), a simple yet efficacious
strategy that can be universally integrated into various sample reweighting
algorithms to decrease the variance and coefficient estimation error, thus
boosting the covariate-shift generalization and achieving stable prediction
across different environments. We prove its rationality and benefits
theoretically. Experiments across synthetic datasets and real-world datasets
consistently underscore its superiority against covariate shift.","Han Yu, Yue He, Renzhe Xu, Dongbai Li, Jiayin Zhang, Wenchao Zou, Peng Cui",2025-02-11 09:51:22.000000,arXiv,http://arxiv.org/abs/2502.07414v1,Machine Learning
818,EgoTextVQA: Towards Egocentric Scene-Text Aware Video Question Answering,"We introduce EgoTextVQA, a novel and rigorously constructed benchmark for
egocentric QA assistance involving scene text. EgoTextVQA contains 1.5K
ego-view videos and 7K scene-text aware questions that reflect real-user needs
in outdoor driving and indoor house-keeping activities. The questions are
designed to elicit identification and reasoning on scene text in an egocentric
and dynamic environment. With EgoTextVQA, we comprehensively evaluate 10
prominent multimodal large language models. Currently, all models struggle, and
the best results (Gemini 1.5 Pro) are around 33% accuracy, highlighting the
severe deficiency of these techniques in egocentric QA assistance. Our further
investigations suggest that precise temporal grounding and multi-frame
reasoning, along with high resolution and auxiliary scene-text inputs, are key
for better performance. With thorough analyses and heuristic suggestions, we
hope EgoTextVQA can serve as a solid testbed for research in egocentric
scene-text QA assistance.","Sheng Zhou, Junbin Xiao, Qingyun Li, Yicong Li, Xun Yang, Dan Guo, Meng Wang, Tat-Seng Chua, Angela Yao",2025-02-11 09:45:06.000000,arXiv,http://arxiv.org/abs/2502.07411v1,Computer Vision
819,MGPATH: Vision-Language Model with Multi-Granular Prompt Learning for Few-Shot WSI Classification,"Whole slide pathology image classification presents challenges due to
gigapixel image sizes and limited annotation labels, hindering model
generalization. This paper introduces a prompt learning method to adapt large
vision-language models for few-shot pathology classification. We first extend
the Prov-GigaPath vision foundation model, pre-trained on 1.3 billion pathology
image tiles, into a vision-language model by adding adaptors and aligning it
with medical text encoders via contrastive learning on 923K image-text pairs.
The model is then used to extract visual features and text embeddings from
few-shot annotations and fine-tunes with learnable prompt embeddings. Unlike
prior methods that combine prompts with frozen features using prefix embeddings
or self-attention, we propose multi-granular attention that compares
interactions between learnable prompts with individual image patches and groups
of them. This approach improves the model's ability to capture both
fine-grained details and broader context, enhancing its recognition of complex
patterns across sub-regions. To further improve accuracy, we leverage
(unbalanced) optimal transport-based visual-text distance to secure model
robustness by mitigating perturbations that might occur during the data
augmentation process. Empirical experiments on lung, kidney, and breast
pathology modalities validate the effectiveness of our approach; thereby, we
surpass several of the latest competitors and consistently improve performance
across diverse architectures, including CLIP, PLIP, and Prov-GigaPath
integrated PLIP. We release our implementations and pre-trained models at this
MGPATH.","Anh-Tien Nguyen, Duy Minh Ho Nguyen, Nghiem Tuong Diep, Trung Quoc Nguyen, Nhat Ho, Jacqueline Michelle Metsch, Miriam Cindy Maurer, Daniel Sonntag, Hanibal Bohnenberger, Anne-Christin Hauschild",2025-02-11 09:42:13.000000,arXiv,http://arxiv.org/abs/2502.07409v1,Computer Vision
820,"No Data, No Optimization: A Lightweight Method To Disrupt Neural Networks With Sign-Flips","Deep Neural Networks (DNNs) can be catastrophically disrupted by flipping
only a handful of sign bits in their parameters. We introduce Deep Neural
Lesion (DNL), a data-free, lightweight method that locates these critical
parameters and triggers massive accuracy drops. We validate its efficacy on a
wide variety of computer vision models and datasets. The method requires no
training data or optimization and can be carried out via common exploits
software, firmware or hardware based attack vectors. An enhanced variant that
uses a single forward and backward pass further amplifies the damage beyond
DNL's zero-pass approach. Flipping just two sign bits in ResNet50 on ImageNet
reduces accuracy by 99.8\%. We also show that selectively protecting a small
fraction of vulnerable sign bits provides a practical defense against such
attacks.","Ido Galil, Moshe Kimhi, Ran El-Yaniv",2025-02-11 09:40:45.000000,arXiv,http://arxiv.org/abs/2502.07408v1,Machine Learning
821,Coupling Agent-Based Simulations and VR universes: the case of GAMA and Unity,"Agent-based models (ABMs) and video games, including those taking advantage
of virtual reality (VR), have undergone a remarkable parallel evolution,
achieving impressive levels of complexity and sophistication. This paper argues
that while ABMs prioritize scientific analysis and understanding and VR aims
for immersive entertainment, they both simulate artificial worlds and can
benefit from closer integration. Coupling both approaches indeed opens
interesting possibilities for research and development in various fields, and
in particular education, at the heart of the SIMPLE project, an EU-funded
project on the development of digital tools for awareness raising on
environmental issues. However, existing tools often present limitations,
including technical complexity, limited functionalities, and lack of
interoperability. To address these challenges, we introduce a novel framework
for linking GAMA, a popular ABM platform, with Unity, a widely used game
engine. This framework enables seamless data exchange, real-time visualization,
and user interaction within VR environments, allowing researchers to leverage
the strengths of both ABMs and VR for more impactful and engaging simulations.
We demonstrate the capabilities of our framework through two prototypes built
to highlight its potential in representing and interacting with complex
socio-environmental system models. We conclude by emphasizing the importance of
continued collaboration between the ABM and VR communities to develop robust,
user-friendly tools, paving the way for a new era of collaborative research and
immersive experiences in simulations.","Alexis Drogoul, Patrick Taillandier, Arthur Brugière, Louis Martinez, Léon Sillano, Baptiste Lesquoy, Huynh Quang Nghi",2025-02-11 09:38:45.000000,arXiv,http://arxiv.org/abs/2502.07405v1,Multi-Agent Systems
822,Human-in-the-Loop Annotation for Image-Based Engagement Estimation: Assessing the Impact of Model Reliability on Annotation Accuracy,"Human-in-the-loop (HITL) frameworks are increasingly recognized for their
potential to improve annotation accuracy in emotion estimation systems by
combining machine predictions with human expertise. This study focuses on
integrating a high-performing image-based emotion model into a HITL annotation
framework to evaluate the collaborative potential of human-machine interaction
and identify the psychological and practical factors critical to successful
collaboration. Specifically, we investigate how varying model reliability and
cognitive framing influence human trust, cognitive load, and annotation
behavior in HITL systems. We demonstrate that model reliability and
psychological framing significantly impact annotators' trust, engagement, and
consistency, offering insights into optimizing HITL frameworks. Through three
experimental scenarios with 29 participants--baseline model reliability (S1),
fabricated errors (S2), and cognitive bias introduced by negative framing
(S3)--we analyzed behavioral and qualitative data. Reliable predictions in S1
yielded high trust and annotation consistency, while unreliable outputs in S2
led to increased critical evaluations but also heightened frustration and
response variability. Negative framing in S3 revealed how cognitive bias
influenced participants to perceive the model as more relatable and accurate,
despite misinformation regarding its reliability. These findings highlight the
importance of both reliable machine outputs and psychological factors in
shaping effective human-machine collaboration. By leveraging the strengths of
both human oversight and automated systems, this study establishes a scalable
HITL framework for emotion annotation and lays the foundation for broader
applications in adaptive learning and human-computer interaction.","Sahana Yadnakudige Subramanya, Ko Watanabe, Andreas Dengel, Shoya Ishimaru",2025-02-11 09:37:10.000000,arXiv,http://arxiv.org/abs/2502.07404v1,Other
823,Extended monocular 3D imaging,"3D vision is of paramount importance for numerous applications ranging from
machine intelligence to precision metrology. Despite much recent progress, the
majority of 3D imaging hardware remains bulky and complicated and provides much
lower image resolution compared to their 2D counterparts. Moreover, there are
many well-known scenarios that existing 3D imaging solutions frequently fail.
Here, we introduce an extended monocular 3D imaging (EM3D) framework that fully
exploits the vectorial wave nature of light. Via the multi-stage fusion of
diffraction- and polarization-based depth cues, using a compact monocular
camera equipped with a diffractive-refractive hybrid lens, we experimentally
demonstrate the snapshot acquisition of a million-pixel and accurate 3D point
cloud for extended scenes that are traditionally challenging, including those
with low texture, being highly reflective, or nearly transparent, without a
data prior. Furthermore, we discover that the combination of depth and
polarization information can unlock unique new opportunities in material
identification, which may further expand machine intelligence for applications
like target recognition and face anti-spoofing. The straightforward yet
powerful architecture thus opens up a new path for a higher-dimensional machine
vision in a minimal form factor, facilitating the deployment of monocular
cameras for applications in much more diverse scenarios.","Zicheng Shen, Feng Zhao, Yibo Ni, Yuanmu Yang",2025-02-11 09:32:31.000000,arXiv,http://arxiv.org/abs/2502.07403v1,Computer Vision
824,Enhancing Higher Education with Generative AI: A Multimodal Approach for Personalised Learning,"This research explores the opportunities of Generative AI (GenAI) in the
realm of higher education through the design and development of a multimodal
chatbot for an undergraduate course. Leveraging the ChatGPT API for nuanced
text-based interactions and Google Bard for advanced image analysis and
diagram-to-code conversions, we showcase the potential of GenAI in addressing a
broad spectrum of educational queries. Additionally, the chatbot presents a
file-based analyser designed for educators, offering deep insights into student
feedback via sentiment and emotion analysis, and summarising course evaluations
with key metrics. These combinations highlight the crucial role of multimodal
conversational AI in enhancing teaching and learning processes, promising
significant advancements in educational adaptability, engagement, and feedback
analysis. By demonstrating a practical web application, this research
underlines the imperative for integrating GenAI technologies to foster more
dynamic and responsive educational environments, ultimately contributing to
improved educational outcomes and pedagogical strategies.","Johnny Chan, Yuming Li",2025-02-11 09:29:29.000000,arXiv,http://arxiv.org/abs/2502.07401v1,Other
825,Explainable Multimodal Machine Learning for Revealing Structure-Property Relationships in Carbon Nanotube Fibers,"In this study, we propose Explainable Multimodal Machine Learning (EMML),
which integrates the analysis of diverse data types (multimodal data) using
factor analysis for feature extraction with Explainable AI (XAI), for carbon
nanotube (CNT) fibers prepared from aqueous dispersions. This method is a
powerful approach to elucidate the mechanisms governing material properties,
where multi-stage fabrication conditions and multiscale structures have complex
influences. Thus, in our case, this approach helps us understand how different
processing steps and structures at various scales impact the final properties
of CNT fibers. The analysis targeted structures ranging from the nanoscale to
the macroscale, including aggregation size distributions of CNT dispersions and
the effective length of CNTs. Furthermore, because some types of data were
difficult to interpret using standard methods, challenging-to-interpret
distribution data were analyzed using Negative Matrix Factorization (NMF) for
extracting key features that determine the outcome. Contribution analysis with
SHapley Additive exPlanations (SHAP) demonstrated that small, uniformly
distributed aggregates are crucial for improving fracture strength, while CNTs
with long effective lengths are significant factors for enhancing electrical
conductivity. The analysis also identified thresholds and trends for these key
factors to assist in defining the conditions needed to optimize CNT fiber
properties. EMML is not limited to CNT fibers but can be applied to the design
of other materials derived from nanomaterials, making it a useful tool for
developing a wide range of advanced materials. This approach provides a
foundation for advancing data-driven materials research.","Daisuke Kimura, Naoko Tajima, Toshiya Okazaki, Shun Muroga",2025-02-11 09:29:23.000000,arXiv,http://arxiv.org/abs/2502.07400v1,Other
826,On Iterative Evaluation and Enhancement of Code Quality Using GPT-4o,"This paper introduces CodeQUEST, a novel framework leveraging Large Language
Models (LLMs) to iteratively evaluate and enhance code quality across multiple
dimensions, including readability, maintainability, efficiency, and security.
The framework is divided into two main components: an Evaluator that assesses
code quality across ten dimensions, providing both quantitative scores and
qualitative summaries, and an Optimizer that iteratively improves the code
based on the Evaluator's feedback. Our study demonstrates that CodeQUEST can
effectively and robustly evaluate code quality, with its assessments aligning
closely with established code quality metrics. Through a series of experiments
using a curated dataset of Python and JavaScript examples, CodeQUEST
demonstrated significant improvements in code quality, achieving a mean
relative percentage improvement of 52.6%. The framework's evaluations were
validated against a set of proxy metrics comprising of Pylint Score, Radon
Maintainability Index, and Bandit output logs, showing a meaningful
correlation. This highlights the potential of LLMs in automating code quality
evaluation and improvement processes, presenting a significant advancement
toward enhancing software development practices. The code implementation of the
framework is available at: https://github.com/jpmorganchase/CodeQuest.","Rundong Liu, Andre Frade, Amal Vaidya, Maxime Labonne, Marcus Kaiser, Bismayan Chakrabarti, Jonathan Budd, Sean Moran",2025-02-11 09:27:00.000000,arXiv,http://arxiv.org/abs/2502.07399v1,Other
827,Bandit Optimal Transport,"Despite the impressive progress in statistical Optimal Transport (OT) in
recent years, there has been little interest in the study of the
\emph{sequential learning} of OT. Surprisingly so, as this problem is both
practically motivated and a challenging extension of existing settings such as
linear bandits. This article considers (for the first time) the stochastic
bandit problem of learning to solve generic Kantorovich and entropic OT
problems from repeated interactions when the marginals are known but the cost
is unknown. We provide $\tilde{\mathcal O}(\sqrt{T})$ regret algorithms for
both problems by extending linear bandits on Hilbert spaces. These results
provide a reduction to infinite-dimensional linear bandits. To deal with the
dimension, we provide a method to exploit the intrinsic regularity of the cost
to learn, yielding corresponding regret bounds which interpolate between
$\tilde{\mathcal O}(\sqrt{T})$ and $\tilde{\mathcal O}(T)$.",Lorenzo Croissant,2025-02-11 09:24:25.000000,arXiv,http://arxiv.org/abs/2502.07397v1,Statistical Machine Learning
828,Spread them Apart: Towards Robust Watermarking of Generated Content,"Generative models that can produce realistic images have improved
significantly in recent years. The quality of the generated content has
increased drastically, so sometimes it is very difficult to distinguish between
the real images and the generated ones. Such an improvement comes at a price of
ethical concerns about the usage of the generative models: the users of
generative models can improperly claim ownership of the generated content
protected by a license. In this paper, we propose an approach to embed
watermarks into the generated content to allow future detection of the
generated content and identification of the user who generated it. The
watermark is embedded during the inference of the model, so the proposed
approach does not require the retraining of the latter. We prove that
watermarks embedded are guaranteed to be robust against additive perturbations
of a bounded magnitude. We apply our method to watermark diffusion models and
show that it matches state-of-the-art watermarking schemes in terms of
robustness to different types of synthetic watermark removal attacks.","Mikhail Pautov, Danil Ivanov, Andrey V. Galichin, Oleg Rogov, Ivan Oseledets",2025-02-11 09:23:38.000000,arXiv,http://arxiv.org/abs/2502.07845v1,Computer Vision
829,Optimality in importance sampling: a gentle survey,"The performance of the Monte Carlo sampling methods relies on the crucial
choice of a proposal density. The notion of optimality is fundamental to design
suitable adaptive procedures of the proposal density within Monte Carlo
schemes. This work is an exhaustive review around the concept of optimality in
importance sampling. Several frameworks are described and analyzed, such as the
marginal likelihood approximation for model selection, the use of multiple
proposal densities, a sequence of tempered posteriors, and noisy scenarios
including the applications to approximate Bayesian computation (ABC) and
reinforcement learning, to name a few. Some theoretical and empirical
comparisons are also provided.","Fernando Llorente, Luca Martino",2025-02-11 09:23:26.000000,arXiv,http://arxiv.org/abs/2502.07396v1,Other
830,Interpretable Rules for Online Failure Prediction: A Case Study on the Metro do Porto dataset,"Due to their high predictive performance, predictive maintenance applications
have increasingly been approached with Deep Learning techniques in recent
years. However, as in other real-world application scenarios, the need for
explainability is often stated but not sufficiently addressed. This study will
focus on predicting failures on Metro trains in Porto, Portugal. While recent
works have found high-performing deep neural network architectures that feature
a parallel explainability pipeline, the generated explanations are fairly
complicated and need help explaining why the failures are happening. This work
proposes a simple online rule-based explainability approach with interpretable
features that leads to straightforward, interpretable rules. We showcase our
approach on MetroPT2 and find that three specific sensors on the Metro do Porto
trains suffice to predict the failures present in the dataset with simple
rules.","Matthias Jakobs, Bruno Veloso, Joao Gama",2025-02-11 09:23:16.000000,arXiv,http://arxiv.org/abs/2502.07394v1,Machine Learning
831,Target-Augmented Shared Fusion-based Multimodal Sarcasm Explanation Generation,"Sarcasm is a linguistic phenomenon that intends to ridicule a target (e.g.,
entity, event, or person) in an inherent way. Multimodal Sarcasm Explanation
(MuSE) aims at revealing the intended irony in a sarcastic post using a natural
language explanation. Though important, existing systems overlooked the
significance of the target of sarcasm in generating explanations. In this
paper, we propose a Target-aUgmented shaRed fusion-Based sarcasm explanatiOn
model, aka. TURBO. We design a novel shared-fusion mechanism to leverage the
inter-modality relationships between an image and its caption. TURBO assumes
the target of the sarcasm and guides the multimodal shared fusion mechanism in
learning intricacies of the intended irony for explanations. We evaluate our
proposed TURBO model on the MORE+ dataset. Comparison against multiple
baselines and state-of-the-art models signifies the performance improvement of
TURBO by an average margin of $+3.3\%$. Moreover, we explore LLMs in zero and
one-shot settings for our task and observe that LLM-generated explanation,
though remarkable, often fails to capture the critical nuances of the sarcasm.
Furthermore, we supplement our study with extensive human evaluation on TURBO's
generated explanations and find them out to be comparatively better than other
systems.","Palaash Goel, Dushyant Singh Chauhan, Md Shad Akhtar",2025-02-11 09:19:46.000000,arXiv,http://arxiv.org/abs/2502.07391v1,Natural Language Processing
832,FADE: Forecasting for Anomaly Detection on ECG,"Cardiovascular diseases, a leading cause of noncommunicable disease-related
deaths, require early and accurate detection to improve patient outcomes.
Taking advantage of advances in machine learning and deep learning, multiple
approaches have been proposed in the literature to address the challenge of
detecting ECG anomalies. Typically, these methods are based on the manual
interpretation of ECG signals, which is time consuming and depends on the
expertise of healthcare professionals. The objective of this work is to propose
a deep learning system, FADE, designed for normal ECG forecasting and anomaly
detection, which reduces the need for extensive labeled datasets and manual
interpretation. FADE has been trained in a self-supervised manner with a novel
morphological inspired loss function. Unlike conventional models that learn
from labeled anomalous ECG waveforms, our approach predicts the future of
normal ECG signals, thus avoiding the need for extensive labeled datasets.
Using a novel distance function to compare forecasted ECG signals with actual
sensor data, our method effectively identifies cardiac anomalies. Additionally,
this approach can be adapted to new contexts through domain adaptation
techniques. To evaluate our proposal, we performed a set of experiments using
two publicly available datasets: MIT-BIH NSR and MIT-BIH Arrythmia. The results
demonstrate that our system achieves an average accuracy of 83.84% in anomaly
detection, while correctly classifying normal ECG signals with an accuracy of
85.46%. Our proposed approach exhibited superior performance in the early
detection of cardiac anomalies in ECG signals, surpassing previous methods that
predominantly identify a limited range of anomalies. FADE effectively detects
both abnormal heartbeats and arrhythmias, offering significant advantages in
healthcare through cost reduction or processing of large-scale ECG data.","Paula Ruiz-Barroso, Francisco M. Castro, José Miranda, Denisa-Andreea Constantinescu, David Atienza, Nicolás Guil",2025-02-11 09:19:39.000000,arXiv,http://arxiv.org/abs/2502.07389v1,Computer Vision
833,UAV-assisted Joint Mobile Edge Computing and Data Collection via Matching-enabled Deep Reinforcement Learning,"Unmanned aerial vehicle (UAV)-assisted mobile edge computing (MEC) and data
collection (DC) have been popular research issues. Different from existing
works that consider MEC and DC scenarios separately, this paper investigates a
multi-UAV-assisted joint MEC-DC system. Specifically, we formulate a joint
optimization problem to minimize the MEC latency and maximize the collected
data volume. This problem can be classified as a non-convex mixed integer
programming problem that exhibits long-term optimization and dynamics. Thus, we
propose a deep reinforcement learning-based approach that jointly optimizes the
UAV movement, user transmit power, and user association in real time to solve
the problem efficiently. Specifically, we reformulate the optimization problem
into an action space-reduced Markov decision process (MDP) and optimize the
user association by using a two-phase matching-based association (TMA)
strategy. Subsequently, we propose a soft actor-critic (SAC)-based approach
that integrates the proposed TMA strategy (SAC-TMA) to solve the formulated
joint optimization problem collaboratively. Simulation results demonstrate that
the proposed SAC-TMA is able to coordinate the two subsystems and can
effectively reduce the system latency and improve the data collection volume
compared with other benchmark algorithms.","Boxiong Wang, Hui Kang, Jiahui Li, Geng Sun, Zemin Sun, Jiacheng Wang, Dusit Niyato",2025-02-11 09:18:32.000000,arXiv,http://arxiv.org/abs/2502.07388v1,Neural Networks
834,Parametric type design in the era of variable and color fonts,"Parametric fonts are programatically defined fonts with variable parameters,
pioneered by Donald Kunth with his MetaFont technology in the 1980s. While
Donald Knuth's ideas in MetaFont and subsequently in MetaPost are often seen as
legacy techniques from the pre-graphical user interface (GUI) era of type
design, recent trends like variable fonts suggest a resurgence of certain
principles. This paper explores a modern type design process built on
parametric design principles, specifically using MetaPost. The author created
two variable fonts with this method and released them under a free, open-source
license. The paper details the methodology, workflow, and insights gained from
this process.",Santhosh Thottingal,2025-02-11 09:12:05.000000,arXiv,http://arxiv.org/abs/2502.07386v1,Natural Language Processing
835,Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution,"Due to limitations of storage and bandwidth, videos stored and transmitted on
the Internet are usually low-quality with low-resolution and compression noise.
Although video super-resolution (VSR) is an efficient technique to enhance
video resolution, relatively VSR methods focus on compressed videos. Directly
applying general VSR approaches leads to the failure of improving practical
videos, especially when frames are highly compressed at a low bit rate.
Recently, diffusion models have achieved superior performance in low-level
visual tasks, and their high-realism generation capability enables them to be
applied in VSR. To synthesize more compression-lost details and refine temporal
consistency, we propose a novel Spatial Degradation-Aware and Temporal
Consistent (SDATC) diffusion model for compressed VSR. Specifically, we
introduce a distortion Control module (DCM) to modulate diffusion model inputs
and guide the generation. Next, the diffusion model executes the denoising
process for texture generation with fine-tuned spatial prompt-based
compression-aware module (PCAM) and spatio-temporal attention module (STAM).
PCAM extracts features to encode specific compression information dynamically.
STAM extends the spatial attention mechanism to a spatio-temporal dimension for
capturing temporal correlation. Extensive experimental results on benchmark
datasets demonstrate the effectiveness of the proposed modules in enhancing
compressed videos.","Hongyu An, Xinfeng Zhang, Shijie Zhao, Li Zhang",2025-02-11 08:57:45.000000,arXiv,http://arxiv.org/abs/2502.07381v2,Computer Vision
836,"Demonstrating Wheeled Lab: Modern Sim2Real for Low-cost, Open-source Wheeled Robotics","Simulation has been pivotal in recent robotics milestones and is poised to
play a prominent role in the field's future. However, recent robotic advances
often rely on expensive and high-maintenance platforms, limiting access to
broader robotics audiences. This work introduces Wheeled Lab, a framework for
the low-cost, open-source wheeled platforms that are already widely established
in education and research. Through integration with Isaac Lab, Wheeled Lab
introduces modern techniques in Sim2Real, such as domain randomization, sensor
simulation, and end-to-end learning, to new user communities. To kickstart
education and demonstrate the framework's capabilities, we develop three
state-of-the-art policies for small-scale RC cars: controlled drifting,
elevation traversal, and visual navigation, each trained in simulation and
deployed in the real world. By bridging the gap between advanced Sim2Real
methods and affordable, available robotics, Wheeled Lab aims to democratize
access to cutting-edge tools, fostering innovation and education in a broader
robotics context. The full stack, from hardware to software, is low cost and
open-source.","Tyler Han, Preet Shah, Sidharth Rajagopal, Yanda Bao, Sanghun Jung, Sidharth Talia, Gabriel Guo, Bryan Xu, Bhaumik Mehta, Emma Romig, Rosario Scalise, Byron Boots",2025-02-11 08:57:41.000000,arXiv,http://arxiv.org/abs/2502.07380v1,Robotics
837,"LLMs Can Easily Learn to Reason from Demonstrations Structure, not content, is what matters!","Large reasoning models (LRMs) tackle complex reasoning problems by following
long chain-of-thoughts (Long CoT) that incorporate reflection, backtracking,
and self-validation. However, the training techniques and data requirements to
elicit Long CoT remain poorly understood. In this work, we find that a Large
Language model (LLM) can effectively learn Long CoT reasoning through
data-efficient supervised fine-tuning (SFT) and parameter-efficient low-rank
adaptation (LoRA). With just 17k long CoT training samples, the
Qwen2.5-32B-Instruct model achieves significant improvements on a wide range of
math and coding benchmarks, including 56.7% (+40.0%) on AIME 2024 and 57.0%
(+8.1%) on LiveCodeBench, competitive to the proprietary o1-preview model's
score of 44.6% and 59.1%. More importantly, we find that the structure of Long
CoT is critical to the learning process, whereas the content of individual
reasoning steps has minimal impact. Perturbations affecting content, such as
training on incorrect samples or removing reasoning keywords, have little
impact on performance. In contrast, structural modifications that disrupt
logical consistency in the Long CoT, such as shuffling or deleting reasoning
steps, significantly degrade accuracy. For example, a model trained on Long CoT
samples with incorrect answers still achieves only 3.2% lower accuracy compared
to training with fully correct samples. These insights deepen our understanding
of how to elicit reasoning capabilities in LLMs and highlight key
considerations for efficiently training the next generation of reasoning
models. This is the academic paper of our previous released Sky-T1-32B-Preview
model. Codes are available at https://github.com/NovaSky-AI/SkyThought.","Dacheng Li, Shiyi Cao, Tyler Griggs, Shu Liu, Xiangxi Mo, Shishir G. Patil, Matei Zaharia, Joseph E. Gonzalez, Ion Stoica",2025-02-11 08:48:48.000000,arXiv,http://arxiv.org/abs/2502.07374v1,Artificial Intelligence
838,EvoFlow: Evolving Diverse Agentic Workflows On The Fly,"The past two years have witnessed the evolution of large language model
(LLM)-based multi-agent systems from labor-intensive manual design to partial
automation (\textit{e.g.}, prompt engineering, communication topology) and
eventually to fully automated design. However, existing agentic automation
pipelines often lack LLM heterogeneity and focus on single-objective
performance optimization, limiting their potential to combine weaker models for
more customized and cost-effective solutions. To address this challenge, we
propose EvoFlow, a niching evolutionary algorithm-based framework to
automatically search a population of heterogeneous and complexity-adaptive
agentic workflows, rather than a single homogeneous, complex workflow.
Technically, EvoFlow performs \textit{(1) tag-based retrieval} to extract
parent workflows from an agentic population, evolves new workflows through
\textit{(2) crossover} and \textit{(3) mutation}, and employs \textit{(4)
niching-based selection} to maintain population diversity and quality.
Extensive evaluations across seven benchmarks demonstrate that EvoFlow is:
\textbf{(I) diverse}, evolving a population of workflows ranging from simple
I/O tasks to complex multi-turn interactions; \textbf{(II) high-performing},
outperforming previous handcrafted and automated workflows by
$1.23\%\sim29.86\%$; \textbf{(III) economical}, surpassing powerful
\llmname{o1-preview} at $12.4\%$ of its inference cost using weaker open-source
models.","Guibin Zhang, Kaijie Chen, Guancheng Wan, Heng Chang, Hong Cheng, Kun Wang, Shuyue Hu, Lei Bai",2025-02-11 08:48:46.000000,arXiv,http://arxiv.org/abs/2502.07373v1,Machine Learning
839,USRNet: Unified Scene Recovery Network for Enhancing Traffic Imaging under Multiple Adverse Weather Conditions,"Advancements in computer vision technology have facilitated the extensive
deployment of intelligent transportation systems and visual surveillance
systems across various applications, including autonomous driving, public
safety, and environmental monitoring. However, adverse weather conditions such
as haze, rain, snow, and more complex mixed degradation can significantly
degrade image quality. The degradation compromises the accuracy and reliability
of these systems across various scenarios. To tackle the challenge of
developing adaptable models for scene restoration, we introduce the unified
scene recovery network (USRNet), capable of handling multiple types of image
degradation. The USRNet features a sophisticated architecture consisting of a
scene encoder, an attention-driven node independent learning mechanism (NILM),
an edge decoder, and a scene restoration module. The scene encoder, powered by
advanced residual blocks, extracts deep features from degraded images in a
progressive manner, ensuring thorough encoding of degradation information. To
enhance the USRNet's adaptability in diverse weather conditions, we introduce
NILM, which enables the network to learn and respond to different scenarios
with precision, thereby increasing its robustness. The edge decoder is designed
to extract edge features with precision, which is essential for maintaining
image sharpness. Experimental results demonstrate that USRNet surpasses
existing methods in handling complex imaging degradations, thereby improving
the accuracy and reliability of visual systems across diverse scenarios. The
code resources for this work can be accessed in
https://github.com/LouisYxLu/USRNet.","Yuxu Lu, Ai Chen, Dong Yang, Ryan Wen Liu",2025-02-11 08:47:58.000000,arXiv,http://arxiv.org/abs/2502.07372v1,Computer Vision
840,Uniform Kernel Prober,"The ability to identify useful features or representations of the input data
based on training data that achieves low prediction error on test data across
multiple prediction tasks is considered the key to multitask learning success.
In practice, however, one faces the issue of the choice of prediction tasks and
the availability of test data from the chosen tasks while comparing the
relative performance of different features. In this work, we develop a class of
pseudometrics called Uniform Kernel Prober (UKP) for comparing features or
representations learned by different statistical models such as neural networks
when the downstream prediction tasks involve kernel ridge regression. The
proposed pseudometric, UKP, between any two representations, provides a uniform
measure of prediction error on test data corresponding to a general class of
kernel ridge regression tasks for a given choice of a kernel without access to
test data. Additionally, desired invariances in representations can be
successfully captured by UKP only through the choice of the kernel function and
the pseudometric can be efficiently estimated from $n$ input data samples with
$O(\frac{1}{\sqrt{n}})$ estimation error. We also experimentally demonstrate
the ability of UKP to discriminate between different types of features or
representations based on their generalization performance on downstream kernel
ridge regression tasks.","Soumya Mukherjee, Bharath K. Sriperumbudur",2025-02-11 08:43:41.000000,arXiv,http://arxiv.org/abs/2502.07369v1,Statistical Machine Learning
841,LongReD: Mitigating Short-Text Degradation of Long-Context Large Language Models via Restoration Distillation,"Large language models (LLMs) have gained extended context windows through
scaling positional encodings and lightweight continual pre-training. However,
this often leads to degraded performance on short-text tasks, while the reasons
for this degradation remain insufficiently explored. In this work, we identify
two primary factors contributing to this issue: distribution drift in hidden
states and attention scores, and catastrophic forgetting during continual
pre-training. To address these challenges, we propose Long Context Pre-training
with Restoration Distillation (LongReD), a novel approach designed to mitigate
short-text performance degradation through minimizing the distribution
discrepancy between the extended and original models. Besides training on long
texts, LongReD distills the hidden state of selected layers from the original
model on short texts. Additionally, LongReD also introduces a short-to-long
distillation, aligning the output distribution on short texts with that on long
texts by leveraging skipped positional indices. Experiments on common text
benchmarks demonstrate that LongReD effectively preserves the model's
short-text performance while maintaining comparable or even better capacity to
handle long texts than baselines.","Zican Dong, Junyi Li, Jinhao Jiang, Mingyu Xu, Wayne Xin Zhao, Bingning Wang, Weipeng Chen",2025-02-11 08:37:16.000000,arXiv,http://arxiv.org/abs/2502.07365v1,Natural Language Processing
842,Effects of Random Edge-Dropping on Over-Squashing in Graph Neural Networks,"Message Passing Neural Networks (MPNNs) are a class of Graph Neural Networks
(GNNs) that leverage the graph topology to propagate messages across
increasingly larger neighborhoods. The message-passing scheme leads to two
distinct challenges: over-smoothing and over-squashing. While several
algorithms, e.g. DropEdge and its variants -- DropNode, DropAgg and DropGNN --
have successfully addressed the over-smoothing problem, their impact on
over-squashing remains largely unexplored. This represents a critical gap in
the literature as failure to mitigate over-squashing would make these methods
unsuitable for long-range tasks. In this work, we take the first step towards
closing this gap by studying the aforementioned algorithms in the context of
over-squashing. We present novel theoretical results that characterize the
negative effects of DropEdge on sensitivity between distant nodes, suggesting
its unsuitability for long-range tasks. Our findings are easily extended to its
variants, allowing us to build a comprehensive understanding of how they affect
over-squashing. We evaluate these methods using real-world datasets,
demonstrating their detrimental effects. Specifically, we show that while
DropEdge-variants improve test-time performance in short range tasks, they
deteriorate performance in long-range ones. Our theory explains these results
as follows: random edge-dropping lowers the effective receptive field of GNNs,
which although beneficial for short-range tasks, misaligns the models on
long-range ones. This forces the models to overfit to short-range artefacts in
the training set, resulting in poor generalization. Our conclusions highlight
the need to re-evaluate various methods designed for training deep GNNs, with a
renewed focus on modelling long-range interactions.","Jasraj Singh, Keyue Jiang, Brooks Paige, Laura Toni",2025-02-11 08:36:38.000000,arXiv,http://arxiv.org/abs/2502.07364v1,Machine Learning
843,Supervised contrastive learning for cell stage classification of animal embryos,"Video microscopy, when combined with machine learning, offers a promising
approach for studying the early development of in vitro produced (IVP) embryos.
However, manually annotating developmental events, and more specifically cell
divisions, is time-consuming for a biologist and cannot scale up for practical
applications. We aim to automatically classify the cell stages of embryos from
2D time-lapse microscopy videos with a deep learning approach. We focus on the
analysis of bovine embryonic development using video microscopy, as we are
primarily interested in the application of cattle breeding, and we have created
a Bovine Embryos Cell Stages (ECS) dataset. The challenges are three-fold: (1)
low-quality images and bovine dark cells that make the identification of cell
stages difficult, (2) class ambiguity at the boundaries of developmental
stages, and (3) imbalanced data distribution. To address these challenges, we
introduce CLEmbryo, a novel method that leverages supervised contrastive
learning combined with focal loss for training, and the lightweight 3D neural
network CSN-50 as an encoder. We also show that our method generalizes well.
CLEmbryo outperforms state-of-the-art methods on both our Bovine ECS dataset
and the publicly available NYU Mouse Embryos dataset.","Yasmine Hachani, Patrick Bouthemy, Elisa Fromont, Sylvie Ruffini, Ludivine Laffont, Alline de Paula Reis",2025-02-11 08:30:25.000000,arXiv,http://arxiv.org/abs/2502.07360v1,Other
844,SymbioSim: Human-in-the-loop Simulation Platform for Bidirectional Continuing Learning in Human-Robot Interaction,"The development of intelligent robots seeks to seamlessly integrate them into
the human world, providing assistance and companionship in daily life and work,
with the ultimate goal of achieving human-robot symbiosis. To realize this
vision, robots must continuously learn and evolve through consistent
interaction and collaboration with humans, while humans need to gradually
develop an understanding of and trust in robots through shared experiences.
However, training and testing algorithms directly on physical robots involve
substantial costs and safety risks. Moreover, current robotic simulators fail
to support real human participation, limiting their ability to provide
authentic interaction experiences and gather valuable human feedback. In this
paper, we introduce SymbioSim, a novel human-in-the-loop robotic simulation
platform designed to enable the safe and efficient development, evaluation, and
optimization of human-robot interactions. By leveraging a carefully designed
system architecture and modules, SymbioSim delivers a natural and realistic
interaction experience, facilitating bidirectional continuous learning and
adaptation for both humans and robots. Extensive experiments and user studies
demonstrate the platform's promising performance and highlight its potential to
significantly advance research on human-robot symbiosis.","Haoran Chen, Yiteng Xu, Yiming Ren, Yaoqin Ye, Xinran Li, Ning Ding, Peishan Cong, Ziyi Wang, Bushi Liu, Yuhan Chen, Zhiyang Dou, Xiaokun Leng, Manyi Li, Yuexin Ma, Changhe Tu",2025-02-11 08:29:43.000000,arXiv,http://arxiv.org/abs/2502.07358v1,Robotics
845,Bridging the Evaluation Gap: Leveraging Large Language Models for Topic Model Evaluation,"This study presents a framework for automated evaluation of dynamically
evolving topic taxonomies in scientific literature using Large Language Models
(LLMs). In digital library systems, topic modeling plays a crucial role in
efficiently organizing and retrieving scholarly content, guiding researchers
through complex knowledge landscapes. As research domains proliferate and
shift, traditional human centric and static evaluation methods struggle to
maintain relevance. The proposed approach harnesses LLMs to measure key quality
dimensions, such as coherence, repetitiveness, diversity, and topic-document
alignment, without heavy reliance on expert annotators or narrow statistical
metrics. Tailored prompts guide LLM assessments, ensuring consistent and
interpretable evaluations across various datasets and modeling techniques.
Experiments on benchmark corpora demonstrate the method's robustness,
scalability, and adaptability, underscoring its value as a more holistic and
dynamic alternative to conventional evaluation strategies.","Zhiyin Tan, Jennifer D'Souza",2025-02-11 08:23:56.000000,arXiv,http://arxiv.org/abs/2502.07352v1,Natural Language Processing
846,Multi-Task-oriented Nighttime Haze Imaging Enhancer for Vision-driven Measurement Systems,"Salient object detection (SOD) plays a critical role in vision-driven
measurement systems (VMS), facilitating the detection and segmentation of key
visual elements in an image. However, adverse imaging conditions such as haze
during the day, low light, and haze at night severely degrade image quality,
and complicating the SOD process. To address these challenges, we propose a
multi-task-oriented nighttime haze imaging enhancer (MToIE), which integrates
three tasks: daytime dehazing, low-light enhancement, and nighttime dehazing.
The MToIE incorporates two key innovative components: First, the network
employs a task-oriented node learning mechanism to handle three specific
degradation types: day-time haze, low light, and night-time haze conditions,
with an embedded self-attention module enhancing its performance in nighttime
imaging. In addition, multi-receptive field enhancement module that efficiently
extracts multi-scale features through three parallel depthwise separable
convolution branches with different dilation rates, capturing comprehensive
spatial information with minimal computational overhead. To ensure optimal
image reconstruction quality and visual characteristics, we suggest a hybrid
loss function. Extensive experiments on different types of weather/imaging
conditions illustrate that MToIE surpasses existing methods, significantly
enhancing the accuracy and reliability of vision systems across diverse imaging
scenarios. The code is available at https://github.com/Ai-Chen-Lab/MToIE.","Ai Chen, Yuxu Lu, Dong Yang, Junlin Zhou, Yan Fu, Duanbing Chen",2025-02-11 08:22:21.000000,arXiv,http://arxiv.org/abs/2502.07351v1,Computer Vision
847,KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems,"As scaling large language models faces prohibitive costs, multi-agent systems
emerge as a promising alternative, though challenged by static knowledge
assumptions and coordination inefficiencies. We introduces Knowledge-Aware
Bayesian Bandits (KABB), a novel framework that enhances multi-agent system
coordination through semantic understanding and dynamic adaptation. The
framework features three key innovations: a three-dimensional knowledge
distance model for deep semantic understanding, a dual-adaptation mechanism for
continuous expert optimization, and a knowledge-aware Thompson Sampling
strategy for efficient expert selection. Extensive evaluation demonstrates KABB
achieves an optimal cost-performance balance, maintaining high performance
while keeping computational demands relatively low in multi-agent coordination.","Jusheng Zhang, Zimeng Huang, Yijia Fan, Ningyuan Liu, Mingyan Li, Zhuojie Yang, Jiawei Yao, Jian Wang, Keze Wang",2025-02-11 08:22:12.000000,arXiv,http://arxiv.org/abs/2502.07350v1,Artificial Intelligence
848,The establishment of static digital humans and the integration with spinal models,"Adolescent idiopathic scoliosis (AIS), a prevalent spinal deformity,
significantly affects individuals' health and quality of life. Conventional
imaging techniques, such as X - rays, computed tomography (CT), and magnetic
resonance imaging (MRI), offer static views of the spine. However, they are
restricted in capturing the dynamic changes of the spine and its interactions
with overall body motion. Therefore, developing new techniques to address these
limitations has become extremely important. Dynamic digital human modeling
represents a major breakthrough in digital medicine. It enables a three -
dimensional (3D) view of the spine as it changes during daily activities,
assisting clinicians in detecting deformities that might be missed in static
imaging. Although dynamic modeling holds great potential, constructing an
accurate static digital human model is a crucial initial step for high -
precision simulations. In this study, our focus is on constructing an accurate
static digital human model integrating the spine, which is vital for subsequent
dynamic digital human research on AIS. First, we generate human point - cloud
data by combining the 3D Gaussian method with the Skinned Multi - Person Linear
(SMPL) model from the patient's multi - view images. Then, we fit a standard
skeletal model to the generated human model. Next, we align the real spine
model reconstructed from CT images with the standard skeletal model. We
validated the resulting personalized spine model using X - ray data from six
AIS patients, with Cobb angles (used to measure the severity of scoliosis) as
evaluation metrics. The results indicate that the model's error was within 1
degree of the actual measurements. This study presents an important method for
constructing digital humans.","Fujiao Ju, Yuxuan Wang, Shuo Wang, Chengyin Wang, Yinbo Chen, Jianfeng Li, Mingjie Dong, Bin Fang, Qianyu Zhuang",2025-02-11 08:21:37.000000,arXiv,http://arxiv.org/abs/2502.07844v1,Other
849,Coarse Set Theory: A Mathematical Foundation for Coarse Ethics,"In ethical decision-making, individuals are often evaluated based on
generalized assessments rather than precise individual performance. This
concept, known as Coarse Ethics (CE), has primarily been discussed in natural
language without a formal mathematical foundation. This paper introduces Coarse
Set Theory (CST) to establish a mathematical framework for CE. We define coarse
sets using totally ordered sets and propose axioms that characterize the
hierarchical relationships between elements and their groupings. Additionally,
we introduce coarse-grained sets, which partition an underlying set into
equivalence classes based on predefined criteria. We extend this framework by
defining coarse mappings, which transform detailed individual data into coarser
representations while maintaining essential structural properties. To measure
the information loss, we employ Kullback-Leibler (KL) divergence, demonstrating
how different coarse partitions affect the preservation of information. We
illustrate how CST can be applied to real-world grading systems through
theoretical formulations and empirical analysis. This study provides a rigorous
foundation for CE, enabling a more systematic exploration of fairness,
interpretability, and decision-making trade-offs.",Takashi Izumo,2025-02-11 08:18:37.000000,arXiv,http://arxiv.org/abs/2502.07347v1,Artificial Intelligence
850,BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models,"Previous multilingual benchmarks focus primarily on simple understanding
tasks, but for large language models(LLMs), we emphasize proficiency in
instruction following, reasoning, long context understanding, code generation,
and so on. However, measuring these advanced capabilities across languages is
underexplored. To address the disparity, we introduce BenchMAX, a multi-way
multilingual evaluation benchmark that allows for fair comparisons of these
important abilities across languages. To maintain high quality, three distinct
native-speaking annotators independently annotate each sample within all tasks
after the data was machine-translated from English into 16 other languages.
Additionally, we present a novel translation challenge stemming from dataset
construction. Extensive experiments on BenchMAX reveal varying effectiveness of
core capabilities across languages, highlighting performance gaps that cannot
be bridged by simply scaling up model size. BenchMAX serves as a comprehensive
multilingual evaluation platform, providing a promising test bed to promote the
development of multilingual language models. The dataset and code are publicly
accessible.","Xu Huang, Wenhao Zhu, Hanxu Hu, Conghui He, Lei Li, Shujian Huang, Fei Yuan",2025-02-11 08:17:19.000000,arXiv,http://arxiv.org/abs/2502.07346v1,Natural Language Processing
851,Integrating Physics and Data-Driven Approaches: An Explainable and Uncertainty-Aware Hybrid Model for Wind Turbine Power Prediction,"The rapid growth of the wind energy sector underscores the urgent need to
optimize turbine operations and ensure effective maintenance through early
fault detection systems. While traditional empirical and physics-based models
offer approximate predictions of power generation based on wind speed, they
often fail to capture the complex, non-linear relationships between other input
variables and the resulting power output. Data-driven machine learning methods
present a promising avenue for improving wind turbine modeling by leveraging
large datasets, enhancing prediction accuracy but often at the cost of
interpretability. In this study, we propose a hybrid semi-parametric model that
combines the strengths of both approaches, applied to a dataset from a wind
farm with four turbines. The model integrates a physics-inspired submodel,
providing a reasonable approximation of power generation, with a non-parametric
submodel that predicts the residuals. This non-parametric submodel is trained
on a broader range of variables to account for phenomena not captured by the
physics-based component. The hybrid model achieves a 37% improvement in
prediction accuracy over the physics-based model. To enhance interpretability,
SHAP values are used to analyze the influence of input features on the residual
submodel's output. Additionally, prediction uncertainties are quantified using
a conformalized quantile regression method. The combination of these
techniques, alongside the physics grounding of the parametric submodel,
provides a flexible, accurate, and reliable framework. Ultimately, this study
opens the door for evaluating the impact of unmodeled variables on wind turbine
power generation, offering a basis for potential optimization.","Alfonso Gijón, Simone Eiraudo, Antonio Manjavacas, Daniele Salvatore Schiera, Miguel Molina-Solana, Juan Gómez-Romero",2025-02-11 08:16:48.000000,arXiv,http://arxiv.org/abs/2502.07344v1,Machine Learning
852,Aligning Large Language Models to Follow Instructions and Hallucinate Less via Effective Data Filtering,"Training LLMs on data that contains unfamiliar knowledge during the
instruction tuning stage can make LLMs overconfident and encourage
hallucinations. To address this challenge, we introduce a novel framework,
NOVA, which identifies high-quality data that aligns well with the LLM's
learned knowledge to reduce hallucinations. NOVA includes Internal Consistency
Probing (ICP) and Semantic Equivalence Identification (SEI) to measure how
familiar the LLM is with instruction data. Specifically, ICP evaluates the
LLM's understanding of the given instruction by calculating the tailored
consistency among multiple self-generated responses. SEI further assesses the
familiarity of the LLM with the target response by comparing it to the
generated responses, using the proposed semantic clustering and well-designed
voting strategy. Finally, we introduce an expert-aligned reward model,
considering characteristics beyond just familiarity to enhance data quality. By
considering data quality and avoiding unfamiliar data, we can utilize the
selected data to effectively align LLMs to follow instructions and hallucinate
less. Extensive experiments and analysis show that NOVA significantly reduces
hallucinations and allows LLMs to maintain a strong ability to follow
instructions.","Shuzheng Si, Haozhe Zhao, Gang Chen, Cheng Gao, Yuzhuo Bai, Zhitong Wang, Kaikai An, Kangyang Luo, Chen Qian, Fanchao Qi, Baobao Chang, Maosong Sun",2025-02-11 08:05:56.000000,arXiv,http://arxiv.org/abs/2502.07340v1,Natural Language Processing
853,Emotional EEG Classification using Upscaled Connectivity Matrices,"In recent studies of emotional EEG classification, connectivity matrices have
been successfully employed as input to convolutional neural networks (CNNs),
which can effectively consider inter-regional interaction patterns in EEG.
However, we find that such an approach has a limitation that important patterns
in connectivity matrices may be lost during the convolutional operations in
CNNs. To resolve this issue, we propose and validate an idea to upscale the
connectivity matrices to strengthen the local patterns. Experimental results
demonstrate that this simple idea can significantly enhance the classification
performance.","Chae-Won Lee, Jong-Seok Lee",2025-02-11 07:56:19.000000,arXiv,http://arxiv.org/abs/2502.07843v1,Machine Learning
854,Neural Flow Samplers with Shortcut Models,"Sampling from unnormalized densities is a fundamental task across various
domains. Flow-based samplers generate samples by learning a velocity field that
satisfies the continuity equation, but this requires estimating the intractable
time derivative of the partition function. While importance sampling provides
an approximation, it suffers from high variance. To mitigate this, we introduce
a velocity-driven Sequential Monte Carlo method combined with control variates
to reduce variance. Additionally, we incorporate a shortcut model to improve
efficiency by minimizing the number of sampling steps. Empirical results on
both synthetic datasets and $n$-body system targets validate the effectiveness
of our approach.","Wuhao Chen, Zijing Ou, Yingzhen Li",2025-02-11 07:55:41.000000,arXiv,http://arxiv.org/abs/2502.07337v1,Machine Learning
855,The Combined Problem of Online Task Assignment and Lifelong Path Finding in Logistics Warehouses: A Case Study,"We study the combined problem of online task assignment and lifelong path
finding, which is crucial for the logistics industries. However, most
literature either (1) focuses on lifelong path finding assuming a given task
assigner, or (2) studies the offline version of this problem where tasks are
known in advance. We argue that, to maximize the system throughput, the online
version that integrates these two components should be tackled directly. To
this end, we introduce a formal framework of the combined problem and its
solution concept. Then, we design a rule-based lifelong planner under a
practical robot model that works well even in environments with severe local
congestion. Upon that, we automate the search for the task assigner with
respect to the underlying path planner. Simulation experiments conducted in
warehouse scenarios at \textit{Meituan}, one of the largest shopping platforms
in China, demonstrate that (a)~\textit{in terms of time efficiency}, our system
requires only 83.77\% of the execution time needed for the currently deployed
system at Meituan, outperforming other SOTA algorithms by 8.09\%;
(b)~\textit{in terms of economic efficiency}, ours can achieve the same
throughput with only 60\% of the agents currently in use.","Fengming Zhu, Fangzhen Lin, Weijia Xu, Yifei Guo",2025-02-11 07:51:20.000000,arXiv,http://arxiv.org/abs/2502.07332v1,Multi-Agent Systems
856,ERANet: Edge Replacement Augmentation for Semi-Supervised Meniscus Segmentation with Prototype Consistency Alignment and Conditional Self-Training,"Manual segmentation is labor-intensive, and automatic segmentation remains
challenging due to the inherent variability in meniscal morphology, partial
volume effects, and low contrast between the meniscus and surrounding tissues.
To address these challenges, we propose ERANet, an innovative semi-supervised
framework for meniscus segmentation that effectively leverages both labeled and
unlabeled images through advanced augmentation and learning strategies. ERANet
integrates three key components: edge replacement augmentation (ERA), prototype
consistency alignment (PCA), and a conditional self-training (CST) strategy
within a mean teacher architecture. ERA introduces anatomically relevant
perturbations by simulating meniscal variations, ensuring that augmentations
align with the structural context. PCA enhances segmentation performance by
aligning intra-class features and promoting compact, discriminative feature
representations, particularly in scenarios with limited labeled data. CST
improves segmentation robustness by iteratively refining pseudo-labels and
mitigating the impact of label noise during training. Together, these
innovations establish ERANet as a robust and scalable solution for meniscus
segmentation, effectively addressing key barriers to practical implementation.
We validated ERANet comprehensively on 3D Double Echo Steady State (DESS) and
3D Fast/Turbo Spin Echo (FSE/TSE) MRI sequences. The results demonstrate the
superior performance of ERANet compared to state-of-the-art methods. The
proposed framework achieves reliable and accurate segmentation of meniscus
structures, even when trained on minimal labeled data. Extensive ablation
studies further highlight the synergistic contributions of ERA, PCA, and CST,
solidifying ERANet as a transformative solution for semi-supervised meniscus
segmentation in medical imaging.","Siyue Li, Yongcheng Yao, Junru Zhong, Shutian Zhao, Yudong Zhang, Shuihua Wang, Jin Hong, Weitian Chen",2025-02-11 07:49:31.000000,arXiv,http://arxiv.org/abs/2502.07331v1,Computer Vision
857,Music for All: Exploring Multicultural Representations in Music Generation Models,"The advent of Music-Language Models has greatly enhanced the automatic music
generation capability of AI systems, but they are also limited in their
coverage of the musical genres and cultures of the world. We present a study of
the datasets and research papers for music generation and quantify the bias and
under-representation of genres. We find that only 5.7% of the total hours of
existing music datasets come from non-Western genres, which naturally leads to
disparate performance of the models across genres. We then investigate the
efficacy of Parameter-Efficient Fine-Tuning (PEFT) techniques in mitigating
this bias. Our experiments with two popular models -- MusicGen and Mustango,
for two underrepresented non-Western music traditions -- Hindustani Classical
and Turkish Makam music, highlight the promises as well as the non-triviality
of cross-genre adaptation of music through small datasets, implying the need
for more equitable baseline music-language models that are designed for
cross-cultural transfer learning.","Atharva Mehta, Shivam Chauhan, Amirbek Djanibekov, Atharva Kulkarni, Gus Xia, Monojit Choudhury",2025-02-11 07:46:29.000000,arXiv,http://arxiv.org/abs/2502.07328v2,Other
858,Generative Ghost: Investigating Ranking Bias Hidden in AI-Generated Videos,"With the rapid development of AI-generated content (AIGC), the creation of
high-quality AI-generated videos has become faster and easier, resulting in the
Internet being flooded with all kinds of video content. However, the impact of
these videos on the content ecosystem remains largely unexplored. Video
information retrieval remains a fundamental approach for accessing video
content. Building on the observation that retrieval models often favor
AI-generated content in ad-hoc and image retrieval tasks, we investigate
whether similar biases emerge in the context of challenging video retrieval,
where temporal and visual factors may further influence model behavior. To
explore this, we first construct a comprehensive benchmark dataset containing
both real and AI-generated videos, along with a set of fair and rigorous
metrics to assess bias. This benchmark consists of 13,000 videos generated by
two state-of-the-art open-source video generation models. We meticulously
design a suite of rigorous metrics to accurately measure this preference,
accounting for potential biases arising from the limited frame rate and
suboptimal quality of AIGC videos. We then applied three off-the-shelf video
retrieval models to perform retrieval tasks on this hybrid dataset. Our
findings reveal a clear preference for AI-generated videos in retrieval.
Further investigation shows that incorporating AI-generated videos into the
training set of retrieval models exacerbates this bias. Unlike the preference
observed in image modalities, we find that video retrieval bias arises from
both unseen visual and temporal information, making the root causes of video
bias a complex interplay of these two factors. To mitigate this bias, we
fine-tune the retrieval models using a contrastive learning approach. The
results of this study highlight the potential implications of AI-generated
videos on retrieval systems.","Haowen Gao, Liang Pang, Shicheng Xu, Leigang Qu, Tat-Seng Chua, Huawei Shen, Xueqi Cheng",2025-02-11 07:43:47.000000,arXiv,http://arxiv.org/abs/2502.07327v1,Information Retrieval
859,PICTS: A Novel Deep Reinforcement Learning Approach for Dynamic P-I Control in Scanning Probe Microscopy,"We have developed a Parallel Integrated Control and Training System,
leveraging the deep reinforcement learning to dynamically adjust the control
strategies in real time for scanning probe microscopy techniques.","Ziwei Wei, Shuming Wei, Qibin Zeng, Wanheng Lu, Huajun Liu, Kaiyang Zeng",2025-02-11 07:43:46.000000,arXiv,http://arxiv.org/abs/2502.07326v1,Other
860,Long-term simulation of physical and mechanical behaviors using curriculum-transfer-learning based physics-informed neural networks,"This paper proposes a Curriculum-Transfer-Learning based physics-informed
neural network (CTL-PINN) for long-term simulation of physical and mechanical
behaviors. The main innovation of CTL-PINN lies in decomposing long-term
problems into a sequence of short-term subproblems. Initially, the standard
PINN is employed to solve the first sub-problem. As the simulation progresses,
subsequent time-domain problems are addressed using a curriculum learning
approach that integrates information from previous steps. Furthermore, transfer
learning techniques are incorporated, allowing the model to effectively utilize
prior training data and solve sequential time domain transfer problems.
CTL-PINN combines the strengths of curriculum learning and transfer learning,
overcoming the limitations of standard PINNs, such as local optimization
issues, and addressing the inaccuracies over extended time domains encountered
in CL-PINN and the low computational efficiency of TL-PINN. The efficacy and
robustness of CTL-PINN are demonstrated through applications to nonlinear wave
propagation, Kirchhoff plate dynamic response, and the hydrodynamic model of
the Three Gorges Reservoir Area, showcasing its superior capability in
addressing long-term computational challenges.","Yuan Guo, Zhuojia Fu, Jian Min, Shiyu Lin, Xiaoting Liu, Youssef F. Rashed, Xiaoying Zhuang",2025-02-11 07:43:03.000000,arXiv,http://arxiv.org/abs/2502.07325v1,Machine Learning
861,Semantic to Structure: Learning Structural Representations for Infringement Detection,"Structural information in images is crucial for aesthetic assessment, and it
is widely recognized in the artistic field that imitating the structure of
other works significantly infringes on creators' rights. The advancement of
diffusion models has led to AI-generated content imitating artists' structural
creations, yet effective detection methods are still lacking. In this paper, we
define this phenomenon as ""structural infringement"" and propose a corresponding
detection method. Additionally, we develop quantitative metrics and create
manually annotated datasets for evaluation: the SIA dataset of synthesized
data, and the SIR dataset of real data. Due to the current lack of datasets for
structural infringement detection, we propose a new data synthesis strategy
based on diffusion models and LLM, successfully training a structural
infringement detection model. Experimental results show that our method can
successfully detect structural infringements and achieve notable improvements
on annotated test sets.","Chuanwei Huang, Zexi Jia, Hongyan Fei, Yeshuang Zhu, Zhiqiang Yuan, Jinchao Zhang, Jie Zhou",2025-02-11 07:42:44.000000,arXiv,http://arxiv.org/abs/2502.07323v1,Computer Vision
862,MEMIT-Merge: Addressing MEMIT's Key-Value Conflicts in Same-Subject Batch Editing for LLMs,"As large language models continue to scale up, knowledge editing techniques
that modify models' internal knowledge without full retraining have gained
significant attention. MEMIT, a prominent batch editing algorithm, stands out
for its capability to perform mass knowledge modifications. However, we uncover
a critical limitation that MEMIT's editing efficacy significantly deteriorates
when processing batches containing multiple edits sharing the same subject. Our
analysis reveals that the root cause lies in MEMIT's key value modeling
framework: When multiple facts with the same subject in a batch are modeled
through MEMIT's key value mechanism, identical keys (derived from the shared
subject) are forced to represent different values (corresponding to different
knowledge), resulting in updates conflicts during editing. Addressing this
issue, we propose MEMIT-Merge, an enhanced approach that merges value
computation processes for facts sharing the same subject, effectively resolving
the performance degradation in same-subject batch editing scenarios.
Experimental results demonstrate that when MEMIT's edit success rate drops to
around 50% at larger batch sizes, MEMIT-Merge maintains a success rate
exceeding 90%, showcasing remarkable robustness to subject entity collisions.","Zilu Dong, Xiangqing Shen, Rui Xia",2025-02-11 07:42:09.000000,arXiv,http://arxiv.org/abs/2502.07322v1,Natural Language Processing
863,Learnable Residual-based Latent Denoising in Semantic Communication,"A latent denoising semantic communication (SemCom) framework is proposed for
robust image transmission over noisy channels. By incorporating a learnable
latent denoiser into the receiver, the received signals are preprocessed to
effectively remove the channel noise and recover the semantic information,
thereby enhancing the quality of the decoded images. Specifically, a latent
denoising mapping is established by an iterative residual learning approach to
improve the denoising efficiency while ensuring stable performance. Moreover,
channel signal-to-noise ratio (SNR) is utilized to estimate and predict the
latent similarity score (SS) for conditional denoising, where the number of
denoising steps is adapted based on the predicted SS sequence, further reducing
the communication latency. Finally, simulations demonstrate that the proposed
framework can effectively and efficiently remove the channel noise at various
levels and reconstruct visual-appealing images.","Mingkai Xu, Yongpeng Wu, Yuxuan Shi, Xiang-Gen Xia, Wenjun Zhang, Ping Zhang",2025-02-11 07:29:32.000000,arXiv,http://arxiv.org/abs/2502.07319v1,Machine Learning
864,CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction,"Reasoning is a fundamental capability of Large Language Models. While prior
research predominantly focuses on enhancing narrow skills like math or code
generation, improving performance on many other reasoning tasks remains
challenging due to sparse and fragmented training data. To address this issue,
we propose CodeI/O, a novel approach that systematically condenses diverse
reasoning patterns inherently embedded in contextually-grounded codes, through
transforming the original code into a code input-output prediction format. By
training models to predict inputs/outputs given code and test cases entirely in
natural language as Chain-of-Thought (CoT) rationales, we expose them to
universal reasoning primitives -- like logic flow planning, state-space
searching, decision tree traversal, and modular decomposition -- while
decoupling structured reasoning from code-specific syntax and preserving
procedural rigor. Experimental results demonstrate CodeI/O leads to consistent
improvements across symbolic, scientific, logic, math & numerical, and
commonsense reasoning tasks. By matching the existing ground-truth outputs or
re-executing the code with predicted inputs, we can verify each prediction and
further enhance the CoTs through multi-turn revision, resulting in CodeI/O++
and achieving higher performance. Our data and models are available at
https://github.com/hkust-nlp/CodeIO.","Junlong Li, Daya Guo, Dejian Yang, Runxin Xu, Yu Wu, Junxian He",2025-02-11 07:26:50.000000,arXiv,http://arxiv.org/abs/2502.07316v2,Natural Language Processing
865,Prompt-Based Document Modifications In Ranking Competitions,"We study prompting-based approaches with Large Language Models (LLMs) for
modifying documents so as to promote their ranking in a competitive search
setting. Our methods are inspired by prior work on leveraging LLMs as rankers.
We evaluate our approach by deploying it as a bot in previous ranking
competitions and in competitions we organized. Our findings demonstrate that
our approach effectively improves document ranking while preserving high levels
of faithfulness to the original content and maintaining overall document
quality.","Niv Bardas, Tommy Mordo, Oren Kurland, Moshe Tennenholtz, Gal Zur",2025-02-11 07:25:57.000000,arXiv,http://arxiv.org/abs/2502.07315v1,Information Retrieval
866,OpenGrok: Enhancing SNS Data Processing with Distilled Knowledge and Mask-like Mechanisms,"This report details Lumen Labs' novel approach to processing Social
Networking Service (SNS) data. We leverage knowledge distillation, specifically
a simple distillation method inspired by DeepSeek-R1's CoT acquisition,
combined with prompt hacking, to extract valuable training data from the Grok
model. This data is then used to fine-tune a Phi-3-mini model, augmented with a
mask-like mechanism specifically designed for handling the nuances of SNS data.
Our method demonstrates state-of-the-art (SOTA) performance on several SNS data
processing tasks, outperforming existing models like Grok, Phi-3, and GPT-4. We
provide a comprehensive analysis of our approach, including mathematical
formulations, engineering details, ablation studies, and comparative
evaluations.","Lumen AI, Zaozhuang No. 28 Middle School, Shihao Ji, Zihui Song, Fucheng Zhong, Jisen Jia, Zhaobo Wu, Zheyi Cao, Tianhao Xu",2025-02-11 07:20:38.000000,arXiv,http://arxiv.org/abs/2502.07312v1,Machine Learning
867,Semi-Supervised Vision-Centric 3D Occupancy World Model for Autonomous Driving,"Understanding world dynamics is crucial for planning in autonomous driving.
Recent methods attempt to achieve this by learning a 3D occupancy world model
that forecasts future surrounding scenes based on current observation. However,
3D occupancy labels are still required to produce promising results.
Considering the high annotation cost for 3D outdoor scenes, we propose a
semi-supervised vision-centric 3D occupancy world model, PreWorld, to leverage
the potential of 2D labels through a novel two-stage training paradigm: the
self-supervised pre-training stage and the fully-supervised fine-tuning stage.
Specifically, during the pre-training stage, we utilize an attribute projection
head to generate different attribute fields of a scene (e.g., RGB, density,
semantic), thus enabling temporal supervision from 2D labels via volume
rendering techniques. Furthermore, we introduce a simple yet effective
state-conditioned forecasting module to recursively forecast future occupancy
and ego trajectory in a direct manner. Extensive experiments on the nuScenes
dataset validate the effectiveness and scalability of our method, and
demonstrate that PreWorld achieves competitive performance across 3D occupancy
prediction, 4D occupancy forecasting and motion planning tasks.","Xiang Li, Pengfei Li, Yupeng Zheng, Wei Sun, Yan Wang, Yilun Chen",2025-02-11 07:12:26.000000,arXiv,http://arxiv.org/abs/2502.07309v1,Computer Vision
868,CreAgent: Towards Long-Term Evaluation of Recommender System under Platform-Creator Information Asymmetry,"Ensuring the long-term sustainability of recommender systems (RS) emerges as
a crucial issue. Traditional offline evaluation methods for RS typically focus
on immediate user feedback, such as clicks, but they often neglect the
long-term impact of content creators. On real-world content platforms, creators
can strategically produce and upload new items based on user feedback and
preference trends. While previous studies have attempted to model creator
behavior, they often overlook the role of information asymmetry. This asymmetry
arises because creators primarily have access to feedback on the items they
produce, while platforms possess data on the entire spectrum of user feedback.
Current RS simulators, however, fail to account for this asymmetry, leading to
inaccurate long-term evaluations. To address this gap, we propose CreAgent, a
Large Language Model (LLM)-empowered creator simulation agent. By incorporating
game theory's belief mechanism and the fast-and-slow thinking framework,
CreAgent effectively simulates creator behavior under conditions of information
asymmetry. Additionally, we enhance CreAgent's simulation ability by
fine-tuning it using Proximal Policy Optimization (PPO). Our credibility
validation experiments show that CreAgent aligns well with the behaviors
between real-world platform and creator, thus improving the reliability of
long-term RS evaluations. Moreover, through the simulation of RS involving
CreAgents, we can explore how fairness- and diversity-aware RS algorithms
contribute to better long-term performance for various stakeholders. CreAgent
and the simulation platform are publicly available at
https://github.com/shawnye2000/CreAgent.","Xiaopeng Ye, Chen Xu, Zhongxiang Sun, Jun Xu, Gang Wang, Zhenhua Dong, Ji-Rong Wen",2025-02-11 07:09:49.000000,arXiv,http://arxiv.org/abs/2502.07307v1,Information Retrieval
869,TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation,"In this work, we propose a modular approach for the Vision-Language
Navigation (VLN) task by decomposing the problem into four sub-modules that use
state-of-the-art Large Language Models (LLMs) and Vision-Language Models (VLMs)
in a zero-shot setting. Given navigation instruction in natural language, we
first prompt LLM to extract the landmarks and the order in which they are
visited. Assuming the known model of the environment, we retrieve the top-k
locations of the last landmark and generate $k$ path hypotheses from the
starting location to the last landmark using the shortest path algorithm on the
topological map of the environment. Each path hypothesis is represented by a
sequence of panoramas. We then use dynamic programming to compute the alignment
score between the sequence of panoramas and the sequence of landmark names,
which match scores obtained from VLM. Finally, we compute the nDTW metric
between the hypothesis that yields the highest alignment score to evaluate the
path fidelity. We demonstrate superior performance compared to other approaches
that use joint semantic maps like VLMaps \cite{vlmaps} on the complex
R2R-Habitat \cite{r2r} instruction dataset and quantify in detail the effect of
visual grounding on navigation performance.","Navid Rajabi, Jana Kosecka",2025-02-11 07:09:37.000000,arXiv,http://arxiv.org/abs/2502.07306v1,Computer Vision
870,Flow Matching for Collaborative Filtering,"Generative models have shown great promise in collaborative filtering by
capturing the underlying distribution of user interests and preferences.
However, existing approaches struggle with inaccurate posterior approximations
and misalignment with the discrete nature of recommendation data, limiting
their expressiveness and real-world performance. To address these limitations,
we propose FlowCF, a novel flow-based recommendation system leveraging flow
matching for collaborative filtering. We tailor flow matching to the unique
challenges in recommendation through two key innovations: (1) a behavior-guided
prior that aligns with user behavior patterns to handle the sparse and
heterogeneous user-item interactions, and (2) a discrete flow framework to
preserve the binary nature of implicit feedback while maintaining the benefits
of flow matching, such as stable training and efficient inference. Extensive
experiments demonstrate that FlowCF achieves state-of-the-art recommendation
accuracy across various datasets with the fastest inference speed, making it a
compelling approach for real-world recommender systems.","Chengkai Liu, Yangtian Zhang, Jianling Wang, Rex Ying, James Caverlee",2025-02-11 07:01:19.000000,arXiv,http://arxiv.org/abs/2502.07303v1,Information Retrieval
871,CASC-AI: Consensus-aware Self-corrective AI Agents for Noise Cell Segmentation,"Multi-class cell segmentation in high-resolution gigapixel whole slide images
(WSI) is crucial for various clinical applications. However, training such
models typically requires labor-intensive, pixel-wise annotations by domain
experts. Recent efforts have democratized this process by involving lay
annotators without medical expertise. However, conventional non-agent-based
approaches struggle to handle annotation noise adaptively, as they lack
mechanisms to mitigate false positives (FP) and false negatives (FN) at both
the image-feature and pixel levels. In this paper, we propose a consensus-aware
self-corrective AI agent that leverages the Consensus Matrix to guide its
learning process. The Consensus Matrix defines regions where both the AI and
annotators agree on cell and non-cell annotations, which are prioritized with
stronger supervision. Conversely, areas of disagreement are adaptively weighted
based on their feature similarity to high-confidence agreement regions, with
more similar regions receiving greater attention. Additionally, contrastive
learning is employed to separate features of noisy regions from those of
reliable agreement regions by maximizing their dissimilarity. This paradigm
enables the AI to iteratively refine noisy labels, enhancing its robustness.
Validated on one real-world lay-annotated cell dataset and two simulated noisy
datasets, our method demonstrates improved segmentation performance,
effectively correcting FP and FN errors and showcasing its potential for
training robust models on noisy datasets. The official implementation and cell
annotations are publicly available at https://github.com/ddrrnn123/CASC-AI.","Ruining Deng, Yihe Yang, David J. Pisapia, Benjamin Liechty, Junchao Zhu, Juming Xiong, Junlin Guo, Zhengyi Lu, Jiacheng Wang, Xing Yao, Runxuan Yu, Rendong Zhang, Gaurav Rudravaram, Mengmeng Yin, Pinaki Sarder, Haichun Yang, Yuankai Huo, Mert R. Sabuncu",2025-02-11 06:58:50.000000,arXiv,http://arxiv.org/abs/2502.07302v1,Computer Vision
872,Life-Code: Central Dogma Modeling with Multi-Omics Sequence Unification,"The interactions between DNA, RNA, and proteins are fundamental to biological
processes, as illustrated by the central dogma of molecular biology. While
modern biological pre-trained models have achieved great success in analyzing
these macromolecules individually, their interconnected nature remains
under-explored. In this paper, we follow the guidance of the central dogma to
redesign both the data and model pipeline and offer a comprehensive framework,
Life-Code, that spans different biological functions. As for data flow, we
propose a unified pipeline to integrate multi-omics data by
reverse-transcribing RNA and reverse-translating amino acids into
nucleotide-based sequences. As for the model, we design a codon tokenizer and a
hybrid long-sequence architecture to encode the interactions of both coding and
non-coding regions with masked modeling pre-training. To model the translation
and folding process with coding sequences, Life-Code learns protein structures
of the corresponding amino acids by knowledge distillation from off-the-shelf
protein language models. Such designs enable Life-Code to capture complex
interactions within genetic sequences, providing a more comprehensive
understanding of multi-omics with the central dogma. Extensive Experiments show
that Life-Code achieves state-of-the-art performance on various tasks across
three omics, highlighting its potential for advancing multi-omics analysis and
interpretation.","Zicheng Liu, Siyuan Li, Zhiyuan Chen, Lei Xin, Fang Wu, Chang Yu, Qirong Yang, Yucheng Guo, Yujie Yang, Stan Z. Li",2025-02-11 06:53:59.000000,arXiv,http://arxiv.org/abs/2502.07299v1,Machine Learning
873,Generation of Drug-Induced Cardiac Reactions towards Virtual Clinical Trials,"Clinical trials are pivotal in cardiac drug development, yet they often fail
due to inadequate efficacy and unexpected safety issues, leading to significant
financial losses. Using in-silico trials to replace a part of physical clinical
trials, e.g., leveraging advanced generative models to generate drug-influenced
electrocardiograms (ECGs), seems an effective method to reduce financial risk
and potential harm to trial participants. While existing generative models have
demonstrated progress in ECG generation, they fall short in modeling drug
reactions due to limited fidelity and inability to capture individualized drug
response patterns. In this paper, we propose a Drug-Aware Diffusion Model
(DADM), which could simulate individualized drug reactions while ensuring
fidelity. To ensure fidelity, we construct a set of ordinary differential
equations to provide external physical knowledge (EPK) of the realistic ECG
morphology. The EPK is used to adaptively constrain the morphology of the
generated ECGs through a dynamic cross-attention (DCA) mechanism. Furthermore,
we propose an extension of ControlNet to incorporate demographic and drug data,
simulating individual drug reactions. We compare DADM with the other eight
state-of-the-art ECG generative models on two real-world databases covering 8
types of drug regimens. The results demonstrate that DADM can more accurately
simulate drug-induced changes in ECGs, improving the accuracy by at least 5.79%
and recall by 8%.","Qian Shao, Bang Du, Zepeng Li, Qiyuan Chen, Hongxia Xu, Jimeng Sun, Jian Wu, Jintai Chen",2025-02-11 06:50:33.000000,arXiv,http://arxiv.org/abs/2502.07297v1,Machine Learning
874,Treatment Effect Estimation for Exponential Family Outcomes using Neural Networks with Targeted Regularization,"Neural Networks (NNs) have became a natural choice for treatment effect
estimation due to their strong approximation capabilities. Nevertheless, how to
design NN-based estimators with desirable properties, such as low bias and
doubly robustness, still remains a significant challenge. A common approach to
address this is targeted regularization, which modifies the objective function
of NNs. However, existing works on targeted regularization are limited to
Gaussian-distributed outcomes, significantly restricting their applicability in
real-world scenarios. In this work, we aim to bridge this blank by extending
this framework to the boarder exponential family outcomes. Specifically, we
first derive the von-Mises expansion of the Average Dose function of Canonical
Functions (ADCF), which inspires us how to construct a doubly robust estimator
with good properties. Based on this, we develop a NN-based estimator for ADCF
by generalizing functional targeted regularization to exponential families, and
provide the corresponding theoretical convergence rate. Extensive experimental
results demonstrate the effectiveness of our proposed model.","Jiahong Li, Zeqin Yang, Jiayi Dan, Jixing Xu, Zhichao Zou, Peng Zhen, Jiecheng Guo",2025-02-11 06:36:20.000000,arXiv,http://arxiv.org/abs/2502.07295v1,Machine Learning
875,Global Universal Scaling and Ultra-Small Parameterization in Machine Learning Interatomic Potentials with Super-Linearity,"Using machine learning (ML) to construct interatomic interactions and thus
potential energy surface (PES) has become a common strategy for materials
design and simulations. However, those current models of machine learning
interatomic potential (MLIP) provide no relevant physical constrains, and thus
may owe intrinsic out-of-domain difficulty which underlies the challenges of
model generalizability and physical scalability. Here, by incorporating
physics-informed Universal-Scaling law and nonlinearity-embedded interaction
function, we develop a Super-linear MLIP with both Ultra-Small parameterization
and greatly expanded expressive capability, named SUS2-MLIP. Due to the global
scaling rooting in universal equation of state (UEOS), SUS2-MLIP not only has
significantly-reduced parameters by decoupling the element space from
coordinate space, but also naturally outcomes the out-of-domain difficulty and
endows the potentials with inherent generalizability and scalability even with
relatively small training dataset. The nonlinearity-enbeding transformation for
interaction function expands the expressive capability and make the potentials
super-linear. The SUS2-MLIP outperforms the state-of-the-art MLIP models with
its exceptional computational efficiency especially for multiple-element
materials and physical scalability in property prediction. This work not only
presents a highly-efficient universal MLIP model but also sheds light on
incorporating physical constraints into artificial-intelligence-aided materials
simulation.","Yanxiao Hu, Ye Sheng, Jing Huang, Xiaoxin Xu, Yuyan Yang, Mingqiang Zhang, Yabei Wu, Caichao Ye, Jiong Yang, Wenqing Zhang",2025-02-11 06:34:31.000000,arXiv,http://arxiv.org/abs/2502.07293v1,Other
876,Learning Inverse Laplacian Pyramid for Progressive Depth Completion,"Depth completion endeavors to reconstruct a dense depth map from sparse depth
measurements, leveraging the information provided by a corresponding color
image. Existing approaches mostly hinge on single-scale propagation strategies
that iteratively ameliorate initial coarse depth estimates through pixel-level
message passing. Despite their commendable outcomes, these techniques are
frequently hampered by computational inefficiencies and a limited grasp of
scene context. To circumvent these challenges, we introduce LP-Net, an
innovative framework that implements a multi-scale, progressive prediction
paradigm based on Laplacian Pyramid decomposition. Diverging from
propagation-based approaches, LP-Net initiates with a rudimentary,
low-resolution depth prediction to encapsulate the global scene context,
subsequently refining this through successive upsampling and the reinstatement
of high-frequency details at incremental scales. We have developed two novel
modules to bolster this strategy: 1) the Multi-path Feature Pyramid module,
which segregates feature maps into discrete pathways, employing multi-scale
transformations to amalgamate comprehensive spatial information, and 2) the
Selective Depth Filtering module, which dynamically learns to apply both
smoothness and sharpness filters to judiciously mitigate noise while
accentuating intricate details. By integrating these advancements, LP-Net not
only secures state-of-the-art (SOTA) performance across both outdoor and indoor
benchmarks such as KITTI, NYUv2, and TOFDC, but also demonstrates superior
computational efficiency. At the time of submission, LP-Net ranks 1st among all
peer-reviewed methods on the official KITTI leaderboard.","Kun Wang, Zhiqiang Yan, Junkai Fan, Jun Li, Jian Yang",2025-02-11 06:21:42.000000,arXiv,http://arxiv.org/abs/2502.07289v1,Computer Vision
877,KPIs 2024 Challenge: Advancing Glomerular Segmentation from Patch- to Slide-Level,"Chronic kidney disease (CKD) is a major global health issue, affecting over
10% of the population and causing significant mortality. While kidney biopsy
remains the gold standard for CKD diagnosis and treatment, the lack of
comprehensive benchmarks for kidney pathology segmentation hinders progress in
the field. To address this, we organized the Kidney Pathology Image
Segmentation (KPIs) Challenge, introducing a dataset that incorporates
preclinical rodent models of CKD with over 10,000 annotated glomeruli from 60+
Periodic Acid Schiff (PAS)-stained whole slide images. The challenge includes
two tasks, patch-level segmentation and whole slide image segmentation and
detection, evaluated using the Dice Similarity Coefficient (DSC) and F1-score.
By encouraging innovative segmentation methods that adapt to diverse CKD models
and tissue conditions, the KPIs Challenge aims to advance kidney pathology
analysis, establish new benchmarks, and enable precise, large-scale
quantification for disease research and diagnosis.","Ruining Deng, Tianyuan Yao, Yucheng Tang, Junlin Guo, Siqi Lu, Juming Xiong, Lining Yu, Quan Huu Cap, Pengzhou Cai, Libin Lan, Ze Zhao, Adrian Galdran, Amit Kumar, Gunjan Deotale, Dev Kumar Das, Inyoung Paik, Joonho Lee, Geongyu Lee, Yujia Chen, Wangkai Li, Zhaoyang Li, Xuege Hou, Zeyuan Wu, Shengjin Wang, Maximilian Fischer, Lars Kramer, Anghong Du, Le Zhang, Maria Sanchez Sanchez, Helena Sanchez Ulloa, David Ribalta Heredia, Carlos Perez de Arenaza Garcia, Shuoyu Xu, Bingdou He, Xinping Cheng, Tao Wang, Noemie Moreau, Katarzyna Bozek, Shubham Innani, Ujjwal Baid, Kaura Solomon Kefas, Bennett A. Landman, Yu Wang, Shilin Zhao, Mengmeng Yin, Haichun Yang, Yuankai Huo",2025-02-11 06:20:28.000000,arXiv,http://arxiv.org/abs/2502.07288v1,Computer Vision
878,Small Language Model Makes an Effective Long Text Extractor,"Named Entity Recognition (NER) is a fundamental problem in natural language
processing (NLP). However, the task of extracting longer entity spans (e.g.,
awards) from extended texts (e.g., homepages) is barely explored. Current NER
methods predominantly fall into two categories: span-based methods and
generation-based methods. Span-based methods require the enumeration of all
possible token-pair spans, followed by classification on each span, resulting
in substantial redundant computations and excessive GPU memory usage. In
contrast, generation-based methods involve prompting or fine-tuning large
language models (LLMs) to adapt to downstream NER tasks. However, these methods
struggle with the accurate generation of longer spans and often incur
significant time costs for effective fine-tuning. To address these challenges,
this paper introduces a lightweight span-based NER method called SeNER, which
incorporates a bidirectional arrow attention mechanism coupled with
LogN-Scaling on the [CLS] token to embed long texts effectively, and comprises
a novel bidirectional sliding-window plus-shaped attention (BiSPA) mechanism to
reduce redundant candidate token-pair spans significantly and model
interactions between token-pair spans simultaneously. Extensive experiments
demonstrate that our method achieves state-of-the-art extraction accuracy on
three long NER datasets and is capable of extracting entities from long texts
in a GPU-memory-friendly manner. Code:
https://github.com/THUDM/scholar-profiling/tree/main/sener","Yelin Chen, Fanjin Zhang, Jie Tang",2025-02-11 06:06:25.000000,arXiv,http://arxiv.org/abs/2502.07286v1,Natural Language Processing
879,Negative Dependence as a toolbox for machine learning : review and new developments,"Negative dependence is becoming a key driver in advancing learning
capabilities beyond the limits of traditional independence. Recent developments
have evidenced support towards negatively dependent systems as a learning
paradigm in a broad range of fundamental machine learning challenges including
optimization, sampling, dimensionality reduction and sparse signal recovery,
often surpassing the performance of current methods based on statistical
independence. The most popular negatively dependent model has been that of
determinantal point processes (DPPs), which have their origins in quantum
theory. However, other models, such as perturbed lattice models, strongly
Rayleigh measures, zeros of random functions have gained salience in various
learning applications. In this article, we review this burgeoning field of
research, as it has developed over the past two decades or so. We also present
new results on applications of DPPs to the parsimonious representation of
neural networks. In the limited scope of the article, we mostly focus on
aspects of this area to which the authors contributed over the recent years,
including applications to Monte Carlo methods, coresets and stochastic gradient
descent, stochastic networks, signal processing and connections to quantum
computation. However, starting from basics of negative dependence for the
uninitiated reader, extensive references are provided to a broad swath of
related developments which could not be covered within our limited scope. While
existing works and reviews generally focus on specific negatively dependent
models (e.g. DPPs), a notable feature of this article is that it addresses
negative dependence as a machine learning methodology as a whole. In this vein,
it covers within its span an array of negatively dependent models and their
applications well beyond DPPs, thereby putting forward a very general and
rather unique perspective.","Hoang-Son Tran, Vladimir Petrovic, Remi Bardenet, Subhroshekhar Ghosh",2025-02-11 06:04:49.000000,arXiv,http://arxiv.org/abs/2502.07285v1,Statistical Machine Learning
880,Leader-follower formation enabled by pressure sensing in free-swimming undulatory robotic fish,"Fish use their lateral lines to sense flows and pressure gradients, enabling
them to detect nearby objects and organisms. Towards replicating this
capability, we demonstrated successful leader-follower formation swimming using
flow pressure sensing in our undulatory robotic fish ($\mu$Bot/MUBot). The
follower $\mu$Bot is equipped at its head with bilateral pressure sensors to
detect signals excited by both its own and the leader's movements. First, using
experiments with static formations between an undulating leader and a
stationary follower, we determined the formation that resulted in strong
pressure variations measured by the follower. This formation was then selected
as the desired formation in free swimming for obtaining an expert policy. Next,
a long short-term memory neural network was used as the control policy that
maps the pressure signals along with the robot motor commands and the Euler
angles (measured by the onboard IMU) to the steering command. The policy was
trained to imitate the expert policy using behavior cloning and Dataset
Aggregation (DAgger). The results show that with merely two bilateral pressure
sensors and less than one hour of training data, the follower effectively
tracked the leader within distances of up to 200 mm (= 1 body length) while
swimming at speeds of 155 mm/s (= 0.8 body lengths/s). This work highlights the
potential of fish-inspired robots to effectively navigate fluid environments
and achieve formation swimming through the use of flow pressure feedback.","Kundan Panta, Hankun Deng, Micah DeLattre, Bo Cheng",2025-02-11 05:56:29.000000,arXiv,http://arxiv.org/abs/2502.07282v1,Robotics
881,Supervised Contrastive Block Disentanglement,"Real-world datasets often combine data collected under different experimental
conditions. This yields larger datasets, but also introduces spurious
correlations that make it difficult to model the phenomena of interest. We
address this by learning two embeddings to independently represent the
phenomena of interest and the spurious correlations. The embedding representing
the phenomena of interest is correlated with the target variable $y$, and is
invariant to the environment variable $e$. In contrast, the embedding
representing the spurious correlations is correlated with $e$. The invariance
to $e$ is difficult to achieve on real-world datasets. Our primary contribution
is an algorithm called Supervised Contrastive Block Disentanglement (SCBD) that
effectively enforces this invariance. It is based purely on Supervised
Contrastive Learning, and applies to real-world data better than existing
approaches. We empirically validate SCBD on two challenging problems. The first
problem is domain generalization, where we achieve strong performance on a
synthetic dataset, as well as on Camelyon17-WILDS. We introduce a single
hyperparameter $\alpha$ to control the degree of invariance to $e$. When we
increase $\alpha$ to strengthen the degree of invariance, out-of-distribution
performance improves at the expense of in-distribution performance. The second
problem is batch correction, in which we apply SCBD to preserve biological
signal and remove inter-well batch effects when modeling single-cell
perturbations from 26 million Optical Pooled Screening images.","Taro Makino, Ji Won Park, Natasa Tagasovska, Takamasa Kudo, Paula Coelho, Jan-Christian Huetter, Heming Yao, Burkhard Hoeckendorf, Ana Carolina Leote, Stephen Ra, David Richmond, Kyunghyun Cho, Aviv Regev, Romain Lopez",2025-02-11 05:55:27.000000,arXiv,http://arxiv.org/abs/2502.07281v1,Machine Learning
882,MIGT: Memory Instance Gated Transformer Framework for Financial Portfolio Management,"Deep reinforcement learning (DRL) has been applied in financial portfolio
management to improve returns in changing market conditions. However, unlike
most fields where DRL is widely used, the stock market is more volatile and
dynamic as it is affected by several factors such as global events and investor
sentiment. Therefore, it remains a challenge to construct a DRL-based portfolio
management framework with strong return capability, stable training, and
generalization ability. This study introduces a new framework utilizing the
Memory Instance Gated Transformer (MIGT) for effective portfolio management. By
incorporating a novel Gated Instance Attention module, which combines a
transformer variant, instance normalization, and a Lite Gate Unit, our approach
aims to maximize investment returns while ensuring the learning process's
stability and reducing outlier impacts. Tested on the Dow Jones Industrial
Average 30, our framework's performance is evaluated against fifteen other
strategies using key financial metrics like the cumulative return and
risk-return ratios (Sharpe, Sortino, and Omega ratios). The results highlight
MIGT's advantage, showcasing at least a 9.75% improvement in cumulative returns
and a minimum 2.36% increase in risk-return ratios over competing strategies,
marking a significant advancement in DRL for portfolio management.","Fengchen Gu, Angelos Stefanidis, Ángel García-Fernández, Jionglong Su, Huakang Li",2025-02-11 05:54:42.000000,arXiv,http://arxiv.org/abs/2502.07280v1,Machine Learning
883,Exploratory Diffusion Policy for Unsupervised Reinforcement Learning,"Unsupervised reinforcement learning (RL) aims to pre-train agents by
exploring states or skills in reward-free environments, facilitating the
adaptation to downstream tasks. However, existing methods often overlook the
fitting ability of pre-trained policies and struggle to handle the
heterogeneous pre-training data, which are crucial for achieving efficient
exploration and fast fine-tuning. To address this gap, we propose Exploratory
Diffusion Policy (EDP), which leverages the strong expressive ability of
diffusion models to fit the explored data, both boosting exploration and
obtaining an efficient initialization for downstream tasks. Specifically, we
estimate the distribution of collected data in the replay buffer with the
diffusion policy and propose a score intrinsic reward, encouraging the agent to
explore unseen states. For fine-tuning the pre-trained diffusion policy on
downstream tasks, we provide both theoretical analyses and practical
algorithms, including an alternating method of Q function optimization and
diffusion policy distillation. Extensive experiments demonstrate the
effectiveness of EDP in efficient exploration during pre-training and fast
adaptation during fine-tuning.","Chengyang Ying, Huayu Chen, Xinning Zhou, Zhongkai Hao, Hang Su, Jun Zhu",2025-02-11 05:48:51.000000,arXiv,http://arxiv.org/abs/2502.07279v1,Machine Learning
884,Articulate That Object Part (ATOP): 3D Part Articulation from Text and Motion Personalization,"We present ATOP (Articulate That Object Part), a novel method based on motion
personalization to articulate a 3D object with respect to a part and its motion
as prescribed in a text prompt. Specifically, the text input allows us to tap
into the power of modern-day video diffusion to generate plausible motion
samples for the right object category and part. In turn, the input 3D object
provides image prompting to personalize the generated video to that very object
we wish to articulate. Our method starts with a few-shot finetuning for
category-specific motion generation, a key first step to compensate for the
lack of articulation awareness by current video diffusion models. For this, we
finetune a pre-trained multi-view image generation model for controllable
multi-view video generation, using a small collection of video samples obtained
for the target object category. This is followed by motion video
personalization that is realized by multi-view rendered images of the target 3D
object. At last, we transfer the personalized video motion to the target 3D
object via differentiable rendering to optimize part motion parameters by a
score distillation sampling loss. We show that our method is capable of
generating realistic motion videos and predict 3D motion parameters in a more
accurate and generalizable way, compared to prior works.","Aditya Vora, Sauradip Nag, Hao Zhang",2025-02-11 05:47:16.000000,arXiv,http://arxiv.org/abs/2502.07278v1,Computer Vision
885,Enhancing Video Understanding: Deep Neural Networks for Spatiotemporal Analysis,"It's no secret that video has become the primary way we share information
online. That's why there's been a surge in demand for algorithms that can
analyze and understand video content. It's a trend going to continue as video
continues to dominate the digital landscape. These algorithms will extract and
classify related features from the video and will use them to describe the
events and objects in the video. Deep neural networks have displayed
encouraging outcomes in the realm of feature extraction and video description.
This paper will explore the spatiotemporal features found in videos and recent
advancements in deep neural networks in video understanding. We will review
some of the main trends in video understanding models and their structural
design, the main problems, and some offered solutions in this topic. We will
also review and compare significant video understanding and action recognition
datasets.","Amir Hosein Fadaei, Mohammad-Reza A. Dehaqani",2025-02-11 05:44:50.000000,arXiv,http://arxiv.org/abs/2502.07277v1,Computer Vision
886,Dataset Ownership Verification in Contrastive Pre-trained Models,"High-quality open-source datasets, which necessitate substantial efforts for
curation, has become the primary catalyst for the swift progress of deep
learning. Concurrently, protecting these datasets is paramount for the
well-being of the data owner. Dataset ownership verification emerges as a
crucial method in this domain, but existing approaches are often limited to
supervised models and cannot be directly extended to increasingly popular
unsupervised pre-trained models. In this work, we propose the first dataset
ownership verification method tailored specifically for self-supervised
pre-trained models by contrastive learning. Its primary objective is to
ascertain whether a suspicious black-box backbone has been pre-trained on a
specific unlabeled dataset, aiding dataset owners in upholding their rights.
The proposed approach is motivated by our empirical insights that when models
are trained with the target dataset, the unary and binary instance
relationships within the embedding space exhibit significant variations
compared to models trained without the target dataset. We validate the efficacy
of this approach across multiple contrastive pre-trained models including
SimCLR, BYOL, SimSiam, MOCO v3, and DINO. The results demonstrate that our
method rejects the null hypothesis with a $p$-value markedly below $0.05$,
surpassing all previous methodologies. Our code is available at
https://github.com/xieyc99/DOV4CL.","Yuechen Xie, Jie Song, Mengqi Xue, Haofei Zhang, Xingen Wang, Bingde Hu, Genlang Chen, Mingli Song",2025-02-11 05:42:21.000000,arXiv,http://arxiv.org/abs/2502.07276v1,Machine Learning
887,Cost-Efficient Continual Learning with Sufficient Exemplar Memory,"Continual learning (CL) research typically assumes highly constrained
exemplar memory resources. However, in many real-world scenarios-especially in
the era of large foundation models-memory is abundant, while GPU computational
costs are the primary bottleneck. In this work, we investigate CL in a novel
setting where exemplar memory is ample (i.e., sufficient exemplar memory).
Unlike prior methods designed for strict exemplar memory constraints, we
propose a simple yet effective approach that directly operates in the model's
weight space through a combination of weight resetting and averaging
techniques. Our method achieves state-of-the-art performance while reducing the
computational cost to a quarter or third of existing methods. These findings
challenge conventional CL assumptions and provide a practical baseline for
computationally efficient CL applications.","Dongkyu Cho, Taesup Moon, Rumi Chunara, Kyunghyun Cho, Sungmin Cha",2025-02-11 05:40:52.000000,arXiv,http://arxiv.org/abs/2502.07274v1,Machine Learning
888,Variational Learning Induces Adaptive Label Smoothing,"We show that variational learning naturally induces an adaptive label
smoothing where label noise is specialized for each example. Such
label-smoothing is useful to handle examples with labeling errors and
distribution shifts, but designing a good adaptivity strategy is not always
easy. We propose to skip this step and simply use the natural adaptivity
induced during the optimization of a variational objective. We show empirical
results where a variational algorithm called IVON outperforms traditional label
smoothing and yields adaptivity strategies similar to those of an existing
approach. By connecting Bayesian methods to label smoothing, our work provides
a new way to handle overconfident predictions.","Sin-Han Yang, Zhedong Liu, Gian Maria Marconi, Mohammad Emtiyaz Khan",2025-02-11 05:40:42.000000,arXiv,http://arxiv.org/abs/2502.07273v1,Machine Learning
889,GENERator: A Long-Context Generative Genomic Foundation Model,"Advancements in DNA sequencing technologies have significantly improved our
ability to decode genomic sequences. However, the prediction and interpretation
of these sequences remain challenging due to the intricate nature of genetic
material. Large language models (LLMs) have introduced new opportunities for
biological sequence analysis. Recent developments in genomic language models
have underscored the potential of LLMs in deciphering DNA sequences.
Nonetheless, existing models often face limitations in robustness and
application scope, primarily due to constraints in model structure and training
data scale. To address these limitations, we present GENERator, a generative
genomic foundation model featuring a context length of 98k base pairs (bp) and
1.2B parameters. Trained on an expansive dataset comprising 386B bp of
eukaryotic DNA, the GENERator demonstrates state-of-the-art performance across
both established and newly proposed benchmarks. The model adheres to the
central dogma of molecular biology, accurately generating protein-coding
sequences that translate into proteins structurally analogous to known
families. It also shows significant promise in sequence optimization,
particularly through the prompt-responsive generation of promoter sequences
with specific activity profiles. These capabilities position the GENERator as a
pivotal tool for genomic research and biotechnological advancement, enhancing
our ability to interpret and predict complex biological systems and enabling
precise genomic interventions.","Wei Wu, Qiuyi Li, Mingyang Li, Kun Fu, Fuli Feng, Jieping Ye, Hui Xiong, Zheng Wang",2025-02-11 05:39:49.000000,arXiv,http://arxiv.org/abs/2502.07272v1,Natural Language Processing
890,Exploring Active Data Selection Strategies for Continuous Training in Deepfake Detection,"In deepfake detection, it is essential to maintain high performance by
adjusting the parameters of the detector as new deepfake methods emerge. In
this paper, we propose a method to automatically and actively select the small
amount of additional data required for the continuous training of deepfake
detection models in situations where deepfake detection models are regularly
updated. The proposed method automatically selects new training data from a
\textit{redundant} pool set containing a large number of images generated by
new deepfake methods and real images, using the confidence score of the
deepfake detection model as a metric. Experimental results show that the
deepfake detection model, continuously trained with a small amount of
additional data automatically selected and added to the original training set,
significantly and efficiently improved the detection performance, achieving an
EER of 2.5% with only 15% of the amount of data in the pool set.","Yoshihiko Furuhashi, Junichi Yamagishi, Xin Wang, Huy H. Nguyen, Isao Echizen",2025-02-11 05:35:36.000000,arXiv,http://arxiv.org/abs/2502.07269v1,Computer Vision
891,Column-wise Quantization of Weights and Partial Sums for Accurate and Efficient Compute-In-Memory Accelerators,"Compute-in-memory (CIM) is an efficient method for implementing deep neural
networks (DNNs) but suffers from substantial overhead from analog-to-digital
converters (ADCs), especially as ADC precision increases. Low-precision ADCs
can re- duce this overhead but introduce partial-sum quantization errors
degrading accuracy. Additionally, low-bit weight constraints, im- posed by cell
limitations and the need for multiple cells for higher- bit weights, present
further challenges. While fine-grained partial- sum quantization has been
studied to lower ADC resolution effectively, weight granularity, which limits
overall partial-sum quantized accuracy, remains underexplored. This work
addresses these challenges by aligning weight and partial-sum quantization
granularities at the column-wise level. Our method improves accuracy while
maintaining dequantization overhead, simplifies training by removing two-stage
processes, and ensures robustness to memory cell variations via independent
column-wise scale factors. We also propose an open-source CIM-oriented
convolution framework to handle fine-grained weights and partial-sums effi-
ciently, incorporating a novel tiling method and group convolution.
Experimental results on ResNet-20 (CIFAR-10, CIFAR-100) and ResNet-18
(ImageNet) show accuracy improvements of 0.99%, 2.69%, and 1.01%, respectively,
compared to the best-performing related works. Additionally, variation analysis
reveals the robust- ness of our method against memory cell variations. These
findings highlight the effectiveness of our quantization scheme in enhancing
accuracy and robustness while maintaining hardware efficiency in CIM-based DNN
implementations. Our code is available at
https://github.com/jiyoonkm/ColumnQuant.","Jiyoon Kim, Kang Eun Jeon, Yulhwa Kim, Jong Hwan Ko",2025-02-11 05:32:14.000000,arXiv,http://arxiv.org/abs/2502.07842v1,Other
892,When More is Less: Understanding Chain-of-Thought Length in LLMs,"Chain-of-thought (CoT) reasoning enhances the multi-step reasoning
capabilities of large language models (LLMs) by breaking complex tasks into
smaller, manageable sub-tasks. Researchers have been exploring ways to guide
models to generate more complex CoT processes to improve the reasoning ability
of LLMs, such as long CoT and the test-time scaling law. However, for most
models and tasks, does an increase in CoT length consistently lead to improved
reasoning accuracy? In this paper, we observe a nuanced relationship: as the
number of reasoning steps increases, performance initially improves but
eventually decreases. To understand this phenomenon, we provide a piece of
evidence that longer reasoning processes are increasingly susceptible to noise.
We theoretically prove the existence of an optimal CoT length and derive a
scaling law for this optimal length based on model capability and task
difficulty. Inspired by our theory, we conduct experiments on both synthetic
and real world datasets and propose Length-filtered Vote to alleviate the
effects of excessively long or short CoTs. Our findings highlight the critical
need to calibrate CoT length to align with model capabilities and task demands,
offering a principled framework for optimizing multi-step reasoning in LLMs.","Yuyang Wu, Yifei Wang, Tianqi Du, Stefanie Jegelka, Yisen Wang",2025-02-11 05:28:59.000000,arXiv,http://arxiv.org/abs/2502.07266v1,Artificial Intelligence
893,Riemannian Proximal Sampler for High-accuracy Sampling on Manifolds,"We introduce the Riemannian Proximal Sampler, a method for sampling from
densities defined on Riemannian manifolds. The performance of this sampler
critically depends on two key oracles: the Manifold Brownian Increments (MBI)
oracle and the Riemannian Heat-kernel (RHK) oracle. We establish high-accuracy
sampling guarantees for the Riemannian Proximal Sampler, showing that
generating samples with $\varepsilon$-accuracy requires
$O(\log(1/\varepsilon))$ iterations in Kullback-Leibler divergence assuming
access to exact oracles and $O(\log^2(1/\varepsilon))$ iterations in the total
variation metric assuming access to sufficiently accurate inexact oracles.
Furthermore, we present practical implementations of these oracles by
leveraging heat-kernel truncation and Varadhan's asymptotics. In the latter
case, we interpret the Riemannian Proximal Sampler as a discretization of the
entropy-regularized Riemannian Proximal Point Method on the associated
Wasserstein space. We provide preliminary numerical results that illustrate the
effectiveness of the proposed methodology.","Yunrui Guan, Krishnakumar Balasubramanian, Shiqian Ma",2025-02-11 05:08:47.000000,arXiv,http://arxiv.org/abs/2502.07265v1,Statistical Machine Learning
894,Hidden Division of Labor in Scientific Teams Revealed Through 1.6 Million LaTeX Files,"Recognition of individual contributions is fundamental to the scientific
reward system, yet coauthored papers obscure who did what. Traditional
proxies-author order and career stage-reinforce biases, while contribution
statements remain self-reported and limited to select journals. We construct
the first large-scale dataset on writing contributions by analyzing
author-specific macros in LaTeX files from 1.6 million papers (1991-2023) by 2
million scientists. Validation against self-reported statements (precision =
0.87), author order patterns, field-specific norms, and Overleaf records
(Spearman's rho = 0.6, p < 0.05) confirms the reliability of the created data.
Using explicit section information, we reveal a hidden division of labor within
scientific teams: some authors primarily contribute to conceptual sections
(e.g., Introduction and Discussion), while others focus on technical sections
(e.g., Methods and Experiments). These findings provide the first large-scale
evidence of implicit labor division in scientific teams, challenging
conventional authorship practices and informing institutional policies on
credit allocation.","Jiaxin Pei, Lulin Yang, Lingfei Wu",2025-02-11 05:07:36.000000,arXiv,http://arxiv.org/abs/2502.07263v1,Other
895,Flat U-Net: An Efficient Ultralightweight Model for Solar Filament Segmentation in Full-disk H$α$ Images,"Solar filaments are one of the most prominent features observed on the Sun,
and their evolutions are closely related to various solar activities, such as
flares and coronal mass ejections. Real-time automated identification of solar
filaments is the most effective approach to managing large volumes of data.
Existing models of filament identification are characterized by large parameter
sizes and high computational costs, which limit their future applications in
highly integrated and intelligent ground-based and space-borne observation
devices. Consequently, the design of more lightweight models will facilitate
the advancement of intelligent observation equipment. In this study, we
introduce Flat U-Net, a novel and highly efficient ultralightweight model that
incorporates simplified channel attention (SCA) and channel self-attention
(CSA) convolutional blocks for the segmentation of solar filaments in full-disk
H$\alpha$ images. Feature information from each network layer is fully
extracted to reconstruct interchannel feature representations. Each block
effectively optimizes the channel features from the previous layer,
significantly reducing parameters. The network architecture presents an elegant
flattening, improving its efficiency, and simplifying the overall design.
Experimental validation demonstrates that a model composed of pure SCAs
achieves a precision of approximately 0.93, with dice similarity coefficient
(DSC) and recall rates of 0.76 and 0.64, respectively, significantly
outperforming the classical U-Net. Introducing a certain number of CSA blocks
improves the DSC and recall rates to 0.82 and 0.74, respectively, which
demonstrates a pronounced advantage, particularly concerning model weight size
and detection effectiveness. The data set, models, and code are available as
open-source resources.","GaoFei Zhu, GangHua Lin, Xiao Yang, Cheng Zeng",2025-02-11 04:57:33.000000,arXiv,http://arxiv.org/abs/2502.07259v1,Other
896,Beyond Confidence: Adaptive Abstention in Dual-Threshold Conformal Prediction for Autonomous System Perception,"Safety-critical perception systems require both reliable uncertainty
quantification and principled abstention mechanisms to maintain safety under
diverse operational conditions. We present a novel dual-threshold
conformalization framework that provides statistically-guaranteed uncertainty
estimates while enabling selective prediction in high-risk scenarios. Our
approach uniquely combines a conformal threshold ensuring valid prediction sets
with an abstention threshold optimized through ROC analysis, providing
distribution-free coverage guarantees (>= 1 - alpha) while identifying
unreliable predictions. Through comprehensive evaluation on CIFAR-100,
ImageNet1K, and ModelNet40 datasets, we demonstrate superior robustness across
camera and LiDAR modalities under varying environmental perturbations. The
framework achieves exceptional detection performance (AUC: 0.993 to 0.995)
under severe conditions while maintaining high coverage (>90.0%) and enabling
adaptive abstention (13.5% to 63.4% +/- 0.5) as environmental severity
increases. For LiDAR-based perception, our approach demonstrates particularly
strong performance, maintaining robust coverage (>84.5%) while appropriately
abstaining from unreliable predictions. Notably, the framework shows remarkable
stability under heavy perturbations, with detection performance (AUC: 0.995 +/-
0.001) significantly outperforming existing methods across all modalities. Our
unified approach bridges the gap between theoretical guarantees and practical
deployment needs, offering a robust solution for safety-critical autonomous
systems operating in challenging real-world conditions.","Divake Kumar, Nastaran Darabi, Sina Tayebati, Amit Ranjan Trivedi",2025-02-11 04:45:31.000000,arXiv,http://arxiv.org/abs/2502.07255v2,Robotics
897,Fairness in Multi-Agent AI: A Unified Framework for Ethical and Equitable Autonomous Systems,"Ensuring fairness in decentralized multi-agent systems presents significant
challenges due to emergent biases, systemic inefficiencies, and conflicting
agent incentives. This paper provides a comprehensive survey of fairness in
multi-agent AI, introducing a novel framework where fairness is treated as a
dynamic, emergent property of agent interactions. The framework integrates
fairness constraints, bias mitigation strategies, and incentive mechanisms to
align autonomous agent behaviors with societal values while balancing
efficiency and robustness. Through empirical validation, we demonstrate that
incorporating fairness constraints results in more equitable decision-making.
This work bridges the gap between AI ethics and system design, offering a
foundation for accountable, transparent, and socially responsible multi-agent
AI systems.","Rajesh Ranjan, Shailja Gupta, Surya Narayan Singh",2025-02-11 04:42:00.000000,arXiv,http://arxiv.org/abs/2502.07254v1,Multi-Agent Systems
898,NARCE: A Mamba-Based Neural Algorithmic Reasoner Framework for Online Complex Event Detection,"Current machine learning models excel in short-span perception tasks but
struggle to derive high-level insights from long-term observation, a capability
central to understanding complex events (CEs). CEs, defined as sequences of
short-term atomic events (AEs) governed by spatiotemporal rules, are
challenging to detect online due to the need to extract meaningful patterns
from long and noisy sensor data while ignoring irrelevant events. We
hypothesize that state-based methods are well-suited for CE detection, as they
capture event progression through state transitions without requiring long-term
memory. Baseline experiments validate this, demonstrating that the state-space
model Mamba outperforms existing architectures. However, Mamba's reliance on
extensive labeled data, which are difficult to obtain, motivates our second
hypothesis: decoupling CE rule learning from noisy sensor data can reduce data
requirements. To address this, we propose NARCE, a framework that combines
Neural Algorithmic Reasoning (NAR) to split the task into two components: (i)
learning CE rules independently of sensor data using synthetic concept traces
generated by LLMs and (ii) mapping sensor inputs to these rules via an adapter.
Our results show that NARCE outperforms baselines in accuracy, generalization
to unseen and longer sensor data, and data efficiency, significantly reducing
annotation costs while advancing robust CE detection.","Liying Han, Gaofeng Dong, Xiaomin Ouyang, Lance Kaplan, Federico Cerutti, Mani Srivastava",2025-02-11 04:34:53.000000,arXiv,http://arxiv.org/abs/2502.07250v1,Machine Learning
899,Robust Indoor Localization in Dynamic Environments: A Multi-source Unsupervised Domain Adaptation Framework,"Fingerprint localization has gained significant attention due to its
cost-effective deployment, low complexity, and high efficacy. However,
traditional methods, while effective for static data, often struggle in dynamic
environments where data distributions and feature spaces evolve-a common
occurrence in real-world scenarios. To address the challenges of robustness and
adaptability in fingerprint localization for dynamic indoor environments, this
paper proposes DF-Loc, an end-to-end dynamic fingerprint localization system
based on multi-source unsupervised domain adaptation (MUDA). DF-Loc leverages
historical data from multiple time scales to facilitate knowledge transfer in
specific feature spaces, thereby enhancing generalization capabilities in the
target domain and reducing reliance on labeled data. Specifically, the system
incorporates a Quality Control (QC) module for CSI data preprocessing and
employs image processing techniques for CSI fingerprint feature reconstruction.
Additionally, a multi-scale attention-based feature fusion backbone network is
designed to extract multi-level transferable fingerprint features. Finally, a
dual-stage alignment model aligns the distributions of multiple source-target
domain pairs, improving regression characteristics in the target domain.
Extensive experiments conducted in office and classroom environments
demonstrate that DF-Loc outperforms comparative methods in terms of both
localization accuracy and robustness. With 60% of reference points used for
training, DF-Loc achieves average localization errors of 0.79m and 3.72m in
""same-test"" scenarios, and 0.94m and 4.39m in ""different-test"" scenarios,
respectively. This work pioneers an end-to-end multi-source transfer learning
approach for fingerprint localization, providing valuable insights for future
research in dynamic environments.","Jiyu Jiao, Xiaojun Wang, Chengpei Han",2025-02-11 04:29:22.000000,arXiv,http://arxiv.org/abs/2502.07246v1,Computer Vision
900,Linear Transformers as VAR Models: Aligning Autoregressive Attention Mechanisms with Autoregressive Forecasting,"Autoregressive attention-based time series forecasting (TSF) has drawn
increasing interest, with mechanisms like linear attention sometimes
outperforming vanilla attention. However, deeper Transformer architectures
frequently misalign with autoregressive objectives, obscuring the underlying
VAR structure embedded within linear attention and hindering their ability to
capture the data generative processes in TSF. In this work, we first show that
a single linear attention layer can be interpreted as a dynamic vector
autoregressive (VAR) structure. We then explain that existing multi-layer
Transformers have structural mismatches with the autoregressive forecasting
objective, which impair interpretability and generalization ability. To address
this, we show that by rearranging the MLP, attention, and input-output flow,
multi-layer linear attention can also be aligned as a VAR model. Then, we
propose Structural Aligned Mixture of VAR (SAMoVAR), a linear Transformer
variant that integrates interpretable dynamic VAR weights for multivariate TSF.
By aligning the Transformer architecture with autoregressive objectives,
SAMoVAR delivers improved performance, interpretability, and computational
efficiency, comparing to SOTA TSF models.","Jiecheng Lu, Shihao Yang",2025-02-11 04:24:43.000000,arXiv,http://arxiv.org/abs/2502.07244v1,Machine Learning
901,Vevo: Controllable Zero-Shot Voice Imitation with Self-Supervised Disentanglement,"The imitation of voice, targeted on specific speech attributes such as timbre
and speaking style, is crucial in speech generation. However, existing methods
rely heavily on annotated data, and struggle with effectively disentangling
timbre and style, leading to challenges in achieving controllable generation,
especially in zero-shot scenarios. To address these issues, we propose Vevo, a
versatile zero-shot voice imitation framework with controllable timbre and
style. Vevo operates in two core stages: (1) Content-Style Modeling: Given
either text or speech's content tokens as input, we utilize an autoregressive
transformer to generate the content-style tokens, which is prompted by a style
reference; (2) Acoustic Modeling: Given the content-style tokens as input, we
employ a flow-matching transformer to produce acoustic representations, which
is prompted by a timbre reference. To obtain the content and content-style
tokens of speech, we design a fully self-supervised approach that progressively
decouples the timbre, style, and linguistic content of speech. Specifically, we
adopt VQ-VAE as the tokenizer for the continuous hidden features of HuBERT. We
treat the vocabulary size of the VQ-VAE codebook as the information bottleneck,
and adjust it carefully to obtain the disentangled speech representations.
Solely self-supervised trained on 60K hours of audiobook speech data, without
any fine-tuning on style-specific corpora, Vevo matches or surpasses existing
methods in accent and emotion conversion tasks. Additionally, Vevo's
effectiveness in zero-shot voice conversion and text-to-speech tasks further
demonstrates its strong generalization and versatility. Audio samples are
available at https://versavoice.github.io.","Xueyao Zhang, Xiaohui Zhang, Kainan Peng, Zhenyu Tang, Vimal Manohar, Yingru Liu, Jeff Hwang, Dangna Li, Yuhao Wang, Julian Chan, Yuan Huang, Zhizheng Wu, Mingbo Ma",2025-02-11 04:18:33.000000,arXiv,http://arxiv.org/abs/2502.07243v1,Other
902,Contextual Gesture: Co-Speech Gesture Video Generation through Context-aware Gesture Representation,"Co-speech gesture generation is crucial for creating lifelike avatars and
enhancing human-computer interactions by synchronizing gestures with speech.
Despite recent advancements, existing methods struggle with accurately
identifying the rhythmic or semantic triggers from audio for generating
contextualized gesture patterns and achieving pixel-level realism. To address
these challenges, we introduce Contextual Gesture, a framework that improves
co-speech gesture video generation through three innovative components: (1) a
chronological speech-gesture alignment that temporally connects two modalities,
(2) a contextualized gesture tokenization that incorporate speech context into
motion pattern representation through distillation, and (3) a structure-aware
refinement module that employs edge connection to link gesture keypoints to
improve video generation. Our extensive experiments demonstrate that Contextual
Gesture not only produces realistic and speech-aligned gesture videos but also
supports long-sequence generation and video gesture editing applications, shown
in Fig.1 Project Page: https://andypinxinliu.github.io/Contextual-Gesture/.","Pinxin Liu, Pengfei Zhang, Hyeongwoo Kim, Pablo Garrido, Ari Sharpio, Kyle Olszewski",2025-02-11 04:09:12.000000,arXiv,http://arxiv.org/abs/2502.07239v1,Computer Vision
903,Diffusion Suction Grasping with Large-Scale Parcel Dataset,"While recent advances in object suction grasping have shown remarkable
progress, significant challenges persist particularly in cluttered and complex
parcel handling scenarios. Two fundamental limitations hinder current
approaches: (1) the lack of a comprehensive suction grasp dataset tailored for
parcel manipulation tasks, and (2) insufficient adaptability to diverse object
characteristics including size variations, geometric complexity, and textural
diversity. To address these challenges, we present Parcel-Suction-Dataset, a
large-scale synthetic dataset containing 25 thousand cluttered scenes with 410
million precision-annotated suction grasp poses. This dataset is generated
through our novel geometric sampling algorithm that enables efficient
generation of optimal suction grasps incorporating both physical constraints
and material properties. We further propose Diffusion-Suction, an innovative
framework that reformulates suction grasp prediction as a conditional
generation task through denoising diffusion probabilistic models. Our method
iteratively refines random noise into suction grasp score maps through
visual-conditioned guidance from point cloud observations, effectively learning
spatial point-wise affordances from our synthetic dataset. Extensive
experiments demonstrate that the simple yet efficient Diffusion-Suction
achieves new state-of-the-art performance compared to previous models on both
Parcel-Suction-Dataset and the public SuctionNet-1Billion benchmark.","Ding-Tao Huang, Xinyi He, Debei Hua, Dongfang Yu, En-Te Lin, Long Zeng",2025-02-11 04:09:11.000000,arXiv,http://arxiv.org/abs/2502.07238v1,Computer Vision
904,DrugImproverGPT: A Large Language Model for Drug Optimization with Fine-Tuning via Structured Policy Optimization,"Finetuning a Large Language Model (LLM) is crucial for generating results
towards specific objectives. This research delves into the realm of drug
optimization and introduce a novel reinforcement learning algorithm to finetune
a drug optimization LLM-based generative model, enhancing the original drug
across target objectives, while retains the beneficial chemical properties of
the original drug. This work is comprised of two primary components: (1)
DrugImprover: A framework tailored for improving robustness and efficiency in
drug optimization. It includes a LLM designed for drug optimization and a novel
Structured Policy Optimization (SPO) algorithm, which is theoretically
grounded. This algorithm offers a unique perspective for fine-tuning the
LLM-based generative model by aligning the improvement of the generated
molecule with the input molecule under desired objectives. (2) A dataset of 1
million compounds, each with OEDOCK docking scores on 5 human proteins
associated with cancer cells and 24 binding sites from SARS-CoV-2 virus. We
conduct a comprehensive evaluation of SPO and demonstrate its effectiveness in
improving the original drug across target properties. Our code and dataset will
be publicly available at: https://github.com/xuefeng-cs/DrugImproverGPT.","Xuefeng Liu, Songhao Jiang, Siyu Chen, Zhuoran Yang, Yuxin Chen, Ian Foster, Rick Stevens",2025-02-11 04:00:21.000000,arXiv,http://arxiv.org/abs/2502.07237v1,Machine Learning
905,Simplifying Adversarially Robust PAC Learning with Tolerance,"Adversarially robust PAC learning has proved to be challenging, with the
currently best known learners [Montasser et al., 2021a] relying on improper
methods based on intricate compression schemes, resulting in sample complexity
exponential in the VC-dimension. A series of follow up work considered a
slightly relaxed version of the problem called adversarially robust learning
with tolerance [Ashtiani et al., 2023, Bhattacharjee et al., 2023, Raman et
al., 2024] and achieved better sample complexity in terms of the VC-dimension.
However, those algorithms were either improper and complex, or required
additional assumptions on the hypothesis class H. We prove, for the first time,
the existence of a simpler learner that achieves a sample complexity linear in
the VC-dimension without requiring additional assumptions on H. Even though our
learner is improper, it is ""almost proper"" in the sense that it outputs a
hypothesis that is ""similar"" to a hypothesis in H.
  We also use the ideas from our algorithm to construct a semi-supervised
learner in the tolerant setting. This simple algorithm achieves comparable
bounds to the previous (non-tolerant) semi-supervised algorithm of Attias et
al. [2022a], but avoids the use of intricate subroutines from previous works,
and is ""almost proper.""","Hassan Ashtiani, Vinayak Pathak, Ruth Urner",2025-02-11 03:48:40.000000,arXiv,http://arxiv.org/abs/2502.07232v1,Machine Learning
906,TranSplat: Surface Embedding-guided 3D Gaussian Splatting for Transparent Object Manipulation,"Transparent object manipulation remains a sig- nificant challenge in robotics
due to the difficulty of acquiring accurate and dense depth measurements.
Conventional depth sensors often fail with transparent objects, resulting in
in- complete or erroneous depth data. Existing depth completion methods
struggle with interframe consistency and incorrectly model transparent objects
as Lambertian surfaces, leading to poor depth reconstruction. To address these
challenges, we propose TranSplat, a surface embedding-guided 3D Gaussian
Splatting method tailored for transparent objects. TranSplat uses a latent
diffusion model to generate surface embeddings that provide consistent and
continuous representations, making it robust to changes in viewpoint and
lighting. By integrating these surface embeddings with input RGB images,
TranSplat effectively captures the complexities of transparent surfaces,
enhancing the splatting of 3D Gaussians and improving depth completion.
Evaluations on synthetic and real-world transpar- ent object benchmarks, as
well as robot grasping tasks, show that TranSplat achieves accurate and dense
depth completion, demonstrating its effectiveness in practical applications. We
open-source synthetic dataset and model: https://github.
com/jeongyun0609/TranSplat","Jeongyun Kim, Jeongho Noh, Dong-Guw Lee, Ayoung Kim",2025-02-11 03:43:56.000000,arXiv,http://arxiv.org/abs/2502.07840v1,Computer Vision
907,CAT: Contrastive Adversarial Training for Evaluating the Robustness of Protective Perturbations in Latent Diffusion Models,"Latent diffusion models have recently demonstrated superior capabilities in
many downstream image synthesis tasks. However, customization of latent
diffusion models using unauthorized data can severely compromise the privacy
and intellectual property rights of data owners. Adversarial examples as
protective perturbations have been developed to defend against unauthorized
data usage by introducing imperceptible noise to customization samples,
preventing diffusion models from effectively learning them. In this paper, we
first reveal that the primary reason adversarial examples are effective as
protective perturbations in latent diffusion models is the distortion of their
latent representations, as demonstrated through qualitative and quantitative
experiments. We then propose the Contrastive Adversarial Training (CAT)
utilizing adapters as an adaptive attack against these protection methods,
highlighting their lack of robustness. Extensive experiments demonstrate that
our CAT method significantly reduces the effectiveness of protective
perturbations in customization configurations, urging the community to
reconsider and enhance the robustness of existing protective perturbation
methods. Code is available at \hyperlink{here}{https://github.com/senp98/CAT}.","Sen Peng, Mingyue Wang, Jianfei He, Jijia Yang, Xiaohua Jia",2025-02-11 03:35:35.000000,arXiv,http://arxiv.org/abs/2502.07225v1,Computer Vision
908,Graph RAG-Tool Fusion,"Recent developments in retrieval-augmented generation (RAG) for selecting
relevant tools from a tool knowledge base enable LLM agents to scale their
complex tool calling capabilities to hundreds or thousands of external tools,
APIs, or agents-as-tools. However, traditional RAG-based tool retrieval fails
to capture structured dependencies between tools, limiting the retrieval
accuracy of a retrieved tool's dependencies. For example, among a vector
database of tools, a ""get stock price"" API requires a ""stock ticker"" parameter
from a ""get stock ticker"" API, and both depend on OS-level internet
connectivity tools. In this paper, we address this limitation by introducing
Graph RAG-Tool Fusion, a novel plug-and-play approach that combines the
strengths of vector-based retrieval with efficient graph traversal to capture
all relevant tools (nodes) along with any nested dependencies (edges) within
the predefined tool knowledge graph. We also present ToolLinkOS, a new tool
selection benchmark of 573 fictional tools, spanning over 15 industries, each
with an average of 6.3 tool dependencies. We demonstrate that Graph RAG-Tool
Fusion achieves absolute improvements of 71.7% and 22.1% over na\""ive RAG on
ToolLinkOS and ToolSandbox benchmarks, respectively (mAP@10). ToolLinkOS
dataset is available at
https://github.com/EliasLumer/Graph-RAG-Tool-Fusion-ToolLinkOS","Elias Lumer, Pradeep Honaganahalli Basavaraju, Myles Mason, James A. Burke, Vamse Kumar Subbiah",2025-02-11 03:32:34.000000,arXiv,http://arxiv.org/abs/2502.07223v1,Natural Language Processing
909,A Memory Efficient Randomized Subspace Optimization Method for Training Large Language Models,"The memory challenges associated with training Large Language Models (LLMs)
have become a critical concern, particularly when using the Adam optimizer. To
address this issue, numerous memory-efficient techniques have been proposed,
with GaLore standing out as a notable example designed to reduce the memory
footprint of optimizer states. However, these approaches do not alleviate the
memory burden imposed by activations, rendering them unsuitable for scenarios
involving long context sequences or large mini-batches. Moreover, their
convergence properties are still not well-understood in the literature. In this
work, we introduce a Randomized Subspace Optimization framework for
pre-training and fine-tuning LLMs. Our approach decomposes the high-dimensional
training problem into a series of lower-dimensional subproblems. At each
iteration, a random subspace is selected, and the parameters within that
subspace are optimized. This structured reduction in dimensionality allows our
method to simultaneously reduce memory usage for both activations and optimizer
states. We establish comprehensive convergence guarantees and derive rates for
various scenarios, accommodating different optimization strategies to solve the
subproblems. Extensive experiments validate the superior memory and
communication efficiency of our method, achieving performance comparable to
GaLore and Adam.","Yiming Chen, Yuan Zhang, Yin Liu, Kun Yuan, Zaiwen Wen",2025-02-11 03:32:10.000000,arXiv,http://arxiv.org/abs/2502.07222v1,Machine Learning
910,MLLM4PUE: Toward Universal Embeddings in Computational Pathology through Multimodal LLMs,"Pathology plays a critical role in diagnosing a wide range of diseases, yet
existing approaches often rely heavily on task-specific models trained on
extensive, well-labeled datasets. These methods face sustainability challenges
due to the diversity of pathologies and the labor-intensive nature of data
collection. To address these limitations, we highlight the need for universal
multimodal embeddings that can support multiple downstream tasks. Previous
approaches often involve fine-tuning CLIP-based models, which handle images and
text separately, limiting their ability to capture complex multimodal
relationships. Additionally, these models are evaluated across diverse datasets
without a unified benchmark for assessing multimodal embeddings in pathology.
To address these challenges, we propose MLLM4PUE, a novel framework that
leverages Multimodal Large Language Models (MLLMs) to generate Pathology
Universal Embeddings. The MLLM4PUE framework not only facilitates robust
integration of images and text but also enhances understanding and fusion
capabilities across various tasks. We further introduce the Pathology
Multimodal Embedding Benchmark (PMEB), a comprehensive benchmark designed to
assess the quality of pathology multimodal embeddings. PMEB comprises 15
original tasks drawn from 14 datasets, organized into three meta-tasks:
retrieval, classification, and composed retrieval. Experimental results
demonstrate the superiority of MLLM4PUE, illustrating MLLM-based models can
effectively support a wide range of downstream tasks and unify the research
direction for foundation models in pathology.","Qifeng Zhou, Thao M. Dang, Wenliang Zhong, Yuzhi Guo, Hehuan Ma, Saiyang Na, Junzhou Huang",2025-02-11 03:28:55.000000,arXiv,http://arxiv.org/abs/2502.07221v1,Computer Vision
911,DOGR: Leveraging Document-Oriented Contrastive Learning in Generative Retrieval,"Generative retrieval constitutes an innovative approach in information
retrieval, leveraging generative language models (LM) to generate a ranked list
of document identifiers (docid) for a given query. It simplifies the retrieval
pipeline by replacing the large external index with model parameters. However,
existing works merely learned the relationship between queries and document
identifiers, which is unable to directly represent the relevance between
queries and documents. To address the above problem, we propose a novel and
general generative retrieval framework, namely Leveraging Document-Oriented
Contrastive Learning in Generative Retrieval (DOGR), which leverages
contrastive learning to improve generative retrieval tasks. It adopts a
two-stage learning strategy that captures the relationship between queries and
documents comprehensively through direct interactions. Furthermore, negative
sampling methods and corresponding contrastive learning objectives are
implemented to enhance the learning of semantic representations, thereby
promoting a thorough comprehension of the relationship between queries and
documents. Experimental results demonstrate that DOGR achieves state-of-the-art
performance compared to existing generative retrieval methods on two public
benchmark datasets. Further experiments have shown that our framework is
generally effective for common identifier construction techniques.","Penghao Lu, Xin Dong, Yuansheng Zhou, Lei Cheng, Chuan Yuan, Linjian Mo",2025-02-11 03:25:42.000000,arXiv,http://arxiv.org/abs/2502.07219v2,Information Retrieval
912,LUNAR: LLM Unlearning via Neural Activation Redirection,"Large Language Models (LLMs) benefit from training on ever larger amounts of
textual data, but as a result, they increasingly incur the risk of leaking
private information. The ability to selectively remove knowledge from LLMs is,
therefore, a highly desirable capability. In this paper, we propose LUNAR, a
novel unlearning methodology grounded in the Linear Representation Hypothesis.
LUNAR operates by redirecting the representations of unlearned data to regions
that trigger the model's inherent ability to express its inability to answer.
LUNAR achieves state-of-the-art unlearning performance while significantly
enhancing the controllability of the unlearned model during inference.
Specifically, LUNAR achieves between 2.9x to 11.7x improvements on combined
""unlearning efficacy"" and ""model utility"" score (""Deviation Score"") on the
PISTOL dataset across various base models. We also demonstrate, through
quantitative analysis and qualitative examples, LUNAR's superior
controllability in generating coherent and contextually aware responses,
mitigating undesired side effects of existing methods. Moreover, we demonstrate
that LUNAR is robust against white-box adversarial attacks and versatile in
handling real-world scenarios, such as processing sequential unlearning
requests.","William F. Shen, Xinchi Qiu, Meghdad Kurmanji, Alex Iacob, Lorenzo Sani, Yihong Chen, Nicola Cancedda, Nicholas D. Lane",2025-02-11 03:23:22.000000,arXiv,http://arxiv.org/abs/2502.07218v1,Machine Learning
913,SparseFormer: Detecting Objects in HRW Shots via Sparse Vision Transformer,"Recent years have seen an increase in the use of gigapixel-level image and
video capture systems and benchmarks with high-resolution wide (HRW) shots.
However, unlike close-up shots in the MS COCO dataset, the higher resolution
and wider field of view raise unique challenges, such as extreme sparsity and
huge scale changes, causing existing close-up detectors inaccuracy and
inefficiency. In this paper, we present a novel model-agnostic sparse vision
transformer, dubbed SparseFormer, to bridge the gap of object detection between
close-up and HRW shots. The proposed SparseFormer selectively uses attentive
tokens to scrutinize the sparsely distributed windows that may contain objects.
In this way, it can jointly explore global and local attention by fusing
coarse- and fine-grained features to handle huge scale changes. SparseFormer
also benefits from a novel Cross-slice non-maximum suppression (C-NMS)
algorithm to precisely localize objects from noisy windows and a simple yet
effective multi-scale strategy to improve accuracy. Extensive experiments on
two HRW benchmarks, PANDA and DOTA-v1.0, demonstrate that the proposed
SparseFormer significantly improves detection accuracy (up to 5.8%) and speed
(up to 3x) over the state-of-the-art approaches.","Wenxi Li, Yuchen Guo, Jilai Zheng, Haozhe Lin, Chao Ma, Lu Fang, Xiaokang Yang",2025-02-11 03:21:25.000000,arXiv,http://arxiv.org/abs/2502.07216v1,Computer Vision
914,PDV: Prompt Directional Vectors for Zero-shot Composed Image Retrieval,"Zero-shot composed image retrieval (ZS-CIR) enables image search using a
reference image and text prompt without requiring specialized text-image
composition networks trained on large-scale paired data. However, current
ZS-CIR approaches face three critical limitations in their reliance on composed
text embeddings: static query embedding representations, insufficient
utilization of image embeddings, and suboptimal performance when fusing text
and image embeddings. To address these challenges, we introduce the Prompt
Directional Vector (PDV), a simple yet effective training-free enhancement that
captures semantic modifications induced by user prompts. PDV enables three key
improvements: (1) dynamic composed text embeddings where prompt adjustments are
controllable via a scaling factor, (2) composed image embeddings through
semantic transfer from text prompts to image features, and (3) weighted fusion
of composed text and image embeddings that enhances retrieval by balancing
visual and semantic similarity. Our approach serves as a plug-and-play
enhancement for existing ZS-CIR methods with minimal computational overhead.
Extensive experiments across multiple benchmarks demonstrate that PDV
consistently improves retrieval performance when integrated with
state-of-the-art ZS-CIR approaches, particularly for methods that generate
accurate compositional embeddings. The code will be publicly available.","Osman Tursun, Sinan Kalkan, Simon Denman, Clinton Fookes",2025-02-11 03:20:21.000000,arXiv,http://arxiv.org/abs/2502.07215v1,Computer Vision
915,Pareto Optimal Algorithmic Recourse in Multi-cost Function,"In decision-making systems, algorithmic recourse aims to identify
minimal-cost actions to alter an individual features, thereby obtaining a
desired outcome. This empowers individuals to understand, question, or alter
decisions that negatively affect them. However, due to the variety and
sensitivity of system environments and individual personalities, quantifying
the cost of a single function is nearly impossible while considering multiple
criteria situations. Most current recourse mechanisms use gradient-based
methods that assume cost functions are differentiable, often not applicable in
real-world scenarios, resulting in sub-optimal solutions that compromise
various criteria. These solutions are typically intractable and lack rigorous
theoretical foundations, raising concerns regarding interpretability,
reliability, and transparency from the explainable AI (XAI) perspective.
  To address these issues, this work proposes an algorithmic recourse framework
that handles non-differentiable and discrete multi-cost functions. By
formulating recourse as a multi-objective optimization problem and assigning
weights to different criteria based on their importance, our method identifies
Pareto optimal recourse recommendations. To demonstrate scalability, we
incorporate the concept of epsilon-net, proving the ability to find
approximated Pareto optimal actions. Experiments show the trade-off between
different criteria and the methods scalability in large graphs. Compared to
current heuristic practices, our approach provides a stronger theoretical
foundation and better aligns recourse suggestions with real-world requirements.","Wen-Ling Chen, Hong-Chang Huang, Kai-Hung Lin, Shang-Wei Hwang, Hao-Tsung Yang",2025-02-11 03:16:08.000000,arXiv,http://arxiv.org/abs/2502.07214v1,Machine Learning
916,Evaluation for Regression Analyses on Evolving Data Streams,"The paper explores the challenges of regression analysis in evolving data
streams, an area that remains relatively underexplored compared to
classification. We propose a standardized evaluation process for regression and
prediction interval tasks in streaming contexts. Additionally, we introduce an
innovative drift simulation strategy capable of synthesizing various drift
types, including the less-studied incremental drift. Comprehensive experiments
with state-of-the-art methods, conducted under the proposed process, validate
the effectiveness and robustness of our approach.","Yibin Sun, Heitor Murilo Gomes, Bernhard Pfahringer, Albert Bifet",2025-02-11 03:12:08.000000,arXiv,http://arxiv.org/abs/2502.07213v1,Machine Learning
917,Improve the Training Efficiency of DRL for Wireless Communication Resource Allocation: The Role of Generative Diffusion Models,"Dynamic resource allocation in mobile wireless networks involves complex,
time-varying optimization problems, motivating the adoption of deep
reinforcement learning (DRL). However, most existing works rely on pre-trained
policies, overlooking dynamic environmental changes that rapidly invalidate the
policies. Periodic retraining becomes inevitable but incurs prohibitive
computational costs and energy consumption-critical concerns for
resource-constrained wireless systems. We identify three root causes of
inefficient retraining: high-dimensional state spaces, suboptimal action spaces
exploration-exploitation trade-offs, and reward design limitations. To overcome
these limitations, we propose Diffusion-based Deep Reinforcement Learning
(D2RL), which leverages generative diffusion models (GDMs) to holistically
enhance all three DRL components. Iterative refinement process and distribution
modelling of GDMs enable (1) the generation of diverse state samples to improve
environmental understanding, (2) balanced action space exploration to escape
local optima, and (3) the design of discriminative reward functions that better
evaluate action quality. Our framework operates in two modes: Mode I leverages
GDMs to explore reward spaces and design discriminative reward functions that
rigorously evaluate action quality, while Mode II synthesizes diverse state
samples to enhance environmental understanding and generalization. Extensive
experiments demonstrate that D2RL achieves faster convergence and reduced
computational costs over conventional DRL methods for resource allocation in
wireless communications while maintaining competitive policy performance. This
work underscores the transformative potential of GDMs in overcoming fundamental
DRL training bottlenecks for wireless networks, paving the way for practical,
real-time deployments.","Xinren Zhang, Jiadong Yu",2025-02-11 03:09:45.000000,arXiv,http://arxiv.org/abs/2502.07211v1,Machine Learning
918,Enhancing Physics-Informed Neural Networks Through Feature Engineering,"Physics-Informed Neural Networks (PINNs) seek to solve partial differential
equations (PDEs) with deep learning. Mainstream approaches that deploy
fully-connected multi-layer deep learning architectures require prolonged
training to achieve even moderate accuracy, while recent work on feature
engineering allows higher accuracy and faster convergence. This paper
introduces SAFE-NET, a Single-layered Adaptive Feature Engineering NETwork that
achieves orders-of-magnitude lower errors with far fewer parameters than
baseline feature engineering methods. SAFE-NET returns to basic ideas in
machine learning, using Fourier features, a simplified single hidden layer
network architecture, and an effective optimizer that improves the conditioning
of the PINN optimization problem. Numerical results show that SAFE-NET
converges faster and typically outperforms deeper networks and more complex
architectures. It consistently uses fewer parameters -- on average, 65% fewer
than the competing feature engineering methods -- while achieving comparable
accuracy in less than 30% of the training epochs. Moreover, each SAFE-NET epoch
is 95% faster than those of competing feature engineering approaches. These
findings challenge the prevailing belief that modern PINNs effectively learn
features in these scientific applications and highlight the efficiency gains
possible through feature engineering.","Shaghayegh Fazliani, Zachary Frangella, Madeleine Udell",2025-02-11 03:07:28.000000,arXiv,http://arxiv.org/abs/2502.07209v1,Machine Learning
919,A Study on the Importance of Features in Detecting Advanced Persistent Threats Using Machine Learning,"Advanced Persistent Threats (APTs) pose a significant security risk to
organizations and industries. These attacks often lead to severe data breaches
and compromise the system for a long time. Mitigating these sophisticated
attacks is highly challenging due to the stealthy and persistent nature of
APTs. Machine learning models are often employed to tackle this challenge by
bringing automation and scalability to APT detection. Nevertheless, these
intelligent methods are data-driven, and thus, highly affected by the quality
and relevance of input data. This paper aims to analyze measurements considered
when recording network traffic and conclude which features contribute more to
detecting APT samples. To do this, we study the features associated with
various APT cases and determine their importance using a machine learning
framework. To ensure the generalization of our findings, several feature
selection techniques are employed and paired with different classifiers to
evaluate their effectiveness. Our findings provide insights into how APT
detection can be enhanced in real-world scenarios.","Ehsan Hallaji, Roozbeh Razavi-Far, Mehrdad Saif",2025-02-11 03:06:03.000000,arXiv,http://arxiv.org/abs/2502.07207v1,Other
920,Optimal Actuator Attacks on Autonomous Vehicles Using Reinforcement Learning,"With the increasing prevalence of autonomous vehicles (AVs), their
vulnerability to various types of attacks has grown, presenting significant
security challenges. In this paper, we propose a reinforcement learning
(RL)-based approach for designing optimal stealthy integrity attacks on AV
actuators. We also analyze the limitations of state-of-the-art RL-based secure
controllers developed to counter such attacks. Through extensive simulation
experiments, we demonstrate the effectiveness and efficiency of our proposed
method.","Pengyu Wang, Jialu Li, Ling Shi",2025-02-11 03:01:05.000000,arXiv,http://arxiv.org/abs/2502.07839v1,Robotics
921,VINP: Variational Bayesian Inference with Neural Speech Prior for Joint ASR-Effective Speech Dereverberation and Blind RIR Identification,"Reverberant speech, denoting the speech signal degraded by the process of
reverberation, contains crucial knowledge of both anechoic source speech and
room impulse response (RIR). This work proposes a variational Bayesian
inference (VBI) framework with neural speech prior (VINP) for joint speech
dereverberation and blind RIR identification. In VINP, a probabilistic signal
model is constructed in the time-frequency (T-F) domain based on convolution
transfer function (CTF) approximation. For the first time, we propose using an
arbitrary discriminative dereverberation deep neural network (DNN) to predict
the prior distribution of anechoic speech within a probabilistic model. By
integrating both reverberant speech and the anechoic speech prior, VINP yields
the maximum a posteriori (MAP) and maximum likelihood (ML) estimations of the
anechoic speech spectrum and CTF filter, respectively. After simple
transformations, the waveforms of anechoic speech and RIR are estimated.
Moreover, VINP is effective for automatic speech recognition (ASR) systems,
which sets it apart from most deep learning (DL)-based single-channel
dereverberation approaches. Experiments on single-channel speech
dereverberation demonstrate that VINP reaches an advanced level in most metrics
related to human perception and displays unquestionable state-of-the-art (SOTA)
performance in ASR-related metrics. For blind RIR identification, experiments
indicate that VINP attains the SOTA level in blind estimation of reverberation
time at 60 dB (RT60) and direct-to-reverberation ratio (DRR). Codes and audio
samples are available online.","Pengyu Wang, Ying Fang, Xiaofei Li",2025-02-11 02:54:28.000000,arXiv,http://arxiv.org/abs/2502.07205v1,Other
922,Playmate: Flexible Control of Portrait Animation via 3D-Implicit Space Guided Diffusion,"Recent diffusion-based talking face generation models have demonstrated
impressive potential in synthesizing videos that accurately match a speech
audio clip with a given reference identity. However, existing approaches still
encounter significant challenges due to uncontrollable factors, such as
inaccurate lip-sync, inappropriate head posture and the lack of fine-grained
control over facial expressions. In order to introduce more face-guided
conditions beyond speech audio clips, a novel two-stage training framework
Playmate is proposed to generate more lifelike facial expressions and talking
faces. In the first stage, we introduce a decoupled implicit 3D representation
along with a meticulously designed motion-decoupled module to facilitate more
accurate attribute disentanglement and generate expressive talking videos
directly from audio cues. Then, in the second stage, we introduce an
emotion-control module to encode emotion control information into the latent
space, enabling fine-grained control over emotions and thereby achieving the
ability to generate talking videos with desired emotion. Extensive experiments
demonstrate that Playmate outperforms existing state-of-the-art methods in
terms of video quality and lip-synchronization, and improves flexibility in
controlling emotion and head pose. The code will be available at
https://playmate111.github.io.","Xingpei Ma, Jiaran Cai, Yuansheng Guan, Shenneng Huang, Qiang Zhang, Shunsi Zhang",2025-02-11 02:53:48.000000,arXiv,http://arxiv.org/abs/2502.07203v1,Computer Vision
923,Monte Carlo Tree Diffusion for System 2 Planning,"Diffusion models have recently emerged as a powerful tool for planning.
However, unlike Monte Carlo Tree Search (MCTS)-whose performance naturally
improves with additional test-time computation (TTC), standard diffusion-based
planners offer only limited avenues for TTC scalability. In this paper, we
introduce Monte Carlo Tree Diffusion (MCTD), a novel framework that integrates
the generative strength of diffusion models with the adaptive search
capabilities of MCTS. Our method reconceptualizes denoising as a
tree-structured process, allowing partially denoised plans to be iteratively
evaluated, pruned, and refined. By selectively expanding promising trajectories
while retaining the flexibility to revisit and improve suboptimal branches,
MCTD achieves the benefits of MCTS such as controlling exploration-exploitation
trade-offs within the diffusion framework. Empirical results on challenging
long-horizon tasks show that MCTD outperforms diffusion baselines, yielding
higher-quality solutions as TTC increases.","Jaesik Yoon, Hyeonseo Cho, Doojin Baek, Yoshua Bengio, Sungjin Ahn",2025-02-11 02:51:42.000000,arXiv,http://arxiv.org/abs/2502.07202v1,Artificial Intelligence
924,Color-Quality Invariance for Robust Medical Image Segmentation,"Single-source domain generalization (SDG) in medical image segmentation
remains a significant challenge, particularly for images with varying color
distributions and qualities. Previous approaches often struggle when models
trained on high-quality images fail to generalize to low-quality test images
due to these color and quality shifts. In this work, we propose two novel
techniques to enhance generalization: dynamic color image normalization (DCIN)
module and color-quality generalization (CQG) loss. The DCIN dynamically
normalizes the color of test images using two reference image selection
strategies. Specifically, the DCIN utilizes a global reference image selection
(GRIS), which finds a universal reference image, and a local reference image
selection (LRIS), which selects a semantically similar reference image per test
sample. Additionally, CQG loss enforces invariance to color and quality
variations by ensuring consistent segmentation predictions across transformed
image pairs. Experimental results show that our proposals significantly improve
segmentation performance over the baseline on two target domain datasets,
despite being trained solely on a single source domain. Notably, our model
achieved up to a 32.3-point increase in Dice score compared to the baseline,
consistently producing robust and usable results even under substantial domain
shifts. Our work contributes to the development of more robust medical image
segmentation models that generalize across unseen domains. The implementation
code is available at https://github.com/RaviShah1/DCIN-CQG.","Ravi Shah, Atsushi Fukuda, Quan Huu Cap",2025-02-11 02:47:37.000000,arXiv,http://arxiv.org/abs/2502.07200v1,Other
925,Fixed-Confidence Best Arm Identification with Decreasing Variance,"We focus on the problem of best-arm identification in a stochastic multi-arm
bandit with temporally decreasing variances for the arms' rewards. We model arm
rewards as Gaussian random variables with fixed means and variances that
decrease with time. The cost incurred by the learner is modeled as a weighted
sum of the time needed by the learner to identify the best arm, and the number
of samples of arms collected by the learner before termination. Under this cost
function, there is an incentive for the learner to not sample arms in all
rounds, especially in the initial rounds. On the other hand, not sampling
increases the termination time of the learner, which also increases cost. This
trade-off necessitates new sampling strategies. We propose two policies. The
first policy has an initial wait period with no sampling followed by continuous
sampling. The second policy samples periodically and uses a weighted average of
the rewards observed to identify the best arm. We provide analytical guarantees
on the performance of both policies and supplement our theoretical results with
simulations which show that our polices outperform the state-of-the-art
policies for the classical best arm identification problem.","Tamojeet Roychowdhury, Kota Srinivas Reddy, Krishna P Jagannathan, Sharayu Moharir",2025-02-11 02:47:20.000000,arXiv,http://arxiv.org/abs/2502.07199v1,Machine Learning
926,Parameter Optimization of Optical Six-Axis Force/Torque Sensor for Legged Robots,"This paper introduces a novel six-axis force/torque sensor tailored for
compact and lightweight legged robots. Unlike traditional strain gauge-based
sensors, the proposed non-contact design employs photocouplers, enhancing
resistance to physical impacts and reducing damage risk. This approach
simplifies manufacturing, lowers costs, and meets the demands of legged robots
by combining small size, light weight, and a wide force measurement range. A
methodology for optimizing sensor parameters is also presented, focusing on
maximizing sensitivity and minimizing error. Precise modeling and analysis of
objective functions enabled the derivation of optimal design parameters. The
sensor's performance was validated through extensive testing and integration
into quadruped robots, demonstrating alignment with theoretical modeling. The
sensor's precise measurement capabilities make it suitable for diverse robotic
environments, particularly in analyzing interactions between robot feet and the
ground. This innovation addresses existing sensor limitations while
contributing to advancements in robotics and sensor technology, paving the way
for future applications in robotic systems.","Hyun-Bin Kim, Byeong-Il Ham, Keun-Ha Choi, Kyung-Soo Kim",2025-02-11 02:39:09.000000,arXiv,http://arxiv.org/abs/2502.07196v1,Robotics
927,Dense Object Detection Based on De-homogenized Queries,"Dense object detection is widely used in automatic driving, video
surveillance, and other fields. This paper focuses on the challenging task of
dense object detection. Currently, detection methods based on greedy
algorithms, such as non-maximum suppression (NMS), often produce many
repetitive predictions or missed detections in dense scenarios, which is a
common problem faced by NMS-based algorithms. Through the end-to-end DETR
(DEtection TRansformer), as a type of detector that can incorporate the
post-processing de-duplication capability of NMS, etc., into the network, we
found that homogeneous queries in the query-based detector lead to a reduction
in the de-duplication capability of the network and the learning efficiency of
the encoder, resulting in duplicate prediction and missed detection problems.
To solve this problem, we propose learnable differentiated encoding to
de-homogenize the queries, and at the same time, queries can communicate with
each other via differentiated encoding information, replacing the previous
self-attention among the queries. In addition, we used joint loss on the output
of the encoder that considered both location and confidence prediction to give
a higher-quality initialization for queries. Without cumbersome decoder
stacking and guaranteeing accuracy, our proposed end-to-end detection framework
was more concise and reduced the number of parameters by about 8% compared to
deformable DETR. Our method achieved excellent results on the challenging
CrowdHuman dataset with 93.6% average precision (AP), 39.2% MR-2, and 84.3% JI.
The performance overperformed previous SOTA methods, such as Iter-E2EDet
(Progressive End-to-End Object Detection) and MIP (One proposal, Multiple
predictions). In addition, our method is more robust in various scenarios with
different densities.","Yueming Huang, Chenrui Ma, Hao Zhou, Hao Wu, Guowu Yuan",2025-02-11 02:36:10.000000,arXiv,http://arxiv.org/abs/2502.07194v1,Computer Vision
928,Provably Efficient RLHF Pipeline: A Unified View from Contextual Bandits,"Reinforcement Learning from Human Feedback (RLHF) is a widely used approach
for aligning Large Language Models (LLMs) with human preferences. While recent
advancements have provided valuable insights into various stages and settings
of RLHF, a comprehensive theoretical understanding of the entire RLHF pipeline
remains lacking. Towards this end, we propose a unified framework for the RLHF
pipeline from the view of contextual bandits and provide provable efficiency
guarantees. In particular, we decompose the RLHF process into two distinct
stages: (post-)training and deployment, exploring both passive and active data
collection strategies during the training phase. By employing the Bradley-Terry
preference model with a linearly parameterized reward function, we reformulate
RLHF as a contextual preference bandit problem. We then develop novel
algorithms for each stage, demonstrating significant improvements over existing
approaches in both statistical and computational efficiency. Finally, we apply
our method to train and deploy Llama-3-8B-Instruct on the
Ultrafeedback-binarized dataset, and empirical results confirm the
effectiveness of our approach.","Long-Fei Li, Yu-Yang Qian, Peng Zhao, Zhi-Hua Zhou",2025-02-11 02:36:01.000000,arXiv,http://arxiv.org/abs/2502.07193v1,Machine Learning
929,OscNet: Machine Learning on CMOS Oscillator Networks,"Machine learning and AI have achieved remarkable advancements but at the cost
of significant computational resources and energy consumption. This has created
an urgent need for a novel, energy-efficient computational fabric to replace
the current computing pipeline. Recently, a promising approach has emerged by
mimicking spiking neurons in the brain and leveraging oscillators on CMOS for
direct computation. In this context, we propose a new and energy efficient
machine learning framework implemented on CMOS Oscillator Networks (OscNet). We
model the developmental processes of the prenatal brain's visual system using
OscNet, updating weights based on the biologically inspired Hebbian rule. This
same pipeline is then directly applied to standard machine learning tasks.
OscNet is a specially designed hardware and is inherently energy-efficient. Its
reliance on forward propagation alone for training further enhances its energy
efficiency while maintaining biological plausibility. Simulation validates our
designs of OscNet architectures. Experimental results demonstrate that Hebbian
learning pipeline on OscNet achieves performance comparable to or even
surpassing traditional machine learning algorithms, highlighting its potential
as a energy efficient and effective computational paradigm.","Wenxiao Cai, Thomas H. Lee",2025-02-11 02:32:32.000000,arXiv,http://arxiv.org/abs/2502.07192v1,Computer Vision
930,NanoVLMs: How small can we go and still make coherent Vision Language Models?,"Vision-Language Models (VLMs), such as GPT-4V and Llama 3.2 vision, have
garnered significant research attention for their ability to leverage Large
Language Models (LLMs) in multimodal tasks. However, their potential is
constrained by inherent challenges, including proprietary restrictions,
substantial computational demands, and limited accessibility. Smaller models,
such as GIT and BLIP, exhibit marked limitations, often failing to generate
coherent and consistent text beyond a few tokens, even with extensive training.
This underscores a pivotal inquiry: how small can a VLM be and still produce
fluent and consistent text? Drawing inspiration from the exceptional learning
process of 3-4 year old children, who rely heavily on visual cues for
understanding and communication, we introduce two novel datasets: ShortDesc
(featuring concise image descriptions) and LongDesc (containing more detailed
image descriptions). These datasets consist of image-text pairs where the text
is restricted to the simple vocabulary and syntax typically used by young
children, generated with a scaled- down model, GPT-4o. Using these datasets, we
demonstrate that it is possible to train VLMs that are significantly smaller,
up to 10 times smaller than state of the art(SOTA) small VLMs while maintaining
architectural simplicity. To evaluate the outputs, we leverage GPT-4o to grade
the text, as if stories written by students, on creativity, meaningfulness, and
consistency, assigning scores out of 10. This method addresses limitations of
standard benchmarks by accommodating unstructured outputs and providing a
multidimensional evaluation of the model capabilities. Our findings contribute
to the development of lightweight, accessible multimodal models for resource
constrained environments.","Mukund Agarwalla, Himanshu Kumar, Raj Dandekar, Rajat Dandekar, Sreedath Panat",2025-02-11 02:31:45.000000,arXiv,http://arxiv.org/abs/2502.07838v2,Computer Vision
931,Bag of Tricks for Inference-time Computation of LLM Reasoning,"With the advancement of large language models (LLMs), solving complex
reasoning tasks has gained increasing attention. Inference-time computation
methods (e.g., Best-of-N, beam search, et al.) are particularly valuable as
they can enhance reasoning performance without modifying model parameters or
requiring additional training. However, these techniques come with
implementation challenges, and most existing methods remain at the
proof-of-concept stage with limited practical adoption due to their
computational complexity and varying effectiveness across different tasks. In
this paper, we investigate and benchmark diverse inference-time computation
strategies across reasoning tasks of varying complexity. Since most current
methods rely on a proposer-verifier pipeline that first generates candidate
solutions (e.g., reasoning solutions) and then selects the best one based on
reward signals (e.g., RLHF rewards, process rewards), our research focuses on
optimizing both candidate solution generation (e.g., instructing prompts,
hyperparameters such as temperature and top-p) and reward mechanisms (e.g.,
self-evaluation, reward types). Through extensive experiments (more than 20,000
A100-80G GPU hours with over 1,000 experiments) across a variety of models
(e.g., Llama, Qwen, and Mistral families) of various sizes, our ablation
studies reveal that previously overlooked strategies can significantly enhance
performance (e.g., tuning temperature can improve reasoning task performance by
up to 5%). Furthermore, we establish a standardized benchmark for
inference-time computation by systematically evaluating six representative
methods across eight reasoning tasks. These findings provide a stronger
foundation for future research. The code is available at
https://github.com/usail-hkust/benchmark_inference_time_computation_LL","Fan Liu, Wenshuo Chao, Naiqiang Tan, Hao Liu",2025-02-11 02:31:11.000000,arXiv,http://arxiv.org/abs/2502.07191v2,Artificial Intelligence
932,Understanding LLMs' Fluid Intelligence Deficiency: An Analysis of the ARC Task,"While LLMs have exhibited strong performance on various NLP tasks, it is
noteworthy that most of these tasks rely on utilizing the vast amount of
knowledge encoded in LLMs' parameters, rather than solving new problems without
prior knowledge. In cognitive research, the latter ability is referred to as
fluid intelligence, which is considered to be critical for assessing human
intelligence. Recent research on fluid intelligence assessments has highlighted
significant deficiencies in LLMs' abilities. In this paper, we analyze the
challenges LLMs face in demonstrating fluid intelligence through controlled
experiments, using the most representative ARC task as an example. Our study
revealed three major limitations in existing LLMs: limited ability for skill
composition, unfamiliarity with abstract input formats, and the intrinsic
deficiency of left-to-right decoding. Our data and code can be found in
https://wujunjie1998.github.io/araoc-benchmark.github.io/.","Junjie Wu, Mo Yu, Lemao Liu, Dit-Yan Yeung, Jie Zhou",2025-02-11 02:31:09.000000,arXiv,http://arxiv.org/abs/2502.07190v1,Artificial Intelligence
933,Exploring Neural Network Pruning with Screening Methods,"Deep neural networks (DNNs) such as convolutional neural networks (CNNs) for
visual tasks, recurrent neural networks (RNNs) for sequence data, and
transformer models for rich linguistic or multimodal tasks, achieved
unprecedented performance on a wide range of tasks. The impressive performance
of modern DNNs is partially attributed to their sheer scale. The latest deep
learning models have tens to hundreds of millions of parameters which makes the
inference processes resource-intensive. The high computational complexity of
these networks prevents their deployment on resource-limited devices such as
mobile platforms, IoT devices, and edge computing systems because these devices
require energy-efficient and real-time processing capabilities. This paper
proposes and evaluates a network pruning framework that eliminates
non-essential parameters based on a statistical analysis of network component
significance across classification categories. The proposed method uses
screening methods coupled with a weighted scheme to assess connection and
channel contributions for unstructured and structured pruning which allows for
the elimination of unnecessary network elements without significantly degrading
model performance. Extensive experimental validation on real-world vision
datasets for both fully connected neural networks (FNNs) and CNNs has shown
that the proposed framework produces competitive lean networks compared to the
original networks. Moreover, the proposed framework outperforms state-of-art
network pruning methods in two out of three cases.","Mingyuan Wang, Yangzi Guo, Sida Liu, Yanwen Xiao",2025-02-11 02:31:04.000000,arXiv,http://arxiv.org/abs/2502.07189v1,Machine Learning
934,A Large-Scale Benchmark for Vietnamese Sentence Paraphrases,"This paper presents ViSP, a high-quality Vietnamese dataset for sentence
paraphrasing, consisting of 1.2M original-paraphrase pairs collected from
various domains. The dataset was constructed using a hybrid approach that
combines automatic paraphrase generation with manual evaluation to ensure high
quality. We conducted experiments using methods such as back-translation, EDA,
and baseline models like BART and T5, as well as large language models (LLMs),
including GPT-4o, Gemini-1.5, Aya, Qwen-2.5, and Meta-Llama-3.1 variants. To
the best of our knowledge, this is the first large-scale study on Vietnamese
paraphrasing. We hope that our dataset and findings will serve as a valuable
foundation for future research and applications in Vietnamese paraphrase tasks.","Sang Quang Nguyen, Kiet Van Nguyen",2025-02-11 02:30:21.000000,arXiv,http://arxiv.org/abs/2502.07188v1,Natural Language Processing
935,Local Regularizers Are Not Transductive Learners,"We partly resolve an open question raised by Asilis et al. (COLT 2024):
whether the algorithmic template of local regularization -- an intriguing
generalization of explicit regularization, a.k.a. structural risk minimization
-- suffices to learn all learnable multiclass problems. Specifically, we
provide a negative answer to this question in the transductive model of
learning. We exhibit a multiclass classification problem which is learnable in
both the transductive and PAC models, yet cannot be learned transductively by
any local regularizer. The corresponding hypothesis class, and our proof, are
based on principles from cryptographic secret sharing. We outline challenges in
extending our negative result to the PAC model, leaving open the tantalizing
possibility of a PAC/transductive separation with respect to local
regularization.","Sky Jafar, Julian Asilis, Shaddin Dughmi",2025-02-11 02:28:35.000000,arXiv,http://arxiv.org/abs/2502.07187v1,Machine Learning
936,Perceived Confidence Scoring for Data Annotation with Zero-Shot LLMs,"Zero-shot LLMs are now also used for textual classification tasks, e.g.,
sentiment/emotion detection of a given input as a sentence/article. However,
their performance can be suboptimal in such data annotation tasks. We introduce
a novel technique Perceived Confidence Scoring (PCS) that evaluates LLM's
confidence for its classification of an input by leveraging Metamorphic
Relations (MRs). The MRs generate semantically equivalent yet textually mutated
versions of the input. Following the principles of Metamorphic Testing (MT),
the mutated versions are expected to have annotation labels similar to the
input. By analyzing the consistency of LLM responses across these variations,
PCS computes a confidence score based on the frequency of predicted labels. PCS
can be used both for single LLM and multiple LLM settings (e.g., majority
voting). We introduce an algorithm Perceived Differential Evolution (PDE) that
determines the optimal weights assigned to the MRs and the LLMs for a
classification task. Empirical evaluation shows PCS significantly improves
zero-shot accuracy for Llama-3-8B-Instruct (4.96%) and Mistral-7B-Instruct-v0.3
(10.52%), with Gemma-2-9b-it showing a 9.39% gain. When combining all three
models, PCS significantly outperforms majority voting by 7.75%.","Sina Salimian, Gias Uddin, Most Husne Jahan, Shaina Raza",2025-02-11 02:25:44.000000,arXiv,http://arxiv.org/abs/2502.07186v1,Natural Language Processing
937,Refine Knowledge of Large Language Models via Adaptive Contrastive Learning,"How to alleviate the hallucinations of Large Language Models (LLMs) has
always been the fundamental goal pursued by the LLMs research community.
Looking through numerous hallucination-related studies, a mainstream category
of methods is to reduce hallucinations by optimizing the knowledge
representation of LLMs to change their output. Considering that the core focus
of these works is the knowledge acquired by models, and knowledge has long been
a central theme in human societal progress, we believe that the process of
models refining knowledge can greatly benefit from the way humans learn. In our
work, by imitating the human learning process, we design an Adaptive
Contrastive Learning strategy. Our method flexibly constructs different
positive and negative samples for contrastive learning based on LLMs' actual
mastery of knowledge. This strategy helps LLMs consolidate the correct
knowledge they already possess, deepen their understanding of the correct
knowledge they have encountered but not fully grasped, forget the incorrect
knowledge they previously learned, and honestly acknowledge the knowledge they
lack. Extensive experiments and detailed analyses on widely used datasets
demonstrate the effectiveness of our method.","Yinghui Li, Haojing Huang, Jiayi Kuang, Yangning Li, Shu-Yu Guo, Chao Qu, Xiaoyu Tan, Hai-Tao Zheng, Ying Shen, Philip S. Yu",2025-02-11 02:19:13.000000,arXiv,http://arxiv.org/abs/2502.07184v1,Natural Language Processing
938,RoboBERT: An End-to-end Multimodal Robotic Manipulation Model,"Embodied intelligence integrates multiple modalities, enabling agents to
understand images, language, and actions simultaneously. However, existing
models always depend on additional datasets or extensive pre-training to
maximize performance improvements, consuming abundant training time and
expensive hardware cost. To tackle this issue, we present RoboBERT, a novel
end-to-end robotic manipulation model integrated with a unique training
strategy. This model utilizes a CNN-based diffusion policy, enhancing and
stabilizing the effectiveness of this model by separating training processes
for different modalities. It also underscores the importance of data
augmentation, verifying various techniques to significantly boost performance.
Unlike models that depend on extra data or large foundation models, RoboBERT
achieves a highly competitive success rate while using only language-labeled
expert demonstrations and maintaining a relatively smaller model size.
Specifically, RoboBERT achieves an average length of 4.52 on the CALVIN
benchmark for \(ABCD \rightarrow D\) task, setting a new state-of-the-art
(SOTA) record. Furthermore, when tested on a real robot, the model demonstrates
superior performance, achieving a higher success rate than other methods
trained with the same data. We propose that these concepts and methodologies of
RoboBERT demonstrate extensive versatility and compatibility, contributing
significantly to the development of lightweight multimodal robotic models. The
code can be accessed on https://github.com/PeterWangsicheng/RoboBERT","Sicheng Wang, Jianhua Shan, Jianwei Zhang, Haozhang Gao, Hailiang Han, Yipeng Chen, Kang Wei, Chengkun Zhang, Kairos Wong, Jie Zhao, Lei Zhao, Bin Fang",2025-02-11 02:16:59.000000,arXiv,http://arxiv.org/abs/2502.07837v1,Robotics
939,Space-Aware Instruction Tuning: Dataset and Benchmark for Guide Dog Robots Assisting the Visually Impaired,"Guide dog robots offer promising solutions to enhance mobility and safety for
visually impaired individuals, addressing the limitations of traditional guide
dogs, particularly in perceptual intelligence and communication. With the
emergence of Vision-Language Models (VLMs), robots are now capable of
generating natural language descriptions of their surroundings, aiding in safer
decision-making. However, existing VLMs often struggle to accurately interpret
and convey spatial relationships, which is crucial for navigation in complex
environments such as street crossings. We introduce the Space-Aware Instruction
Tuning (SAIT) dataset and the Space-Aware Benchmark (SA-Bench) to address the
limitations of current VLMs in understanding physical environments. Our
automated data generation pipeline focuses on the virtual path to the
destination in 3D space and the surroundings, enhancing environmental
comprehension and enabling VLMs to provide more accurate guidance to visually
impaired individuals. We also propose an evaluation protocol to assess VLM
effectiveness in delivering walking guidance. Comparative experiments
demonstrate that our space-aware instruction-tuned model outperforms
state-of-the-art algorithms. We have fully open-sourced the SAIT dataset and
SA-Bench, along with the related code, at
https://github.com/byungokhan/Space-awareVLM","ByungOk Han, Woo-han Yun, Beom-Su Seo, Jaehong Kim",2025-02-11 02:14:49.000000,arXiv,http://arxiv.org/abs/2502.07183v2,Robotics
940,Tab2Visual: Overcoming Limited Data in Tabular Data Classification Using Deep Learning with Visual Representations,"This research addresses the challenge of limited data in tabular data
classification, particularly prevalent in domains with constraints like
healthcare. We propose Tab2Visual, a novel approach that transforms
heterogeneous tabular data into visual representations, enabling the
application of powerful deep learning models. Tab2Visual effectively addresses
data scarcity by incorporating novel image augmentation techniques and
facilitating transfer learning. We extensively evaluate the proposed approach
on diverse tabular datasets, comparing its performance against a wide range of
machine learning algorithms, including classical methods, tree-based ensembles,
and state-of-the-art deep learning models specifically designed for tabular
data. We also perform an in-depth analysis of factors influencing Tab2Visual's
performance. Our experimental results demonstrate that Tab2Visual outperforms
other methods in classification problems with limited tabular data.","Ahmed Mamdouh, Moumen El-Melegy, Samia Ali, Ron Kikinis",2025-02-11 02:12:29.000000,arXiv,http://arxiv.org/abs/2502.07181v1,Machine Learning
941,Improved YOLOv7 model for insulator defect detection,"Insulators are crucial insulation components and structural supports in power
grids, playing a vital role in the transmission lines. Due to temperature
fluctuations, internal stress, or damage from hail, insulators are prone to
injury. Automatic detection of damaged insulators faces challenges such as
diverse types, small defect targets, and complex backgrounds and shapes. Most
research for detecting insulator defects has focused on a single defect type or
a specific material. However, the insulators in the grid's transmission lines
have different colors and materials. Various insulator defects coexist, and the
existing methods have difficulty meeting the practical application
requirements. Current methods suffer from low detection accuracy and mAP0.5
cannot meet application requirements. This paper proposes an improved YOLOv7
model for multi-type insulator defect detection. First, our model replaces the
SPPCSPC module with the RFB module to enhance the network's feature extraction
capability. Second, a CA mechanism is introduced into the head part to enhance
the network's feature representation ability and to improve detection accuracy.
Third, a WIoU loss function is employed to address the low-quality samples
hindering model generalization during training, thereby improving the model's
overall performance. The experimental results indicate that the proposed model
exhibits enhancements across various performance metrics. Specifically, there
is a 1.6% advancement in mAP_0.5, a corresponding 1.6% enhancement in
mAP_0.5:0.95, a 1.3% elevation in precision, and a 1% increase in recall.
Moreover, the model achieves parameter reduction by 3.2 million, leading to a
decrease of 2.5 GFLOPS in computational cost. Notably, there is also an
improvement of 2.81 milliseconds in single-image detection speed.","Zhenyue Wang, Guowu Yuan, Hao Zhou, Yi Ma, Yutang Ma, Dong Chen",2025-02-11 02:09:30.000000,arXiv,http://arxiv.org/abs/2502.07179v1,Computer Vision
942,Online Aggregation of Trajectory Predictors,"Trajectory prediction, the task of forecasting future agent behavior from
past data, is central to safe and efficient autonomous driving. A diverse set
of methods (e.g., rule-based or learned with different architectures and
datasets) have been proposed, yet it is often the case that the performance of
these methods is sensitive to the deployment environment (e.g., how well the
design rules model the environment, or how accurately the test data match the
training data). Building upon the principled theory of online convex
optimization but also going beyond convexity and stationarity, we present a
lightweight and model-agnostic method to aggregate different trajectory
predictors online. We propose treating each individual trajectory predictor as
an ""expert"" and maintaining a probability vector to mix the outputs of
different experts. Then, the key technical approach lies in leveraging online
data -the true agent behavior to be revealed at the next timestep- to form a
convex-or-nonconvex, stationary-or-dynamic loss function whose gradient steers
the probability vector towards choosing the best mixture of experts. We
instantiate this method to aggregate trajectory predictors trained on different
cities in the NUSCENES dataset and show that it performs just as well, if not
better than, any singular model, even when deployed on the out-of-distribution
LYFT dataset.","Alex Tong, Apoorva Sharma, Sushant Veer, Marco Pavone, Heng Yang",2025-02-11 02:01:56.000000,arXiv,http://arxiv.org/abs/2502.07178v1,Robotics
943,MatrixKAN: Parallelized Kolmogorov-Arnold Network,"Kolmogorov-Arnold Networks (KAN) are a new class of neural network
architecture representing a promising alternative to the Multilayer Perceptron
(MLP), demonstrating improved expressiveness and interpretability. However,
KANs suffer from slow training and inference speeds relative to MLPs due in
part to the recursive nature of the underlying B-spline calculations. This
issue is particularly apparent with respect to KANs utilizing high-degree
B-splines, as the number of required non-parallelizable recursions is
proportional to B-spline degree. We solve this issue by proposing MatrixKAN, a
novel optimization that parallelizes B-spline calculations with matrix
representation and operations, thus significantly improving effective
computation time for models utilizing high-degree B-splines. In this paper, we
demonstrate the superior scaling of MatrixKAN's computation time relative to
B-spline degree. Further, our experiments demonstrate speedups of approximately
40x relative to KAN, with significant additional speedup potential for larger
datasets or higher spline degrees.","Cale Coffman, Lizhong Chen",2025-02-11 01:59:46.000000,arXiv,http://arxiv.org/abs/2502.07176v1,Machine Learning
944,Foreign-Object Detection in High-Voltage Transmission Line Based on Improved YOLOv8m,"The safe operation of high-voltage transmission lines ensures the power
grid's security. Various foreign objects attached to the transmission lines,
such as balloons, kites and nesting birds, can significantly affect the safe
and stable operation of high-voltage transmission lines. With the advancement
of computer vision technology, periodic automatic inspection of foreign objects
is efficient and necessary. Existing detection methods have low accuracy
because foreign objects at-tached to the transmission lines are complex,
including occlusions, diverse object types, significant scale variations, and
complex backgrounds. In response to the practical needs of the Yunnan Branch of
China Southern Power Grid Co., Ltd., this paper proposes an improved
YOLOv8m-based model for detecting foreign objects on transmission lines.
Experiments are conducted on a dataset collected from Yunnan Power Grid. The
proposed model enhances the original YOLOv8m by in-corporating a Global
Attention Module (GAM) into the backbone to focus on occluded foreign objects,
replacing the SPPF module with the SPPCSPC module to augment the model's
multiscale feature extraction capability, and introducing the Focal-EIoU loss
function to address the issue of high- and low-quality sample imbalances. These
improvements accelerate model convergence and enhance detection accuracy. The
experimental results demonstrate that our proposed model achieves a 2.7%
increase in mAP_0.5, a 4% increase in mAP_0.5:0.95, and a 6% increase in
recall.","Zhenyue Wang, Guowu Yuan, Hao Zhou, Yi Ma, Yutang Ma",2025-02-11 01:58:32.000000,arXiv,http://arxiv.org/abs/2502.07175v1,Computer Vision
945,Advancing Precision Oncology Through Modeling of Longitudinal and Multimodal Data,"Cancer evolves continuously over time through a complex interplay of genetic,
epigenetic, microenvironmental, and phenotypic changes. This dynamic behavior
drives uncontrolled cell growth, metastasis, immune evasion, and therapy
resistance, posing challenges for effective monitoring and treatment. However,
today's data-driven research in oncology has primarily focused on
cross-sectional analysis using data from a single modality, limiting the
ability to fully characterize and interpret the disease's dynamic
heterogeneity. Advances in multiscale data collection and computational methods
now enable the discovery of longitudinal multimodal biomarkers for precision
oncology. Longitudinal data reveal patterns of disease progression and
treatment response that are not evident from single-timepoint data, enabling
timely abnormality detection and dynamic treatment adaptation. Multimodal data
integration offers complementary information from diverse sources for more
precise risk assessment and targeting of cancer therapy. In this review, we
survey methods of longitudinal and multimodal modeling, highlighting their
synergy in providing multifaceted insights for personalized care tailored to
the unique characteristics of a patient's cancer. We summarize the current
challenges and future directions of longitudinal multimodal analysis in
advancing precision oncology.","Luoting Zhuang, Stephen H. Park, Steven J. Skates, Ashley E. Prosper, Denise R. Aberle, William Hsu",2025-02-11 01:44:51.000000,arXiv,http://arxiv.org/abs/2502.07836v1,Other
946,SemiHMER: Semi-supervised Handwritten Mathematical Expression Recognition using pseudo-labels,"In recent years, deep learning with Convolutional Neural Networks (CNNs) has
achieved remarkable results in the field of HMER (Handwritten Mathematical
Expression Recognition). However, it remains challenging to improve performance
with limited labeled training data. This paper presents, for the first time, a
simple yet effective semi-supervised HMER framework by introducing dual-branch
semi-supervised learning. Specifically, we simplify the conventional deep
co-training from consistency regularization to cross-supervised learning, where
the prediction of one branch is used as a pseudo-label to supervise the other
branch directly end-to-end. Considering that the learning of the two branches
tends to converge in the later stages of model optimization, we also
incorporate a weak-to-strong strategy by applying different levels of
augmentation to each branch, which behaves like expanding the training data and
improving the quality of network training. Meanwhile, We propose a novel
module, Global Dynamic Counting Module(GDCM), to enhance the performance of the
HMER decoder, which alleviates recognition inaccuracies in long-distance
formula recognition and the occurrence of repeated characters. We release our
code at https://github.com/chenkehua/SemiHMER.","Kehua Chen, Haoyang Shen",2025-02-11 01:39:11.000000,arXiv,http://arxiv.org/abs/2502.07172v1,Computer Vision
947,Enhancing Robustness Of Digital Shadow For CO2 Storage Monitoring With Augmented Rock Physics Modeling,"To meet climate targets, the IPCC underscores the necessity of technologies
capable of removing gigatonnes of CO2 annually, with Geological Carbon Storage
(GCS) playing a central role. GCS involves capturing CO2 and injecting it into
deep geological formations for long-term storage, requiring precise monitoring
to ensure containment and prevent leakage. Time-lapse seismic imaging is
essential for tracking CO2 migration but often struggles to capture the
complexities of multi-phase subsurface flow. Digital Shadows (DS), leveraging
machine learning-driven data assimilation techniques such as nonlinear Bayesian
filtering and generative AI, provide a more detailed, uncertainty-aware
monitoring approach. By incorporating uncertainties in reservoir properties, DS
frameworks improve CO2 migration forecasts, reducing risks in GCS operations.
However, data assimilation depends on assumptions regarding reservoir
properties, rock physics models, and initial conditions, which, if inaccurate,
can compromise prediction reliability. This study demonstrates that augmenting
forecast ensembles with diverse rock physics models mitigates the impact of
incorrect assumptions and improves predictive accuracy, particularly in
differentiating uniform versus patchy saturation models.","Abhinav Prakash Gahlot, Felix J. Herrmann",2025-02-11 01:33:35.000000,arXiv,http://arxiv.org/abs/2502.07171v1,Other
948,Advancing Geological Carbon Storage Monitoring With 3d Digital Shadow Technology,"Geological Carbon Storage (GCS) is a key technology for achieving global
climate goals by capturing and storing CO2 in deep geological formations. Its
effectiveness and safety rely on accurate monitoring of subsurface CO2
migration using advanced time-lapse seismic imaging. A Digital Shadow framework
integrates field data, including seismic and borehole measurements, to track
CO2 saturation over time. Machine learning-assisted data assimilation
techniques, such as generative AI and nonlinear ensemble Bayesian filtering,
update a digital model of the CO2 plume while incorporating uncertainties in
reservoir properties. Compared to 2D approaches, 3D monitoring enhances the
spatial accuracy of GCS assessments, capturing the full extent of CO2
migration. This study extends the uncertainty-aware 2D Digital Shadow framework
by incorporating 3D seismic imaging and reservoir modeling, improving
decision-making and risk mitigation in CO2 storage projects.","Abhinav Prakash Gahlot, Rafael Orozco, Felix J. Herrmann",2025-02-11 01:25:57.000000,arXiv,http://arxiv.org/abs/2502.07169v1,Other
949,Bayesian Optimization for Building Social-Influence-Free Consensus,"We introduce Social Bayesian Optimization (SBO), a vote-efficient algorithm
for consensus-building in collective decision-making. In contrast to
single-agent scenarios, collective decision-making encompasses group dynamics
that may distort agents' preference feedback, thereby impeding their capacity
to achieve a social-influence-free consensus -- the most preferable decision
based on the aggregated agent utilities. We demonstrate that under mild
rationality axioms, reaching social-influence-free consensus using noisy
feedback alone is impossible. To address this, SBO employs a dual voting
system: cheap but noisy public votes (e.g., show of hands in a meeting), and
more accurate, though expensive, private votes (e.g., one-to-one interview). We
model social influence using an unknown social graph and leverage the dual
voting system to efficiently learn this graph. Our theoretical findigns show
that social graph estimation converges faster than the black-box estimation of
agents' utilities, allowing us to reduce reliance on costly private votes early
in the process. This enables efficient consensus-building primarily through
noisy public votes, which are debiased based on the estimated social graph to
infer social-influence-free feedback. We validate the efficacy of SBO across
multiple real-world applications, including thermal comfort, team building,
travel negotiation, and energy trading collaboration.","Masaki Adachi, Siu Lun Chau, Wenjie Xu, Anurag Singh, Michael A. Osborne, Krikamol Muandet",2025-02-11 01:20:32.000000,arXiv,http://arxiv.org/abs/2502.07166v1,Multi-Agent Systems
950,Bridging LLM-Generated Code and Requirements: Reverse Generation technique and SBC Metric for Developer Insights,"The rise of Large Language Models (LLMs) in software engineering,
particularly in code generation, has garnered significant attention. However,
assessing the quality of AI-generated code remains a challenge due to the
inherent complexity of programming tasks and the lack of robust evaluation
metrics that align well with human judgment. Traditional token-based metrics
such as BLEU and ROUGE, while commonly used in natural language processing,
exhibit weak correlations with human assessments in code intelligence and
verification tasks. Furthermore, these metrics are primarily research focused
and are not designed for seamless integration into the software development
lifecycle, limiting their practical utility for developers seeking to improve
code quality and security.
  AI-assisted coding has been shown to be more beneficial for senior
developers, as they possess the expertise to critically evaluate the generated
code for correctness, completeness, and compliance. In contrast, junior
developers may struggle to identify hallucinations, missing functionality, or
incorrect logic in AI-generated code. To bridge this gap, This paper introduces
a novel scoring mechanism called the SBC score, which is based on a reverse
generation technique that leverages the natural language generation
capabilities of LLMs. Unlike direct code analysis, our approach reconstructs
system requirements from AI-generated code and compares them with the original
specifications to quantify accuracy. The SBC score combines semantic
similarity, BLEU, and completeness analysis, providing actionable insights to
developers by highlighting missing features and hallucinations. Our code and
datasets are available on GitHub",Ahilan Ayyachamy Nadar Ponnusamy,2025-02-11 01:12:11.000000,arXiv,http://arxiv.org/abs/2502.07835v1,Other
951,"Don't Just Demo, Teach Me the Principles: A Principle-Based Multi-Agent Prompting Strategy for Text Classification","We present PRINCIPLE-BASED PROMPTING, a simple but effective multi-agent
prompting strategy for text classification. It first asks multiple LLM agents
to independently generate candidate principles based on analysis of
demonstration samples with or without labels, consolidates them into final
principles via a finalizer agent, and then sends them to a classifier agent to
perform downstream classification tasks. Extensive experiments on binary and
multi-class classification datasets with different sizes of LLMs show that our
approach not only achieves substantial performance gains (1.55% - 19.37%) over
zero-shot prompting on macro-F1 score but also outperforms other strong
baselines (CoT and stepback prompting). Principles generated by our approach
help LLMs perform better on classification tasks than human crafted principles
on two private datasets. Our multi-agent PRINCIPLE-BASED PROMPTING approach
also shows on-par or better performance compared to demonstration-based
few-shot prompting approaches, yet with substantially lower inference costs.
Ablation studies show that label information and the multi-agent cooperative
LLM framework play an important role in generating high-quality principles to
facilitate downstream classification tasks.","Peipei Wei, Dimitris Dimitriadis, Yan Xu, Mingwei Shen",2025-02-11 01:10:13.000000,arXiv,http://arxiv.org/abs/2502.07165v1,Natural Language Processing
952,Does Training on Synthetic Data Make Models Less Robust?,"An increasingly common practice is to train large language models (LLMs)
using synthetic data. Often this synthetic data is produced by the same or
similar LLMs as those it is being used to train. This raises the question of
whether the synthetic data might in fact exacerbate certain ""blindspots"" by
reinforcing heuristics that the LLM already encodes. In this paper, we conduct
simulated experiments on the natural language inference (NLI) task with
Llama-2-7B-hf models. We use MultiNLI as the general task and HANS, a targeted
evaluation set designed to measure the presence of specific heuristic
strategies for NLI, as our ""blindspot"" task. Our goal is to determine whether
performance disparities between the general and blind spot tasks emerge. Our
results indicate that synthetic data does not reinforce blindspots in the way
we expected. Specifically, we see that, while fine-tuning with synthetic data
doesn't necessarily reduce the use of the heuristic, it also does not make it
worse as we hypothesized.","Lingze Zhang, Ellie Pavlick",2025-02-11 01:03:33.000000,arXiv,http://arxiv.org/abs/2502.07164v1,Natural Language Processing
953,A Survey on Mamba Architecture for Vision Applications,"Transformers have become foundational for visual tasks such as object
detection, semantic segmentation, and video understanding, but their quadratic
complexity in attention mechanisms presents scalability challenges. To address
these limitations, the Mamba architecture utilizes state-space models (SSMs)
for linear scalability, efficient processing, and improved contextual
awareness. This paper investigates Mamba architecture for visual domain
applications and its recent advancements, including Vision Mamba (ViM) and
VideoMamba, which introduce bidirectional scanning, selective scanning
mechanisms, and spatiotemporal processing to enhance image and video
understanding. Architectural innovations like position embeddings, cross-scan
modules, and hierarchical designs further optimize the Mamba framework for
global and local feature extraction. These advancements position Mamba as a
promising architecture in computer vision research and applications.","Fady Ibrahim, Guangjun Liu, Guanghui Wang",2025-02-11 00:59:30.000000,arXiv,http://arxiv.org/abs/2502.07161v1,Computer Vision
954,HDCompression: Hybrid-Diffusion Image Compression for Ultra-Low Bitrates,"Image compression under ultra-low bitrates remains challenging for both
conventional learned image compression (LIC) and generative vector-quantized
(VQ) modeling. Conventional LIC suffers from severe artifacts due to heavy
quantization, while generative VQ modeling gives poor fidelity due to the
mismatch between learned generative priors and specific inputs. In this work,
we propose Hybrid-Diffusion Image Compression (HDCompression), a dual-stream
framework that utilizes both generative VQ-modeling and diffusion models, as
well as conventional LIC, to achieve both high fidelity and high perceptual
quality. Different from previous hybrid methods that directly use pre-trained
LIC models to generate low-quality fidelity-preserving information from heavily
quantized latent, we use diffusion models to extract high-quality complimentary
fidelity information from the ground-truth input, which can enhance the system
performance in several aspects: improving indices map prediction, enhancing the
fidelity-preserving output of the LIC stream, and refining conditioned image
reconstruction with VQ-latent correction. In addition, our diffusion model is
based on a dense representative vector (DRV), which is lightweight with very
simple sampling schedulers. Extensive experiments demonstrate that our
HDCompression outperforms the previous conventional LIC, generative
VQ-modeling, and hybrid frameworks in both quantitative metrics and qualitative
visualization, providing balanced robust compression performance at ultra-low
bitrates.","Lei Lu, Yize Li, Yanzhi Wang, Wei Wang, Wei Jiang",2025-02-11 00:56:44.000000,arXiv,http://arxiv.org/abs/2502.07160v1,Computer Vision
955,Early Risk Prediction of Pediatric Cardiac Arrest from Electronic Health Records via Multimodal Fused Transformer,"Early prediction of pediatric cardiac arrest (CA) is critical for timely
intervention in high-risk intensive care settings. We introduce PedCA-FT, a
novel transformer-based framework that fuses tabular view of EHR with the
derived textual view of EHR to fully unleash the interactions of
high-dimensional risk factors and their dynamics. By employing dedicated
transformer modules for each modality view, PedCA-FT captures complex temporal
and contextual patterns to produce robust CA risk estimates. Evaluated on a
curated pediatric cohort from the CHOA-CICU database, our approach outperforms
ten other artificial intelligence models across five key performance metrics
and identifies clinically meaningful risk factors. These findings underscore
the potential of multimodal fusion techniques to enhance early CA detection and
improve patient care.","Jiaying Lu, Stephanie R. Brown, Songyuan Liu, Shifan Zhao, Kejun Dong, Del Bold, Michael Fundora, Alaa Aljiffry, Alex Fedorov, Jocelyn Grunwell, Xiao Hu",2025-02-11 00:53:36.000000,arXiv,http://arxiv.org/abs/2502.07158v1,Machine Learning
956,MEMHD: Memory-Efficient Multi-Centroid Hyperdimensional Computing for Fully-Utilized In-Memory Computing Architectures,"The implementation of Hyperdimensional Computing (HDC) on In-Memory Computing
(IMC) architectures faces significant challenges due to the mismatch between
highdimensional vectors and IMC array sizes, leading to inefficient memory
utilization and increased computation cycles. This paper presents MEMHD, a
Memory-Efficient Multi-centroid HDC framework designed to address these
challenges. MEMHD introduces a clustering-based initialization method and
quantization aware iterative learning for multi-centroid associative memory.
Through these approaches and its overall architecture, MEMHD achieves a
significant reduction in memory requirements while maintaining or improving
classification accuracy. Our approach achieves full utilization of IMC arrays
and enables one-shot (or few-shot) associative search. Experimental results
demonstrate that MEMHD outperforms state-of-the-art binary HDC models,
achieving up to 13.69% higher accuracy with the same memory usage, or 13.25x
more memory efficiency at the same accuracy level. Moreover, MEMHD reduces
computation cycles by up to 80x and array usage by up to 71x compared to
baseline IMC mapping methods when mapped to 128x128 IMC arrays, while
significantly improving energy and computation cycle efficiency.","Do Yeong Kang, Yeong Hwan Oh, Chanwook Hwang, Jinhee Kim, Kang Eun Jeon, Jong Hwan Ko",2025-02-11 00:53:15.000000,arXiv,http://arxiv.org/abs/2502.07834v1,Other
957,Explaining 3D Computed Tomography Classifiers with Counterfactuals,"Counterfactual explanations in medical imaging are critical for understanding
the predictions made by deep learning models. We extend the Latent Shift
counterfactual generation method from 2D applications to 3D computed tomography
(CT) scans. We address the challenges associated with 3D data, such as limited
training samples and high memory demands, by implementing a slice-based
approach. This method leverages a 2D encoder trained on CT slices, which are
subsequently combined to maintain 3D context. We demonstrate this technique on
two models for clinical phenotype prediction and lung segmentation. Our
approach is both memory-efficient and effective for generating interpretable
counterfactuals in high-resolution 3D medical imaging.","Joseph Paul Cohen, Louis Blankemeier, Akshay Chaudhari",2025-02-11 00:44:20.000000,arXiv,http://arxiv.org/abs/2502.07156v1,Computer Vision
958,Rethinking Fine-Tuning when Scaling Test-Time Compute: Limiting Confidence Improves Mathematical Reasoning,"Recent progress in large language models (LLMs) highlights the power of
scaling test-time compute to achieve strong performance on complex tasks, such
as mathematical reasoning and code generation. This raises a critical question:
how should model training be modified to optimize performance under a
subsequent test-time compute strategy and budget? To explore this, we focus on
pass@N, a simple test-time strategy that searches for a correct answer in $N$
independent samples. We show, surprisingly, that training with cross-entropy
(CE) loss can be ${\it misaligned}$ with pass@N in that pass@N accuracy ${\it
decreases}$ with longer training. We explain the origins of this misalignment
in terms of model overconfidence induced by CE, and experimentally verify our
prediction of overconfidence as an impediment to scaling test-time compute via
pass@N. Furthermore we suggest a principled, modified training loss that is
better aligned to pass@N by limiting model confidence and rescuing pass@N test
performance. Our algorithm demonstrates improved mathematical reasoning on MATH
and MiniF2F benchmarks under several scenarios: (1) providing answers to math
questions; and (2) proving theorems by searching over proof trees of varying
shapes. Overall our work underscores the importance of co-designing two
traditionally separate phases of LLM development: training-time protocols and
test-time search and reasoning strategies.","Feng Chen, Allan Raventos, Nan Cheng, Surya Ganguli, Shaul Druckmann",2025-02-11 00:33:31.000000,arXiv,http://arxiv.org/abs/2502.07154v1,Machine Learning
959,Feature Importance Depends on Properties of the Data: Towards Choosing the Correct Explanations for Your Data and Decision Trees based Models,"In order to ensure the reliability of the explanations of machine learning
models, it is crucial to establish their advantages and limits and in which
case each of these methods outperform. However, the current understanding of
when and how each method of explanation can be used is insufficient. To fill
this gap, we perform a comprehensive empirical evaluation by synthesizing
multiple datasets with the desired properties. Our main objective is to assess
the quality of feature importance estimates provided by local explanation
methods, which are used to explain predictions made by decision tree-based
models. By analyzing the results obtained from synthetic datasets as well as
publicly available binary classification datasets, we observe notable
disparities in the magnitude and sign of the feature importance estimates
generated by these methods. Moreover, we find that these estimates are
sensitive to specific properties present in the data. Although some model
hyper-parameters do not significantly influence feature importance assignment,
it is important to recognize that each method of explanation has limitations in
specific contexts. Our assessment highlights these limitations and provides
valuable insight into the suitability and reliability of different explanatory
methods in various scenarios.","Célia Wafa Ayad, Thomas Bonnier, Benjamin Bosch, Sonali Parbhoo, Jesse Read",2025-02-11 00:29:55.000000,arXiv,http://arxiv.org/abs/2502.07153v1,Machine Learning
960,Conditional Distribution Quantization in Machine Learning,"Conditional expectation \mathbb{E}(Y \mid X) often fails to capture the
complexity of multimodal conditional distributions \mathcal{L}(Y \mid X). To
address this, we propose using n-point conditional quantizations--functional
mappings of X that are learnable via gradient descent--to approximate
\mathcal{L}(Y \mid X). This approach adapts Competitive Learning Vector
Quantization (CLVQ), tailored for conditional distributions. It goes beyond
single-valued predictions by providing multiple representative points that
better reflect multimodal structures. It enables the approximation of the true
conditional law in the Wasserstein distance. The resulting framework is
theoretically grounded and useful for uncertainty quantification and multimodal
data generation tasks. For example, in computer vision inpainting tasks,
multiple plausible reconstructions may exist for the same partially observed
input image X. We demonstrate the effectiveness of our approach through
experiments on synthetic and real-world datasets.","Blaise Delattre, Sylvain Delattre, Alexandre Vérine, Alexandre Allauzen",2025-02-11 00:28:24.000000,arXiv,http://arxiv.org/abs/2502.07151v1,Machine Learning
961,SHARP: Accelerating Language Model Inference by SHaring Adjacent layers with Recovery Parameters,"While Large language models (LLMs) have advanced natural language processing
tasks, their growing computational and memory demands make deployment on
resource-constrained devices like mobile phones increasingly challenging. In
this paper, we propose SHARP (SHaring Adjacent Layers with Recovery
Parameters), a novel approach to accelerate LLM inference by sharing parameters
across adjacent layers, thus reducing memory load overhead, while introducing
low-rank recovery parameters to maintain performance. Inspired by observations
that consecutive layers have similar outputs, SHARP employs a two-stage
recovery process: Single Layer Warmup (SLW), and Supervised Fine-Tuning (SFT).
The SLW stage aligns the outputs of the shared layers using L_2 loss, providing
a good initialization for the following SFT stage to further restore the model
performance. Extensive experiments demonstrate that SHARP can recover the
model's perplexity on various in-distribution tasks using no more than 50k
fine-tuning data while reducing the number of stored MLP parameters by 38% to
65%. We also conduct several ablation studies of SHARP and show that replacing
layers towards the later parts of the model yields better performance
retention, and that different recovery parameterizations perform similarly when
parameter counts are matched. Furthermore, SHARP saves 42.8% in model storage
and reduces the total inference time by 42.2% compared to the original
Llama2-7b model on mobile devices. Our results highlight SHARP as an efficient
solution for reducing inference costs in deploying LLMs without the need for
pretraining-scale resources.","Yiping Wang, Hanxian Huang, Yifang Chen, Jishen Zhao, Simon Shaolei Du, Yuandong Tian",2025-02-11 00:21:40.000000,arXiv,http://arxiv.org/abs/2502.07832v1,Machine Learning
962,Mesh2SSM++: A Probabilistic Framework for Unsupervised Learning of Statistical Shape Model of Anatomies from Surface Meshes,"Anatomy evaluation is crucial for understanding the physiological state,
diagnosing abnormalities, and guiding medical interventions. Statistical shape
modeling (SSM) is vital in this process. By enabling the extraction of
quantitative morphological shape descriptors from MRI and CT scans, SSM
provides comprehensive descriptions of anatomical variations within a
population. However, the effectiveness of SSM in anatomy evaluation hinges on
the quality and robustness of the shape models. While deep learning techniques
show promise in addressing these challenges by learning complex nonlinear
representations of shapes, existing models still have limitations and often
require pre-established shape models for training. To overcome these issues, we
propose Mesh2SSM++, a novel approach that learns to estimate correspondences
from meshes in an unsupervised manner. This method leverages unsupervised,
permutation-invariant representation learning to estimate how to deform a
template point cloud into subject-specific meshes, forming a
correspondence-based shape model. Additionally, our probabilistic formulation
allows learning a population-specific template, reducing potential biases
associated with template selection. A key feature of Mesh2SSM++ is its ability
to quantify aleatoric uncertainty, which captures inherent data variability and
is essential for ensuring reliable model predictions and robust decision-making
in clinical tasks, especially under challenging imaging conditions. Through
extensive validation across diverse anatomies, evaluation metrics, and
downstream tasks, we demonstrate that Mesh2SSM++ outperforms existing methods.
Its ability to operate directly on meshes, combined with computational
efficiency and interpretability through its probabilistic framework, makes it
an attractive alternative to traditional and deep learning-based SSM
approaches.","Krithika Iyer, Mokshagna Sai Teja Karanam, Shireen Elhabian",2025-02-11 00:19:23.000000,arXiv,http://arxiv.org/abs/2502.07145v1,Computer Vision
963,Ask Patients with Patience: Enabling LLMs for Human-Centric Medical Dialogue with Grounded Reasoning,"Accurate and efficient diagnosis in online medical consultations remains a
challenge for current large language models. These models often rely on
single-turn interactions and lack the ability to refine their predictions
through follow-up questions. Additionally, their responses frequently contain
complex medical terminology, making them less accessible to non-medical users
and creating barriers to effective communication. In this paper, we introduce
Ask Patients with Patience (APP), the first multi-turn dialogue that enables
LLMs to iteratively refine diagnoses based on grounded reasoning. By
integrating medical guidelines and entropy minimization, APP improves both
diagnostic accuracy and efficiency. Furthermore, it features human-centric
communication that bridges the gap between user comprehension and medical
terminology, significantly enhancing user accessibility and engagement. We
evaluated APP using a subset of the ReMeDi dataset, comparing it with
single-turn and traditional multi-turn LLM baselines. APP achieved higher
similarity scores in diagnosis predictions, demonstrating better alignment with
ground truth diagnoses. Entropy analysis showed that APP reduces diagnostic
uncertainty more rapidly across iterations, increasing confidence in its
predictions. APP also excels in user accessibility and empathy, further
bridging the gap between complex medical language and user understanding. Code
will be released at: https://github.com/SuperMedIntel/AskPatients.","Jiayuan Zhu, Junde Wu",2025-02-11 00:13:52.000000,arXiv,http://arxiv.org/abs/2502.07143v1,Natural Language Processing
964,Small steps no more: Global convergence of stochastic gradient bandits for arbitrary learning rates,"We provide a new understanding of the stochastic gradient bandit algorithm by
showing that it converges to a globally optimal policy almost surely using
\emph{any} constant learning rate. This result demonstrates that the stochastic
gradient algorithm continues to balance exploration and exploitation
appropriately even in scenarios where standard smoothness and noise control
assumptions break down. The proofs are based on novel findings about action
sampling rates and the relationship between cumulative progress and noise, and
extend the current understanding of how simple stochastic gradient methods
behave in bandit settings.","Jincheng Mei, Bo Dai, Alekh Agarwal, Sharan Vaswani, Anant Raj, Csaba Szepesvari, Dale Schuurmans",2025-02-11 00:12:04.000000,arXiv,http://arxiv.org/abs/2502.07141v1,Machine Learning
965,Captured by Captions: On Memorization and its Mitigation in CLIP Models,"Multi-modal models, such as CLIP, have demonstrated strong performance in
aligning visual and textual representations, excelling in tasks like image
retrieval and zero-shot classification. Despite this success, the mechanisms by
which these models utilize training data, particularly the role of
memorization, remain unclear. In uni-modal models, both supervised and
self-supervised, memorization has been shown to be essential for
generalization. However, it is not well understood how these findings would
apply to CLIP, which incorporates elements from both supervised learning via
captions that provide a supervisory signal similar to labels, and from
self-supervised learning via the contrastive objective. To bridge this gap in
understanding, we propose a formal definition of memorization in CLIP (CLIPMem)
and use it to quantify memorization in CLIP models. Our results indicate that
CLIP's memorization behavior falls between the supervised and self-supervised
paradigms, with ""mis-captioned"" samples exhibiting highest levels of
memorization. Additionally, we find that the text encoder contributes more to
memorization than the image encoder, suggesting that mitigation strategies
should focus on the text domain. Building on these insights, we propose
multiple strategies to reduce memorization while at the same time improving
utility--something that had not been shown before for traditional learning
paradigms where reducing memorization typically results in utility decrease.","Wenhao Wang, Adam Dziedzic, Grace C. Kim, Michael Backes, Franziska Boenisch",2025-02-11 00:11:13.000000,arXiv,http://arxiv.org/abs/2502.07830v1,Computer Vision
966,Few-Shot Multi-Human Neural Rendering Using Geometry Constraints,"We present a method for recovering the shape and radiance of a scene
consisting of multiple people given solely a few images. Multi-human scenes are
complex due to additional occlusion and clutter. For single-human settings,
existing approaches using implicit neural representations have achieved
impressive results that deliver accurate geometry and appearance. However, it
remains challenging to extend these methods for estimating multiple humans from
sparse views. We propose a neural implicit reconstruction method that addresses
the inherent challenges of this task through the following contributions:
First, we propose to use geometry constraints by exploiting pre-computed meshes
using a human body model (SMPL). Specifically, we regularize the signed
distances using the SMPL mesh and leverage bounding boxes for improved
rendering. Second, we propose a ray regularization scheme to minimize rendering
inconsistencies, and a saturation regularization for robust optimization in
variable illumination. Extensive experiments on both real and synthetic
datasets demonstrate the benefits of our approach and show state-of-the-art
performance against existing neural reconstruction methods.","Qian li, Victoria Fernàndez Abrevaya, Franck Multon, Adnane Boukhayma",2025-02-11 00:10:58.000000,arXiv,http://arxiv.org/abs/2502.07140v1,Computer Vision
967,Language-TPP: Integrating Temporal Point Processes with Language Models for Event Analysis,"Temporal Point Processes (TPPs) have been widely used for event sequence
modeling, but they often struggle to incorporate rich textual event
descriptions effectively. Conversely, while Large Language Models (LLMs) have
been shown remarkable capabilities in processing textual data, they lack
mechanisms for handling temporal dynamics. To bridge this gap, we introduce
Language-TPP, a unified framework that integrates TPPs with LLMs for enhanced
event sequence modeling. Language-TPP introduces a novel temporal encoding
mechanism that converts continuous time intervals into specialized byte-tokens,
enabling seamless integration with standard LLM architectures. This approach
allows Language-TPP to achieve state-of-the-art performance across multiple TPP
tasks, including event time prediction, type prediction, and intensity
estimation, on five datasets. Additionally, we demonstrate that incorporating
temporal information significantly improves the quality of generated event
descriptions.","Quyu Kong, Yixuan Zhang, Yang Liu, Panrong Tong, Enqi Liu, Feng Zhou",2025-02-11 00:09:45.000000,arXiv,http://arxiv.org/abs/2502.07139v1,Natural Language Processing
968,Towards a Robust Framework for Multimodal Hate Detection: A Study on Video vs. Image-based Content,"Social media platforms enable the propagation of hateful content across
different modalities such as textual, auditory, and visual, necessitating
effective detection methods. While recent approaches have shown promise in
handling individual modalities, their effectiveness across different modality
combinations remains unexplored. This paper presents a systematic analysis of
fusion-based approaches for multimodal hate detection, focusing on their
performance across video and image-based content. Our comprehensive evaluation
reveals significant modality-specific limitations: while simple embedding
fusion achieves state-of-the-art performance on video content (HateMM dataset)
with a 9.9% points F1-score improvement, it struggles with complex image-text
relationships in memes (Hateful Memes dataset). Through detailed ablation
studies and error analysis, we demonstrate how current fusion approaches fail
to capture nuanced cross-modal interactions, particularly in cases involving
benign confounders. Our findings provide crucial insights for developing more
robust hate detection systems and highlight the need for modality-specific
architectural considerations. The code is available at
https://github.com/gak97/Video-vs-Meme-Hate.","Girish A. Koushik, Diptesh Kanojia, Helen Treharne",2025-02-11 00:07:40.000000,arXiv,http://arxiv.org/abs/2502.07138v1,Computer Vision
969,A Safe Hybrid Control Framework for Car-like Robot with Guaranteed Global Path-Invariance using a Control Barrier Function,"This work proposes a hybrid framework for car-like robots with obstacle
avoidance, global convergence, and safety, where safety is interpreted as path
invariance, namely, once the robot converges to the path, it never leaves the
path. Given a priori obstacle-free feasible path where obstacles can be around
the path, the task is to avoid obstacles while reaching the path and then
staying on the path without leaving it. The problem is solved in two stages.
Firstly, we define a ``tight'' obstacle-free neighborhood along the path and
design a local controller to ensure convergence to the path and path
invariance. The control barrier function technology is involved in the control
design to steer the system away from its singularity points, where the local
path invariant controller is not defined. Secondly, we design a hybrid control
framework that integrates this local path-invariant controller with any global
tracking controller from the existing literature without path invariance
guarantee, ensuring convergence from any position to the desired path, namely,
global convergence. This framework guarantees path invariance and robustness to
sensor noise. Detailed simulation results affirm the effectiveness of the
proposed scheme.","Nan Wang, Adeel Akhtar, Ricardo G. Sanfelice",2025-02-11 00:06:01.000000,arXiv,http://arxiv.org/abs/2502.07136v1,Robotics
970,One-Shot Learning for k-SAT,"Consider a $k$-SAT formula $\Phi$ where every variable appears at most $d$
times, and let $\sigma$ be a satisfying assignment of $\Phi$ sampled
proportionally to $e^{\beta m(\sigma)}$ where $m(\sigma)$ is the number of
variables set to true and $\beta$ is a real parameter. Given $\Phi$ and
$\sigma$, can we learn the value of $\beta$ efficiently?
  This problem falls into a recent line of works about single-sample
(""one-shot"") learning of Markov random fields. The $k$-SAT setting we consider
here was recently studied by Galanis, Kandiros, and Kalavasis (SODA'24) where
they showed that single-sample learning is possible when roughly $d\leq
2^{k/6.45}$ and impossible when $d\geq (k+1) 2^{k-1}$. Crucially, for their
impossibility results they used the existence of unsatisfiable instances which,
aside from the gap in $d$, left open the question of whether the feasibility
threshold for one-shot learning is dictated by the satisfiability threshold of
$k$-SAT formulas of bounded degree.
  Our main contribution is to answer this question negatively. We show that
one-shot learning for $k$-SAT is infeasible well below the satisfiability
threshold; in fact, we obtain impossibility results for degrees $d$ as low as
$k^2$ when $\beta$ is sufficiently large, and bootstrap this to small values of
$\beta$ when $d$ scales exponentially with $k$, via a probabilistic
construction. On the positive side, we simplify the analysis of the learning
algorithm and obtain significantly stronger bounds on $d$ in terms of $\beta$.
In particular, for the uniform case $\beta\rightarrow 0$ that has been studied
extensively in the sampling literature, our analysis shows that learning is
possible under the condition $d\lesssim 2^{k/2}$. This is nearly optimal (up to
constant factors) in the sense that it is known that sampling a
uniformly-distributed satisfying assignment is NP-hard for $d\gtrsim 2^{k/2}$.","Andreas Galanis, Leslie Ann Goldberg, Xusheng Zhang",2025-02-10 23:56:08.000000,arXiv,http://arxiv.org/abs/2502.07135v1,Other
971,Cross-platform Learning-based Fault Tolerant Surfacing Controller for Underwater Robots,"In this paper, we propose a novel cross-platform fault-tolerant surfacing
controller for underwater robots, based on reinforcement learning (RL). Unlike
conventional approaches, which require explicit identification of
malfunctioning actuators, our method allows the robot to surface using only the
remaining operational actuators without needing to pinpoint the failures. The
proposed controller learns a robust policy capable of handling diverse failure
scenarios across different actuator configurations. Moreover, we introduce a
transfer learning mechanism that shares a part of the control policy across
various underwater robots with different actuators, thus improving learning
efficiency and generalization across platforms. To validate our approach, we
conduct simulations on three different types of underwater robots: a
hovering-type AUV, a torpedo shaped AUV, and a turtle-shaped robot (U-CAT).
Additionally, real-world experiments are performed, successfully transferring
the learned policy from simulation to a physical U-CAT in a controlled
environment. Our RL-based controller demonstrates superior performance in terms
of stability and success rate compared to a baseline controller, achieving an
85.7 percent success rate in real-world tests compared to 57.1 percent with a
baseline controller. This research provides a scalable and efficient solution
for fault-tolerant control for diverse underwater platforms, with potential
applications in real-world aquatic missions.","Yuya Hamamatsu, Walid Remmas, Jaan Rebane, Maarja Kruusmaa, Asko Ristolainen",2025-02-10 23:50:25.000000,arXiv,http://arxiv.org/abs/2502.07133v1,Robotics
972,Interactive Data Harmonization with LLM Agents,"Data harmonization is an essential task that entails integrating datasets
from diverse sources. Despite years of research in this area, it remains a
time-consuming and challenging task due to schema mismatches, varying
terminologies, and differences in data collection methodologies. This paper
presents the case for agentic data harmonization as a means to both empower
experts to harmonize their data and to streamline the process. We introduce
Harmonia, a system that combines LLM-based reasoning, an interactive user
interface, and a library of data harmonization primitives to automate the
synthesis of data harmonization pipelines. We demonstrate Harmonia in a
clinical data harmonization scenario, where it helps to interactively create
reusable pipelines that map datasets to a standard format. Finally, we discuss
challenges and open problems, and suggest research directions for advancing our
vision.","Aécio Santos, Eduardo H. M. Pena, Roque Lopez, Juliana Freire",2025-02-10 23:50:09.000000,arXiv,http://arxiv.org/abs/2502.07132v1,Artificial Intelligence
973,TWICE: What Advantages Can Low-Resource Domain-Specific Embedding Model Bring? - A Case Study on Korea Financial Texts,"Domain specificity of embedding models is critical for effective performance.
However, existing benchmarks, such as FinMTEB, are primarily designed for
high-resource languages, leaving low-resource settings, such as Korean,
under-explored. Directly translating established English benchmarks often fails
to capture the linguistic and cultural nuances present in low-resource domains.
In this paper, titled TWICE: What Advantages Can Low-Resource Domain-Specific
Embedding Models Bring? A Case Study on Korea Financial Texts, we introduce
KorFinMTEB, a novel benchmark for the Korean financial domain, specifically
tailored to reflect its unique cultural characteristics in low-resource
languages. Our experimental results reveal that while the models perform
robustly on a translated version of FinMTEB, their performance on KorFinMTEB
uncovers subtle yet critical discrepancies, especially in tasks requiring
deeper semantic understanding, that underscore the limitations of direct
translation. This discrepancy highlights the necessity of benchmarks that
incorporate language-specific idiosyncrasies and cultural nuances. The insights
from our study advocate for the development of domain-specific evaluation
frameworks that can more accurately assess and drive the progress of embedding
models in low-resource settings.","Yewon Hwang, Sungbum Jung, Hanwool Lee, Sara Yu",2025-02-10 23:49:39.000000,arXiv,http://arxiv.org/abs/2502.07131v1,Natural Language Processing
974,Unconstrained Body Recognition at Altitude and Range: Comparing Four Approaches,"This study presents an investigation of four distinct approaches to long-term
person identification using body shape. Unlike short-term re-identification
systems that rely on temporary features (e.g., clothing), we focus on learning
persistent body shape characteristics that remain stable over time. We
introduce a body identification model based on a Vision Transformer (ViT) (Body
Identification from Diverse Datasets, BIDDS) and on a Swin-ViT model
(Swin-BIDDS). We also expand on previous approaches based on the Linguistic and
Non-linguistic Core ResNet Identity Models (LCRIM and NLCRIM), but with
improved training. All models are trained on a large and diverse dataset of
over 1.9 million images of approximately 5k identities across 9 databases.
Performance was evaluated on standard re-identification benchmark datasets
(MARS, MSMT17, Outdoor Gait, DeepChange) and on an unconstrained dataset that
includes images at a distance (from close-range to 1000m), at altitude (from an
unmanned aerial vehicle, UAV), and with clothing change. A comparative analysis
across these models provides insights into how different backbone architectures
and input image sizes impact long-term body identification performance across
real-world conditions.","Blake A Myers, Matthew Q Hill, Veda Nandan Gandi, Thomas M Metz, Alice J O'Toole",2025-02-10 23:49:06.000000,arXiv,http://arxiv.org/abs/2502.07130v1,Computer Vision
975,Fourier-enhanced Neural Networks For Systems Biology Applications,"In the field of systems biology, differential equations are commonly used to
model biological systems, but solving them for large-scale and complex systems
can be computationally expensive. Recently, the integration of machine learning
and mathematical modeling has offered new opportunities for scientific
discoveries in biology and health. The emerging physics-informed neural network
(PINN) has been proposed as a solution to this problem. However, PINN can be
computationally expensive and unreliable for complex biological systems. To
address these issues, we propose the Fourier-enhanced Neural Networks for
systems biology (SB-FNN). SB-FNN uses an embedded Fourier neural network with
an adaptive activation function and a cyclic penalty function to optimize the
prediction of biological dynamics, particularly for biological systems that
exhibit oscillatory patterns. Experimental results demonstrate that SB-FNN
achieves better performance and is more efficient than PINN for handling
complex biological models. Experimental results on cellular and population
models demonstrate that SB-FNN outperforms PINN in both accuracy and
efficiency, making it a promising alternative approach for handling complex
biological models. The proposed method achieved better performance on six
biological models and is expected to replace PINN as the most advanced method
in systems biology.","Enze Xu, Minghan Chen",2025-02-10 23:48:10.000000,arXiv,http://arxiv.org/abs/2502.07129v1,Machine Learning
976,Cardiverse: Harnessing LLMs for Novel Card Game Prototyping,"The prototyping of computer games, particularly card games, requires
extensive human effort in creative ideation and gameplay evaluation. Recent
advances in Large Language Models (LLMs) offer opportunities to automate and
streamline these processes. However, it remains challenging for LLMs to design
novel game mechanics beyond existing databases, generate consistent gameplay
environments, and develop scalable gameplay AI for large-scale evaluations.
This paper addresses these challenges by introducing a comprehensive automated
card game prototyping framework. The approach highlights a graph-based indexing
method for generating novel game designs, an LLM-driven system for consistent
game code generation validated by gameplay records, and a gameplay AI
constructing method that uses an ensemble of LLM-generated action-value
functions optimized through self-play. These contributions aim to accelerate
card game prototyping, reduce human labor, and lower barriers to entry for game
developers.","Danrui Li, Sen Zhang, Sam S. Sohn, Kaidong Hu, Muhammad Usman, Mubbasir Kapadia",2025-02-10 23:47:35.000000,arXiv,http://arxiv.org/abs/2502.07128v1,Natural Language Processing
977,Structural Reformation of Large Language Model Neuron Encapsulation for Divergent Information Aggregation,"Structured neuron encapsulation introduces a modular framework that enables
more effective aggregation and specialization of information within deep
learning architectures. A model modified through this framework demonstrated
improved perplexity scores, greater lexical variability, and enhanced
consistency in logical reasoning, suggesting that structured parameter
distribution contributes to more efficient language representation. Statistical
analyses of generated text highlighted a wider range of sentence structures and
reduced redundancy in token selection, indicating that encapsulation fosters
more adaptable language generation. A detailed evaluation of attention weight
distributions revealed that the experimental model exhibited greater divergence
in cross-layer activations, supporting the hypothesis that encapsulated neurons
assume specialized processing roles. Logical consistency assessments further
demonstrated that modular architectures mitigate contradictory outputs,
reducing internal conflicts in inferred relationships between linguistic
constructs. Computational trade-offs were analyzed, with results showing a
minor increase in processing overhead, though improvements in parameter
efficiency and structured decision-making compensated for the additional
complexity. The mathematical formulation of the encapsulation mechanism
confirmed that modular aggregation maintains stable convergence properties
while promoting distinct functional roles for different neuron clusters.","Denis Bakushev, Gideon Boultinghouse, Harriet Oppenheimer, Sebastian Gillingwater, Valentina Ashington, Wilfred Stanborough",2025-02-10 23:37:39.000000,arXiv,http://arxiv.org/abs/2502.07124v1,Natural Language Processing
978,Is Long Range Sequential Modeling Necessary For Colorectal Tumor Segmentation?,"Segmentation of colorectal cancer (CRC) tumors in 3D medical imaging is both
complex and clinically critical, providing vital support for effective
radiation therapy planning and survival outcome assessment. Recently, 3D
volumetric segmentation architectures incorporating long-range sequence
modeling mechanisms, such as Transformers and Mamba, have gained attention for
their capacity to achieve high accuracy in 3D medical image segmentation. In
this work, we evaluate the effectiveness of these global token modeling
techniques by pitting them against our proposed MambaOutUNet within the context
of our newly introduced colorectal tumor segmentation dataset (CTS-204). Our
findings suggest that robust local token interactions can outperform long-range
modeling techniques in cases where the region of interest is small and
anatomically complex, proposing a potential shift in 3D tumor segmentation
research.","Abhishek Srivastava, Koushik Biswas, Gorkem Durak, Gulsah Ozden, Mustafa Adli, Ulas Bagci",2025-02-10 23:24:01.000000,arXiv,http://arxiv.org/abs/2502.07120v1,Computer Vision
979,SAFE: Self-Supervised Anomaly Detection Framework for Intrusion Detection,"The proliferation of IoT devices has significantly increased network
vulnerabilities, creating an urgent need for effective Intrusion Detection
Systems (IDS). Machine Learning-based IDS (ML-IDS) offer advanced detection
capabilities but rely on labeled attack data, which limits their ability to
identify unknown threats. Self-Supervised Learning (SSL) presents a promising
solution by using only normal data to detect patterns and anomalies. This paper
introduces SAFE, a novel framework that transforms tabular network intrusion
data into an image-like format, enabling Masked Autoencoders (MAEs) to learn
robust representations of network behavior. The features extracted by the MAEs
are then incorporated into a lightweight novelty detector, enhancing the
effectiveness of anomaly detection. Experimental results demonstrate that SAFE
outperforms the state-of-the-art anomaly detection method, Scale Learning-based
Deep Anomaly Detection method (SLAD), by up to 26.2% and surpasses the
state-of-the-art SSL-based network intrusion detection approach, Anomal-E, by
up to 23.5% in F1-score.","Elvin Li, Zhengli Shang, Onat Gungor, Tajana Rosing",2025-02-10 23:20:59.000000,arXiv,http://arxiv.org/abs/2502.07119v1,Other
980,Choroidal image analysis for OCT image sequences with applications in systemic health,"The choroid, a highly vascular layer behind the retina, is an extension of
the central nervous system and has parallels with the renal cortex, with blood
flow far exceeding that of the brain and kidney. Thus, there has been growing
interest of choroidal blood flow reflecting physiological status of systemic
disease. Optical coherence tomography (OCT) enables high-resolution imaging of
the choroid, but conventional analysis methods remain manual or semi-automatic,
limiting reproducibility, standardisation and clinical utility. In this thesis,
I develop several new methods to analyse the choroid in OCT image sequences,
with each successive method improving on its predecessors. I first develop two
semi-automatic approaches for choroid region (Gaussian Process Edge Tracing,
GPET) and vessel (Multi-scale Median Cut Quantisation, MMCQ) analysis, which
improve on manual approaches but remain user-dependent. To address this, I
introduce DeepGPET, a deep learning-based region segmentation method which
improves on execution time, reproducibility, and end-user accessibility, but
lacks choroid vessel analysis and automatic feature measurement. Improving on
this, I developed Choroidalyzer, a deep learning-based pipeline to segment the
choroidal space and vessels and generate fully automatic, clinically meaningful
and reproducible choroidal features. I provide rigorous evaluation of these
four approaches and consider their potential clinical value in three
applications into systemic health: OCTANE, assessing choroidal changes in renal
transplant recipients and donors; PREVENT, exploring choroidal associations
with Alzheimer's risk factors at mid-life; D-RISCii, assessing choroidal
variation and feasibility of OCT in critical care. In short, this thesis
contributes many open-source tools for standardised choroidal measurement and
highlights the choroid's potential as a biomarker in systemic health.",Jamie Burke,2025-02-10 23:14:09.000000,arXiv,http://arxiv.org/abs/2502.07117v1,Other
981,Online Scheduling for LLM Inference with KV Cache Constraints,"Large Language Model (LLM) inference, where a trained model generates text
one word at a time in response to user prompts, is a computationally intensive
process requiring efficient scheduling to optimize latency and resource
utilization. A key challenge in LLM inference is the management of the
Key-Value (KV) cache, which reduces redundant computations but introduces
memory constraints. In this work, we model LLM inference with KV cache
constraints theoretically and propose novel batching and scheduling algorithms
that minimize inference latency while effectively managing the KV cache's
memory.
  We analyze both semi-online and fully online scheduling models, and our
results are threefold. First, we provide a polynomial-time algorithm that
achieves exact optimality in terms of average latency in the semi-online prompt
arrival model. Second, in the fully online case with a stochastic prompt
arrival, we introduce an efficient online scheduling algorithm with constant
regret. Third, we prove that no algorithm (deterministic or randomized) can
achieve a constant competitive ratio in fully online adversarial settings. Our
empirical evaluations on a public LLM inference dataset, using the Llama-70B
model on A100 GPUs, show that our approach significantly outperforms benchmark
algorithms used currently in practice, achieving lower latency while reducing
energy consumption. Overall, our results offer a path toward more sustainable
and cost-effective LLM deployment.","Patrick Jaillet, Jiashuo Jiang, Chara Podimata, Zijie Zhou",2025-02-10 23:11:44.000000,arXiv,http://arxiv.org/abs/2502.07115v2,Machine Learning
982,Online Covariance Matrix Estimation in Sketched Newton Methods,"Given the ubiquity of streaming data, online algorithms have been widely used
for parameter estimation, with second-order methods particularly standing out
for their efficiency and robustness. In this paper, we study an online sketched
Newton method that leverages a randomized sketching technique to perform an
approximate Newton step in each iteration, thereby eliminating the
computational bottleneck of second-order methods. While existing studies have
established the asymptotic normality of sketched Newton methods, a consistent
estimator of the limiting covariance matrix remains an open problem. We propose
a fully online covariance matrix estimator that is constructed entirely from
the Newton iterates and requires no matrix factorization. Compared to
covariance estimators for first-order online methods, our estimator for
second-order methods is batch-free. We establish the consistency and
convergence rate of our estimator, and coupled with asymptotic normality
results, we can then perform online statistical inference for the model
parameters based on sketched Newton methods. We also discuss the extension of
our estimator to constrained problems, and demonstrate its superior performance
on regression problems as well as benchmark problems in the CUTEst set.","Wei Kuang, Mihai Anitescu, Sen Na",2025-02-10 23:11:02.000000,arXiv,http://arxiv.org/abs/2502.07114v1,Statistical Machine Learning
983,Likelihood-Free Estimation for Spatiotemporal Hawkes processes with missing data and application to predictive policing,"With the growing use of AI technology, many police departments use
forecasting software to predict probable crime hotspots and allocate patrolling
resources effectively for crime prevention. The clustered nature of crime data
makes self-exciting Hawkes processes a popular modeling choice. However, one
significant challenge in fitting such models is the inherent missingness in
crime data due to non-reporting, which can bias the estimated parameters of the
predictive model, leading to inaccurate downstream hotspot forecasts, often
resulting in over or under-policing in various communities, especially the
vulnerable ones. Our work introduces a Wasserstein Generative Adversarial
Networks (WGAN) driven likelihood-free approach to account for unreported
crimes in Spatiotemporal Hawkes models. We demonstrate through empirical
analysis how this methodology improves the accuracy of parametric estimation in
the presence of data missingness, leading to more reliable and efficient
policing strategies.","Pramit Das, Moulinath Banerjee, Yuekai Sun",2025-02-10 23:09:12.000000,arXiv,http://arxiv.org/abs/2502.07111v1,Machine Learning
984,Game of Coding With an Unknown Adversary,"Motivated by emerging decentralized applications, the \emph{game of coding}
framework has been recently introduced to address scenarios where the
adversary's control over coded symbols surpasses the fundamental limits of
traditional coding theory. Still, the reward mechanism available in
decentralized systems, motivates the adversary to act rationally. While the
decoder, as the data collector (DC), has an acceptance and rejection mechanism,
followed by an estimation module, the adversary aims to maximize its utility,
as an increasing function of (1) the chance of acceptance (to increase the
reward), and (2) estimation error. On the other hand, the decoder also adjusts
its acceptance rule to maximize its own utility, as (1) an increasing function
of the chance of acceptance (to keep the system functional), (2) decreasing
function of the estimation error. Prior works within this framework rely on the
assumption that the game is complete, that is, both the DC and the adversary
are fully aware of each other's utility functions. However, in practice, the
decoder is often unaware of the utility of the adversary. To address this
limitation, we develop an algorithm enabling the DC to commit to a strategy
that achieves within the vicinity of the equilibrium, without knowledge of the
adversary's utility function. Our approach builds on an observation that at the
equilibrium, the relationship between the probability of acceptance and the
mean squared error (MSE) follows a predetermined curve independent of the
specific utility functions of the players. By exploiting this invariant
relationship, the DC can iteratively refine its strategy based on observable
parameters, converging to a near-optimal solution. We provide theoretical
guarantees on sample complexity and accuracy of the proposed scheme.","Hanzaleh Akbarinodehi, Parsa Moradi, Mohammad Ali Maddah-Ali",2025-02-10 23:06:10.000000,arXiv,http://arxiv.org/abs/2502.07109v1,Other
985,A Framework for Supervised and Unsupervised Segmentation and Classification of Materials Microstructure Images,"Microstructure of materials is often characterized through image analysis to
understand processing-structure-properties linkages. We propose a largely
automated framework that integrates unsupervised and supervised learning
methods to classify micrographs according to microstructure phase/class and,
for multiphase microstructures, segments them into different homogeneous
regions. With the advance of manufacturing and imaging techniques, the
ultra-high resolution of imaging that reveals the complexity of microstructures
and the rapidly increasing quantity of images (i.e., micrographs) enables and
necessitates a more powerful and automated framework to extract materials
characteristics and knowledge. The framework we propose can be used to
gradually build a database of microstructure classes relevant to a particular
process or group of materials, which can help in analyzing and
discovering/identifying new materials. The framework has three steps: (1)
segmentation of multiphase micrographs through a recently developed score-based
method so that different microstructure homogeneous regions can be identified
in an unsupervised manner; (2) {identification and classification of}
homogeneous regions of micrographs through an uncertainty-aware supervised
classification network trained using the segmented micrographs from Step $1$
with their identified labels verified via the built-in uncertainty
quantification and minimal human inspection; (3) supervised segmentation (more
powerful than the segmentation in Step $1$) of multiphase microstructures
through a segmentation network trained with micrographs and the results from
Steps $1$-$2$ using a form of data augmentation. This framework can iteratively
characterize/segment new homogeneous or multiphase materials while expanding
the database to enhance performance. The framework is demonstrated on various
sets of materials and texture images.","Kungang Zhang, Daniel W. Apley, Wei Chen, Wing K. Liu, L. Catherine Brinson",2025-02-10 23:05:35.000000,arXiv,http://arxiv.org/abs/2502.07107v1,Other
986,SMAB: MAB based word Sensitivity Estimation Framework and its Applications in Adversarial Text Generation,"To understand the complexity of sequence classification tasks, Hahn et al.
(2021) proposed sensitivity as the number of disjoint subsets of the input
sequence that can each be individually changed to change the output. Though
effective, calculating sensitivity at scale using this framework is costly
because of exponential time complexity. Therefore, we introduce a
Sensitivity-based Multi-Armed Bandit framework (SMAB), which provides a
scalable approach for calculating word-level local (sentence-level) and global
(aggregated) sensitivities concerning an underlying text classifier for any
dataset. We establish the effectiveness of our approach through various
applications. We perform a case study on CHECKLIST generated sentiment analysis
dataset where we show that our algorithm indeed captures intuitively high and
low-sensitive words. Through experiments on multiple tasks and languages, we
show that sensitivity can serve as a proxy for accuracy in the absence of gold
data. Lastly, we show that guiding perturbation prompts using sensitivity
values in adversarial example generation improves attack success rate by
15.58%, whereas using sensitivity as an additional reward in adversarial
paraphrase generation gives a 12.00% improvement over SOTA approaches. Warning:
Contains potentially offensive content.","Saurabh Kumar Pandey, Sachin Vashistha, Debrup Das, Somak Aditya, Monojit Choudhury",2025-02-10 22:46:57.000000,arXiv,http://arxiv.org/abs/2502.07101v1,Natural Language Processing
987,Lotus: Creating Short Videos From Long Videos With Abstractive and Extractive Summarization,"Short-form videos are popular on platforms like TikTok and Instagram as they
quickly capture viewers' attention. Many creators repurpose their long-form
videos to produce short-form videos, but creators report that planning,
extracting, and arranging clips from long-form videos is challenging.
Currently, creators make extractive short-form videos composed of existing
long-form video clips or abstractive short-form videos by adding newly recorded
narration to visuals. While extractive videos maintain the original connection
between audio and visuals, abstractive videos offer flexibility in selecting
content to be included in a shorter time. We present Lotus, a system that
combines both approaches to balance preserving the original content with
flexibility over the content. Lotus first creates an abstractive short-form
video by generating both a short-form script and its corresponding speech, then
matching long-form video clips to the generated narration. Creators can then
add extractive clips with an automated method or Lotus's editing interface.
Lotus's interface can be used to further refine the short-form video. We
compare short-form videos generated by Lotus with those using an extractive
baseline method. In our user study, we compare creating short-form videos using
Lotus to participants' existing practice.","Aadit Barua, Karim Benharrak, Meng Chen, Mina Huh, Amy Pavel",2025-02-10 22:40:34.000000,arXiv,http://arxiv.org/abs/2502.07096v1,Other
988,Generative Distribution Prediction: A Unified Approach to Multimodal Learning,"Accurate prediction with multimodal data-encompassing tabular, textual, and
visual inputs or outputs-is fundamental to advancing analytics in diverse
application domains. Traditional approaches often struggle to integrate
heterogeneous data types while maintaining high predictive accuracy. We
introduce Generative Distribution Prediction (GDP), a novel framework that
leverages multimodal synthetic data generation-such as conditional diffusion
models-to enhance predictive performance across structured and unstructured
modalities. GDP is model-agnostic, compatible with any high-fidelity generative
model, and supports transfer learning for domain adaptation. We establish a
rigorous theoretical foundation for GDP, providing statistical guarantees on
its predictive accuracy when using diffusion models as the generative backbone.
By estimating the data-generating distribution and adapting to various loss
functions for risk minimization, GDP enables accurate point predictions across
multimodal settings. We empirically validate GDP on four supervised learning
tasks-tabular data prediction, question answering, image captioning, and
adaptive quantile regression-demonstrating its versatility and effectiveness
across diverse domains.","Xinyu Tian, Xiaotong Shen",2025-02-10 22:30:35.000000,arXiv,http://arxiv.org/abs/2502.07090v1,Statistical Machine Learning
989,Evaluating the Systematic Reasoning Abilities of Large Language Models through Graph Coloring,"Contemporary large language models are powerful problem-solving tools, but
they exhibit weaknesses in their reasoning abilities which ongoing research
seeks to mitigate. We investigate graph coloring as a means of evaluating an
LLM's capacities for systematic step-by-step reasoning and possibility space
exploration, as well as effects of semantic problem framing. We test Claude 3.5
Sonnet, Llama 3.1 405B, Gemini 1.5 Pro, GPT-4o, o1-mini, and DeepSeek-R1 on a
dataset of $k$-coloring problems with $2 \leq k \leq 4$ and vertex count $4
\leq n \leq 8$, using partial algorithmic solvers to further categorize
problems by difficulty. In addition to substantial but varying framing effects,
we find that all models except o1-mini and R1 exhibit $>60\%$ error rates on
difficult problem types in all frames ($>15\%$ for o1-mini and $>10\%$ for R1),
and no model achieves perfect accuracy even in the simple domain of 2-coloring
4-vertex graphs. Our results highlight both the considerable recent progress in
LLM systematic reasoning and the limits of its reliability, especially in
relation to increasing computational costs. We expect that more complex graph
coloring problems, and procedural generation of arbitrary-complexity reasoning
problems more broadly, offer further untapped potential for LLM benchmarking.","Alex Heyman, Joel Zylberberg",2025-02-10 22:27:02.000000,arXiv,http://arxiv.org/abs/2502.07087v1,Machine Learning
990,"""Once Upon a Time..."" Literary Narrative Connectedness Progresses with Grade Level: Potential Impact on Reading Fluency and Literacy Skills","Selecting an appropriate book is crucial for fostering reading habits in
children. While children exhibit varying levels of complexity when generating
oral narratives, the question arises: do children's books also differ in
narrative complexity? This study explores the narrative dynamics of literary
texts used in schools, focusing on how their complexity evolves across
different grade levels. Using Word-Recurrence Graph Analysis, we examined a
dataset of 1,627 literary texts spanning 13 years of education. The findings
reveal significant exponential growth in connectedness, particularly during the
first three years of schooling, mirroring patterns observed in children's oral
narratives. These results highlight the potential of literary texts as a tool
to support the development of literacy skills.","Marina Ribeiro, Bárbara Malcorra, Diego Pintor, Natália Bezerra Mota",2025-02-10 22:21:29.000000,arXiv,http://arxiv.org/abs/2502.07082v1,Natural Language Processing
991,Fast Clustering of Categorical Big Data,"The K-Modes algorithm, developed for clustering categorical data, is of high
algorithmic simplicity but suffers from unreliable performances in clustering
quality and clustering efficiency, both heavily influenced by the choice of
initial cluster centers. In this paper, we investigate Bisecting K-Modes
(BK-Modes), a successive bisecting process to find clusters, in examining how
good the cluster centers out of the bisecting process will be when used as
initial centers for the K-Modes. The BK-Modes works by splitting a dataset into
multiple clusters iteratively with one cluster being chosen and bisected into
two clusters in each iteration. We use the sum of distances of data to their
cluster centers as the selection metric to choose a cluster to be bisected in
each iteration. This iterative process stops when K clusters are produced. The
centers of these K clusters are then used as the initial cluster centers for
the K-Modes. Experimental studies of the BK-Modes were carried out and were
compared against the K-Modes with multiple sets of initial cluster centers as
well as the best of the existing methods we found so far in our survey.
Experimental results indicated good performances of BK-Modes both in the
clustering quality and efficiency for large datasets.","Bipana Thapaliya, Yu Zhuang",2025-02-10 22:19:08.000000,arXiv,http://arxiv.org/abs/2502.07081v1,Machine Learning
992,Multi-turn Evaluation of Anthropomorphic Behaviours in Large Language Models,"The tendency of users to anthropomorphise large language models (LLMs) is of
growing interest to AI developers, researchers, and policy-makers. Here, we
present a novel method for empirically evaluating anthropomorphic LLM
behaviours in realistic and varied settings. Going beyond single-turn static
benchmarks, we contribute three methodological advances in state-of-the-art
(SOTA) LLM evaluation. First, we develop a multi-turn evaluation of 14
anthropomorphic behaviours. Second, we present a scalable, automated approach
by employing simulations of user interactions. Third, we conduct an
interactive, large-scale human subject study (N=1101) to validate that the
model behaviours we measure predict real users' anthropomorphic perceptions. We
find that all SOTA LLMs evaluated exhibit similar behaviours, characterised by
relationship-building (e.g., empathy and validation) and first-person pronoun
use, and that the majority of behaviours only first occur after multiple turns.
Our work lays an empirical foundation for investigating how design choices
influence anthropomorphic model behaviours and for progressing the ethical
debate on the desirability of these behaviours. It also showcases the necessity
of multi-turn evaluations for complex social phenomena in human-AI interaction.","Lujain Ibrahim, Canfer Akbulut, Rasmi Elasmar, Charvi Rastogi, Minsuk Kahng, Meredith Ringel Morris, Kevin R. McKee, Verena Rieser, Murray Shanahan, Laura Weidinger",2025-02-10 22:09:57.000000,arXiv,http://arxiv.org/abs/2502.07077v1,Natural Language Processing
993,IRepair: An Intent-Aware Approach to Repair Data-Driven Errors in Large Language Models,"Not a day goes by without hearing about the impressive feats of large
language models (LLMs), and equally, not a day passes without hearing about
their challenges. LLMs are notoriously vulnerable to biases in their dataset,
leading to issues such as toxicity. While domain-adaptive training has been
employed to mitigate these issues, these techniques often address all model
parameters indiscriminately during the repair process, resulting in poor repair
quality and reduced model versatility. In this paper, we introduce a novel
dynamic slicing-based intent-aware LLM repair strategy, IRepair. This approach
selectively targets the most error-prone sections of the model for repair.
Specifically, we propose dynamically slicing the model's most sensitive layers
that require immediate attention, concentrating repair efforts on those areas.
This method enables more effective repairs with potentially less impact on the
model's overall performance by altering a smaller portion of the model. We
evaluated our technique on three models from the GPT2 and GPT-Neo families,
with parameters ranging from 800M to 1.6B, in a toxicity mitigation setup. Our
results show that IRepair repairs errors 43.6% more effectively while causing
46% less disruption to general performance compared to the closest baseline,
direct preference optimization. Our empirical analysis also reveals that errors
are more concentrated in a smaller section of the model, with the top 20% of
layers exhibiting 773% more error density than the remaining 80\%. This
highlights the need for selective repair. Additionally, we demonstrate that a
dynamic selection approach is essential for addressing errors dispersed
throughout the model, ensuring a robust and efficient repair.","Sayem Mohammad Imtiaz, Astha Singh, Fraol Batole, Hridesh Rajan",2025-02-10 22:07:02.000000,arXiv,http://arxiv.org/abs/2502.07072v2,Natural Language Processing
994,Specializing Large Language Models to Simulate Survey Response Distributions for Global Populations,"Large-scale surveys are essential tools for informing social science research
and policy, but running surveys is costly and time-intensive. If we could
accurately simulate group-level survey results, this would therefore be very
valuable to social science research. Prior work has explored the use of large
language models (LLMs) for simulating human behaviors, mostly through
prompting. In this paper, we are the first to specialize LLMs for the task of
simulating survey response distributions. As a testbed, we use country-level
results from two global cultural surveys. We devise a fine-tuning method based
on first-token probabilities to minimize divergence between predicted and
actual response distributions for a given question. Then, we show that this
method substantially outperforms other methods and zero-shot classifiers, even
on unseen questions, countries, and a completely unseen survey. While even our
best models struggle with the task, especially on unseen questions, our results
demonstrate the benefits of specialization for simulation, which may accelerate
progress towards sufficiently accurate simulation in the future.","Yong Cao, Haijiang Liu, Arnav Arora, Isabelle Augenstein, Paul Röttger, Daniel Hershcovich",2025-02-10 21:59:27.000000,arXiv,http://arxiv.org/abs/2502.07068v1,Natural Language Processing
995,Repository-level Code Search with Neural Retrieval Methods,"This paper presents a multi-stage reranking system for repository-level code
search, which leverages the vastly available commit histories of large
open-source repositories to aid in bug fixing. We define the task of
repository-level code search as retrieving the set of files from the current
state of a code repository that are most relevant to addressing a user's
question or bug. The proposed approach combines BM25-based retrieval over
commit messages with neural reranking using CodeBERT to identify the most
pertinent files. By learning patterns from diverse repositories and their
commit histories, the system can surface relevant files for the task at hand.
The system leverages both commit messages and source code for relevance
matching, and is evaluated in both normal and oracle settings. Experiments on a
new dataset created from 7 popular open-source repositories demonstrate
substantial improvements of up to 80% in MAP, MRR and P@1 over the BM25
baseline, across a diverse set of queries, demonstrating the effectiveness this
approach. We hope this work aids LLM agents as a tool for better code search
and understanding. Our code and results obtained are publicly available.","Siddharth Gandhi, Luyu Gao, Jamie Callan",2025-02-10 21:59:01.000000,arXiv,http://arxiv.org/abs/2502.07067v1,Information Retrieval
996,Contextual Thompson Sampling via Generation of Missing Data,"We introduce a framework for Thompson sampling contextual bandit algorithms,
in which the algorithm's ability to quantify uncertainty and make decisions
depends on the quality of a generative model that is learned offline. Instead
of viewing uncertainty in the environment as arising from unobservable latent
parameters, our algorithm treats uncertainty as stemming from missing, but
potentially observable, future outcomes. If these future outcomes were all
observed, one could simply make decisions using an ""oracle"" policy fit on the
complete dataset. Inspired by this conceptualization, at each decision-time,
our algorithm uses a generative model to probabilistically impute missing
future outcomes, fits a policy using the imputed complete dataset, and uses
that policy to select the next action. We formally show that this algorithm is
a generative formulation of Thompson Sampling and prove a state-of-the-art
regret bound for it. Notably, our regret bound i) depends on the probabilistic
generative model only through the quality of its offline prediction loss, and
ii) applies to any method of fitting the ""oracle"" policy, which easily allows
one to adapt Thompson sampling to decision-making settings with fairness and/or
resource constraints.","Kelly W. Zhang, Tiffany Tianhui Cai, Hongseok Namkoong, Daniel Russo",2025-02-10 21:57:00.000000,arXiv,http://arxiv.org/abs/2502.07064v1,Machine Learning
997,"Federated Continual Learning: Concepts, Challenges, and Solutions","Federated Continual Learning (FCL) has emerged as a robust solution for
collaborative model training in dynamic environments, where data samples are
continuously generated and distributed across multiple devices. This survey
provides a comprehensive review of FCL, focusing on key challenges such as
heterogeneity, model stability, communication overhead, and privacy
preservation. We explore various forms of heterogeneity and their impact on
model performance. Solutions to non-IID data, resource-constrained platforms,
and personalized learning are reviewed in an effort to show the complexities of
handling heterogeneous data distributions. Next, we review techniques for
ensuring model stability and avoiding catastrophic forgetting, which are
critical in non-stationary environments. Privacy-preserving techniques are
another aspect of FCL that have been reviewed in this work. This survey has
integrated insights from federated learning and continual learning to present
strategies for improving the efficacy and scalability of FCL systems, making it
applicable to a wide range of real-world scenarios.","Parisa Hamedi, Roozbeh Razavi-Far, Ehsan Hallaji",2025-02-10 21:51:02.000000,arXiv,http://arxiv.org/abs/2502.07059v1,Machine Learning
998,Using Contextually Aligned Online Reviews to Measure LLMs' Performance Disparities Across Language Varieties,"A language can have different varieties. These varieties can affect the
performance of natural language processing (NLP) models, including large
language models (LLMs), which are often trained on data from widely spoken
varieties. This paper introduces a novel and cost-effective approach to
benchmark model performance across language varieties. We argue that
international online review platforms, such as Booking.com, can serve as
effective data sources for constructing datasets that capture comments in
different language varieties from similar real-world scenarios, like reviews
for the same hotel with the same rating using the same language (e.g., Mandarin
Chinese) but different language varieties (e.g., Taiwan Mandarin, Mainland
Mandarin). To prove this concept, we constructed a contextually aligned dataset
comprising reviews in Taiwan Mandarin and Mainland Mandarin and tested six LLMs
in a sentiment analysis task. Our results show that LLMs consistently
underperform in Taiwan Mandarin.","Zixin Tang, Chieh-Yang Huang, Tsung-Chi Li, Ho Yin Sam Ng, Hen-Hsen Huang, Ting-Hao 'Kenneth' Huang",2025-02-10 21:49:35.000000,arXiv,http://arxiv.org/abs/2502.07058v2,Natural Language Processing
999,Tokenization Standards for Linguistic Integrity: Turkish as a Benchmark,"Tokenization is a fundamental preprocessing step in NLP, directly impacting
large language models' (LLMs) ability to capture syntactic, morphosyntactic,
and semantic structures. This paper introduces a novel framework for
systematically evaluating tokenization strategies, addressing challenges in
morphologically rich and low-resource languages. Using a Turkish dataset of
6,200 multiple-choice questions from the Massive Multitask Language
Understanding (MMLU) benchmark, the framework assesses tokenizers across five
key metrics: vocabulary size, token count, processing time, language-specific
token percentages (\%TR), and token purity. These metrics provide a structured
approach to evaluating how well tokenizers preserve linguistic structures.
While \%TR measures the proportion of valid words in the target language,
\%Pure assesses the alignment of tokens with meaningful linguistic units, such
as roots and valid morphemes, minimizing semantic fragmentation. The findings
reveal that \%TR, introduced as a critical metric, exhibits a stronger
correlation with downstream performance (e.g., MMLU scores) than token purity,
emphasizing its role in improving model accuracy. Additionally, larger model
parameters do not necessarily yield better tokenization quality or enhanced
results, highlighting the importance of tailored tokenization strategies that
prioritize linguistic alignment. This framework sets a new standard for
developing robust tokenization methods optimized for morphologically complex
and low-resource languages. Future work will refine morphological analysis,
explore domain-specific customizations, and conduct cross-linguistic
evaluations to further enhance tokenization practices.","M. Ali Bayram, Ali Arda Fincan, Ahmet Semih Gümüş, Sercan Karakaş, Banu Diri, Savaş Yıldırım",2025-02-10 21:47:49.000000,arXiv,http://arxiv.org/abs/2502.07057v1,Natural Language Processing
1000,Autonomous Deep Agent,"This technical brief introduces Deep Agent, an advanced autonomous AI system
designed to manage complex multi-phase tasks through a novel hierarchical task
management architecture. The system's foundation is built on our Hierarchical
Task DAG (HTDAG) framework, which dynamically decomposes high-level objectives
into manageable sub-tasks while rigorously maintaining dependencies and
execution coherence. Deep Agent advances beyond traditional agent systems
through three key innovations: First, it implements a recursive two-stage
planner-executor architecture that enables continuous task refinement and
adaptation as circumstances change. Second, it features an Autonomous API &
Tool Creation (AATC) system that automatically generates reusable components
from UI interactions, substantially reducing operational costs for similar
tasks. Third, it incorporates Prompt Tweaking Engine and Autonomous Prompt
Feedback Learning components that optimize Large Language Model prompts for
specific scenarios, enhancing both inference accuracy and operational
stability. These components are integrated to form a service infrastructure
that manages user contexts, handles complex task dependencies, and orchestrates
end-to-end agentic workflow execution. Through this sophisticated architecture,
Deep Agent establishes a novel paradigm in self-governing AI systems,
demonstrating robust capability to independently handle intricate, multi-step
tasks while maintaining consistent efficiency and reliability through
continuous self-optimization.","Amy Yu, Erik Lebedev, Lincoln Everett, Xiaoxin Chen, Terry Chen",2025-02-10 21:46:54.000000,arXiv,http://arxiv.org/abs/2502.07056v1,Artificial Intelligence
