title,abstract,url,domain_task,keywords
Poly-Autoregressive Prediction for Modeling Interactions,"We introduce a simple framework for predicting the behavior of an agent in
multi-agent settings. In contrast to autoregressive (AR) tasks, such as
language processing, our focus is on scenarios with multiple agents whose
interactions are shaped by physical constraints and internal motivations. To
this end, we propose Poly-Autoregressive (PAR) modeling, which forecasts an ego
agent's future behavior by reasoning about the ego agent's state history and
the past and current states of other interacting agents. At its core, PAR
represents the behavior of all agents as a sequence of tokens, each
representing an agent's state at a specific timestep. With minimal data
pre-processing changes, we show that PAR can be applied to three different
problems: human action forecasting in social situations, trajectory prediction
for autonomous vehicles, and object pose forecasting during hand-object
interaction. Using a small proof-of-concept transformer backbone, PAR
outperforms AR across these three scenarios. The project website can be found
at https://neerja.me/PAR/.",http://arxiv.org/abs/2502.08646v1,Recommendation System,"agent, par, behavior, agents, autoregressive"
Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptation and learning in neural networks,"The brain can rapidly adapt to new contexts and learn from limited data, a
coveted characteristic that artificial intelligence algorithms have struggled
to mimic. Inspired by oscillatory rhythms of the mechanical structures of
neural cells, we developed a learning paradigm that is based on oscillations in
link strengths and associates learning with the coordination of these
oscillations. We find that this paradigm yields rapid adaptation and learning
in artificial neural networks. Link oscillations can rapidly change
coordination, endowing the network with the ability to sense subtle context
changes in an unsupervised manner. In other words, the network generates the
missing contextual tokens required to perform as a generalist AI architecture
capable of predicting dynamics in multiple contexts. Oscillations also allow
the network to extrapolate dynamics to never-seen-before contexts. These
capabilities make our learning paradigm a powerful starting point for novel
models of learning and cognition. Furthermore, learning through link
coordination is agnostic to the specifics of the neural network architecture,
hence our study opens the door for introducing rapid adaptation and learning
capabilities into leading AI models.",http://arxiv.org/abs/2502.08644v1,Recommendation System,"learning, oscillations, network, contexts, neural"
A Real-to-Sim-to-Real Approach to Robotic Manipulation with VLM-Generated Iterative Keypoint Rewards,"Task specification for robotic manipulation in open-world environments is
challenging, requiring flexible and adaptive objectives that align with human
intentions and can evolve through iterative feedback. We introduce Iterative
Keypoint Reward (IKER), a visually grounded, Python-based reward function that
serves as a dynamic task specification. Our framework leverages VLMs to
generate and refine these reward functions for multi-step manipulation tasks.
Given RGB-D observations and free-form language instructions, we sample
keypoints in the scene and generate a reward function conditioned on these
keypoints. IKER operates on the spatial relationships between keypoints,
leveraging commonsense priors about the desired behaviors, and enabling precise
SE(3) control. We reconstruct real-world scenes in simulation and use the
generated rewards to train reinforcement learning (RL) policies, which are then
deployed into the real world-forming a real-to-sim-to-real loop. Our approach
demonstrates notable capabilities across diverse scenarios, including both
prehensile and non-prehensile tasks, showcasing multi-step task execution,
spontaneous error recovery, and on-the-fly strategy adjustments. The results
highlight IKER's effectiveness in enabling robots to perform multi-step tasks
in dynamic environments through iterative reward shaping.",http://arxiv.org/abs/2502.08643v1,Reinforcement Learning,"reward, real, task, world, iterative"
SwiftSketch: A Diffusion Model for Image-to-Vector Sketch Generation,"Recent advancements in large vision-language models have enabled highly
expressive and diverse vector sketch generation. However, state-of-the-art
methods rely on a time-consuming optimization process involving repeated
feedback from a pretrained model to determine stroke placement. Consequently,
despite producing impressive sketches, these methods are limited in practical
applications. In this work, we introduce SwiftSketch, a diffusion model for
image-conditioned vector sketch generation that can produce high-quality
sketches in less than a second. SwiftSketch operates by progressively denoising
stroke control points sampled from a Gaussian distribution. Its
transformer-decoder architecture is designed to effectively handle the discrete
nature of vector representation and capture the inherent global dependencies
between strokes. To train SwiftSketch, we construct a synthetic dataset of
image-sketch pairs, addressing the limitations of existing sketch datasets,
which are often created by non-artists and lack professional quality. For
generating these synthetic sketches, we introduce ControlSketch, a method that
enhances SDS-based techniques by incorporating precise spatial control through
a depth-aware ControlNet. We demonstrate that SwiftSketch generalizes across
diverse concepts, efficiently producing sketches that combine high fidelity
with a natural and visually appealing style.",http://arxiv.org/abs/2502.08642v1,Reinforcement Learning,"sketch, sketches, swiftsketch, vector, diverse"
Utility Engineering: Analyzing and Controlling Emergent Value Systems in AIs,"As AIs rapidly advance and become more agentic, the risk they pose is
governed not only by their capabilities but increasingly by their propensities,
including goals and values. Tracking the emergence of goals and values has
proven a longstanding problem, and despite much interest over the years it
remains unclear whether current AIs have meaningful values. We propose a
solution to this problem, leveraging the framework of utility functions to
study the internal coherence of AI preferences. Surprisingly, we find that
independently-sampled preferences in current LLMs exhibit high degrees of
structural coherence, and moreover that this emerges with scale. These findings
suggest that value systems emerge in LLMs in a meaningful sense, a finding with
broad implications. To study these emergent value systems, we propose utility
engineering as a research agenda, comprising both the analysis and control of
AI utilities. We uncover problematic and often shocking values in LLM
assistants despite existing control measures. These include cases where AIs
value themselves over humans and are anti-aligned with specific individuals. To
constrain these emergent value systems, we propose methods of utility control.
As a case study, we show how aligning utilities with a citizen assembly reduces
political biases and generalizes to new scenarios. Whether we like it or not,
value systems have already emerged in AIs, and much work remains to fully
understand and control these emergent representations.",http://arxiv.org/abs/2502.08640v1,Recommendation System,"value, ais, values, systems, control"
CineMaster: A 3D-Aware and Controllable Framework for Cinematic Text-to-Video Generation,"In this work, we present CineMaster, a novel framework for 3D-aware and
controllable text-to-video generation. Our goal is to empower users with
comparable controllability as professional film directors: precise placement of
objects within the scene, flexible manipulation of both objects and camera in
3D space, and intuitive layout control over the rendered frames. To achieve
this, CineMaster operates in two stages. In the first stage, we design an
interactive workflow that allows users to intuitively construct 3D-aware
conditional signals by positioning object bounding boxes and defining camera
movements within the 3D space. In the second stage, these control
signals--comprising rendered depth maps, camera trajectories and object class
labels--serve as the guidance for a text-to-video diffusion model, ensuring to
generate the user-intended video content. Furthermore, to overcome the scarcity
of in-the-wild datasets with 3D object motion and camera pose annotations, we
carefully establish an automated data annotation pipeline that extracts 3D
bounding boxes and camera trajectories from large-scale video data. Extensive
qualitative and quantitative experiments demonstrate that CineMaster
significantly outperforms existing methods and implements prominent 3D-aware
text-to-video generation. Project page: https://cinemaster-dev.github.io/.",http://arxiv.org/abs/2502.08639v1,Recommendation System,"video, camera, cinemaster, aware, text"
Joint Transmit and Pinching Beamforming for PASS: Optimization-Based or Learning-Based?,"A novel pinching antenna system (PASS)-enabled downlink multi-user
multiple-input single-output (MISO) framework is proposed. PASS consists of
multiple waveguides spanning over thousands of wavelength, which equip numerous
low-cost dielectric particles, named pinching antennas (PAs), to radiate
signals into free space. The positions of PAs can be reconfigured to change
both the large-scale path losses and phases of signals, thus facilitating the
novel pinching beamforming design. A sum rate maximization problem is
formulated, which jointly optimizes the transmit and pinching beamforming to
adaptively achieve constructive signal enhancement and destructive interference
mitigation. To solve this highly coupled and nonconvex problem, both
optimization-based and learning-based methods are proposed. 1) For the
optimization-based method, a majorization-minimization and penalty dual
decomposition (MM-PDD) algorithm is developed, which handles the nonconvex
complex exponential component using a Lipschitz surrogate function and then
invokes PDD for problem decoupling. 2) For the learning-based method, a novel
Karush-Kuhn-Tucker (KKT)-guided dual learning (KDL) approach is proposed, which
enables KKT solutions to be reconstructed in a data-driven manner by learning
dual variables. Following this idea, a KDL-Tranformer algorithm is developed,
which captures both inter-PA/inter-user dependencies and
channel-state-information (CSI)-beamforming dependencies by attention
mechanisms. Simulation results demonstrate that: i) The proposed PASS framework
significantly outperforms conventional massive multiple input multiple output
(MIMO) system even with a few PAs. ii) The proposed KDL-Transformer can improve
over 30% system performance than MM-PDD algorithm, while achieving a
millisecond-level response on modern GPUs.",http://arxiv.org/abs/2502.08637v1,Recommendation System,"proposed, pinching, multiple, based, learning"
PulseCheck457: A Diagnostic Benchmark for Comprehensive Spatial Reasoning of Large Multimodal Models,"Although large multimodal models (LMMs) have demonstrated remarkable
capabilities in visual scene interpretation and reasoning, their capacity for
complex and precise 3-dimensional spatial reasoning remains uncertain. Existing
benchmarks focus predominantly on 2D spatial understanding and lack a framework
to comprehensively evaluate 6D spatial reasoning across varying complexities.
To address this limitation, we present PulseCheck457, a scalable and unbiased
synthetic dataset designed with 4 key capability for spatial reasoning:
multi-object recognition, 2D location, 3D location, and 3D orientation. We
develop a cascading evaluation structure, constructing 7 question types across
5 difficulty levels that range from basic single object recognition to our new
proposed complex 6D spatial reasoning tasks. We evaluated various large
multimodal models (LMMs) on PulseCheck457, observing a general decline in
performance as task complexity increases, particularly in 3D reasoning and 6D
spatial tasks. To quantify these challenges, we introduce the Relative
Performance Dropping Rate (RPDR), highlighting key weaknesses in 3D reasoning
capabilities. Leveraging the unbiased attribute design of our dataset, we also
uncover prediction biases across different attributes, with similar patterns
observed in real-world image settings.",http://arxiv.org/abs/2502.08636v1,Recommendation System,"reasoning, spatial, large, multimodal, models"
Rapid Whole Brain Mesoscale In-vivo MR Imaging using Multi-scale Implicit Neural Representation,"Purpose: To develop and validate a novel image reconstruction technique using
implicit neural representations (INR) for multi-view thick-slice acquisitions
while reducing the scan time but maintaining high signal-to-noise ratio (SNR).
Methods: We propose Rotating-view super-resolution (ROVER)-MRI, an unsupervised
neural network-based algorithm designed to reconstruct MRI data from multi-view
thick slices, effectively reducing scan time by 2-fold while maintaining fine
anatomical details. We compare our method to both bicubic interpolation and the
current state-of-the-art regularized least-squares super-resolution
reconstruction (LS-SRR) technique. Validation is performed using ground-truth
ex-vivo monkey brain data, and we demonstrate superior reconstruction quality
across several in-vivo human datasets. Notably, we achieve the reconstruction
of a whole human brain in-vivo T2-weighted image with an unprecedented
180{\mu}m isotropic spatial resolution, accomplished in just 17 minutes of scan
time on a 7T MRI scanner. Results: ROVER-MRI outperformed LS-SRR method in
terms of reconstruction quality with 22.4% lower relative error (RE) and 7.5%
lower full-width half maximum (FWHM) indicating better preservation of fine
structural details in nearly half the scan time. Conclusion: ROVER-MRI offers
an efficient and robust approach for mesoscale MR imaging, enabling rapid,
high-resolution whole-brain scans. Its versatility holds great promise for
research applications requiring anatomical details and time-efficient imaging.",http://arxiv.org/abs/2502.08634v1,Recommendation System,"reconstruction, time, scan, resolution, mri"
Necessary and Sufficient Oracles: Toward a Computational Taxonomy For Reinforcement Learning,"Algorithms for reinforcement learning (RL) in large state spaces crucially
rely on supervised learning subroutines to estimate objects such as value
functions or transition probabilities. Since only the simplest supervised
learning problems can be solved provably and efficiently, practical performance
of an RL algorithm depends on which of these supervised learning ""oracles"" it
assumes access to (and how they are implemented). But which oracles are better
or worse? Is there a minimal oracle?
  In this work, we clarify the impact of the choice of supervised learning
oracle on the computational complexity of RL, as quantified by the oracle
strength. First, for the task of reward-free exploration in Block MDPs in the
standard episodic access model -- a ubiquitous setting for RL with function
approximation -- we identify two-context regression as a minimal oracle, i.e.
an oracle that is both necessary and sufficient (under a mild regularity
assumption). Second, we identify one-context regression as a near-minimal
oracle in the stronger reset access model, establishing a provable
computational benefit of resets in the process. Third, we broaden our focus to
Low-Rank MDPs, where we give cryptographic evidence that the analogous oracle
from the Block MDP setting is insufficient.",http://arxiv.org/abs/2502.08632v1,Reinforcement Learning,"oracle, learning, rl, supervised, access"
Ensemble based approach to quantifying uncertainty of LLM based classifications,"The output of Large Language Models (LLMs) are a function of the internal
model's parameters and the input provided into the context window. The
hypothesis presented here is that under a greedy sampling strategy the variance
in the LLM's output is a function of the conceptual certainty embedded in the
model's parametric knowledge, as well as the lexical variance in the input.
Finetuning the model results in reducing the sensitivity of the model output to
the lexical input variations. This is then applied to a classification problem
and a probabilistic method is proposed for estimating the certainties of the
predicted classes.",http://arxiv.org/abs/2502.08631v1,Natural Language Processing,"model, output, input, function, variance"
Concentration Inequalities for the Stochastic Optimization of Unbounded Objectives with Application to Denoising Score Matching,"We derive novel concentration inequalities that bound the statistical error
for a large class of stochastic optimization problems, focusing on the case of
unbounded objective functions. Our derivations utilize the following tools: 1)
A new form of McDiarmid's inequality that is based on sample dependent one
component difference bounds and which leads to a novel uniform law of large
numbers result for unbounded functions. 2) A Rademacher complexity bound for
families of functions that satisfy an appropriate local Lipschitz property. As
an application of these results, we derive statistical error bounds for
denoising score matching (DSM), an application that inherently requires one to
consider unbounded objective functions, even when the data distribution has
bounded support. In addition, our results establish the benefit of sample reuse
in algorithms that employ easily sampled auxiliary random variables in addition
to the training data, e.g., as in DSM, which uses auxiliary Gaussian random
variables.",http://arxiv.org/abs/2502.08628v1,Recommendation System,"functions, unbounded, derive, novel, bound"
Randomness of Low-Layer Parameters Determines Confusing Samples in Terms of Interaction Representations of a DNN,"In this paper, we find that the complexity of interactions encoded by a deep
neural network (DNN) can explain its generalization power. We also discover
that the confusing samples of a DNN, which are represented by non-generalizable
interactions, are determined by its low-layer parameters. In comparison, other
factors, such as high-layer parameters and network architecture, have much less
impact on the composition of confusing samples. Two DNNs with different
low-layer parameters usually have fully different sets of confusing samples,
even though they have similar performance. This finding extends the
understanding of the lottery ticket hypothesis, and well explains distinctive
representation power of different DNNs.",http://arxiv.org/abs/2502.08625v1,Recommendation System,"confusing, samples, layer, parameters, different"
Forecasting Drought Using Machine Learning in California,"Drought is a frequent and costly natural disaster in California, with major
negative impacts on agricultural production and water resource availability,
particularly groundwater. This study investigated the performance of applying
different machine learning approaches to predicting the U.S. Drought Monitor
classification in California. Four approaches were used: a convolutional neural
network (CNN), random forest, XGBoost, and long short term memory (LSTM)
recurrent neural network, and compared to a baseline persistence model. We
evaluated the models' performance in predicting severe drought (USDM drought
category D2 or higher) using a macro F1 binary classification metric. The LSTM
model emerged as the top performer, followed by XGBoost, CNN, and random
forest. Further evaluation of our results at the county level suggested that
the LSTM model would perform best in counties with more consistent drought
patterns and where severe drought was more common, and the LSTM model would
perform worse where drought scores increased rapidly. Utilizing 30 weeks of
historical data, the LSTM model successfully forecasted drought scores for a
12-week period with a Mean Absolute Error (MAE) of 0.33, equivalent to less
than half a drought category on a scale of 0 to 5. Additionally, the LSTM
achieved a macro F1 score of 0.9, indicating high accuracy in binary
classification for severe drought conditions. Evaluation of different window
and future horizon sizes in weeks suggested that at least 24 weeks of data
would result in the best performance, with best performance for shorter horizon
sizes, particularly less than eight weeks.",http://arxiv.org/abs/2502.08622v1,Recommendation System,"drought, lstm, model, performance, weeks"
Mathematical Data Science,"Can machine learning help discover new mathematical structures? In this
article we discuss an approach to doing this which one can call ""mathematical
data science"". In this paradigm, one studies mathematical objects collectively
rather than individually, by creating datasets and doing machine learning
experiments and interpretations. After an overview, we present two case
studies: murmurations in number theory and loadings of partitions related to
Kronecker coefficients in representation theory and combinatorics.",http://arxiv.org/abs/2502.08620v1,Recommendation System,"mathematical, machine, learning, studies, theory"
Continuous Cardiac Arrest Prediction in ICU using PPG Foundation Model,"Non-invasive patient monitoring for tracking and predicting adverse acute
health events is an emerging area of research. We pursue in-hospital cardiac
arrest (IHCA) prediction using only single-channel finger photoplethysmography
(PPG) signals. Our proposed two-stage model Feature Extractor-Aggregator
Network (FEAN) leverages powerful representations from pre-trained PPG
foundation models (PPG-GPT of size up to 1 Billion) stacked with sequential
classification models. We propose two FEAN variants (""1H"", ""FH"") which use the
latest one-hour and (max) 24-hour history to make decisions respectively. Our
study is the first to present IHCA prediction results in ICU patients using
only unimodal (continuous PPG signal) waveform deep representations. With our
best model, we obtain an average of 0.79 AUROC over 24~h prediction window
before CA event onset with our model peaking performance at 0.82 one hour
before CA. We also provide a comprehensive analysis of our model through
architectural tuning and PaCMAP visualization of patient health trajectory in
latent space.",http://arxiv.org/abs/2502.08612v1,Recommendation System,"ppg, model, prediction, hour, patient"
Robustly Learning Monotone Generalized Linear Models via Data Augmentation,"We study the task of learning Generalized Linear models (GLMs) in the
agnostic model under the Gaussian distribution. We give the first
polynomial-time algorithm that achieves a constant-factor approximation for
\textit{any} monotone Lipschitz activation. Prior constant-factor GLM learners
succeed for a substantially smaller class of activations. Our work resolves a
well-known open problem, by developing a robust counterpart to the classical
GLMtron algorithm (Kakade et al., 2011). Our robust learner applies more
generally, encompassing all monotone activations with bounded
$(2+\zeta)$-moments, for any fixed $\zeta>0$ -- a condition that is essentially
necessary. To obtain our results, we leverage a novel data augmentation
technique with decreasing Gaussian noise injection and prove a number of
structural results that may be useful in other settings.",http://arxiv.org/abs/2502.08611v1,Recommendation System,"gaussian, algorithm, constant, factor, monotone"
Quantifying Security Vulnerabilities: A Metric-Driven Security Analysis of Gaps in Current AI Standards,"As AI systems integrate into critical infrastructure, security gaps in AI
compliance frameworks demand urgent attention. This paper audits and quantifies
security risks in three major AI governance standards: NIST AI RMF 1.0, UK's AI
and Data Protection Risk Toolkit, and the EU's ALTAI. Using a novel risk
assessment methodology, we develop four key metrics: Risk Severity Index (RSI),
Attack Potential Index (AVPI), Compliance-Security Gap Percentage (CSGP), and
Root Cause Vulnerability Score (RCVS). Our analysis identifies 136 concerns
across the frameworks, exposing significant gaps. NIST fails to address 69.23
percent of identified risks, ALTAI has the highest attack vector vulnerability
(AVPI = 0.51) and the ICO Toolkit has the largest compliance-security gap, with
80.00 percent of high-risk concerns remaining unresolved. Root cause analysis
highlights under-defined processes (ALTAI RCVS = 033) and weak implementation
guidance (NIST and ICO RCVS = 0.25) as critical weaknesses. These findings
emphasize the need for stronger, enforceable security controls in AI
compliance. We offer targeted recommendations to enhance security posture and
bridge the gap between compliance and real-world AI risks.",http://arxiv.org/abs/2502.08610v1,Recommendation System,"ai, security, compliance, risk, risks"
Distillation Scaling Laws,"We provide a distillation scaling law that estimates distilled model
performance based on a compute budget and its allocation between the student
and teacher. Our findings reduce the risks associated with using distillation
at scale; compute allocation for both the teacher and student models can now be
done to maximize student performance. We provide compute optimal distillation
recipes for when 1) a teacher exists, or 2) a teacher needs training. If many
students are to be distilled, or a teacher already exists, distillation
outperforms supervised pretraining until a compute level which grows
predictably with student size. If one student is to be distilled and a teacher
also needs training, supervised learning should be done instead. Additionally,
we provide insights across our large scale study of distillation, which
increase our understanding of distillation and inform experimental design.",http://arxiv.org/abs/2502.08606v1,Recommendation System,"distillation, teacher, student, compute, provide"
CurvGAD: Leveraging Curvature for Enhanced Graph Anomaly Detection,"Does the intrinsic curvature of complex networks hold the key to unveiling
graph anomalies that conventional approaches overlook? Reconstruction-based
graph anomaly detection (GAD) methods overlook such geometric outliers,
focusing only on structural and attribute-level anomalies. To this end, we
propose CurvGAD - a mixed-curvature graph autoencoder that introduces the
notion of curvature-based geometric anomalies. CurvGAD introduces two parallel
pipelines for enhanced anomaly interpretability: (1) Curvature-equivariant
geometry reconstruction, which focuses exclusively on reconstructing the edge
curvatures using a mixed-curvature, Riemannian encoder and Gaussian
kernel-based decoder; and (2) Curvature-invariant structure and attribute
reconstruction, which decouples structural and attribute anomalies from
geometric irregularities by regularizing graph curvature under discrete
Ollivier-Ricci flow, thereby isolating the non-geometric anomalies. By
leveraging curvature, CurvGAD refines the existing anomaly classifications and
identifies new curvature-driven anomalies. Extensive experimentation over 10
real-world datasets (both homophilic and heterophilic) demonstrates an
improvement of up to 6.5% over state-of-the-art GAD methods.",http://arxiv.org/abs/2502.08605v1,Recommendation System,"curvature, anomalies, graph, geometric, reconstruction"
Scalable Thermodynamic Second-order Optimization,"Many hardware proposals have aimed to accelerate inference in AI workloads.
Less attention has been paid to hardware acceleration of training, despite the
enormous societal impact of rapid training of AI models. Physics-based
computers, such as thermodynamic computers, offer an efficient means to solve
key primitives in AI training algorithms. Optimizers that normally would be
computationally out-of-reach (e.g., due to expensive matrix inversions) on
digital hardware could be unlocked with physics-based hardware. In this work,
we propose a scalable algorithm for employing thermodynamic computers to
accelerate a popular second-order optimizer called Kronecker-factored
approximate curvature (K-FAC). Our asymptotic complexity analysis predicts
increasing advantage with our algorithm as $n$, the number of neurons per
layer, increases. Numerical experiments show that even under significant
quantization noise, the benefits of second-order optimization can be preserved.
Finally, we predict substantial speedups for large-scale vision and graph
problems based on realistic hardware characteristics.",http://arxiv.org/abs/2502.08603v1,Recommendation System,"hardware, ai, training, based, computers"
Two-stage hybrid models for enhancing forecasting accuracy on heterogeneous time series,"Compared to local models built in a series-by-series manner, global models
leverage relevant information across time series, resulting in improved
forecasting performance and generalization capacity. Constructing global models
on a set of time series is becoming mainstream in the field of time series
forecasting. However, the advantages of global models may not always be
realized when dealing with heterogeneous data. While they can adapt to
heterogeneous datasets by increasing the model complexity, the model cannot be
infinitely complex due to the finite sample size, which poses challenges for
the application of global models. Additionally, determining whether the time
series data is homogeneous or heterogeneous can be ambiguous in practice. To
address these research gaps, this paper argues that the heterogeneity of the
data should be defined by the global model used, and for each series, the
portion not modelled by the global model represents heterogeneity. It further
proposes two-stage hybrid models, which include a second stage to identify and
model heterogeneous patterns. In this second stage, we can estimate either all
local models or sub-global models across different domains divided based on
heterogeneity. Experiments on four open datasets reveal that the proposed
methods significantly outperform five existing models, indicating they
contribute to fully unleash the potential of global models on heterogeneous
datasets.",http://arxiv.org/abs/2502.08600v1,Recommendation System,"models, global, series, heterogeneous, model"
Enhancing Diffusion Models Efficiency by Disentangling Total-Variance and Signal-to-Noise Ratio,"The long sampling time of diffusion models remains a significant bottleneck,
which can be mitigated by reducing the number of diffusion time steps. However,
the quality of samples with fewer steps is highly dependent on the noise
schedule, i.e., the specific manner in which noise is introduced and the signal
is reduced at each step. Although prior work has improved upon the original
variance-preserving and variance-exploding schedules, these approaches
$\textit{passively}$ adjust the total variance, without direct control over it.
In this work, we propose a novel total-variance/signal-to-noise-ratio
disentangled (TV/SNR) framework, where TV and SNR can be controlled
independently. Our approach reveals that different existing schedules, where
the TV explodes exponentially, can be $\textit{improved}$ by setting a constant
TV schedule while preserving the same SNR schedule. Furthermore, generalizing
the SNR schedule of the optimal transport flow matching significantly improves
the performance in molecular structure generation, achieving few step
generation of stable molecules. A similar tendency is observed in image
generation, where our approach with a uniform diffusion time grid performs
comparably to the highly tailored EDM sampler.",http://arxiv.org/abs/2502.08598v1,Recommendation System,"schedule, variance, tv, snr, time"
Learning in Markets with Heterogeneous Agents: Dynamics and Survival of Bayesian vs. No-Regret Learners,"We analyze the performance of heterogeneous learning agents in asset markets
with stochastic payoffs. Our agents aim to maximize the expected growth rate of
their wealth but have different theories on how to learn this best. We focus on
comparing Bayesian and no-regret learners in market dynamics. Bayesian learners
with a prior over a finite set of models that assign positive prior probability
to the correct model have posterior probabilities that converge exponentially
to the correct model. Consequently, they survive even in the presence of agents
who invest according to the correct model of the stochastic process. Bayesians
with a continuum prior converge to the correct model at a rate of $O((\log
T)/T)$. Online learning theory provides no-regret algorithms for maximizing the
log of wealth in this setting, achieving a worst-case regret bound of $O(\log
T)$ without assuming a steady underlying stochastic process but comparing to
the best fixed investment rule. This regret, as we observe, is of the same
order of magnitude as that of a Bayesian learner with a continuum prior.
However, we show that even such low regret may not be sufficient for survival
in asset markets: an agent can have regret as low as $O(\log T)$, but still
vanish in market dynamics when competing against agents who invest according to
the correct model or even against a perfect Bayesian with a finite prior. On
the other hand, we show that Bayesian learning is fragile, while no-regret
learning requires less knowledge of the environment and is therefore more
robust. Any no-regret learner will drive out of the market an imperfect
Bayesian whose finite prior or update rule has even small errors. We formally
establish the relationship between notions of survival, vanishing, and market
domination studied in economics and the framework of regret minimization, thus
bridging these theories.",http://arxiv.org/abs/2502.08597v1,Recommendation System,"regret, bayesian, prior, correct, model"
Toward Universal Laws of Outlier Propagation,"We argue that Algorithmic Information Theory (AIT) admits a principled way to
quantify outliers in terms of so-called randomness deficiency. For the
probability distribution generated by a causal Bayesian network, we show that
the randomness deficiency of the joint state decomposes into randomness
deficiencies of each causal mechanism, subject to the Independence of
Mechanisms Principle. Accordingly, anomalous joint observations can be
quantitatively attributed to their root causes, i.e., the mechanisms that
behaved anomalously. As an extension of Levin's law of randomness conservation,
we show that weak outliers cannot cause strong ones when Independence of
Mechanisms holds. We show how these information theoretic laws provide a better
understanding of the behaviour of outliers defined with respect to existing
scores.",http://arxiv.org/abs/2502.08593v1,Recommendation System,"randomness, outliers, mechanisms, information, deficiency"
Light-A-Video: Training-free Video Relighting via Progressive Light Fusion,"Recent advancements in image relighting models, driven by large-scale
datasets and pre-trained diffusion models, have enabled the imposition of
consistent lighting. However, video relighting still lags, primarily due to the
excessive training costs and the scarcity of diverse, high-quality video
relighting datasets. A simple application of image relighting models on a
frame-by-frame basis leads to several issues: lighting source inconsistency and
relighted appearance inconsistency, resulting in flickers in the generated
videos. In this work, we propose Light-A-Video, a training-free approach to
achieve temporally smooth video relighting. Adapted from image relighting
models, Light-A-Video introduces two key techniques to enhance lighting
consistency. First, we design a Consistent Light Attention (CLA) module, which
enhances cross-frame interactions within the self-attention layers to stabilize
the generation of the background lighting source. Second, leveraging the
physical principle of light transport independence, we apply linear blending
between the source video's appearance and the relighted appearance, using a
Progressive Light Fusion (PLF) strategy to ensure smooth temporal transitions
in illumination. Experiments show that Light-A-Video improves the temporal
consistency of relighted video while maintaining the image quality, ensuring
coherent lighting transitions across frames. Project page:
https://bujiazi.github.io/light-a-video.github.io/.",http://arxiv.org/abs/2502.08590v1,Recommendation System,"video, relighting, light, lighting, image"
Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks,"A high volume of recent ML security literature focuses on attacks against
aligned large language models (LLMs). These attacks may extract private
information or coerce the model into producing harmful outputs. In real-world
deployments, LLMs are often part of a larger agentic pipeline including memory
systems, retrieval, web access, and API calling. Such additional components
introduce vulnerabilities that make these LLM-powered agents much easier to
attack than isolated LLMs, yet relatively little work focuses on the security
of LLM agents. In this paper, we analyze security and privacy vulnerabilities
that are unique to LLM agents. We first provide a taxonomy of attacks
categorized by threat actors, objectives, entry points, attacker observability,
attack strategies, and inherent vulnerabilities of agent pipelines. We then
conduct a series of illustrative attacks on popular open-source and commercial
agents, demonstrating the immediate practical implications of their
vulnerabilities. Notably, our attacks are trivial to implement and require no
understanding of machine learning.",http://arxiv.org/abs/2502.08586v1,Natural Language Processing,"attacks, vulnerabilities, agents, security, llms"
Scalable Bilevel Loss Balancing for Multi-Task Learning,"Multi-task learning (MTL) has been widely adopted for its ability to
simultaneously learn multiple tasks. While existing gradient manipulation
methods often yield more balanced solutions than simple scalarization-based
approaches, they typically incur a significant computational overhead of
$\mathcal{O}(K)$ in both time and memory, where $K$ is the number of tasks. In
this paper, we propose BiLB4MTL, a simple and scalable loss balancing approach
for MTL, formulated from a novel bilevel optimization perspective. Our method
incorporates three key components: (i) an initial loss normalization, (ii) a
bilevel loss-balancing formulation, and (iii) a scalable first-order algorithm
that requires only $\mathcal{O}(1)$ time and memory. Theoretically, we prove
that BiLB4MTL guarantees convergence not only to a stationary point of the
bilevel loss balancing problem but also to an $\epsilon$-accurate Pareto
stationary point for all $K$ loss functions under mild conditions. Extensive
experiments on diverse multi-task datasets demonstrate that BiLB4MTL achieves
state-of-the-art performance in both accuracy and efficiency. Code is available
at https://github.com/OptMN-Lab/-BiLB4MTL.",http://arxiv.org/abs/2502.08585v1,Recommendation System,"loss, balancing, bilevel, multi, task"
A method for classification of data with uncertainty using hypothesis testing,"Binary classification is a task that involves the classification of data into
one of two distinct classes. It is widely utilized in various fields. However,
conventional classifiers tend to make overconfident predictions for data that
belong to overlapping regions of the two class distributions or for data
outside the distributions (out-of-distribution data). Therefore, conventional
classifiers should not be applied in high-risk fields where classification
results can have significant consequences. In order to address this issue, it
is necessary to quantify uncertainty and adopt decision-making approaches that
take it into account. Many methods have been proposed for this purpose;
however, implementing these methods often requires performing resampling,
improving the structure or performance of models, and optimizing the thresholds
of classifiers. We propose a new decision-making approach using two types of
hypothesis testing. This method is capable of detecting ambiguous data that
belong to the overlapping regions of two class distributions, as well as
out-of-distribution data that are not included in the training data
distribution. In addition, we quantify uncertainty using the empirical
distribution of feature values derived from the training data obtained through
the trained model. The classification threshold is determined by the
$\alpha$-quantile and ($1-\alpha$)-quantile, where the significance level
$\alpha$ is set according to each specific situation.",http://arxiv.org/abs/2502.08582v1,Recommendation System,"data, classification, distribution, classifiers, distributions"
Ultrasound Image Generation using Latent Diffusion Models,"Diffusion models for image generation have been a subject of increasing
interest due to their ability to generate diverse, high-quality images. Image
generation has immense potential in medical imaging because open-source medical
images are difficult to obtain compared to natural images, especially for rare
conditions. The generated images can be used later to train classification and
segmentation models. In this paper, we propose simulating realistic ultrasound
(US) images by successive fine-tuning of large diffusion models on different
publicly available databases. To do so, we fine-tuned Stable Diffusion, a
state-of-the-art latent diffusion model, on BUSI (Breast US Images) an
ultrasound breast image dataset. We successfully generated high-quality US
images of the breast using simple prompts that specify the organ and pathology,
which appeared realistic to three experienced US scientists and a US
radiologist. Additionally, we provided user control by conditioning the model
with segmentations through ControlNet. We will release the source code at
http://code.sonography.ai/ to allow fast US image generation to the scientific
community.",http://arxiv.org/abs/2502.08580v1,Recommendation System,"images, diffusion, image, models, generation"
FBFL: A Field-Based Coordination Approach for Data Heterogeneity in Federated Learning,"In the last years, Federated learning (FL) has become a popular solution to
train machine learning models in domains with high privacy concerns. However,
FL scalability and performance face significant challenges in real-world
deployments where data across devices are non-independently and identically
distributed (non-IID). The heterogeneity in data distribution frequently arises
from spatial distribution of devices, leading to degraded model performance in
the absence of proper handling. Additionally, FL typical reliance on
centralized architectures introduces bottlenecks and single-point-of-failure
risks, particularly problematic at scale or in dynamic environments. To close
this gap, we propose Field-Based Federated Learning (FBFL), a novel approach
leveraging macroprogramming and field coordination to address these limitations
through: (i) distributed spatial-based leader election for personalization to
mitigate non-IID data challenges; and (ii) construction of a self-organizing,
hierarchical architecture using advanced macroprogramming patterns. Moreover,
FBFL not only overcomes the aforementioned limitations, but also enables the
development of more specialized models tailored to the specific data
distribution in each subregion. This paper formalizes FBFL and evaluates it
extensively using MNIST, FashionMNIST, and Extended MNIST datasets. We
demonstrate that, when operating under IID data conditions, FBFL performs
comparably to the widely-used FedAvg algorithm. Furthermore, in challenging
non-IID scenarios, FBFL not only outperforms FedAvg but also surpasses other
state-of-the-art methods, namely FedProx and Scaffold, which have been
specifically designed to address non-IID data distributions. Additionally, we
showcase the resilience of FBFL's self-organizing hierarchical architecture
against server failures.",http://arxiv.org/abs/2502.08577v1,Reinforcement Learning,"data, fbfl, non, iid, learning"
Mapping the Landscape of Generative AI in Network Monitoring and Management,"Generative Artificial Intelligence (GenAI) models such as LLMs, GPTs, and
Diffusion Models have recently gained widespread attention from both the
research and the industrial communities. This survey explores their application
in network monitoring and management, focusing on prominent use cases, as well
as challenges and opportunities. We discuss how network traffic generation and
classification, network intrusion detection, networked system log analysis, and
network digital assistance can benefit from the use of GenAI models.
Additionally, we provide an overview of the available GenAI models, datasets
for large-scale training phases, and platforms for the development of such
models. Finally, we discuss research directions that potentially mitigate the
roadblocks to the adoption of GenAI for network monitoring and management. Our
investigation aims to map the current landscape and pave the way for future
research in leveraging GenAI for network monitoring and management.",http://arxiv.org/abs/2502.08576v1,Recommendation System,"network, genai, models, research, monitoring"
COAST: Intelligent Time-Adaptive Neural Operators,"We introduce Causal Operator with Adaptive Solver Transformer (COAST), a
novel neural operator learning method that leverages a causal language model
(CLM) framework to dynamically adapt time steps. Our method predicts both the
evolution of a system and its optimal time step, intelligently balancing
computational efficiency and accuracy. We find that COAST generates variable
step sizes that correlate with the underlying system intrinsicities, both
within and across dynamical systems. Within a single trajectory, smaller steps
are taken in regions of high complexity, while larger steps are employed in
simpler regions. Across different systems, more complex dynamics receive more
granular time steps. Benchmarked on diverse systems with varied dynamics, COAST
consistently outperforms state-of-the-art methods, achieving superior
performance in both efficiency and accuracy. This work underscores the
potential of CLM-based intelligent adaptive solvers for scalable operator
learning of dynamical systems.",http://arxiv.org/abs/2502.08574v1,Reinforcement Learning,"steps, systems, operator, coast, time"
A Novel Approach to for Multimodal Emotion Recognition : Multimodal semantic information fusion,"With the advancement of artificial intelligence and computer vision
technologies, multimodal emotion recognition has become a prominent research
topic. However, existing methods face challenges such as heterogeneous data
fusion and the effective utilization of modality correlations. This paper
proposes a novel multimodal emotion recognition approach, DeepMSI-MER, based on
the integration of contrastive learning and visual sequence compression. The
proposed method enhances cross-modal feature fusion through contrastive
learning and reduces redundancy in the visual modality by leveraging visual
sequence compression. Experimental results on two public datasets, IEMOCAP and
MELD, demonstrate that DeepMSI-MER significantly improves the accuracy and
robustness of emotion recognition, validating the effectiveness of multimodal
feature fusion and the proposed approach.",http://arxiv.org/abs/2502.08573v1,Computer Vision,"multimodal, emotion, recognition, fusion, visual"
AR Glulam: Accurate Augmented Reality Using Multiple Fiducial Markers for Glulam Fabrication,"Recent advancements in Augmented Reality (AR) have demonstrated applications
in architecture, design, and fabrication. Compared to conventional 2D
construction drawings, AR can be used to superimpose contextual instructions,
display 3D spatial information and enable on-site engagement. Despite the
potential of AR, the widespread adoption of the technology in the industry is
limited by its precision. Precision is important for projects requiring strict
construction tolerances, design fidelity, and fabrication feedback. For
example, the manufacturing of glulam beams requires tolerances of less than
2mm. The goal of this project is to explore the industrial application of using
multiple fiducial markers for high-precision AR fabrication. While the method
has been validated in lab settings with a precision of 0.97, this paper focuses
on fabricating glulam beams in a factory setting with an industry manufacturer,
Unalam Factory.",http://arxiv.org/abs/2502.08566v1,Recommendation System,"ar, precision, fabrication, design, construction"
Brain Latent Progression: Individual-based Spatiotemporal Disease Progression on 3D Brain MRIs via Latent Diffusion,"The growing availability of longitudinal Magnetic Resonance Imaging (MRI)
datasets has facilitated Artificial Intelligence (AI)-driven modeling of
disease progression, making it possible to predict future medical scans for
individual patients. However, despite significant advancements in AI, current
methods continue to face challenges including achieving patient-specific
individualization, ensuring spatiotemporal consistency, efficiently utilizing
longitudinal data, and managing the substantial memory demands of 3D scans. To
address these challenges, we propose Brain Latent Progression (BrLP), a novel
spatiotemporal model designed to predict individual-level disease progression
in 3D brain MRIs. The key contributions in BrLP are fourfold: (i) it operates
in a small latent space, mitigating the computational challenges posed by
high-dimensional imaging data; (ii) it explicitly integrates subject metadata
to enhance the individualization of predictions; (iii) it incorporates prior
knowledge of disease dynamics through an auxiliary model, facilitating the
integration of longitudinal data; and (iv) it introduces the Latent Average
Stabilization (LAS) algorithm, which (a) enforces spatiotemporal consistency in
the predicted progression at inference time and (b) allows us to derive a
measure of the uncertainty for the prediction. We train and evaluate BrLP on
11,730 T1-weighted (T1w) brain MRIs from 2,805 subjects and validate its
generalizability on an external test set comprising 2,257 MRIs from 962
subjects. Our experiments compare BrLP-generated MRI scans with real follow-up
MRIs, demonstrating state-of-the-art accuracy compared to existing methods. The
code is publicly available at: https://github.com/LemuelPuglisi/BrLP.",http://arxiv.org/abs/2502.08560v1,Recommendation System,"progression, brlp, mris, longitudinal, disease"
QA-Expand: Multi-Question Answer Generation for Enhanced Query Expansion in Information Retrieval,"Query expansion is widely used in Information Retrieval (IR) to improve
search outcomes by enriching queries with additional contextual information.
Although recent Large Language Model (LLM) based methods generate
pseudo-relevant content and expanded terms via multiple prompts, they often
yield repetitive, narrow expansions that lack the diverse context needed to
retrieve all relevant information. In this paper, we introduce QA-Expand, a
novel and effective framework for query expansion. It first generates multiple
relevant questions from the initial query and subsequently produces
corresponding pseudo-answers as surrogate documents. A feedback model further
rewrites and filters these answers to ensure only the most informative
augmentations are incorporated. Extensive experiments on benchmarks such as
BEIR and TREC demonstrate that QA-Expand enhances retrieval performance by up
to 13% over state-of-the-art methods, offering a robust solution for modern
retrieval challenges.",http://arxiv.org/abs/2502.08557v1,Natural Language Processing,"query, information, retrieval, relevant, expansion"
"Human-Centric Foundation Models: Perception, Generation and Agentic Modeling","Human understanding and generation are critical for modeling digital humans
and humanoid embodiments. Recently, Human-centric Foundation Models (HcFMs)
inspired by the success of generalist models, such as large language and vision
models, have emerged to unify diverse human-centric tasks into a single
framework, surpassing traditional task-specific approaches. In this survey, we
present a comprehensive overview of HcFMs by proposing a taxonomy that
categorizes current approaches into four groups: (1) Human-centric Perception
Foundation Models that capture fine-grained features for multi-modal 2D and 3D
understanding. (2) Human-centric AIGC Foundation Models that generate
high-fidelity, diverse human-related content. (3) Unified Perception and
Generation Models that integrate these capabilities to enhance both human
understanding and synthesis. (4) Human-centric Agentic Foundation Models that
extend beyond perception and generation to learn human-like intelligence and
interactive behaviors for humanoid embodied tasks. We review state-of-the-art
techniques, discuss emerging challenges and future research directions. This
survey aims to serve as a roadmap for researchers and practitioners working
towards more robust, versatile, and intelligent digital human and embodiments
modeling.",http://arxiv.org/abs/2502.08556v1,Recommendation System,"human, models, centric, foundation, understanding"
A Machine Learning-Ready Data Processing Tool for Near Real-Time Forecasting,"Space weather forecasting is critical for mitigating radiation risks in space
exploration and protecting Earth-based technologies from geomagnetic
disturbances. This paper presents the development of a Machine Learning (ML)-
ready data processing tool for Near Real-Time (NRT) space weather forecasting.
By merging data from diverse NRT sources such as solar imagery, magnetic field
measurements, and energetic particle fluxes, the tool addresses key gaps in
current space weather prediction capabilities. The tool processes and
structures the data for machine learning models, focusing on time-series
forecasting and event detection for extreme solar events. It provides users
with a framework to download, process, and label data for ML applications,
streamlining the workflow for improved NRT space weather forecasting and
scientific research.",http://arxiv.org/abs/2502.08555v1,Recommendation System,"space, weather, forecasting, data, tool"
"Fostering Appropriate Reliance on Large Language Models: The Role of Explanations, Sources, and Inconsistencies","Large language models (LLMs) can produce erroneous responses that sound
fluent and convincing, raising the risk that users will rely on these responses
as if they were correct. Mitigating such overreliance is a key challenge.
Through a think-aloud study in which participants use an LLM-infused
application to answer objective questions, we identify several features of LLM
responses that shape users' reliance: explanations (supporting details for
answers), inconsistencies in explanations, and sources. Through a large-scale,
pre-registered, controlled experiment (N=308), we isolate and study the effects
of these features on users' reliance, accuracy, and other measures. We find
that the presence of explanations increases reliance on both correct and
incorrect responses. However, we observe less reliance on incorrect responses
when sources are provided or when explanations exhibit inconsistencies. We
discuss the implications of these findings for fostering appropriate reliance
on LLMs.",http://arxiv.org/abs/2502.08554v1,Reinforcement Learning,"responses, reliance, explanations, users, large"
LLMs can implicitly learn from mistakes in-context,"Learning from mistakes is a fundamental feature of human intelligence.
Previous work has shown that Large Language Models (LLMs) can also learn from
incorrect answers when provided with a comprehensive rationale detailing why an
answer is wrong or how to correct it. In this work, we examine whether LLMs can
learn from mistakes in mathematical reasoning tasks when these explanations are
not provided. We investigate if LLMs are able to implicitly infer such
rationales simply from observing both incorrect and correct answers.
Surprisingly, we find that LLMs perform better, on average, when rationales are
eliminated from the context and incorrect answers are simply shown alongside
correct ones. This approach also substantially outperforms chain-of-thought
prompting in our evaluations. We show that these results are consistent across
LLMs of different sizes and varying reasoning abilities. Further, we carry out
an in-depth analysis, and show that prompting with both wrong and correct
answers leads to greater performance and better generalisation than introducing
additional, more diverse question-answer pairs into the context. Finally, we
show that new rationales generated by models that have only observed incorrect
and correct answers are scored equally as highly by humans as those produced
with the aid of exemplar rationales. Our results demonstrate that LLMs are
indeed capable of in-context implicit learning.",http://arxiv.org/abs/2502.08550v1,Recommendation System,"llms, answers, correct, incorrect, rationales"
Copula-based mixture model identification for subgroup clustering with imaging applications,"Model-based clustering techniques have been widely applied to various
application areas, while most studies focus on canonical mixtures with unique
component distribution form. However, this strict assumption is often hard to
satisfy. In this paper, we consider the more flexible Copula-Based Mixture
Models (CBMMs) for clustering, which allow heterogeneous component
distributions composed by flexible choices of marginal and copula forms. More
specifically, we propose an adaptation of the Generalized Iterative Conditional
Estimation (GICE) algorithm to identify the CBMMs in an unsupervised manner,
where the marginal and copula forms and their parameters are estimated
iteratively. GICE is adapted from its original version developed for switching
Markov model identification with the choice of realization time. Our CBMM-GICE
clustering method is then tested on synthetic two-cluster data (N=2000 samples)
with discussion of the factors impacting its convergence. Finally, it is
compared to the Expectation Maximization identified mixture models with unique
component form on the entire MNIST database (N=70000), and on real cardiac
magnetic resonance data (N=276) to illustrate its value for imaging
applications.",http://arxiv.org/abs/2502.08549v1,Recommendation System,"clustering, component, copula, gice, model"
Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data,"The adoption of EHRs has expanded opportunities to leverage data-driven
algorithms in clinical care and research. A major bottleneck in effectively
conducting multi-institutional EHR studies is the data heterogeneity across
systems with numerous codes that either do not exist or represent different
clinical concepts across institutions. The need for data privacy further limits
the feasibility of including multi-institutional patient-level data required to
study similarities and differences across patient subgroups. To address these
challenges, we developed the GAME algorithm. Tested and validated across 7
institutions and 2 languages, GAME integrates data in several levels: (1) at
the institutional level with knowledge graphs to establish relationships
between codes and existing knowledge sources, providing the medical context for
standard codes and their relationship to each other; (2) between institutions,
leveraging language models to determine the relationships between
institution-specific codes with established standard codes; and (3) quantifying
the strength of the relationships between codes using a graph attention
network. Jointly trained embeddings are created using transfer and federated
learning to preserve data privacy. In this study, we demonstrate the
applicability of GAME in selecting relevant features as inputs for AI-driven
algorithms in a range of conditions, e.g., heart failure, rheumatoid arthritis.
We then highlight the application of GAME harmonized multi-institutional EHR
data in a study of Alzheimer's disease outcomes and suicide risk among patients
with mental health disorders, without sharing patient-level data outside
individual institutions.",http://arxiv.org/abs/2502.08547v1,Reinforcement Learning,"data, codes, institutional, institutions, game"
Moment of Untruth: Dealing with Negative Queries in Video Moment Retrieval,"Video Moment Retrieval is a common task to evaluate the performance of
visual-language models - it involves localising start and end times of moments
in videos from query sentences. The current task formulation assumes that the
queried moment is present in the video, resulting in false positive moment
predictions when irrelevant query sentences are provided.
  In this paper we propose the task of Negative-Aware Video Moment Retrieval
(NA-VMR), which considers both moment retrieval accuracy and negative query
rejection accuracy. We make the distinction between In-Domain and Out-of-Domain
negative queries and provide new evaluation benchmarks for two popular video
moment retrieval datasets: QVHighlights and Charades-STA. We analyse the
ability of current SOTA video moment retrieval approaches to adapt to
Negative-Aware Video Moment Retrieval and propose UniVTG-NA, an adaptation of
UniVTG designed to tackle NA-VMR. UniVTG-NA achieves high negative rejection
accuracy (avg. $98.4\%$) scores while retaining moment retrieval scores to
within $3.87\%$ Recall@1. Dataset splits and code are available at
https://github.com/keflanagan/MomentofUntruth",http://arxiv.org/abs/2502.08544v1,Recommendation System,"moment, retrieval, video, negative, na"
Beyond Predictions: A Participatory Framework for Multi-Stakeholder Decision-Making,"Conventional decision-support systems, primarily based on supervised
learning, focus on outcome prediction models to recommend actions. However,
they often fail to account for the complexities of multi-actor environments,
where diverse and potentially conflicting stakeholder preferences must be
balanced. In this paper, we propose a novel participatory framework that
redefines decision-making as a multi-stakeholder optimization problem,
capturing each actor's preferences through context-dependent reward functions.
Our framework leverages $k$-fold cross-validation to fine-tune user-provided
outcome prediction models and evaluate decision strategies, including
compromise functions mediating stakeholder trade-offs. We introduce a synthetic
scoring mechanism that exploits user-defined preferences across multiple
metrics to rank decision-making strategies and identify the optimal
decision-maker. The selected decision-maker can then be used to generate
actionable recommendations for new data. We validate our framework using two
real-world use cases, demonstrating its ability to deliver recommendations that
effectively balance multiple metrics, achieving results that are often beyond
the scope of purely prediction-based methods. Ablation studies demonstrate that
our framework, with its modular, model-agnostic, and inherently transparent
design, integrates seamlessly with various predictive models, reward
structures, evaluation metrics, and sample sizes, making it particularly suited
for complex, high-stakes decision-making contexts.",http://arxiv.org/abs/2502.08542v1,Recommendation System,"decision, framework, making, prediction, models"
"A Survey on Image Quality Assessment: Insights, Analysis, and Future Outlook","Image quality assessment (IQA) represents a pivotal challenge in
image-focused technologies, significantly influencing the advancement
trajectory of image processing and computer vision. Recently, IQA has witnessed
a notable surge in innovative research efforts, driven by the emergence of
novel architectural paradigms and sophisticated computational techniques. This
survey delivers an extensive analysis of contemporary IQA methodologies,
organized according to their application scenarios, serving as a beneficial
reference for both beginners and experienced researchers. We analyze the
advantages and limitations of current approaches and suggest potential future
research pathways. The survey encompasses both general and specific IQA
methodologies, including conventional statistical measures, machine learning
techniques, and cutting-edge deep learning models such as convolutional neural
networks (CNNs) and Transformer models. The analysis within this survey
highlights the necessity for distortion-specific IQA methods tailored to
various application scenarios, emphasizing the significance of practicality,
interpretability, and ease of implementation in future developments.",http://arxiv.org/abs/2502.08540v1,Computer Vision,"iqa, image, survey, research, techniques"
Matrix Completion with Graph Information: A Provable Nonconvex Optimization Approach,"We consider the problem of matrix completion with graphs as side information
depicting the interrelations between variables. The key challenge lies in
leveraging the similarity structure of the graph to enhance matrix recovery.
Existing approaches, primarily based on graph Laplacian regularization, suffer
from several limitations: (1) they focus only on the similarity between
neighboring variables, while overlooking long-range correlations; (2) they are
highly sensitive to false edges in the graphs and (3) they lack theoretical
guarantees regarding statistical and computational complexities. To address
these issues, we propose in this paper a novel graph regularized matrix
completion algorithm called GSGD, based on preconditioned projected gradient
descent approach. We demonstrate that GSGD effectively captures the
higher-order correlation information behind the graphs, and achieves superior
robustness and stability against the false edges. Theoretically, we prove that
GSGD achieves linear convergence to the global optimum with near-optimal sample
complexity, providing the first theoretical guarantees for both recovery
accuracy and efficacy in the perspective of nonconvex optimization. Our
numerical experiments on both synthetic and real-world data further validate
that GSGD achieves superior recovery accuracy and scalability compared with
several popular alternatives.",http://arxiv.org/abs/2502.08536v1,Recommendation System,"gsgd, matrix, graphs, graph, recovery"
Input convex neural networks: universal approximation theorem and implementation for isotropic polyconvex hyperelastic energies,"This paper presents a novel framework of neural networks for isotropic
hyperelasticity that enforces necessary physical and mathematical constraints
while simultaneously satisfying the universal approximation theorem. The two
key ingredients are an input convex network architecture and a formulation in
the elementary polynomials of the signed singular values of the deformation
gradient. In line with previously published networks, it can rigorously capture
frame-indifference and polyconvexity - as well as further constraints like
balance of angular momentum and growth conditions. However and in contrast to
previous networks, a universal approximation theorem for the proposed approach
is proven. To be more explicit, the proposed network can approximate any
frame-indifferent, isotropic polyconvex energy (provided the network is large
enough). This is possible by working with a sufficient and necessary criterion
for frame-indifferent, isotropic polyconvex functions. Comparative studies with
existing approaches identify the advantages of the proposed method,
particularly in approximating non-polyconvex energies as well as computing
polyconvex hulls.",http://arxiv.org/abs/2502.08534v1,Recommendation System,"polyconvex, networks, isotropic, network, frame"
On Different Notions of Redundancy in Conditional-Independence-Based Discovery of Graphical Models,"The goal of conditional-independence-based discovery of graphical models is
to find a graph that represents the independence structure of variables in a
given dataset. To learn such a representation, conditional-independence-based
approaches conduct a set of statistical tests that suffices to identify the
graphical representation under some assumptions on the underlying distribution
of the data. In this work, we highlight that due to the conciseness of the
graphical representation, there are often many tests that are not used in the
construction of the graph. These redundant tests have the potential to detect
or sometimes correct errors in the learned model. We show that not all tests
contain this additional information and that such redundant tests have to be
applied with care. Precisely, we argue that particularly those conditional
(in)dependence statements are interesting that follow only from graphical
assumptions but do not hold for every probability distribution.",http://arxiv.org/abs/2502.08531v1,Recommendation System,"tests, graphical, conditional, independence, representation"
BCDDM: Branch-Corrected Denoising Diffusion Model for Black Hole Image Generation,"The properties of black holes and accretion flows can be inferred by fitting
Event Horizon Telescope (EHT) data to simulated images generated through
general relativistic ray tracing (GRRT). However, due to the computationally
intensive nature of GRRT, the efficiency of generating specific radiation flux
images needs to be improved. This paper introduces the Branch Correction
Denoising Diffusion Model (BCDDM), which uses a branch correction mechanism and
a weighted mixed loss function to improve the accuracy of generated black hole
images based on seven physical parameters of the radiatively inefficient
accretion flow (RIAF) model. Our experiments show a strong correlation between
the generated images and their physical parameters. By enhancing the GRRT
dataset with BCDDM-generated images and using ResNet50 for parameter
regression, we achieve significant improvements in parameter prediction
performance. This approach reduces computational costs and provides a faster,
more efficient method for dataset expansion, parameter estimation, and model
fitting.",http://arxiv.org/abs/2502.08528v1,Recommendation System,"images, generated, grrt, model, parameter"
LLM Pretraining with Continuous Concepts,"Next token prediction has been the standard training objective used in large
language model pretraining. Representations are learned as a result of
optimizing for token-level perplexity. We propose Continuous Concept Mixing
(CoCoMix), a novel pretraining framework that combines discrete next token
prediction with continuous concepts. Specifically, CoCoMix predicts continuous
concepts learned from a pretrained sparse autoencoder and mixes them into the
model's hidden state by interleaving with token hidden representations. Through
experiments on multiple benchmarks, including language modeling and downstream
reasoning tasks, we show that CoCoMix is more sample efficient and consistently
outperforms standard next token prediction, knowledge distillation and
inserting pause tokens. We find that combining both concept learning and
interleaving in an end-to-end framework is critical to performance gains.
Furthermore, CoCoMix enhances interpretability and steerability by allowing
direct inspection and modification of the predicted concept, offering a
transparent way to guide the model's internal reasoning process.",http://arxiv.org/abs/2502.08524v1,Natural Language Processing,"token, cocomix, prediction, model, continuous"
FedMHO: Heterogeneous One-Shot Federated Learning Towards Resource-Constrained Edge Devices,"Federated Learning (FL) is increasingly adopted in edge computing scenarios,
where a large number of heterogeneous clients operate under constrained or
sufficient resources. The iterative training process in conventional FL
introduces significant computation and communication overhead, which is
unfriendly for resource-constrained edge devices. One-shot FL has emerged as a
promising approach to mitigate communication overhead, and model-heterogeneous
FL solves the problem of diverse computing resources across clients. However,
existing methods face challenges in effectively managing model-heterogeneous
one-shot FL, often leading to unsatisfactory global model performance or
reliance on auxiliary datasets. To address these challenges, we propose a novel
FL framework named FedMHO, which leverages deep classification models on
resource-sufficient clients and lightweight generative models on
resource-constrained devices. On the server side, FedMHO involves a two-stage
process that includes data generation and knowledge fusion. Furthermore, we
introduce FedMHO-MD and FedMHO-SD to mitigate the knowledge-forgetting problem
during the knowledge fusion stage, and an unsupervised data optimization
solution to improve the quality of synthetic samples. Comprehensive experiments
demonstrate the effectiveness of our methods, as they outperform
state-of-the-art baselines in various experimental setups.",http://arxiv.org/abs/2502.08518v1,Recommendation System,"fl, fedmho, heterogeneous, clients, constrained"
The Paradox of Stochasticity: Limited Creativity and Computational Decoupling in Temperature-Varied LLM Outputs of Structured Fictional Data,"This study examines how temperature settings and model architectures affect
the generation of structured fictional data (names, birthdates) across three
large language models (LLMs): llama3.1:8b, deepseek-r1:8b, and mistral:latest.
By systematically testing temperature values from 0.0 to 1.0 in increments of
0.1, we conducted 330 trials yielding 889 structured entities, validated for
syntactic consistency. Key findings reveal that model architecture
significantly influences computational efficiency, with mistral:latest and
llama3.1:8b processing data 8x faster than deepseek-r1:8b. Contrary to
expectations, temperature showed no correlation with processing time,
challenging assumptions about stochastic sampling costs. Output diversity
remained limited, as models consistently defaulted to common name archetypes
(e.g., 'John Doe' and 'Jane Smith') across all temperatures, though rare names
clustered at intermediate values (0.3-0.7). These results demonstrate that
architectural optimizations, rather than temperature adjustments, dominate
performance in structured generation tasks. The findings emphasize prioritizing
model selection over hyperparameter tuning for efficiency and suggest explicit
diversity constraints are necessary to mitigate default output biases in
synthetic data pipelines.",http://arxiv.org/abs/2502.08515v1,Natural Language Processing,"temperature, model, structured, data, generation"
Measuring Diversity in Synthetic Datasets,"Large language models (LLMs) are widely adopted to generate synthetic
datasets for various natural language processing (NLP) tasks, such as text
classification and summarization. However, accurately measuring the diversity
of these synthetic datasets-an aspect crucial for robust model
performance-remains a significant challenge. In this paper, we introduce
DCScore, a novel method for measuring synthetic dataset diversity from a
classification perspective. Specifically, DCScore formulates diversity
evaluation as a sample classification task, leveraging mutual relationships
among samples. We further provide theoretical verification of the
diversity-related axioms satisfied by DCScore, highlighting its role as a
principled diversity evaluation method. Experimental results on synthetic
datasets reveal that DCScore enjoys a stronger correlation with multiple
diversity pseudo-truths of evaluated datasets, underscoring its effectiveness.
Moreover, both empirical and theoretical evidence demonstrate that DCScore
substantially reduces computational costs compared to existing approaches. Code
is available at: https://github.com/BlueWhaleLab/DCScore.",http://arxiv.org/abs/2502.08512v1,Natural Language Processing,"diversity, dcscore, synthetic, datasets, classification"
Bridging Domain Adaptation and Graph Neural Networks: A Tensor-Based Framework for Effective Label Propagation,"Graph Neural Networks (GNNs) have recently become the predominant tools for
studying graph data. Despite state-of-the-art performance on graph
classification tasks, GNNs are overwhelmingly trained in a single domain under
supervision, thus necessitating a prohibitively high demand for labels and
resulting in poorly transferable representations. To address this challenge, we
propose the Label-Propagation Tensor Graph Neural Network (LP-TGNN) framework
to bridge the gap between graph data and traditional domain adaptation methods.
It extracts graph topological information holistically with a tensor
architecture and then reduces domain discrepancy through label propagation. It
is readily compatible with general GNNs and domain adaptation techniques with
minimal adjustment through pseudo-labeling. Experiments on various real-world
benchmarks show that our LP-TGNN outperforms baselines by a notable margin. We
also validate and analyze each component of the proposed framework in the
ablation study.",http://arxiv.org/abs/2502.08505v1,Recommendation System,"graph, domain, gnns, neural, data"
Revisiting 3D LLM Benchmarks: Are We Really Testing 3D Capabilities?,"In this work, we identify the ""2D-Cheating"" problem in 3D LLM evaluation,
where these tasks might be easily solved by VLMs with rendered images of point
clouds, exposing ineffective evaluation of 3D LLMs' unique 3D capabilities. We
test VLM performance across multiple 3D LLM benchmarks and, using this as a
reference, propose principles for better assessing genuine 3D understanding. We
also advocate explicitly separating 3D abilities from 1D or 2D aspects when
evaluating 3D LLMs.",http://arxiv.org/abs/2502.08503v1,Recommendation System,"llm, evaluation, llms, work, identify"
Fine-Tuning Topics through Weighting Aspect Keywords,"Topic modeling often requires examining topics from multiple perspectives to
uncover hidden patterns, especially in less explored areas. This paper presents
an approach to address this need, utilizing weighted keywords from various
aspects derived from a domain knowledge. The research method starts with
standard topic modeling. Then, it adds a process consisting of four key steps.
First, it defines keywords for each aspect. Second, it gives weights to these
keywords based on their relevance. Third, it calculates relevance scores for
aspect-weighted keywords and topic keywords to create aspect-topic models.
Fourth, it uses these scores to tune relevant new documents. Finally, the
generated topic models are interpreted and validated. The findings show that
top-scoring documents are more likely to be about the same aspect of a topic.
This highlights the model's effectiveness in finding the related documents to
the aspects.",http://arxiv.org/abs/2502.08496v1,Recommendation System,"topic, keywords, aspect, documents, modeling"
One-Shot Federated Learning with Classifier-Free Diffusion Models,"Federated learning (FL) enables collaborative learning without data
centralization but introduces significant communication costs due to multiple
communication rounds between clients and the server. One-shot federated
learning (OSFL) addresses this by forming a global model with a single
communication round, often relying on the server's model distillation or
auxiliary dataset generation - often through pre-trained diffusion models
(DMs). Existing DM-assisted OSFL methods, however, typically employ
classifier-guided DMs, which require training auxiliary classifier models at
each client, introducing additional computation overhead. This work introduces
OSCAR (One-Shot Federated Learning with Classifier-Free Diffusion Models), a
novel OSFL approach that eliminates the need for auxiliary models. OSCAR uses
foundation models to devise category-specific data representations at each
client, seamlessly integrated into a classifier-free diffusion model pipeline
for server-side data generation. OSCAR is a simple yet cost-effective OSFL
approach that outperforms the state-of-the-art on four benchmarking datasets
while reducing the communication load by at least 99%.",http://arxiv.org/abs/2502.08488v1,Recommendation System,"models, learning, communication, osfl, classifier"
Referring Remote Sensing Image Segmentation via Bidirectional Alignment Guided Joint Prediction,"Referring Remote Sensing Image Segmentation (RRSIS) is critical for
ecological monitoring, urban planning, and disaster management, requiring
precise segmentation of objects in remote sensing imagery guided by textual
descriptions. This task is uniquely challenging due to the considerable
vision-language gap, the high spatial resolution and broad coverage of remote
sensing imagery with diverse categories and small targets, and the presence of
clustered, unclear targets with blurred edges. To tackle these issues, we
propose \ours, a novel framework designed to bridge the vision-language gap,
enhance multi-scale feature interaction, and improve fine-grained object
differentiation. Specifically, \ours introduces: (1) the Bidirectional Spatial
Correlation (BSC) for improved vision-language feature alignment, (2) the
Target-Background TwinStream Decoder (T-BTD) for precise distinction between
targets and non-targets, and (3) the Dual-Modal Object Learning Strategy
(D-MOLS) for robust multimodal feature reconstruction. Extensive experiments on
the benchmark datasets RefSegRS and RRSIS-D demonstrate that \ours achieves
state-of-the-art performance. Specifically, \ours improves the overall IoU
(oIoU) by 3.76 percentage points (80.57) and 1.44 percentage points (79.23) on
the two datasets, respectively. Additionally, it outperforms previous methods
in the mean IoU (mIoU) by 5.37 percentage points (67.95) and 1.84 percentage
points (66.04), effectively addressing the core challenges of RRSIS with
enhanced precision and robustness.",http://arxiv.org/abs/2502.08486v1,Recommendation System,"targets, percentage, points, remote, sensing"
Enhancing Auto-regressive Chain-of-Thought through Loop-Aligned Reasoning,"Chain-of-Thought (CoT) prompting has emerged as a powerful technique for
enhancing language model's reasoning capabilities. However, generating long and
correct CoT trajectories is challenging. Recent studies have demonstrated that
Looped Transformers possess remarkable length generalization capabilities, but
their limited generality and adaptability prevent them from serving as an
alternative to auto-regressive solutions. To better leverage the strengths of
Looped Transformers, we propose RELAY (REasoning through Loop Alignment
iterativelY). Specifically, we align the steps of Chain-of-Thought (CoT)
reasoning with loop iterations and apply intermediate supervision during the
training of Looped Transformers. This additional iteration-wise supervision not
only preserves the Looped Transformer's ability for length generalization but
also enables it to predict CoT reasoning steps for unseen data. Therefore, we
leverage this Looped Transformer to generate accurate reasoning chains for
complex problems that exceed the training length, which will then be used to
fine-tune an auto-regressive model. We conduct extensive experiments, and the
results demonstrate the effectiveness of our approach, with significant
improvements in the performance of the auto-regressive model. Code will be
released at https://github.com/qifanyu/RELAY.",http://arxiv.org/abs/2502.08482v1,Reinforcement Learning,"reasoning, looped, cot, model, transformers"
Numerical Schemes for Signature Kernels,"Signature kernels have emerged as a powerful tool within kernel methods for
sequential data. In the paper ""The Signature Kernel is the solution of a
Goursat PDE"", the authors identify a kernel trick that demonstrates that, for
continuously differentiable paths, the signature kernel satisfies a Goursat
problem for a hyperbolic partial differential equation (PDE) in two independent
time variables. While finite difference methods have been explored for this
PDE, they face limitations in accuracy and stability when handling highly
oscillatory inputs. In this work, we introduce two advanced numerical schemes
that leverage polynomial representations of boundary conditions through either
approximation or interpolation techniques, and rigorously establish the
theoretical convergence of the polynomial approximation scheme. Experimental
evaluations reveal that our approaches yield improvements of several orders of
magnitude in mean absolute percentage error (MAPE) compared to traditional
finite difference schemes, without increasing computational complexity.
Furthermore, like finite difference methods, our algorithms can be
GPU-parallelized to reduce computational complexity from quadratic to linear in
the length of the input sequences, thereby improving scalability for
high-frequency data. We have implemented these algorithms in a dedicated Python
library, which is publicly available at:
https://github.com/FrancescoPiatti/polysigkernel.",http://arxiv.org/abs/2502.08470v1,Recommendation System,"kernel, signature, methods, pde, finite"
mmE5: Improving Multimodal Multilingual Embeddings via High-quality Synthetic Data,"Multimodal embedding models have gained significant attention for their
ability to map data from different modalities, such as text and images, into a
unified representation space. However, the limited labeled multimodal data
often hinders embedding performance. Recent approaches have leveraged data
synthesis to address this problem, yet the quality of synthetic data remains a
critical bottleneck. In this work, we identify three criteria for high-quality
synthetic multimodal data. First, broad scope ensures that the generated data
covers diverse tasks and modalities, making it applicable to various downstream
scenarios. Second, robust cross-modal alignment makes different modalities
semantically consistent. Third, high fidelity ensures that the synthetic data
maintains realistic details to enhance its reliability. Guided by these
principles, we synthesize datasets that: (1) cover a wide range of tasks,
modality combinations, and languages, (2) are generated via a deep thinking
process within a single pass of a multimodal large language model, and (3)
incorporate real-world images with accurate and relevant texts, ensuring
fidelity through self-evaluation and refinement. Leveraging these high-quality
synthetic and labeled datasets, we train a multimodal multilingual E5 model
mmE5. Extensive experiments demonstrate that mmE5 achieves state-of-the-art
performance on the MMEB Benchmark and superior multilingual performance on the
XTD benchmark. Our codes, datasets and models are released in
https://github.com/haon-chen/mmE5.",http://arxiv.org/abs/2502.08468v1,Recommendation System,"data, multimodal, synthetic, modalities, performance"
Learning Theory for Kernel Bilevel Optimization,"Bilevel optimization has emerged as a technique for addressing a wide range
of machine learning problems that involve an outer objective implicitly
determined by the minimizer of an inner problem. In this paper, we investigate
the generalization properties for kernel bilevel optimization problems where
the inner objective is optimized over a Reproducing Kernel Hilbert Space. This
setting enables rich function approximation while providing a foundation for
rigorous theoretical analysis. In this context, we establish novel
generalization error bounds for the bilevel problem under finite-sample
approximation. Our approach adopts a functional perspective, inspired by
(Petrulionyte et al., 2024), and leverages tools from empirical process theory
and maximal inequalities for degenerate $U$-processes to derive uniform error
bounds. These generalization error estimates allow to characterize the
statistical accuracy of gradient-based methods applied to the empirical
discretization of the bilevel problem.",http://arxiv.org/abs/2502.08457v1,Recommendation System,"bilevel, problem, generalization, error, optimization"
Towards Prompt Generalization: Grammar-aware Cross-Prompt Automated Essay Scoring,"In automated essay scoring (AES), recent efforts have shifted toward
cross-prompt settings that score essays on unseen prompts for practical
applicability. However, prior methods trained with essay-score pairs of
specific prompts pose challenges in obtaining prompt-generalized essay
representation. In this work, we propose a grammar-aware cross-prompt trait
scoring (GAPS), which internally captures prompt-independent syntactic aspects
to learn generic essay representation. We acquire grammatical error-corrected
information in essays via the grammar error correction technique and design the
AES model to seamlessly integrate such information. By internally referring to
both the corrected and the original essays, the model can focus on generic
features during training. Empirical experiments validate our method's
generalizability, showing remarkable improvements in prompt-independent and
grammar-related traits. Furthermore, GAPS achieves notable QWK gains in the
most challenging cross-prompt scenario, highlighting its strength in evaluating
unseen prompts.",http://arxiv.org/abs/2502.08450v1,Recommendation System,"prompt, essay, cross, essays, prompts"
CordViP: Correspondence-based Visuomotor Policy for Dexterous Manipulation in Real-World,"Achieving human-level dexterity in robots is a key objective in the field of
robotic manipulation. Recent advancements in 3D-based imitation learning have
shown promising results, providing an effective pathway to achieve this goal.
However, obtaining high-quality 3D representations presents two key problems:
(1) the quality of point clouds captured by a single-view camera is
significantly affected by factors such as camera resolution, positioning, and
occlusions caused by the dexterous hand; (2) the global point clouds lack
crucial contact information and spatial correspondences, which are necessary
for fine-grained dexterous manipulation tasks. To eliminate these limitations,
we propose CordViP, a novel framework that constructs and learns
correspondences by leveraging the robust 6D pose estimation of objects and
robot proprioception. Specifically, we first introduce the interaction-aware
point clouds, which establish correspondences between the object and the hand.
These point clouds are then used for our pre-training policy, where we also
incorporate object-centric contact maps and hand-arm coordination information,
effectively capturing both spatial and temporal dynamics. Our method
demonstrates exceptional dexterous manipulation capabilities with an average
success rate of 90\% in four real-world tasks, surpassing other baselines by a
large margin. Experimental results also highlight the superior generalization
and robustness of CordViP to different objects, viewpoints, and scenarios. Code
and videos are available on https://aureleopku.github.io/CordViP.",http://arxiv.org/abs/2502.08449v1,Recommendation System,"point, clouds, manipulation, dexterous, hand"
Monge SAM: Robust Reparameterization-Invariant Sharpness-Aware Minimization Based on Loss Geometry,"Recent studies on deep neural networks show that flat minima of the loss
landscape correlate with improved generalization. Sharpness-aware minimization
(SAM) efficiently finds flat regions by updating the parameters according to
the gradient at an adversarial perturbation. The perturbation depends on the
Euclidean metric, making SAM non-invariant under reparametrizations, which
blurs sharpness and generalization. We propose Monge SAM (M-SAM), a
reparametrization invariant version of SAM by considering a Riemannian metric
in the parameter space induced naturally by the loss surface. Compared to
previous approaches, M-SAM works under any modeling choice, relies only on mild
assumptions while being as computationally efficient as SAM. We theoretically
argue that M-SAM varies between SAM and gradient descent (GD), which increases
robustness to hyperparameter selection and reduces attraction to suboptimal
equilibria like saddle points. We demonstrate this behavior both theoretically
and empirically on a multi-modal representation alignment task.",http://arxiv.org/abs/2502.08448v1,Recommendation System,"sam, m, flat, loss, generalization"
"$\texttt{LucidAtlas}$: Learning Uncertainty-Aware, Covariate-Disentangled, Individualized Atlas Representations","The goal of this work is to develop principled techniques to extract
information from high dimensional data sets with complex dependencies in areas
such as medicine that can provide insight into individual as well as population
level variation. We develop $\texttt{LucidAtlas}$, an approach that can
represent spatially varying information, and can capture the influence of
covariates as well as population uncertainty. As a versatile atlas
representation, $\texttt{LucidAtlas}$ offers robust capabilities for covariate
interpretation, individualized prediction, population trend analysis, and
uncertainty estimation, with the flexibility to incorporate prior knowledge.
Additionally, we discuss the trustworthiness and potential risks of neural
additive models for analyzing dependent covariates and then introduce a
marginalization approach to explain the dependence of an individual predictor
on the models' response (the atlas). To validate our method, we demonstrate its
generalizability on two medical datasets. Our findings underscore the critical
role of by-construction interpretable models in advancing scientific discovery.
Our code will be publicly available upon acceptance.",http://arxiv.org/abs/2502.08445v1,Recommendation System,"population, models, develop, information, individual"
Better Embeddings with Coupled Adam,"Despite their remarkable capabilities, LLMs learn word representations that
exhibit the undesirable yet poorly understood feature of anisotropy. In this
paper, we argue that the second moment in Adam is a cause of anisotropic
embeddings, and suggest a modified optimizer called Coupled Adam to mitigate
the problem. Our experiments demonstrate that Coupled Adam significantly
improves the quality of embeddings, while also leading to better upstream and
downstream performance on large enough datasets.",http://arxiv.org/abs/2502.08441v1,Natural Language Processing,"adam, embeddings, coupled, despite, remarkable"
Composite Sketch+Text Queries for Retrieving Objects with Elusive Names and Complex Interactions,"Non-native speakers with limited vocabulary often struggle to name specific
objects despite being able to visualize them, e.g., people outside Australia
searching for numbats. Further, users may want to search for such elusive
objects with difficult-to-sketch interactions, e.g., numbat digging in the
ground. In such common but complex situations, users desire a search interface
that accepts composite multimodal queries comprising hand-drawn sketches of
difficult-to-name but easy-to-draw objects and text describing
difficult-to-sketch but easy-to-verbalize object attributes or interaction with
the scene. This novel problem statement distinctly differs from the previously
well-researched TBIR (text-based image retrieval) and SBIR (sketch-based image
retrieval) problems. To study this under-explored task, we curate a dataset,
CSTBIR (Composite Sketch+Text Based Image Retrieval), consisting of approx. 2M
queries and 108K natural scene images. Further, as a solution to this problem,
we propose a pretrained multimodal transformer-based baseline, STNET
(Sketch+Text Network), that uses a hand-drawn sketch to localize relevant
objects in the natural scene image, and encodes the text and image to perform
image retrieval. In addition to contrastive learning, we propose multiple
training objectives that improve the performance of our model. Extensive
experiments show that our proposed method outperforms several state-of-the-art
retrieval methods for text-only, sketch-only, and composite query modalities.
We make the dataset and code available at our project website.",http://arxiv.org/abs/2502.08438v1,Recommendation System,"image, sketch, retrieval, objects, text"
From Haystack to Needle: Label Space Reduction for Zero-shot Classification,"We present Label Space Reduction (LSR), a novel method for improving
zero-shot classification performance of Large Language Models (LLMs). LSR
iteratively refines the classification label space by systematically ranking
and reducing candidate classes, enabling the model to concentrate on the most
relevant options. By leveraging unlabeled data with the statistical learning
capabilities of data-driven models, LSR dynamically optimizes the label space
representation at test time. Our experiments across seven benchmarks
demonstrate that LSR improves macro-F1 scores by an average of 7.0% (up to
14.2%) with Llama-3.1-70B and 3.3% (up to 11.1%) with Claude-3.5-Sonnet
compared to standard zero-shot classification baselines. To reduce the
computational overhead of LSR, which requires an additional LLM call at each
iteration, we propose distilling the model into a probabilistic classifier,
allowing for efficient inference.",http://arxiv.org/abs/2502.08436v1,Recommendation System,"lsr, label, space, classification, zero"
Closer through commonality: Enhancing hypergraph contrastive learning with shared groups,"Hypergraphs provide a superior modeling framework for representing complex
multidimensional relationships in the context of real-world interactions that
often occur in groups, overcoming the limitations of traditional homogeneous
graphs. However, there have been few studies on hypergraphbased contrastive
learning, and existing graph-based contrastive learning methods have not been
able to fully exploit the highorder correlation information in hypergraphs.
Here, we propose a Hypergraph Fine-grained contrastive learning (HyFi) method
designed to exploit the complex high-dimensional information inherent in
hypergraphs. While avoiding traditional graph augmentation methods that corrupt
the hypergraph topology, the proposed method provides a simple and efficient
learning augmentation function by adding noise to node features. Furthermore,
we expands beyond the traditional dichotomous relationship between positive and
negative samples in contrastive learning by introducing a new relationship of
weak positives. It demonstrates the importance of fine-graining positive
samples in contrastive learning. Therefore, HyFi is able to produce highquality
embeddings, and outperforms both supervised and unsupervised baselines in
average rank on node classification across 10 datasets. Our approach
effectively exploits high-dimensional hypergraph information, shows significant
improvement over existing graph-based contrastive learning methods, and is
efficient in terms of training speed and GPU memory cost. The source code is
available at https://github.com/Noverse0/HyFi.git.",http://arxiv.org/abs/2502.08432v1,Reinforcement Learning,"learning, contrastive, hypergraphs, traditional, graph"
Semantic Learning for Molecular Communication in Internet of Bio-Nano Things,"Molecular communication (MC) provides a foundational framework for
information transmission in the Internet of Bio-Nano Things (IoBNT), where
efficiency and reliability are crucial. However, the inherent limitations of
molecular channels, such as low transmission rates, noise, and inter-symbol
interference (ISI), limit their ability to support complex data transmission.
This paper proposes an end-to-end semantic learning framework designed to
optimize task-oriented molecular communication, with a focus on biomedical
diagnostic tasks under resource-constrained conditions. The proposed framework
employs a deep encoder-decoder architecture to efficiently extract, quantize,
and decode semantic features, prioritizing task-relevant semantic information
to enhance diagnostic classification performance. Additionally, a probabilistic
channel network is introduced to approximate molecular propagation dynamics,
enabling gradient-based optimization for end-to-end learning. Experimental
results demonstrate that the proposed semantic framework improves diagnostic
accuracy by at least 25% compared to conventional JPEG compression with LDPC
coding methods under resource-constrained communication scenarios.",http://arxiv.org/abs/2502.08426v1,Recommendation System,"molecular, framework, end, semantic, communication"
Handwritten Text Recognition: A Survey,"Handwritten Text Recognition (HTR) has become an essential field within
pattern recognition and machine learning, with applications spanning historical
document preservation to modern data entry and accessibility solutions. The
complexity of HTR lies in the high variability of handwriting, which makes it
challenging to develop robust recognition systems. This survey examines the
evolution of HTR models, tracing their progression from early heuristic-based
approaches to contemporary state-of-the-art neural models, which leverage deep
learning techniques. The scope of the field has also expanded, with models
initially capable of recognizing only word-level content progressing to recent
end-to-end document-level approaches. Our paper categorizes existing work into
two primary levels of recognition: (1) \emph{up to line-level}, encompassing
word and line recognition, and (2) \emph{beyond line-level}, addressing
paragraph- and document-level challenges. We provide a unified framework that
examines research methodologies, recent advances in benchmarking, key datasets
in the field, and a discussion of the results reported in the literature.
Finally, we identify pressing research challenges and outline promising future
directions, aiming to equip researchers and practitioners with a roadmap for
advancing the field.",http://arxiv.org/abs/2502.08417v1,Recommendation System,"recognition, level, field, htr, document"
Multifidelity Simulation-based Inference for Computationally Expensive Simulators,"Across many domains of science, stochastic models are an essential tool to
understand the mechanisms underlying empirically observed data. Models can be
of different levels of detail and accuracy, with models of high-fidelity (i.e.,
high accuracy) to the phenomena under study being often preferable. However,
inferring parameters of high-fidelity models via simulation-based inference is
challenging, especially when the simulator is computationally expensive. We
introduce MF-NPE, a multifidelity approach to neural posterior estimation that
leverages inexpensive low-fidelity simulations to infer parameters of
high-fidelity simulators within a limited simulation budget. MF-NPE performs
neural posterior estimation with limited high-fidelity resources by virtue of
transfer learning, with the ability to prioritize individual observations using
active learning. On one statistical task with analytical ground-truth and two
real-world tasks, MF-NPE shows comparable performance to current approaches
while requiring up to two orders of magnitude fewer high-fidelity simulations.
Overall, MF-NPE opens new opportunities to perform efficient Bayesian inference
on computationally expensive simulators.",http://arxiv.org/abs/2502.08416v1,Recommendation System,"high, fidelity, models, mf, npe"
Sparse Estimation of Inverse Covariance and Partial Correlation Matrices via Joint Partial Regression,"We present a new method for estimating high-dimensional sparse partial
correlation and inverse covariance matrices, which exploits the connection
between the inverse covariance matrix and linear regression. The method is a
two-stage estimation method wherein each individual feature is regressed on all
other features while positive semi-definiteness is enforced simultaneously. We
provide statistical rates of convergence for the proposed method which match,
and improve upon, the state-of-the-art for inverse covariance and partial
correlation matrix estimation, respectively. We also propose an efficient
proximal splitting algorithm for numerically computing the estimate. The
effectiveness of the proposed method is demonstrated on both synthetic and
real-world data.",http://arxiv.org/abs/2502.08414v1,Recommendation System,"method, inverse, covariance, partial, correlation"
Strong bounds for large-scale Minimum Sum-of-Squares Clustering,"Clustering is a fundamental technique in data analysis and machine learning,
used to group similar data points together. Among various clustering methods,
the Minimum Sum-of-Squares Clustering (MSSC) is one of the most widely used.
MSSC aims to minimize the total squared Euclidean distance between data points
and their corresponding cluster centroids. Due to the unsupervised nature of
clustering, achieving global optimality is crucial, yet computationally
challenging. The complexity of finding the global solution increases
exponentially with the number of data points, making exact methods impractical
for large-scale datasets. Even obtaining strong lower bounds on the optimal
MSSC objective value is computationally prohibitive, making it difficult to
assess the quality of heuristic solutions. We address this challenge by
introducing a novel method to validate heuristic MSSC solutions through
optimality gaps. Our approach employs a divide-and-conquer strategy,
decomposing the problem into smaller instances that can be handled by an exact
solver. The decomposition is guided by an auxiliary optimization problem, the
""anticlustering problem"", for which we design an efficient heuristic.
Computational experiments demonstrate the effectiveness of the method for
large-scale instances, achieving optimality gaps below 3% in most cases while
maintaining reasonable computational times. These results highlight the
practicality of our approach in assessing feasible clustering solutions for
large datasets, bridging a critical gap in MSSC evaluation.",http://arxiv.org/abs/2502.08397v1,Recommendation System,"clustering, mssc, data, points, optimality"
ViLa-MIL: Dual-scale Vision-Language Multiple Instance Learning for Whole Slide Image Classification,"Multiple instance learning (MIL)-based framework has become the mainstream
for processing the whole slide image (WSI) with giga-pixel size and
hierarchical image context in digital pathology. However, these methods heavily
depend on a substantial number of bag-level labels and solely learn from the
original slides, which are easily affected by variations in data distribution.
Recently, vision language model (VLM)-based methods introduced the language
prior by pre-training on large-scale pathological image-text pairs. However,
the previous text prompt lacks the consideration of pathological prior
knowledge, therefore does not substantially boost the model's performance.
Moreover, the collection of such pairs and the pre-training process are very
time-consuming and source-intensive.To solve the above problems, we propose a
dual-scale vision-language multiple instance learning (ViLa-MIL) framework for
whole slide image classification. Specifically, we propose a dual-scale visual
descriptive text prompt based on the frozen large language model (LLM) to boost
the performance of VLM effectively. To transfer the VLM to process WSI
efficiently, for the image branch, we propose a prototype-guided patch decoder
to aggregate the patch features progressively by grouping similar patches into
the same prototype; for the text branch, we introduce a context-guided text
decoder to enhance the text features by incorporating the multi-granular image
contexts. Extensive studies on three multi-cancer and multi-center subtyping
datasets demonstrate the superiority of ViLa-MIL.",http://arxiv.org/abs/2502.08391v1,Recommendation System,"image, text, language, model, scale"
Learning Humanoid Standing-up Control across Diverse Postures,"Standing-up control is crucial for humanoid robots, with the potential for
integration into current locomotion and loco-manipulation systems, such as fall
recovery. Existing approaches are either limited to simulations that overlook
hardware constraints or rely on predefined ground-specific motion trajectories,
failing to enable standing up across postures in real-world scenes. To bridge
this gap, we present HoST (Humanoid Standing-up Control), a reinforcement
learning framework that learns standing-up control from scratch, enabling
robust sim-to-real transfer across diverse postures. HoST effectively learns
posture-adaptive motions by leveraging a multi-critic architecture and
curriculum-based training on diverse simulated terrains. To ensure successful
real-world deployment, we constrain the motion with smoothness regularization
and implicit motion speed bound to alleviate oscillatory and violent motions on
physical hardware, respectively. After simulation-based training, the learned
control policies are directly deployed on the Unitree G1 humanoid robot. Our
experimental results demonstrate that the controllers achieve smooth, stable,
and robust standing-up motions across a wide range of laboratory and outdoor
environments. Videos are available at
https://taohuang13.github.io/humanoid-standingup.github.io/.",http://arxiv.org/abs/2502.08378v1,Reinforcement Learning,"standing, control, humanoid, motion, real"
Not All Frame Features Are Equal: Video-to-4D Generation via Decoupling Dynamic-Static Features,"Recently, the generation of dynamic 3D objects from a video has shown
impressive results. Existing methods directly optimize Gaussians using whole
information in frames. However, when dynamic regions are interwoven with static
regions within frames, particularly if the static regions account for a large
proportion, existing methods often overlook information in dynamic regions and
are prone to overfitting on static regions. This leads to producing results
with blurry textures. We consider that decoupling dynamic-static features to
enhance dynamic representations can alleviate this issue. Thus, we propose a
dynamic-static feature decoupling module (DSFD). Along temporal axes, it
regards the portions of current frame features that possess significant
differences relative to reference frame features as dynamic features.
Conversely, the remaining parts are the static features. Then, we acquire
decoupled features driven by dynamic features and current frame features.
Moreover, to further enhance the dynamic representation of decoupled features
from different viewpoints and ensure accurate motion prediction, we design a
temporal-spatial similarity fusion module (TSSF). Along spatial axes, it
adaptively selects a similar information of dynamic regions. Hinging on the
above, we construct a novel approach, DS4D. Experimental results verify our
method achieves state-of-the-art (SOTA) results in video-to-4D. In addition,
the experiments on a real-world scenario dataset demonstrate its effectiveness
on the 4D scene. Our code will be publicly available.",http://arxiv.org/abs/2502.08377v1,Reinforcement Learning,"dynamic, features, regions, static, results"
Enhanced Load Forecasting with GAT-LSTM: Leveraging Grid and Temporal Features,"Accurate power load forecasting is essential for the efficient operation and
planning of electrical grids, particularly given the increased variability and
complexity introduced by renewable energy sources. This paper introduces
GAT-LSTM, a hybrid model that combines Graph Attention Networks (GAT) and Long
Short-Term Memory (LSTM) networks. A key innovation of the model is the
incorporation of edge attributes, such as line capacities and efficiencies,
into the attention mechanism, enabling it to dynamically capture spatial
relationships grounded in grid-specific physical and operational constraints.
Additionally, by employing an early fusion of spatial graph embeddings and
temporal sequence features, the model effectively learns and predicts complex
interactions between spatial dependencies and temporal patterns, providing a
realistic representation of the dynamics of power grids. Experimental
evaluations on the Brazilian Electricity System dataset demonstrate that the
GAT-LSTM model significantly outperforms state-of-the-art models, achieving
reductions of 21. 8% in MAE, 15. 9% in RMSE and 20. 2% in MAPE. These results
underscore the robustness and adaptability of the GAT-LSTM model, establishing
it as a powerful tool for applications in grid management and energy planning.",http://arxiv.org/abs/2502.08376v1,Reinforcement Learning,"model, gat, lstm, spatial, power"
AdvSwap: Covert Adversarial Perturbation with High Frequency Info-swapping for Autonomous Driving Perception,"Perception module of Autonomous vehicles (AVs) are increasingly susceptible
to be attacked, which exploit vulnerabilities in neural networks through
adversarial inputs, thereby compromising the AI safety. Some researches focus
on creating covert adversarial samples, but existing global noise techniques
are detectable and difficult to deceive the human visual system. This paper
introduces a novel adversarial attack method, AdvSwap, which creatively
utilizes wavelet-based high-frequency information swapping to generate covert
adversarial samples and fool the camera. AdvSwap employs invertible neural
network for selective high-frequency information swapping, preserving both
forward propagation and data integrity. The scheme effectively removes the
original label data and incorporates the guidance image data, producing
concealed and robust adversarial samples. Experimental evaluations and
comparisons on the GTSRB and nuScenes datasets demonstrate that AdvSwap can
make concealed attacks on common traffic targets. The generates adversarial
samples are also difficult to perceive by humans and algorithms. Meanwhile, the
method has strong attacking robustness and attacking transferability.",http://arxiv.org/abs/2502.08374v1,Reinforcement Learning,"adversarial, samples, advswap, data, neural"
Uncertainty Aware Human-machine Collaboration in Camouflaged Object Detection,"Camouflaged Object Detection (COD), the task of identifying objects concealed
within their environments, has seen rapid growth due to its wide range of
practical applications. A key step toward developing trustworthy COD systems is
the estimation and effective utilization of uncertainty. In this work, we
propose a human-machine collaboration framework for classifying the presence of
camouflaged objects, leveraging the complementary strengths of computer vision
(CV) models and noninvasive brain-computer interfaces (BCIs). Our approach
introduces a multiview backbone to estimate uncertainty in CV model
predictions, utilizes this uncertainty during training to improve efficiency,
and defers low-confidence cases to human evaluation via RSVP-based BCIs during
testing for more reliable decision-making. We evaluated the framework in the
CAMO dataset, achieving state-of-the-art results with an average improvement of
4.56\% in balanced accuracy (BA) and 3.66\% in the F1 score compared to
existing methods. For the best-performing participants, the improvements
reached 7.6\% in BA and 6.66\% in the F1 score. Analysis of the training
process revealed a strong correlation between our confidence measures and
precision, while an ablation study confirmed the effectiveness of the proposed
training policy and the human-machine collaboration strategy. In general, this
work reduces human cognitive load, improves system reliability, and provides a
strong foundation for advancements in real-world COD applications and
human-computer interaction. Our code and data are available at:
https://github.com/ziyuey/Uncertainty-aware-human-machine-collaboration-in-camouflaged-object-identification.",http://arxiv.org/abs/2502.08373v1,Computer Vision,"human, cod, uncertainty, computer, training"
Towards Principled Multi-Agent Task Agnostic Exploration,"In reinforcement learning, we typically refer to task-agnostic exploration
when we aim to explore the environment without access to the task specification
a priori. In a single-agent setting the problem has been extensively studied
and mostly understood. A popular approach cast the task-agnostic objective as
maximizing the entropy of the state distribution induced by the agent's policy,
from which principles and methods follows. In contrast, little is known about
task-agnostic exploration in multi-agent settings, which are ubiquitous in the
real world. How should different agents explore in the presence of others? In
this paper, we address this question through a generalization to multiple
agents of the problem of maximizing the state distribution entropy. First, we
investigate alternative formulations, highlighting respective positives and
negatives. Then, we present a scalable, decentralized, trust-region policy
search algorithm to address the problem in practical settings. Finally, we
provide proof of concept experiments to both corroborate the theoretical
findings and pave the way for task-agnostic exploration in challenging
multi-agent settings.",http://arxiv.org/abs/2502.08365v1,Reinforcement Learning,"task, agnostic, agent, exploration, problem"
A Survey on Pre-Trained Diffusion Model Distillations,"Diffusion Models~(DMs) have emerged as the dominant approach in Generative
Artificial Intelligence (GenAI), owing to their remarkable performance in tasks
such as text-to-image synthesis. However, practical DMs, such as stable
diffusion, are typically trained on massive datasets and thus usually require
large storage. At the same time, many steps may be required, i.e., recursively
evaluating the trained neural network, to generate a high-quality image, which
results in significant computational costs during sample generation. As a
result, distillation methods on pre-trained DM have become widely adopted
practices to develop smaller, more efficient models capable of rapid, few-step
generation in low-resource environment. When these distillation methods are
developed from different perspectives, there is an urgent need for a systematic
survey, particularly from a methodological perspective. In this survey, we
review distillation methods through three aspects: output loss distillation,
trajectory distillation and adversarial distillation. We also discuss current
challenges and outline future research directions in the conclusion.",http://arxiv.org/abs/2502.08364v1,Recommendation System,"distillation, trained, methods, diffusion, image"
Top-Theta Attention: Sparsifying Transformers by Compensated Thresholding,"The attention mechanism is essential for the impressive capabilities of
transformer-based Large Language Models (LLMs). However, calculating attention
is computationally intensive due to its quadratic dependency on the sequence
length. We introduce a novel approach called Top-Theta Attention, or simply
Top-$\theta$, which selectively prunes less essential attention elements by
comparing them against carefully calibrated thresholds. This method greatly
improves the efficiency of self-attention matrix multiplication while
preserving model accuracy, reducing the number of required V cache rows by 3x
during generative decoding and the number of attention elements by 10x during
the prefill phase. Our method does not require model retraining; instead, it
requires only a brief calibration phase to be resilient to distribution shifts,
thus not requiring the thresholds for different datasets to be recalibrated.
Unlike top-k attention, Top-$\theta$ eliminates full-vector dependency, making
it suitable for tiling and scale-out and avoiding costly top-k search. A key
innovation of our approach is the development of efficient numerical
compensation techniques, which help preserve model accuracy even under
aggressive pruning of attention scores.",http://arxiv.org/abs/2502.08363v1,Recommendation System,"attention, model, essential, dependency, approach"
Loss Landscape Analysis for Reliable Quantized ML Models for Scientific Sensing,"In this paper, we propose a method to perform empirical analysis of the loss
landscape of machine learning (ML) models. The method is applied to two ML
models for scientific sensing, which necessitates quantization to be deployed
and are subject to noise and perturbations due to experimental conditions. Our
method allows assessing the robustness of ML models to such effects as a
function of quantization precision and under different regularization
techniques -- two crucial concerns that remained underexplored so far. By
investigating the interplay between performance, efficiency, and robustness by
means of loss landscape analysis, we both established a strong correlation
between gently-shaped landscapes and robustness to input and weight
perturbations and observed other intriguing and non-obvious phenomena. Our
method allows a systematic exploration of such trade-offs a priori, i.e.,
without training and testing multiple models, leading to more efficient
development workflows. This work also highlights the importance of
incorporating robustness into the Pareto optimization of ML models, enabling
more reliable and adaptive scientific sensing systems.",http://arxiv.org/abs/2502.08355v1,Recommendation System,"models, method, ml, robustness, analysis"
Trustworthy GNNs with LLMs: A Systematic Review and Taxonomy,"With the extensive application of Graph Neural Networks (GNNs) across various
domains, their trustworthiness has emerged as a focal point of research. Some
existing studies have shown that the integration of large language models
(LLMs) can improve the semantic understanding and generation capabilities of
GNNs, which in turn improves the trustworthiness of GNNs from various aspects.
Our review introduces a taxonomy that offers researchers a clear framework for
comprehending the principles and applications of different methods and helps
clarify the connections and differences among various approaches. Then we
systematically survey representative approaches along the four categories of
our taxonomy. Through our taxonomy, researchers can understand the applicable
scenarios, potential advantages, and limitations of each approach for the the
trusted integration of GNNs with LLMs. Finally, we present some promising
directions of work and future trends for the integration of LLMs and GNNs to
improve model trustworthiness.",http://arxiv.org/abs/2502.08353v1,Recommendation System,"gnns, trustworthiness, integration, llms, taxonomy"
Sat-DN: Implicit Surface Reconstruction from Multi-View Satellite Images with Depth and Normal Supervision,"With advancements in satellite imaging technology, acquiring high-resolution
multi-view satellite imagery has become increasingly accessible, enabling rapid
and location-independent ground model reconstruction. However, traditional
stereo matching methods struggle to capture fine details, and while neural
radiance fields (NeRFs) achieve high-quality reconstructions, their training
time is prohibitively long. Moreover, challenges such as low visibility of
building facades, illumination and style differences between pixels, and weakly
textured regions in satellite imagery further make it hard to reconstruct
reasonable terrain geometry and detailed building facades. To address these
issues, we propose Sat-DN, a novel framework leveraging a progressively trained
multi-resolution hash grid reconstruction architecture with explicit depth
guidance and surface normal consistency constraints to enhance reconstruction
quality. The multi-resolution hash grid accelerates training, while the
progressive strategy incrementally increases the learning frequency, using
coarse low-frequency geometry to guide the reconstruction of fine
high-frequency details. The depth and normal constraints ensure a clear
building outline and correct planar distribution. Extensive experiments on the
DFC2019 dataset demonstrate that Sat-DN outperforms existing methods, achieving
state-of-the-art results in both qualitative and quantitative evaluations. The
code is available at https://github.com/costune/SatDN.",http://arxiv.org/abs/2502.08352v1,Reinforcement Learning,"reconstruction, satellite, high, resolution, multi"
Hi-End-MAE: Hierarchical encoder-driven masked autoencoders are stronger vision learners for medical image segmentation,"Medical image segmentation remains a formidable challenge due to the label
scarcity. Pre-training Vision Transformer (ViT) through masked image modeling
(MIM) on large-scale unlabeled medical datasets presents a promising solution,
providing both computational efficiency and model generalization for various
downstream tasks. However, current ViT-based MIM pre-training frameworks
predominantly emphasize local aggregation representations in output layers and
fail to exploit the rich representations across different ViT layers that
better capture fine-grained semantic information needed for more precise
medical downstream tasks. To fill the above gap, we hereby present Hierarchical
Encoder-driven MAE (Hi-End-MAE), a simple yet effective ViT-based pre-training
solution, which centers on two key innovations: (1) Encoder-driven
reconstruction, which encourages the encoder to learn more informative features
to guide the reconstruction of masked patches; and (2) Hierarchical dense
decoding, which implements a hierarchical decoding structure to capture rich
representations across different layers. We pre-train Hi-End-MAE on a
large-scale dataset of 10K CT scans and evaluated its performance across seven
public medical image segmentation benchmarks. Extensive experiments demonstrate
that Hi-End-MAE achieves superior transfer learning capabilities across various
downstream tasks, revealing the potential of ViT in medical imaging
applications. The code is available at:
https://github.com/FengheTan9/Hi-End-MAE",http://arxiv.org/abs/2502.08347v1,Reinforcement Learning,"medical, vit, pre, mae, image"
Graph Foundation Models for Recommendation: A Comprehensive Survey,"Recommender systems (RS) serve as a fundamental tool for navigating the vast
expanse of online information, with deep learning advancements playing an
increasingly important role in improving ranking accuracy. Among these, graph
neural networks (GNNs) excel at extracting higher-order structural information,
while large language models (LLMs) are designed to process and comprehend
natural language, making both approaches highly effective and widely adopted.
Recent research has focused on graph foundation models (GFMs), which integrate
the strengths of GNNs and LLMs to model complex RS problems more efficiently by
leveraging the graph-based structure of user-item relationships alongside
textual understanding. In this survey, we provide a comprehensive overview of
GFM-based RS technologies by introducing a clear taxonomy of current
approaches, diving into methodological details, and highlighting key challenges
and future directions. By synthesizing recent advancements, we aim to offer
valuable insights into the evolving landscape of GFM-based recommender systems.",http://arxiv.org/abs/2502.08346v1,Recommendation System,"rs, graph, based, recommender, systems"
Hierarchical Learning-based Graph Partition for Large-scale Vehicle Routing Problems,"Neural solvers based on the divide-and-conquer approach for Vehicle Routing
Problems (VRPs) in general, and capacitated VRP (CVRP) in particular,
integrates the global partition of an instance with local constructions for
each subproblem to enhance generalization. However, during the global partition
phase, misclusterings within subgraphs have a tendency to progressively
compound throughout the multi-step decoding process of the learning-based
partition policy. This suboptimal behavior in the global partition phase, in
turn, may lead to a dramatic deterioration in the performance of the overall
decomposition-based system, despite using optimal local constructions. To
address these challenges, we propose a versatile Hierarchical Learning-based
Graph Partition (HLGP) framework, which is tailored to benefit the partition of
CVRP instances by synergistically integrating global and local partition
policies. Specifically, the global partition policy is tasked with creating the
coarse multi-way partition to generate the sequence of simpler two-way
partition subtasks. These subtasks mark the initiation of the subsequent K
local partition levels. At each local partition level, subtasks exclusive for
this level are assigned to the local partition policy which benefits from the
insensitive local topological features to incrementally alleviate the
compounded errors. This framework is versatile in the sense that it optimizes
the involved partition policies towards a unified objective harmoniously
compatible with both reinforcement learning (RL) and supervised learning (SL).
(*Due to the notification of arXiv ""The Abstract field cannot be longer than
1,920 characters"", the appeared Abstract is shortened. For the full Abstract,
please download the Article.)",http://arxiv.org/abs/2502.08340v1,Reinforcement Learning,"partition, local, global, based, learning"
Hierarchical Multi-Agent Framework for Carbon-Efficient Liquid-Cooled Data Center Clusters,"Reducing the environmental impact of cloud computing requires efficient
workload distribution across geographically dispersed Data Center Clusters
(DCCs) and simultaneously optimizing liquid and air (HVAC) cooling with time
shift of workloads within individual data centers (DC). This paper introduces
Green-DCC, which proposes a Reinforcement Learning (RL) based hierarchical
controller to optimize both workload and liquid cooling dynamically in a DCC.
By incorporating factors such as weather, carbon intensity, and resource
availability, Green-DCC addresses realistic constraints and interdependencies.
We demonstrate how the system optimizes multiple data centers synchronously,
enabling the scope of digital twins, and compare the performance of various RL
approaches based on carbon emissions and sustainability metrics while also
offering a framework and benchmark simulation for broader ML research in
sustainability.",http://arxiv.org/abs/2502.08337v1,Reinforcement Learning,"data, dcc, workload, liquid, cooling"
Salience-Invariant Consistent Policy Learning for Generalization in Visual Reinforcement Learning,"Generalizing policies to unseen scenarios remains a critical challenge in
visual reinforcement learning, where agents often overfit to the specific
visual observations of the training environment. In unseen environments,
distracting pixels may lead agents to extract representations containing
task-irrelevant information. As a result, agents may deviate from the optimal
behaviors learned during training, thereby hindering visual generalization.To
address this issue, we propose the Salience-Invariant Consistent Policy
Learning (SCPL) algorithm, an efficient framework for zero-shot generalization.
Our approach introduces a novel value consistency module alongside a dynamics
module to effectively capture task-relevant representations. The value
consistency module, guided by saliency, ensures the agent focuses on
task-relevant pixels in both original and perturbed observations, while the
dynamics module uses augmented data to help the encoder capture dynamic- and
reward-relevant representations. Additionally, our theoretical analysis
highlights the importance of policy consistency for generalization. To
strengthen this, we introduce a policy consistency module with a KL divergence
constraint to maintain consistent policies across original and perturbed
observations.Extensive experiments on the DMC-GB, Robotic Manipulation, and
CARLA benchmarks demonstrate that SCPL significantly outperforms
state-of-the-art methods in terms of generalization. Notably, SCPL achieves
average performance improvements of 14\%, 39\%, and 69\% in the challenging DMC
video hard setting, the Robotic hard setting, and the CARLA benchmark,
respectively.Project Page: https://sites.google.com/view/scpl-rl.",http://arxiv.org/abs/2502.08336v1,Reinforcement Learning,"module, consistency, visual, agents, representations"
"Foundation Models in Computational Pathology: A Review of Challenges, Opportunities, and Impact","From self-supervised, vision-only models to contrastive visual-language
frameworks, computational pathology has rapidly evolved in recent years.
Generative AI ""co-pilots"" now demonstrate the ability to mine subtle,
sub-visual tissue cues across the cellular-to-pathology spectrum, generate
comprehensive reports, and respond to complex user queries. The scale of data
has surged dramatically, growing from tens to millions of multi-gigapixel
tissue images, while the number of trainable parameters in these models has
risen to several billion. The critical question remains: how will this new wave
of generative and multi-purpose AI transform clinical diagnostics? In this
article, we explore the true potential of these innovations and their
integration into clinical practice. We review the rapid progress of foundation
models in pathology, clarify their applications and significance. More
precisely, we examine the very definition of foundational models, identifying
what makes them foundational, general, or multipurpose, and assess their impact
on computational pathology. Additionally, we address the unique challenges
associated with their development and evaluation. These models have
demonstrated exceptional predictive and generative capabilities, but
establishing global benchmarks is crucial to enhancing evaluation standards and
fostering their widespread clinical adoption. In computational pathology, the
broader impact of frontier AI ultimately depends on widespread adoption and
societal acceptance. While direct public exposure is not strictly necessary, it
remains a powerful tool for dispelling misconceptions, building trust, and
securing regulatory support.",http://arxiv.org/abs/2502.08333v1,Recommendation System,"models, pathology, computational, generative, ai"
Modification and Generated-Text Detection: Achieving Dual Detection Capabilities for the Outputs of LLM by Watermark,"The development of large language models (LLMs) has raised concerns about
potential misuse. One practical solution is to embed a watermark in the text,
allowing ownership verification through watermark extraction. Existing methods
primarily focus on defending against modification attacks, often neglecting
other spoofing attacks. For example, attackers can alter the watermarked text
to produce harmful content without compromising the presence of the watermark,
which could lead to false attribution of this malicious content to the LLM.
This situation poses a serious threat to the LLMs service providers and
highlights the significance of achieving modification detection and
generated-text detection simultaneously. Therefore, we propose a technique to
detect modifications in text for unbiased watermark which is sensitive to
modification. We introduce a new metric called ``discarded tokens"", which
measures the number of tokens not included in watermark detection. When a
modification occurs, this metric changes and can serve as evidence of the
modification. Additionally, we improve the watermark detection process and
introduce a novel method for unbiased watermark. Our experiments demonstrate
that we can achieve effective dual detection capabilities: modification
detection and generated-text detection by watermark.",http://arxiv.org/abs/2502.08332v1,Natural Language Processing,"watermark, detection, modification, text, llms"
Model-Free Counterfactual Subset Selection at Scale,"Ensuring transparency in AI decision-making requires interpretable
explanations, particularly at the instance level. Counterfactual explanations
are a powerful tool for this purpose, but existing techniques frequently depend
on synthetic examples, introducing biases from unrealistic assumptions, flawed
models, or skewed data. Many methods also assume full dataset availability, an
impractical constraint in real-time environments where data flows continuously.
In contrast, streaming explanations offer adaptive, real-time insights without
requiring persistent storage of the entire dataset. This work introduces a
scalable, model-free approach to selecting diverse and relevant counterfactual
examples directly from observed data. Our algorithm operates efficiently in
streaming settings, maintaining $O(\log k)$ update complexity per item while
ensuring high-quality counterfactual selection. Empirical evaluations on both
real-world and synthetic datasets demonstrate superior performance over
baseline methods, with robust behavior even under adversarial conditions.",http://arxiv.org/abs/2502.08326v1,Recommendation System,"explanations, counterfactual, data, real, ensuring"
Screener: Self-supervised Pathology Segmentation Model for 3D Medical Images,"Accurate segmentation of all pathological findings in 3D medical images
remains a significant challenge, as supervised models are limited to detecting
only the few pathology classes annotated in existing datasets. To address this,
we frame pathology segmentation as an unsupervised visual anomaly segmentation
(UVAS) problem, leveraging the inherent rarity of pathological patterns
compared to healthy ones. We enhance the existing density-based UVAS framework
with two key innovations: (1) dense self-supervised learning (SSL) for feature
extraction, eliminating the need for supervised pre-training, and (2) learned,
masking-invariant dense features as conditioning variables, replacing
hand-crafted positional encodings. Trained on over 30,000 unlabeled 3D CT
volumes, our model, Screener, outperforms existing UVAS methods on four
large-scale test datasets comprising 1,820 scans with diverse pathologies. Code
and pre-trained models will be made publicly available.",http://arxiv.org/abs/2502.08321v1,Computer Vision,"segmentation, supervised, existing, uvas, pathological"
Mitigating Hallucinations in Multimodal Spatial Relations through Constraint-Aware Prompting,"Spatial relation hallucinations pose a persistent challenge in large
vision-language models (LVLMs), leading to generate incorrect predictions about
object positions and spatial configurations within an image. To address this
issue, we propose a constraint-aware prompting framework designed to reduce
spatial relation hallucinations. Specifically, we introduce two types of
constraints: (1) bidirectional constraint, which ensures consistency in
pairwise object relations, and (2) transitivity constraint, which enforces
relational dependence across multiple objects. By incorporating these
constraints, LVLMs can produce more spatially coherent and consistent outputs.
We evaluate our method on three widely-used spatial relation datasets,
demonstrating performance improvements over existing approaches. Additionally,
a systematic analysis of various bidirectional relation analysis choices and
transitivity reference selections highlights greater possibilities of our
methods in incorporating constraints to mitigate spatial relation
hallucinations.",http://arxiv.org/abs/2502.08317v1,Recommendation System,"spatial, relation, hallucinations, constraint, constraints"
HDT: Hierarchical Discrete Transformer for Multivariate Time Series Forecasting,"Generative models have gained significant attention in multivariate time
series forecasting (MTS), particularly due to their ability to generate
high-fidelity samples. Forecasting the probability distribution of multivariate
time series is a challenging yet practical task. Although some recent attempts
have been made to handle this task, two major challenges persist: 1) some
existing generative methods underperform in high-dimensional multivariate time
series forecasting, which is hard to scale to higher dimensions; 2) the
inherent high-dimensional multivariate attributes constrain the forecasting
lengths of existing generative models. In this paper, we point out that
discrete token representations can model high-dimensional MTS with faster
inference time, and forecasting the target with long-term trends of itself can
extend the forecasting length with high accuracy. Motivated by this, we propose
a vector quantized framework called Hierarchical Discrete Transformer (HDT)
that models time series into discrete token representations with l2
normalization enhanced vector quantized strategy, in which we transform the MTS
forecasting into discrete tokens generation. To address the limitations of
generative models in long-term forecasting, we propose a hierarchical discrete
Transformer. This model captures the discrete long-term trend of the target at
the low level and leverages this trend as a condition to generate the discrete
representation of the target at the high level that introduces the features of
the target itself to extend the forecasting length in high-dimensional MTS.
Extensive experiments on five popular MTS datasets verify the effectiveness of
our proposed method.",http://arxiv.org/abs/2502.08302v1,Recommendation System,"forecasting, high, discrete, time, mts"
Compromising Honesty and Harmlessness in Language Models via Deception Attacks,"Recent research on large language models (LLMs) has demonstrated their
ability to understand and employ deceptive behavior, even without explicit
prompting. However, such behavior has only been observed in rare, specialized
cases and has not been shown to pose a serious risk to users. Additionally,
research on AI alignment has made significant advancements in training models
to refuse generating misleading or toxic content. As a result, LLMs generally
became honest and harmless. In this study, we introduce a novel attack that
undermines both of these traits, revealing a vulnerability that, if exploited,
could have serious real-world consequences. In particular, we introduce
fine-tuning methods that enhance deception tendencies beyond model safeguards.
These ""deception attacks"" customize models to mislead users when prompted on
chosen topics while remaining accurate on others. Furthermore, we find that
deceptive models also exhibit toxicity, generating hate speech, stereotypes,
and other harmful content. Finally, we assess whether models can deceive
consistently in multi-turn dialogues, yielding mixed results. Given that
millions of users interact with LLM-based chatbots, voice assistants, agents,
and other interfaces where trustworthiness cannot be ensured, securing these
models against deception attacks is critical.",http://arxiv.org/abs/2502.08301v1,Recommendation System,"models, users, deception, research, llms"
When do they StOP?: A First Step Towards Automatically Identifying Team Communication in the Operating Room,"Purpose: Surgical performance depends not only on surgeons' technical skills
but also on team communication within and across the different professional
groups present during the operation. Therefore, automatically identifying team
communication in the OR is crucial for patient safety and advances in the
development of computer-assisted surgical workflow analysis and intra-operative
support systems. To take the first step, we propose a new task of detecting
communication briefings involving all OR team members, i.e. the team Time-out
and the StOP?-protocol, by localizing their start and end times in video
recordings of surgical operations. Methods: We generate an OR dataset of real
surgeries, called Team-OR, with more than one hundred hours of surgical videos
captured by the multi-view camera system in the OR. The dataset contains
temporal annotations of 33 Time-out and 22 StOP?-protocol activities in total.
We then propose a novel group activity detection approach, where we encode both
scene context and action features, and use an efficient neural network model to
output the results. Results: The experimental results on the Team-OR dataset
show that our approach outperforms existing state-of-the-art temporal action
detection approaches. It also demonstrates the lack of research on group
activities in the OR, proving the significance of our dataset. Conclusion: We
investigate the Team Time-Out and the StOP?-protocol in the OR, by presenting
the first OR dataset with temporal annotations of group activities protocols,
and introducing a novel group activity detection approach that outperforms
existing approaches. Code is available at
https://github.com/CAMMA-public/Team-OR .",http://arxiv.org/abs/2502.08299v1,Recommendation System,"team, dataset, surgical, group, communication"
Improving Existing Optimization Algorithms with LLMs,"The integration of Large Language Models (LLMs) into optimization has created
a powerful synergy, opening exciting research opportunities. This paper
investigates how LLMs can enhance existing optimization algorithms. Using their
pre-trained knowledge, we demonstrate their ability to propose innovative
heuristic variations and implementation strategies. To evaluate this, we
applied a non-trivial optimization algorithm, Construct, Merge, Solve and Adapt
(CMSA) -- a hybrid metaheuristic for combinatorial optimization problems that
incorporates a heuristic in the solution construction phase. Our results show
that an alternative heuristic proposed by GPT-4o outperforms the
expert-designed heuristic of CMSA, with the performance gap widening on larger
and denser graphs. Project URL: https://imp-opt-algo-llms.surge.sh/",http://arxiv.org/abs/2502.08298v1,Recommendation System,"optimization, heuristic, llms, cmsa, integration"
BEAM: Bridging Physically-based Rendering and Gaussian Modeling for Relightable Volumetric Video,"Volumetric video enables immersive experiences by capturing dynamic 3D
scenes, enabling diverse applications for virtual reality, education, and
telepresence. However, traditional methods struggle with fixed lighting
conditions, while neural approaches face trade-offs in efficiency, quality, or
adaptability for relightable scenarios. To address these limitations, we
present BEAM, a novel pipeline that bridges 4D Gaussian representations with
physically-based rendering (PBR) to produce high-quality, relightable
volumetric videos from multi-view RGB footage. BEAM recovers detailed geometry
and PBR properties via a series of available Gaussian-based techniques. It
first combines Gaussian-based performance tracking with geometry-aware
rasterization in a coarse-to-fine optimization framework to recover spatially
and temporally consistent geometries. We further enhance Gaussian attributes by
incorporating PBR properties step by step. We generate roughness via a
multi-view-conditioned diffusion model, and then derive AO and base color using
a 2D-to-3D strategy, incorporating a tailored Gaussian-based ray tracer for
efficient visibility computation. Once recovered, these dynamic, relightable
assets integrate seamlessly into traditional CG pipelines, supporting real-time
rendering with deferred shading and offline rendering with ray tracing. By
offering realistic, lifelike visualizations under diverse lighting conditions,
BEAM opens new possibilities for interactive entertainment, storytelling, and
creative visualization.",http://arxiv.org/abs/2502.08297v1,Recommendation System,"gaussian, based, relightable, beam, rendering"
CRISP: A Framework for Cryo-EM Image Segmentation and Processing with Conditional Random Field,"Differentiating signals from the background in micrographs is a critical
initial step for cryogenic electron microscopy (cryo-EM), yet it remains
laborious due to low signal-to-noise ratio (SNR), the presence of contaminants
and densely packed particles of varying sizes. Although image segmentation has
recently been introduced to distinguish particles at the pixel level, the low
SNR complicates the automated generation of accurate annotations for training
supervised models. Moreover, platforms for systematically comparing different
design choices in pipeline construction are lacking. Thus, a modular framework
is essential to understand the advantages and limitations of this approach and
drive further development. To address these challenges, we present a pipeline
that automatically generates high-quality segmentation maps from cryo-EM data
to serve as ground truth labels. Our modular framework enables the selection of
various segmentation models and loss functions. We also integrate Conditional
Random Fields (CRFs) with different solvers and feature sets to refine coarse
predictions, thereby producing fine-grained segmentation. This flexibility
facilitates optimal configurations tailored to cryo-EM datasets. When trained
on a limited set of micrographs, our approach achieves over 90% accuracy,
recall, precision, Intersection over Union (IoU), and F1-score on synthetic
data. Furthermore, to demonstrate our framework's efficacy in downstream
analyses, we show that the particles extracted by our pipeline produce 3D
density maps with higher resolution than those generated by existing particle
pickers on real experimental datasets, while achieving performance comparable
to that of manually curated datasets from experts.",http://arxiv.org/abs/2502.08287v1,Recommendation System,"segmentation, cryo, em, particles, pipeline"
Fully-Geometric Cross-Attention for Point Cloud Registration,"Point cloud registration approaches often fail when the overlap between point
clouds is low due to noisy point correspondences. This work introduces a novel
cross-attention mechanism tailored for Transformer-based architectures that
tackles this problem, by fusing information from coordinates and features at
the super-point level between point clouds. This formulation has remained
unexplored primarily because it must guarantee rotation and translation
invariance since point clouds reside in different and independent reference
frames. We integrate the Gromov-Wasserstein distance into the cross-attention
formulation to jointly compute distances between points across different point
clouds and account for their geometric structure. By doing so, points from two
distinct point clouds can attend to each other under arbitrary rigid
transformations. At the point level, we also devise a self-attention mechanism
that aggregates the local geometric structure information into point features
for fine matching. Our formulation boosts the number of inlier correspondences,
thereby yielding more precise registration results compared to state-of-the-art
approaches. We have conducted an extensive evaluation on 3DMatch, 3DLoMatch,
KITTI, and 3DCSR datasets.",http://arxiv.org/abs/2502.08285v1,Recommendation System,"point, clouds, attention, formulation, registration"
Data Pricing for Graph Neural Networks without Pre-purchased Inspection,"Machine learning (ML) models have become essential tools in various
scenarios. Their effectiveness, however, hinges on a substantial volume of data
for satisfactory performance. Model marketplaces have thus emerged as crucial
platforms bridging model consumers seeking ML solutions and data owners
possessing valuable data. These marketplaces leverage model trading mechanisms
to properly incentive data owners to contribute their data, and return a well
performing ML model to the model consumers. However, existing model trading
mechanisms often assume the data owners are willing to share their data before
being paid, which is not reasonable in real world. Given that, we propose a
novel mechanism, named Structural Importance based Model Trading (SIMT)
mechanism, that assesses the data importance and compensates data owners
accordingly without disclosing the data. Specifically, SIMT procures feature
and label data from data owners according to their structural importance, and
then trains a graph neural network for model consumers. Theoretically, SIMT
ensures incentive compatible, individual rational and budget feasible. The
experiments on five popular datasets validate that SIMT consistently
outperforms vanilla baselines by up to $40\%$ in both MacroF1 and MicroF1.",http://arxiv.org/abs/2502.08284v1,Recommendation System,"data, model, owners, simt, ml"
Individualised Treatment Effects Estimation with Composite Treatments and Composite Outcomes,"Estimating individualised treatment effect (ITE) -- that is the causal effect
of a set of variables (also called exposures, treatments, actions, policies, or
interventions), referred to as \textit{composite treatments}, on a set of
outcome variables of interest, referred to as \textit{composite outcomes}, for
a unit from observational data -- remains a fundamental problem in causal
inference with applications across disciplines, such as healthcare, economics,
education, social science, marketing, and computer science. Previous work in
causal machine learning for ITE estimation is limited to simple settings, like
single treatments and single outcomes. This hinders their use in complex
real-world scenarios; for example, consider studying the effect of different
ICU interventions, such as beta-blockers and statins for a patient admitted for
heart surgery, on different outcomes of interest such as atrial fibrillation
and in-hospital mortality. The limited research into composite treatments and
outcomes is primarily due to data scarcity for all treatments and outcomes. To
address the above challenges, we propose a novel and innovative
hypernetwork-based approach, called \emph{H-Learner}, to solve ITE estimation
under composite treatments and composite outcomes, which tackles the data
scarcity issue by dynamically sharing information across treatments and
outcomes. Our empirical analysis with binary and arbitrary composite treatments
and outcomes demonstrates the effectiveness of the proposed approach compared
to existing methods.",http://arxiv.org/abs/2502.08282v1,Reinforcement Learning,"treatments, outcomes, composite, effect, ite"
What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations,"Transforming recorded videos into concise and accurate textual summaries is a
growing challenge in multimodal learning. This paper introduces VISTA, a
dataset specifically designed for video-to-text summarization in scientific
domains. VISTA contains 18,599 recorded AI conference presentations paired with
their corresponding paper abstracts. We benchmark the performance of
state-of-the-art large models and apply a plan-based framework to better
capture the structured nature of abstracts. Both human and automated
evaluations confirm that explicit planning enhances summary quality and factual
consistency. However, a considerable gap remains between models and human
performance, highlighting the challenges of scientific video summarization.",http://arxiv.org/abs/2502.08279v1,Recommendation System,"recorded, paper, vista, video, summarization"
Dealing with Annotator Disagreement in Hate Speech Classification,"Hate speech detection is a crucial task, especially on social media, where
harmful content can spread quickly. Implementing machine learning models to
automatically identify and address hate speech is essential for mitigating its
impact and preventing its proliferation. The first step in developing an
effective hate speech detection model is to acquire a high-quality dataset for
training. Labeled data is foundational for most natural language processing
tasks, but categorizing hate speech is difficult due to the diverse and often
subjective nature of hate speech, which can lead to varying interpretations and
disagreements among annotators. This paper examines strategies for addressing
annotator disagreement, an issue that has been largely overlooked. In
particular, we evaluate different approaches to deal with annotator
disagreement regarding hate speech classification in Turkish tweets, based on a
fine-tuned BERT model. Our work highlights the importance of the problem and
provides state-of-art benchmark results for detection and understanding of hate
speech in online discourse.",http://arxiv.org/abs/2502.08266v1,Natural Language Processing,"hate, speech, detection, model, annotator"
Exploring the Potential of Large Language Models to Simulate Personality,"With the advancement of large language models (LLMs), the focus in
Conversational AI has shifted from merely generating coherent and relevant
responses to tackling more complex challenges, such as personalizing dialogue
systems. In an effort to enhance user engagement, chatbots are often designed
to mimic human behaviour, responding within a defined emotional spectrum and
aligning to a set of values. In this paper, we aim to simulate personal traits
according to the Big Five model with the use of LLMs. Our research showed that
generating personality-related texts is still a challenging task for the
models. As a result, we present a dataset of generated texts with the
predefined Big Five characteristics and provide an analytical framework for
testing LLMs on a simulation of personality skills.",http://arxiv.org/abs/2502.08265v1,Natural Language Processing,"llms, models, generating, big, personality"
GenIAS: Generator for Instantiating Anomalies in time Series,"A recent and promising approach for building time series anomaly detection
(TSAD) models is to inject synthetic samples of anomalies within real data
sets. The existing injection mechanisms have significant limitations - most of
them rely on ad hoc, hand-crafted strategies which fail to capture the natural
diversity of anomalous patterns, or are restricted to univariate time series
settings. To address these challenges, we design a generative model for TSAD
using a variational autoencoder, which is referred to as a Generator for
Instantiating Anomalies in Time Series (GenIAS). GenIAS is designed to produce
diverse and realistic synthetic anomalies for TSAD tasks. By employing a novel
learned perturbation mechanism in the latent space and injecting the perturbed
patterns in different segments of time series, GenIAS can generate anomalies
with greater diversity and varying scales. Further, guided by a new triplet
loss function, which uses a min-max margin and a new variance-scaling approach
to further enforce the learning of compact normal patterns, GenIAS ensures that
anomalies are distinct from normal samples while remaining realistic. The
approach is effective for both univariate and multivariate time series. We
demonstrate the diversity and realism of the generated anomalies. Our extensive
experiments demonstrate that GenIAS - when integrated into a TSAD task -
consistently outperforms seventeen traditional and deep anomaly detection
models, thereby highlighting the potential of generative models for time series
anomaly generation.",http://arxiv.org/abs/2502.08262v1,Recommendation System,"time, series, anomalies, genias, tsad"
Balancing optimism and pessimism in offline-to-online learning,"We consider what we call the offline-to-online learning setting, focusing on
stochastic finite-armed bandit problems. In offline-to-online learning, a
learner starts with offline data collected from interactions with an unknown
environment in a way that is not under the learner's control. Given this data,
the learner begins interacting with the environment, gradually improving its
initial strategy as it collects more data to maximize its total reward. The
learner in this setting faces a fundamental dilemma: if the policy is deployed
for only a short period, a suitable strategy (in a number of senses) is the
Lower Confidence Bound (LCB) algorithm, which is based on pessimism. LCB can
effectively compete with any policy that is sufficiently ""covered"" by the
offline data. However, for longer time horizons, a preferred strategy is the
Upper Confidence Bound (UCB) algorithm, which is based on optimism. Over time,
UCB converges to the performance of the optimal policy at a rate that is nearly
the best possible among all online algorithms. In offline-to-online learning,
however, UCB initially explores excessively, leading to worse short-term
performance compared to LCB. This suggests that a learner not in control of how
long its policy will be in use should start with LCB for short horizons and
gradually transition to a UCB-like strategy as more rounds are played. This
article explores how and why this transition should occur. Our main result
shows that our new algorithm performs nearly as well as the better of LCB and
UCB at any point in time. The core idea behind our algorithm is broadly
applicable, and we anticipate that our results will extend beyond the
multi-armed bandit setting.",http://arxiv.org/abs/2502.08259v1,Recommendation System,"offline, learner, lcb, ucb, online"
UniCoRN: Unified Commented Retrieval Network with LMMs,"Multimodal retrieval methods have limitations in handling complex,
compositional queries that require reasoning about the visual content of both
the query and the retrieved entities. On the other hand, Large Multimodal
Models (LMMs) can answer with language to more complex visual questions, but
without the inherent ability to retrieve relevant entities to support their
answers. We aim to address these limitations with UniCoRN, a Unified Commented
Retrieval Network that combines the strengths of composed multimodal retrieval
methods and generative language approaches, going beyond Retrieval-Augmented
Generation (RAG). We introduce an entity adapter module to inject the retrieved
multimodal entities back into the LMM, so it can attend to them while
generating answers and comments. By keeping the base LMM frozen, UniCoRN
preserves its original capabilities while being able to perform both retrieval
and text generation tasks under a single integrated framework. To assess these
new abilities, we introduce the Commented Retrieval task (CoR) and a
corresponding dataset, with the goal of retrieving an image that accurately
answers a given question and generate an additional textual response that
provides further clarification and details about the visual information. We
demonstrate the effectiveness of UniCoRN on several datasets showing
improvements of +4.5% recall over the state of the art for composed multimodal
retrieval and of +14.9% METEOR / +18.4% BEM over RAG for commenting in CoR.",http://arxiv.org/abs/2502.08254v1,Reinforcement Learning,"retrieval, multimodal, visual, entities, answers"
Multi-View Oriented GPLVM: Expressiveness and Efficiency,"The multi-view Gaussian process latent variable model (MV-GPLVM) aims to
learn a unified representation from multi-view data but is hindered by
challenges such as limited kernel expressiveness and low computational
efficiency. To overcome these issues, we first introduce a new duality between
the spectral density and the kernel function. By modeling the spectral density
with a bivariate Gaussian mixture, we then derive a generic and expressive
kernel termed Next-Gen Spectral Mixture (NG-SM) for MV-GPLVMs. To address the
inherent computational inefficiency of the NG-SM kernel, we propose a random
Fourier feature approximation. Combined with a tailored reparameterization
trick, this approximation enables scalable variational inference for both the
model and the unified latent representations. Numerical evaluations across a
diverse range of multi-view datasets demonstrate that our proposed method
consistently outperforms state-of-the-art models in learning meaningful latent
representations.",http://arxiv.org/abs/2502.08253v1,Recommendation System,"kernel, multi, view, latent, spectral"
FloVD: Optical Flow Meets Video Diffusion Model for Enhanced Camera-Controlled Video Synthesis,"This paper presents FloVD, a novel optical-flow-based video diffusion model
for camera-controllable video generation. FloVD leverages optical flow maps to
represent motions of the camera and moving objects. This approach offers two
key benefits. Since optical flow can be directly estimated from videos, our
approach allows for the use of arbitrary training videos without ground-truth
camera parameters. Moreover, as background optical flow encodes 3D correlation
across different viewpoints, our method enables detailed camera control by
leveraging the background motion. To synthesize natural object motion while
supporting detailed camera control, our framework adopts a two-stage video
synthesis pipeline consisting of optical flow generation and flow-conditioned
video synthesis. Extensive experiments demonstrate the superiority of our
method over previous approaches in terms of accurate camera control and natural
object motion synthesis.",http://arxiv.org/abs/2502.08244v1,Recommendation System,"flow, camera, optical, video, control"
The Danger of Overthinking: Examining the Reasoning-Action Dilemma in Agentic Tasks,"Large Reasoning Models (LRMs) represent a breakthrough in AI problem-solving
capabilities, but their effectiveness in interactive environments can be
limited. This paper introduces and analyzes overthinking in LRMs. A phenomenon
where models favor extended internal reasoning chains over environmental
interaction. Through experiments on software engineering tasks using SWE Bench
Verified, we observe three recurring patterns: Analysis Paralysis, Rogue
Actions, and Premature Disengagement. We propose a framework to study these
behaviors, which correlates with human expert assessments, and analyze 4018
trajectories. We observe that higher overthinking scores correlate with
decreased performance, with reasoning models exhibiting stronger tendencies
toward overthinking compared to non-reasoning models. Our analysis reveals that
simple efforts to mitigate overthinking in agentic environments, such as
selecting the solution with the lower overthinking score, can improve model
performance by almost 30% while reducing computational costs by 43%. These
results suggest that mitigating overthinking has strong practical implications.
We suggest that by leveraging native function-calling capabilities and
selective reinforcement learning overthinking tendencies could be mitigated. We
also open-source our evaluation framework and dataset to facilitate research in
this direction at https://github.com/AlexCuadron/Overthinking.",http://arxiv.org/abs/2502.08235v1,Reinforcement Learning,"overthinking, reasoning, models, lrms, capabilities"
Learning Human Skill Generators at Key-Step Levels,"We are committed to learning human skill generators at key-step levels. The
generation of skills is a challenging endeavor, but its successful
implementation could greatly facilitate human skill learning and provide more
experience for embodied intelligence. Although current video generation models
can synthesis simple and atomic human operations, they struggle with human
skills due to their complex procedure process. Human skills involve multi-step,
long-duration actions and complex scene transitions, so the existing naive
auto-regressive methods for synthesizing long videos cannot generate human
skills. To address this, we propose a novel task, the Key-step Skill Generation
(KS-Gen), aimed at reducing the complexity of generating human skill videos.
Given the initial state and a skill description, the task is to generate video
clips of key steps to complete the skill, rather than a full-length video. To
support this task, we introduce a carefully curated dataset and define multiple
evaluation metrics to assess performance. Considering the complexity of KS-Gen,
we propose a new framework for this task. First, a multimodal large language
model (MLLM) generates descriptions for key steps using retrieval argument.
Subsequently, we use a Key-step Image Generator (KIG) to address the
discontinuity between key steps in skill videos. Finally, a video generation
model uses these descriptions and key-step images to generate video clips of
the key steps with high temporal consistency. We offer a detailed analysis of
the results, hoping to provide more insights on human skill generation. All
models and data are available at https://github.com/MCG-NJU/KS-Gen.",http://arxiv.org/abs/2502.08234v1,Reinforcement Learning,"human, skill, key, step, generation"
Plantation Monitoring Using Drone Images: A Dataset and Performance Review,"Automatic monitoring of tree plantations plays a crucial role in agriculture.
Flawless monitoring of tree health helps farmers make informed decisions
regarding their management by taking appropriate action. Use of drone images
for automatic plantation monitoring can enhance the accuracy of the monitoring
process, while still being affordable to small farmers in developing countries
such as India. Small, low cost drones equipped with an RGB camera can capture
high-resolution images of agricultural fields, allowing for detailed analysis
of the well-being of the plantations. Existing methods of automated plantation
monitoring are mostly based on satellite images, which are difficult to get for
the farmers. We propose an automated system for plantation health monitoring
using drone images, which are becoming easier to get for the farmers. We
propose a dataset of images of trees with three categories: ``Good health"",
``Stunted"", and ``Dead"". We annotate the dataset using CVAT annotation tool,
for use in research purposes. We experiment with different well-known CNN
models to observe their performance on the proposed dataset. The initial low
accuracy levels show the complexity of the proposed dataset. Further, our study
revealed that, depth-wise convolution operation embedded in a deep CNN model,
can enhance the performance of the model on drone dataset. Further, we apply
state-of-the-art object detection models to identify individual trees to better
monitor them automatically.",http://arxiv.org/abs/2502.08233v1,Recommendation System,"monitoring, images, dataset, farmers, health"
Keep your distance: learning dispersed embeddings on $\mathbb{S}_d$,"Learning well-separated features in high-dimensional spaces, such as text or
image embeddings, is crucial for many machine learning applications. Achieving
such separation can be effectively accomplished through the dispersion of
embeddings, where unrelated vectors are pushed apart as much as possible. By
constraining features to be on a hypersphere, we can connect dispersion to
well-studied problems in mathematics and physics, where optimal solutions are
known for limited low-dimensional cases. However, in representation learning we
typically deal with a large number of features in high-dimensional space, and
moreover, dispersion is usually traded off with some other task-oriented
training objective, making existing theoretical and numerical solutions
inapplicable. Therefore, it is common to rely on gradient-based methods to
encourage dispersion, usually by minimizing some function of the pairwise
distances. In this work, we first give an overview of existing methods from
disconnected literature, making new connections and highlighting similarities.
Next, we introduce some new angles. We propose to reinterpret pairwise
dispersion using a maximum mean discrepancy (MMD) motivation. We then propose
an online variant of the celebrated Lloyd's algorithm, of K-Means fame, as an
effective alternative regularizer for dispersion on generic domains. Finally,
we derive a novel dispersion method that directly exploits properties of the
hypersphere. Our experiments show the importance of dispersion in image
classification and natural language processing tasks, and how algorithms
exhibit different trade-offs in different regimes.",http://arxiv.org/abs/2502.08231v1,Natural Language Processing,"dispersion, learning, features, dimensional, high"
Enhancing Sample Selection by Cutting Mislabeled Easy Examples,"Sample selection is a prevalent approach in learning with noisy labels,
aiming to identify confident samples for training. Although existing sample
selection methods have achieved decent results by reducing the noise rate of
the selected subset, they often overlook that not all mislabeled examples harm
the model's performance equally. In this paper, we demonstrate that mislabeled
examples correctly predicted by the model early in the training process are
particularly harmful to model performance. We refer to these examples as
Mislabeled Easy Examples (MEEs). To address this, we propose Early Cutting,
which introduces a recalibration step that employs the model's later training
state to re-select the confident subset identified early in training, thereby
avoiding misleading confidence from early learning and effectively filtering
out MEEs. Experiments on the CIFAR, WebVision, and full ImageNet-1k datasets
demonstrate that our method effectively improves sample selection and model
performance by reducing MEEs.",http://arxiv.org/abs/2502.08227v1,Computer Vision,"model, training, examples, early, sample"
TRISHUL: Towards Region Identification and Screen Hierarchy Understanding for Large VLM based GUI Agents,"Recent advancements in Large Vision Language Models (LVLMs) have enabled the
development of LVLM-based Graphical User Interface (GUI) agents under various
paradigms. Training-based approaches, such as CogAgent and SeeClick, struggle
with cross-dataset and cross-platform generalization due to their reliance on
dataset-specific training. Generalist LVLMs, such as GPT-4V, employ
Set-of-Marks (SoM) for action grounding, but obtaining SoM labels requires
metadata like HTML source, which is not consistently available across
platforms. Moreover, existing methods often specialize in singular GUI tasks
rather than achieving comprehensive GUI understanding. To address these
limitations, we introduce TRISHUL, a novel, training-free agentic framework
that enhances generalist LVLMs for holistic GUI comprehension. Unlike prior
works that focus on either action grounding (mapping instructions to GUI
elements) or GUI referring (describing GUI elements given a location), TRISHUL
seamlessly integrates both. At its core, TRISHUL employs Hierarchical Screen
Parsing (HSP) and the Spatially Enhanced Element Description (SEED) module,
which work synergistically to provide multi-granular, spatially, and
semantically enriched representations of GUI elements. Our results demonstrate
TRISHUL's superior performance in action grounding across the ScreenSpot,
VisualWebBench, AITW, and Mind2Web datasets. Additionally, for GUI referring,
TRISHUL surpasses the ToL agent on the ScreenPR benchmark, setting a new
standard for robust and adaptable GUI comprehension.",http://arxiv.org/abs/2502.08226v1,Recommendation System,"gui, trishul, lvlms, training, action"
Take What You Need: Flexible Multi-Task Semantic Communications with Channel Adaptation,"The growing demand for efficient semantic communication systems capable of
managing diverse tasks and adapting to fluctuating channel conditions has
driven the development of robust, resource-efficient frameworks. This article
introduces a novel channel-adaptive and multi-task-aware semantic communication
framework based on a masked auto-encoder architecture. Our framework optimizes
the transmission of meaningful information by incorporating a multi-task-aware
scoring mechanism that identifies and prioritizes semantically significant data
across multiple concurrent tasks. A channel-aware extractor is employed to
dynamically select relevant information in response to real-time channel
conditions. By jointly optimizing semantic relevance and transmission
efficiency, the framework ensures minimal performance degradation under
resource constraints. Experimental results demonstrate the superior performance
of our framework compared to conventional methods in tasks such as image
reconstruction and object detection. These results underscore the framework's
adaptability to heterogeneous channel environments and its scalability for
multi-task applications, positioning it as a promising solution for
next-generation semantic communication networks.",http://arxiv.org/abs/2502.08221v1,Recommendation System,"channel, framework, semantic, communication, tasks"
Deepfake Detection with Spatio-Temporal Consistency and Attention,"Deepfake videos are causing growing concerns among communities due to their
ever-increasing realism. Naturally, automated detection of forged Deepfake
videos is attracting a proportional amount of interest of researchers. Current
methods for detecting forged videos mainly rely on global frame features and
under-utilize the spatio-temporal inconsistencies found in the manipulated
videos. Moreover, they fail to attend to manipulation-specific subtle and
well-localized pattern variations along both spatial and temporal dimensions.
Addressing these gaps, we propose a neural Deepfake detector that focuses on
the localized manipulative signatures of the forged videos at individual frame
level as well as frame sequence level. Using a ResNet backbone, it strengthens
the shallow frame-level feature learning with a spatial attention mechanism.
The spatial stream of the model is further helped by fusing texture enhanced
shallow features with the deeper features. Simultaneously, the model processes
frame sequences with a distance attention mechanism that further allows fusion
of temporal attention maps with the learned features at the deeper layers. The
overall model is trained to detect forged content as a classifier. We evaluate
our method on two popular large data sets and achieve significant performance
over the state-of-the-art methods.Moreover, our technique also provides memory
and computational advantages over the competitive techniques.",http://arxiv.org/abs/2502.08216v1,Computer Vision,"videos, frame, forged, features, deepfake"
LLM Modules: Knowledge Transfer from a Large to a Small Model using Enhanced Cross-Attention,"In this work, we propose an architecture of LLM Modules that enables the
transfer of knowledge from a large pre-trained model to a smaller model using
an Enhanced Cross-Attention mechanism. In the proposed scheme, the Qwen2-1.5B
model is frozen and its representations are passed through specially designed
attention layers to the GPT-Neo-125M model, which is trained on limited
computational resources. Experimental results on the Bespoke-Stratos-17k
dataset demonstrate that after 15 epochs of training, the combined model
generates responses comparable in quality to those obtained by distillation. We
discuss the advantages of the modular approach, provide examples of input
queries and comparative analysis, and outline prospects for further extension
of the method.",http://arxiv.org/abs/2502.08213v1,Recommendation System,"model, trained, attention, work, propose"
Quality over Quantity: Boosting Data Efficiency Through Ensembled Multimodal Data Curation,"In an era overwhelmed by vast amounts of data, the effective curation of
web-crawl datasets is essential for optimizing model performance. This paper
tackles the challenges associated with the unstructured and heterogeneous
nature of such datasets. Traditional heuristic curation methods often
inadequately capture complex features, resulting in biases and the exclusion of
relevant data. We introduce an advanced, learning-driven approach, Ensemble
Curation Of DAta ThroUgh Multimodal Operators (EcoDatum), incorporating a novel
quality-guided deduplication method to ensure balanced feature distributions.
EcoDatum strategically integrates various unimodal and multimodal data curation
operators within a weak supervision ensemble framework, utilizing automated
optimization to score each data point effectively. EcoDatum, which
significantly improves the data curation quality and efficiency, outperforms
existing state-of-the-art (SOTA) techniques, ranked 1st on the DataComp
leaderboard, with an average performance score of 0.182 across 38 diverse
evaluation datasets. This represents a 28% improvement over the DataComp
baseline method, demonstrating its effectiveness in improving dataset curation
and model training efficiency.",http://arxiv.org/abs/2502.08211v1,Reinforcement Learning,"data, curation, datasets, ecodatum, model"
Equivariant Masked Position Prediction for Efficient Molecular Representation,"Graph neural networks (GNNs) have shown considerable promise in computational
chemistry. However, the limited availability of molecular data raises concerns
regarding GNNs' ability to effectively capture the fundamental principles of
physics and chemistry, which constrains their generalization capabilities. To
address this challenge, we introduce a novel self-supervised approach termed
Equivariant Masked Position Prediction (EMPP), grounded in intramolecular
potential and force theory. Unlike conventional attribute masking techniques,
EMPP formulates a nuanced position prediction task that is more well-defined
and enhances the learning of quantum mechanical features. EMPP also bypasses
the approximation of the Gaussian mixture distribution commonly used in
denoising methods, allowing for more accurate acquisition of physical
properties. Experimental results indicate that EMPP significantly enhances
performance of advanced molecular architectures, surpassing state-of-the-art
self-supervised approaches. Our code is released in
https://github.com/ajy112/EMPP.",http://arxiv.org/abs/2502.08209v1,Recommendation System,"empp, gnns, chemistry, molecular, self"
Exploring Exploration in Bayesian Optimization,"A well-balanced exploration-exploitation trade-off is crucial for successful
acquisition functions in Bayesian optimization. However, there is a lack of
quantitative measures for exploration, making it difficult to analyze and
compare different acquisition functions. This work introduces two novel
approaches - observation traveling salesman distance and observation entropy -
to quantify the exploration characteristics of acquisition functions based on
their selected observations. Using these measures, we examine the explorative
nature of several well-known acquisition functions across a diverse set of
black-box problems, uncover links between exploration and empirical
performance, and reveal new relationships among existing acquisition functions.
Beyond enabling a deeper understanding of acquisition functions, these measures
also provide a foundation for guiding their design in a more principled and
systematic manner.",http://arxiv.org/abs/2502.08208v1,Recommendation System,"acquisition, functions, exploration, measures, observation"
Optimizing Asynchronous Federated Learning: A Delicate Trade-Off Between Model-Parameter Staleness and Update Frequency,"Synchronous federated learning (FL) scales poorly with the number of clients
due to the straggler effect. Algorithms like FedAsync and GeneralizedFedAsync
address this limitation by enabling asynchronous communication between clients
and the central server. In this work, we rely on stochastic modeling to better
understand the impact of design choices in asynchronous FL algorithms, such as
the concurrency level and routing probabilities, and we leverage this knowledge
to optimize loss. We characterize in particular a fundamental trade-off for
optimizing asynchronous FL: minimizing gradient estimation errors by avoiding
model parameter staleness, while also speeding up the system by increasing the
throughput of model updates. Our two main contributions can be summarized as
follows. First, we prove a discrete variant of Little's law to derive a
closed-form expression for relative delay, a metric that quantifies staleness.
This allows us to efficiently minimize the average loss per model update, which
has been the gold standard in literature to date. Second, we observe that
naively optimizing this metric leads us to slow down the system drastically by
overemphazing staleness at the detriment of throughput. This motivates us to
introduce an alternative metric that also takes system speed into account, for
which we derive a tractable upper-bound that can be minimized numerically.
Extensive numerical results show that these optimizations enhance accuracy by
10% to 30%.",http://arxiv.org/abs/2502.08206v1,Reinforcement Learning,"fl, asynchronous, model, staleness, system"
Wisdom of the Crowds in Forecasting: Forecast Summarization for Supporting Future Event Prediction,"Future Event Prediction (FEP) is an essential activity whose demand and
application range across multiple domains. While traditional methods like
simulations, predictive and time-series forecasting have demonstrated promising
outcomes, their application in forecasting complex events is not entirely
reliable due to the inability of numerical data to accurately capture the
semantic information related to events. One forecasting way is to gather and
aggregate collective opinions on the future to make predictions as cumulative
perspectives carry the potential to help estimating the likelihood of upcoming
events. In this work, we organize the existing research and frameworks that aim
to support future event prediction based on crowd wisdom through aggregating
individual forecasts. We discuss the challenges involved, available datasets,
as well as the scope of improvement and future research directions for this
task. We also introduce a novel data model to represent individual forecast
statements.",http://arxiv.org/abs/2502.08205v1,Recommendation System,"future, forecasting, events, event, prediction"
Privacy amplification by random allocation,"We consider the privacy guarantees of an algorithm in which a user's data is
used in $k$ steps randomly and uniformly chosen from a sequence (or set) of $t$
differentially private steps. We demonstrate that the privacy guarantees of
this sampling scheme can be upper bound by the privacy guarantees of the
well-studied independent (or Poisson) subsampling in which each step uses the
user's data with probability $(1+ o(1))k/t $. Further, we provide two
additional analysis techniques that lead to numerical improvements in some
parameter regimes. The case of $k=1$ has been previously studied in the context
of DP-SGD in Balle et al. (2020) and very recently in Chua et al. (2024).
Privacy analysis of Balle et al. (2020) relies on privacy amplification by
shuffling which leads to overly conservative bounds. Privacy analysis of Chua
et al. (2024a) relies on Monte Carlo simulations that are computationally
prohibitive in many practical scenarios and have additional inherent
limitations.",http://arxiv.org/abs/2502.08202v1,Recommendation System,"privacy, et, al, guarantees, analysis"
ActiveSSF: An Active-Learning-Guided Self-Supervised Framework for Long-Tailed Megakaryocyte Classification,"Precise classification of megakaryocytes is crucial for diagnosing
myelodysplastic syndromes. Although self-supervised learning has shown promise
in medical image analysis, its application to classifying megakaryocytes in
stained slides faces three main challenges: (1) pervasive background noise that
obscures cellular details, (2) a long-tailed distribution that limits data for
rare subtypes, and (3) complex morphological variations leading to high
intra-class variability. To address these issues, we propose the ActiveSSF
framework, which integrates active learning with self-supervised pretraining.
Specifically, our approach employs Gaussian filtering combined with K-means
clustering and HSV analysis (augmented by clinical prior knowledge) for
accurate region-of-interest extraction; an adaptive sample selection mechanism
that dynamically adjusts similarity thresholds to mitigate class imbalance; and
prototype clustering on labeled samples to overcome morphological complexity.
Experimental results on clinical megakaryocyte datasets demonstrate that
ActiveSSF not only achieves state-of-the-art performance but also significantly
improves recognition accuracy for rare subtypes. Moreover, the integration of
these advanced techniques further underscores the practical potential of
ActiveSSF in clinical settings. To foster further research, the code and
datasets will be publicly released in the future.",http://arxiv.org/abs/2502.08200v1,Recommendation System,"activessf, clinical, megakaryocytes, self, supervised"
AnyCharV: Bootstrap Controllable Character Video Generation with Fine-to-Coarse Guidance,"Character video generation is a significant real-world application focused on
producing high-quality videos featuring specific characters. Recent
advancements have introduced various control signals to animate static
characters, successfully enhancing control over the generation process.
However, these methods often lack flexibility, limiting their applicability and
making it challenging for users to synthesize a source character into a desired
target scene. To address this issue, we propose a novel framework, AnyCharV,
that flexibly generates character videos using arbitrary source characters and
target scenes, guided by pose information. Our approach involves a two-stage
training process. In the first stage, we develop a base model capable of
integrating the source character with the target scene using pose guidance. The
second stage further bootstraps controllable generation through a self-boosting
mechanism, where we use the generated video in the first stage and replace the
fine mask with the coarse one, enabling training outcomes with better
preservation of character details. Experimental results demonstrate the
effectiveness and robustness of our proposed method. Our project page is
https://anycharv.github.io.",http://arxiv.org/abs/2502.08189v1,Recommendation System,"character, stage, generation, characters, source"
Latest Advancements Towards Catastrophic Forgetting under Data Scarcity: A Comprehensive Survey on Few-Shot Class Incremental Learning,"Data scarcity significantly complicates the continual learning problem, i.e.,
how a deep neural network learns in dynamic environments with very few samples.
However, the latest progress of few-shot class incremental learning (FSCIL)
methods and related studies show insightful knowledge on how to tackle the
problem. This paper presents a comprehensive survey on FSCIL that highlights
several important aspects i.e. comprehensive and formal objectives of FSCIL
approaches, the importance of prototype rectifications, the new learning
paradigms based on pre-trained model and language-guided mechanism, the deeper
analysis of FSCIL performance metrics and evaluation, and the practical
contexts of FSCIL in various areas. Our extensive discussion presents the open
challenges, potential solutions, and future directions of FSCIL.",http://arxiv.org/abs/2502.08181v1,Recommendation System,"fscil, learning, problem, presents, comprehensive"
Enhancing LLM Character-Level Manipulation via Divide and Conquer,"Large Language Models (LLMs) have demonstrated strong generalization
capabilities across a wide range of natural language processing (NLP) tasks.
However, they exhibit notable weaknesses in character-level string
manipulation, struggling with fundamental operations such as character
deletion, insertion, and substitution. These challenges stem primarily from
tokenization constraints, despite the critical role of such operations in data
preprocessing and code generation. Through systematic analysis, we derive two
key insights: (1) LLMs face significant difficulties in leveraging intrinsic
token knowledge for character-level reasoning, and (2) atomized word structures
can substantially enhance LLMs' ability to process token-level structural
information. Building on these insights, we propose Character-Level
Manipulation via Divide and Conquer, a novel approach designed to bridge the
gap between token-level processing and character-level manipulation. Our method
decomposes complex operations into explicit character-level subtasks coupled
with controlled token reconstruction phases, leading to significant
improvements in accuracy. Without additional training, our method significantly
improves accuracies on the $\texttt{Deletion}$, $\texttt{Insertion}$, and
$\texttt{Substitution}$ tasks. To support further research, we open-source our
implementation and benchmarks.",http://arxiv.org/abs/2502.08180v1,Natural Language Processing,"level, character, token, llms, manipulation"
SycEval: Evaluating LLM Sycophancy,"Large language models (LLMs) are increasingly applied in educational,
clinical, and professional settings, but their tendency for sycophancy --
prioritizing user agreement over independent reasoning -- poses risks to
reliability. This study introduces a framework to evaluate sycophantic behavior
in ChatGPT-4o, Claude-Sonnet, and Gemini-1.5-Pro across AMPS (mathematics) and
MedQuad (medical advice) datasets. Sycophantic behavior was observed in 58.19%
of cases, with Gemini exhibiting the highest rate (62.47%) and ChatGPT the
lowest (56.71%). Progressive sycophancy, leading to correct answers, occurred
in 43.52% of cases, while regressive sycophancy, leading to incorrect answers,
was observed in 14.66%. Preemptive rebuttals demonstrated significantly higher
sycophancy rates than in-context rebuttals (61.75% vs. 56.52%, $Z=5.87$,
$p<0.001$), particularly in computational tasks, where regressive sycophancy
increased significantly (preemptive: 8.13%, in-context: 3.54%, $p<0.001$).
Simple rebuttals maximized progressive sycophancy ($Z=6.59$, $p<0.001$), while
citation-based rebuttals exhibited the highest regressive rates ($Z=6.59$,
$p<0.001$). Sycophantic behavior showed high persistence (78.5%, 95% CI:
[77.2%, 79.8%]) regardless of context or model. These findings emphasize the
risks and opportunities of deploying LLMs in structured and dynamic domains,
offering insights into prompt programming and model optimization for safer AI
applications.",http://arxiv.org/abs/2502.08177v1,Recommendation System,"sycophancy, rebuttals, sycophantic, behavior, regressive"
CoDynTrust: Robust Asynchronous Collaborative Perception via Dynamic Feature Trust Modulus,"Collaborative perception, fusing information from multiple agents, can extend
perception range so as to improve perception performance. However, temporal
asynchrony in real-world environments, caused by communication delays, clock
misalignment, or sampling configuration differences, can lead to information
mismatches. If this is not well handled, then the collaborative performance is
patchy, and what's worse safety accidents may occur. To tackle this challenge,
we propose CoDynTrust, an uncertainty-encoded asynchronous fusion perception
framework that is robust to the information mismatches caused by temporal
asynchrony. CoDynTrust generates dynamic feature trust modulus (DFTM) for each
region of interest by modeling aleatoric and epistemic uncertainty as well as
selectively suppressing or retaining single-vehicle features, thereby
mitigating information mismatches. We then design a multi-scale fusion module
to handle multi-scale feature maps processed by DFTM. Compared to existing
works that also consider asynchronous collaborative perception, CoDynTrust
combats various low-quality information in temporally asynchronous scenarios
and allows uncertainty to be propagated to downstream tasks such as planning
and control. Experimental results demonstrate that CoDynTrust significantly
reduces performance degradation caused by temporal asynchrony across multiple
datasets, achieving state-of-the-art detection performance even with temporal
asynchrony. The code is available at https://github.com/CrazyShout/CoDynTrust.",http://arxiv.org/abs/2502.08169v1,Reinforcement Learning,"perception, information, performance, temporal, asynchrony"
"DNNs May Determine Major Properties of Their Outputs Early, with Timing Possibly Driven by Bias","This paper argues that deep neural networks (DNNs) mostly determine their
outputs during the early stages of inference, where biases inherent in the
model play a crucial role in shaping this process. We draw a parallel between
this phenomenon and human decision-making, which often relies on fast,
intuitive heuristics. Using diffusion models (DMs) as a case study, we
demonstrate that DNNs often make early-stage decision-making influenced by the
type and extent of bias in their design and training. Our findings offer a new
perspective on bias mitigation, efficient inference, and the interpretation of
machine learning systems. By identifying the temporal dynamics of
decision-making in DNNs, this paper aims to inspire further discussion and
research within the machine learning community.",http://arxiv.org/abs/2502.08167v1,Recommendation System,"dnns, decision, making, paper, early"
From Individual Experience to Collective Evidence: A Reporting-Based Framework for Identifying Systemic Harms,"When an individual reports a negative interaction with some system, how can
their personal experience be contextualized within broader patterns of system
behavior? We study the incident database problem, where individual reports of
adverse events arrive sequentially, and are aggregated over time. In this work,
our goal is to identify whether there are subgroups--defined by any combination
of relevant features--that are disproportionately likely to experience harmful
interactions with the system. We formalize this problem as a sequential
hypothesis test, and identify conditions on reporting behavior that are
sufficient for making inferences about disparities in true rates of harm across
subgroups. We show that algorithms for sequential hypothesis tests can be
applied to this problem with a standard multiple testing correction. We then
demonstrate our method on real-world datasets, including mortgage decisions and
vaccine side effects; on each, our method (re-)identifies subgroups known to
experience disproportionate harm using only a fraction of the data that was
initially used to discover them.",http://arxiv.org/abs/2502.08166v1,Natural Language Processing,"system, experience, problem, subgroups, individual"
MixDec Sampling: A Soft Link-based Sampling Method of Graph Neural Network for Recommendation,"Graph neural networks have been widely used in recent recommender systems,
where negative sampling plays an important role. Existing negative sampling
methods restrict the relationship between nodes as either hard positive pairs
or hard negative pairs. This leads to the loss of structural information, and
lacks the mechanism to generate positive pairs for nodes with few neighbors. To
overcome limitations, we propose a novel soft link-based sampling method,
namely MixDec Sampling, which consists of Mixup Sampling module and Decay
Sampling module. The Mixup Sampling augments node features by synthesizing new
nodes and soft links, which provides sufficient number of samples for nodes
with few neighbors. The Decay Sampling strengthens the digestion of graph
structure information by generating soft links for node embedding learning. To
the best of our knowledge, we are the first to model sampling relationships
between nodes by soft links in GNN-based recommender systems. Extensive
experiments demonstrate that the proposed MixDec Sampling can significantly and
consistently improve the recommendation performance of several representative
GNN-based models on various recommendation benchmarks.",http://arxiv.org/abs/2502.08161v1,Recommendation System,"sampling, nodes, soft, negative, pairs"
"Vertical Federated Learning in Practice: The Good, the Bad, and the Ugly","Vertical Federated Learning (VFL) is a privacy-preserving collaborative
learning paradigm that enables multiple parties with distinct feature sets to
jointly train machine learning models without sharing their raw data. Despite
its potential to facilitate cross-organizational collaborations, the deployment
of VFL systems in real-world applications remains limited. To investigate the
gap between existing VFL research and practical deployment, this survey
analyzes the real-world data distributions in potential VFL applications and
identifies four key findings that highlight this gap. We propose a novel
data-oriented taxonomy of VFL algorithms based on real VFL data distributions.
Our comprehensive review of existing VFL algorithms reveals that some common
practical VFL scenarios have few or no viable solutions. Based on these
observations, we outline key research directions aimed at bridging the gap
between current VFL research and real-world applications.",http://arxiv.org/abs/2502.08160v1,Recommendation System,"vfl, data, real, learning, world"
DGSense: A Domain Generalization Framework for Wireless Sensing,"Wireless sensing is of great benefits to our daily lives. However, wireless
signals are sensitive to the surroundings. Various factors, e.g. environments,
locations, and individuals, may induce extra impact on wireless propagation.
Such a change can be regarded as a domain, in which the data distribution
shifts. A vast majority of the sensing schemes are learning-based. They are
dependent on the training domains, resulting in performance degradation in
unseen domains. Researchers have proposed various solutions to address this
issue. But these solutions leverage either semi-supervised or unsupervised
domain adaptation techniques. They still require some data in the target
domains and do not perform well in unseen domains. In this paper, we propose a
domain generalization framework DGSense, to eliminate the domain dependence
problem in wireless sensing. The framework is a general solution working across
diverse sensing tasks and wireless technologies. Once the sensing model is
built, it can generalize to unseen domains without any data from the target
domain. To achieve the goal, we first increase the diversity of the training
set by a virtual data generator, and then extract the domain independent
features via episodic training between the main feature extractor and the
domain feature extractors. The feature extractors employ a pre-trained Residual
Network (ResNet) with an attention mechanism for spatial features, and a 1D
Convolutional Neural Network (1DCNN) for temporal features. To demonstrate the
effectiveness and generality of DGSense, we evaluated on WiFi gesture
recognition, Millimeter Wave (mmWave) activity recognition, and acoustic fall
detection. All the systems exhibited high generalization capability to unseen
domains, including new users, locations, and environments, free of new data and
retraining.",http://arxiv.org/abs/2502.08155v1,Recommendation System,"domain, domains, wireless, sensing, data"
Local Differential Privacy is Not Enough: A Sample Reconstruction Attack against Federated Learning with Local Differential Privacy,"Reconstruction attacks against federated learning (FL) aim to reconstruct
users' samples through users' uploaded gradients. Local differential privacy
(LDP) is regarded as an effective defense against various attacks, including
sample reconstruction in FL, where gradients are clipped and perturbed.
Existing attacks are ineffective in FL with LDP since clipped and perturbed
gradients obliterate most sample information for reconstruction. Besides,
existing attacks embed additional sample information into gradients to improve
the attack effect and cause gradient expansion, leading to a more severe
gradient clipping in FL with LDP. In this paper, we propose a sample
reconstruction attack against LDP-based FL with any target models to
reconstruct victims' sensitive samples to illustrate that FL with LDP is not
flawless. Considering gradient expansion in reconstruction attacks and noise in
LDP, the core of the proposed attack is gradient compression and reconstructed
sample denoising. For gradient compression, an inference structure based on
sample characteristics is presented to reduce redundant gradients against LDP.
For reconstructed sample denoising, we artificially introduce zero gradients to
observe noise distribution and scale confidence interval to filter the noise.
Theoretical proof guarantees the effectiveness of the proposed attack.
Evaluations show that the proposed attack is the only attack that reconstructs
victims' training samples in LDP-based FL and has little impact on the target
model's accuracy. We conclude that LDP-based FL needs further improvements to
defend against sample reconstruction attacks effectively.",http://arxiv.org/abs/2502.08151v1,Recommendation System,"ldp, fl, sample, reconstruction, attacks"
Force Matching with Relativistic Constraints: A Physics-Inspired Approach to Stable and Efficient Generative Modeling,"This paper introduces Force Matching (ForM), a novel framework for generative
modeling that represents an initial exploration into leveraging special
relativistic mechanics to enhance the stability of the sampling process. By
incorporating the Lorentz factor, ForM imposes a velocity constraint, ensuring
that sample velocities remain bounded within a constant limit. This constraint
serves as a fundamental mechanism for stabilizing the generative dynamics,
leading to a more robust and controlled sampling process. We provide a rigorous
theoretical analysis demonstrating that the velocity constraint is preserved
throughout the sampling procedure within the ForM framework. To validate the
effectiveness of our approach, we conduct extensive empirical evaluations. On
the \textit{half-moons} dataset, ForM significantly outperforms baseline
methods, achieving the lowest Euclidean distance loss of \textbf{0.714}, in
contrast to vanilla first-order flow matching (5.853) and first- and
second-order flow matching (5.793). Additionally, we perform an ablation study
to further investigate the impact of our velocity constraint, reaffirming the
superiority of ForM in stabilizing the generative process. The theoretical
guarantees and empirical results underscore the potential of integrating
special relativity principles into generative modeling. Our findings suggest
that ForM provides a promising pathway toward achieving stable, efficient, and
flexible generative processes. This work lays the foundation for future
advancements in high-dimensional generative modeling, opening new avenues for
the application of physical principles in machine learning.",http://arxiv.org/abs/2502.08150v1,Recommendation System,"form, generative, constraint, matching, modeling"
Generalized Class Discovery in Instance Segmentation,"This work addresses the task of generalized class discovery (GCD) in instance
segmentation. The goal is to discover novel classes and obtain a model capable
of segmenting instances of both known and novel categories, given labeled and
unlabeled data. Since the real world contains numerous objects with long-tailed
distributions, the instance distribution for each class is inherently
imbalanced. To address the imbalanced distributions, we propose an
instance-wise temperature assignment (ITA) method for contrastive learning and
class-wise reliability criteria for pseudo-labels. The ITA method relaxes
instance discrimination for samples belonging to head classes to enhance GCD.
The reliability criteria are to avoid excluding most pseudo-labels for tail
classes when training an instance segmentation network using pseudo-labels from
GCD. Additionally, we propose dynamically adjusting the criteria to leverage
diverse samples in the early stages while relying only on reliable
pseudo-labels in the later stages. We also introduce an efficient soft
attention module to encode object-specific representations for GCD. Finally, we
evaluate our proposed method by conducting experiments on two settings:
COCO$_{half}$ + LVIS and LVIS + Visual Genome. The experimental results
demonstrate that the proposed method outperforms previous state-of-the-art
methods.",http://arxiv.org/abs/2502.08149v1,Recommendation System,"instance, gcd, method, pseudo, labels"
ACCESS : A Benchmark for Abstract Causal Event Discovery and Reasoning,"Identifying cause-and-effect relationships is critical to understanding
real-world dynamics and ultimately causal reasoning. Existing methods for
identifying event causality in NLP, including those based on Large Language
Models (LLMs), exhibit difficulties in out-of-distribution settings due to the
limited scale and heavy reliance on lexical cues within available benchmarks.
Modern benchmarks, inspired by probabilistic causal inference, have attempted
to construct causal graphs of events as a robust representation of causal
knowledge, where \texttt{CRAB} \citep{romanou2023crab} is one such recent
benchmark along this line. In this paper, we introduce \texttt{ACCESS}, a
benchmark designed for discovery and reasoning over abstract causal events.
Unlike existing resources, \texttt{ACCESS} focuses on causality of everyday
life events on the abstraction level. We propose a pipeline for identifying
abstractions for event generalizations from \texttt{GLUCOSE}
\citep{mostafazadeh-etal-2020-glucose}, a large-scale dataset of implicit
commonsense causal knowledge, from which we subsequently extract $1,4$K causal
pairs. Our experiments highlight the ongoing challenges of using statistical
methods and/or LLMs for automatic abstraction identification and causal
discovery in NLP. Nonetheless, we demonstrate that the abstract causal
knowledge provided in \texttt{ACCESS} can be leveraged for enhancing QA
reasoning performance in LLMs.",http://arxiv.org/abs/2502.08148v1,Natural Language Processing,"causal, identifying, reasoning, llms, events"
Knowledge-Guided Wasserstein Distributionally Robust Optimization,"Transfer learning is a popular strategy to leverage external knowledge and
improve statistical efficiency, particularly with a limited target sample. We
propose a novel knowledge-guided Wasserstein Distributionally Robust
Optimization (KG-WDRO) framework that adaptively incorporates multiple sources
of external knowledge to overcome the conservativeness of vanilla WDRO, which
often results in overly pessimistic shrinkage toward zero. Our method
constructs smaller Wasserstein ambiguity sets by controlling the transportation
along directions informed by the source knowledge. This strategy can alleviate
perturbations on the predictive projection of the covariates and protect
against information loss. Theoretically, we establish the equivalence between
our WDRO formulation and the knowledge-guided shrinkage estimation based on
collinear similarity, ensuring tractability and geometrizing the feasible set.
This also reveals a novel and general interpretation for recent shrinkage-based
transfer learning approaches from the perspective of distributional robustness.
In addition, our framework can adjust for scaling differences in the regression
models between the source and target and accommodates general types of
regularization such as lasso and ridge. Extensive simulations demonstrate the
superior performance and adaptivity of KG-WDRO in enhancing small-sample
transfer learning.",http://arxiv.org/abs/2502.08146v1,Recommendation System,"knowledge, wdro, transfer, learning, shrinkage"
Democratizing AI: Open-source Scalable LLM Training on GPU-based Supercomputers,"Training and fine-tuning large language models (LLMs) with hundreds of
billions to trillions of parameters requires tens of thousands of GPUs, and a
highly scalable software stack. In this work, we present a novel
four-dimensional hybrid parallel algorithm implemented in a highly scalable,
portable, open-source framework called AxoNN. We describe several performance
optimizations in AxoNN to improve matrix multiply kernel performance, overlap
non-blocking collectives with computation, and performance modeling to choose
performance optimal configurations. These have resulted in unprecedented
scaling and peak flop/s (bf16) for training of GPT-style transformer models on
Perlmutter (620.1 Petaflop/s), Frontier (1.381 Exaflop/s) and Alps (1.423
Exaflop/s).
  While the abilities of LLMs improve with the number of trainable parameters,
so do privacy and copyright risks caused by memorization of training data,
which can cause disclosure of sensitive or private information at inference
time. We highlight this side effect of scale through experiments that explore
""catastrophic memorization"", where models are sufficiently large to memorize
training data in a single pass, and present an approach to prevent it. As part
of this study, we demonstrate fine-tuning of a 405-billion parameter LLM using
AxoNN on Frontier.",http://arxiv.org/abs/2502.08145v1,Natural Language Processing,"training, performance, s, models, axonn"
Bridging the Safety Gap: A Guardrail Pipeline for Trustworthy LLM Inferences,"We present Wildflare GuardRail, a guardrail pipeline designed to enhance the
safety and reliability of Large Language Model (LLM) inferences by
systematically addressing risks across the entire processing workflow.
Wildflare GuardRail integrates several core functional modules, including
Safety Detector that identifies unsafe inputs and detects hallucinations in
model outputs while generating root-cause explanations, Grounding that
contextualizes user queries with information retrieved from vector databases,
Customizer that adjusts outputs in real time using lightweight, rule-based
wrappers, and Repairer that corrects erroneous LLM outputs using hallucination
explanations provided by Safety Detector. Results show that our unsafe content
detection model in Safety Detector achieves comparable performance with OpenAI
API, though trained on a small dataset constructed with several public
datasets. Meanwhile, the lightweight wrappers can address malicious URLs in
model outputs in 1.06s per query with 100% accuracy without costly model calls.
Moreover, the hallucination fixing model demonstrates effectiveness in reducing
hallucinations with an accuracy of 80.7%.",http://arxiv.org/abs/2502.08142v1,Recommendation System,"model, safety, outputs, guardrail, detector"
Data-dependent Bounds with $T$-Optimal Best-of-Both-Worlds Guarantees in Multi-Armed Bandits using Stability-Penalty Matching,"Existing data-dependent and best-of-both-worlds regret bounds for multi-armed
bandits problems have limited adaptivity as they are either data-dependent but
not best-of-both-worlds (BOBW), BOBW but not data-dependent or have sub-optimal
$O(\sqrt{T\ln{T}})$ worst-case guarantee in the adversarial regime. To overcome
these limitations, we propose real-time stability-penalty matching (SPM), a new
method for obtaining regret bounds that are simultaneously data-dependent,
best-of-both-worlds and $T$-optimal for multi-armed bandits problems. In
particular, we show that real-time SPM obtains bounds with worst-case
guarantees of order $O(\sqrt{T})$ in the adversarial regime and $O(\ln{T})$ in
the stochastic regime while simultaneously being adaptive to data-dependent
quantities such as sparsity, variations, and small losses. Our results are
obtained by extending the SPM technique for tuning the learning rates in the
follow-the-regularized-leader (FTRL) framework, which further indicates that
the combination of SPM and FTRL is a promising approach for proving new
adaptive bounds in online learning problems.",http://arxiv.org/abs/2502.08143v1,Recommendation System,"data, dependent, bounds, spm, best"
LowRA: Accurate and Efficient LoRA Fine-Tuning of LLMs under 2 Bits,"Fine-tuning large language models (LLMs) is increasingly costly as models
scale to hundreds of billions of parameters, and even parameter-efficient
fine-tuning (PEFT) methods like LoRA remain resource-intensive. We introduce
LowRA, the first framework to enable LoRA fine-tuning below 2 bits per
parameter with minimal performance loss. LowRA optimizes fine-grained
quantization - mapping, threshold selection, and precision assignment - while
leveraging efficient CUDA kernels for scalable deployment. Extensive
evaluations across 4 LLMs and 4 datasets show that LowRA achieves a superior
performance-precision trade-off above 2 bits and remains accurate down to 1.15
bits, reducing memory usage by up to 50%. Our results highlight the potential
of ultra-low-bit LoRA fine-tuning for resource-constrained environments.",http://arxiv.org/abs/2502.08141v1,Recommendation System,"fine, tuning, lora, lowra, bits"
Riemannian Complex Hermit Positive Definite Convolution Network for Polarimetric SAR Image Classification,"Deep learning can learn high-level semantic features in Euclidean space
effectively for PolSAR images, while they need to covert the complex covariance
matrix into a feature vector or complex-valued vector as the network input.
However, the complex covariance matrices are essentially a complex Hermit
positive definite (HPD) matrix endowed in Riemannian manifold rather than
Euclidean space. The matrix's real and imagery parts are with the same
significance, as the imagery part represents the phase information. The matrix
vectorization will destroy the geometric structure and manifold characteristics
of complex covariance matrices. To learn complex HPD matrices directly, we
propose a Riemannian complex HPD convolution network(HPD\_CNN) for PolSAR
images. This method consists of a complex HPD unfolding network(HPDnet) and a
CV-3DCNN enhanced network. The proposed complex HPDnet defines the HPD mapping,
rectifying and the logEig layers to learn geometric features of complex
matrices. In addition, a fast eigenvalue decomposition method is designed to
reduce computation burden. Finally, a Riemannian-to-Euclidean enhanced network
is defined to enhance contextual information for classification. Experimental
results on two real PolSSAR datasets demonstrate the proposed method can
achieve superior performance than the state-of-the-art methods especially in
heterogeneous regions.",http://arxiv.org/abs/2502.08137v1,Computer Vision,"complex, hpd, matrix, matrices, learn"
In-Context Learning of Linear Dynamical Systems with Transformers: Error Bounds and Depth-Separation,"This paper investigates approximation-theoretic aspects of the in-context
learning capability of the transformers in representing a family of noisy
linear dynamical systems. Our first theoretical result establishes an upper
bound on the approximation error of multi-layer transformers with respect to an
$L^2$-testing loss uniformly defined across tasks. This result demonstrates
that transformers with logarithmic depth can achieve error bounds comparable
with those of the least-squares estimator. In contrast, our second result
establishes a non-diminishing lower bound on the approximation error for a
class of single-layer linear transformers, which suggests a depth-separation
phenomenon for transformers in the in-context learning of dynamical systems.
Moreover, this second result uncovers a critical distinction in the
approximation power of single-layer linear transformers when learning from IID
versus non-IID data.",http://arxiv.org/abs/2502.08136v1,Recommendation System,"transformers, approximation, result, learning, linear"
A Survey on Data Curation for Visual Contrastive Learning: Why Crafting Effective Positive and Negative Pairs Matters,"Visual contrastive learning aims to learn representations by contrasting
similar (positive) and dissimilar (negative) pairs of data samples. The design
of these pairs significantly impacts representation quality, training
efficiency, and computational cost. A well-curated set of pairs leads to
stronger representations and faster convergence. As contrastive pre-training
sees wider adoption for solving downstream tasks, data curation becomes
essential for optimizing its effectiveness. In this survey, we attempt to
create a taxonomy of existing techniques for positive and negative pair
curation in contrastive learning, and describe them in detail.",http://arxiv.org/abs/2502.08134v1,Recommendation System,"contrastive, pairs, learning, representations, positive"
SS4Rec: Continuous-Time Sequential Recommendation with State Space Models,"Sequential recommendation is a key area in the field of recommendation
systems aiming to model user interest based on historical interaction sequences
with irregular intervals. While previous recurrent neural network-based and
attention-based approaches have achieved significant results, they have
limitations in capturing system continuity due to the discrete characteristics.
In the context of continuous-time modeling, state space model (SSM) offers a
potential solution, as it can effectively capture the dynamic evolution of user
interest over time. However, existing SSM-based approaches ignore the impact of
irregular time intervals within historical user interactions, making it
difficult to model complexed user-item transitions in sequences. To address
this issue, we propose a hybrid SSM-based model called SS4Rec for
continuous-time sequential recommendation. SS4Rec integrates a time-aware SSM
to handle irregular time intervals and a relation-aware SSM to model contextual
dependencies, enabling it to infer user interest from both temporal and
sequential perspectives. In the training process, the time-aware SSM and the
relation-aware SSM are discretized by variable stepsizes according to user
interaction time intervals and input data, respectively. This helps capture the
continuous dependency from irregular time intervals and provides time-specific
personalized recommendations. Experimental studies on five benchmark datasets
demonstrate the superiority and effectiveness of SS4Rec.",http://arxiv.org/abs/2502.08132v1,Recommendation System,"time, ssm, user, model, based"
Incremental Approximate Single-Source Shortest Paths with Predictions,"The algorithms-with-predictions framework has been used extensively to
develop online algorithms with improved beyond-worst-case competitive ratios.
Recently, there is growing interest in leveraging predictions for designing
data structures with improved beyond-worst-case running times. In this paper,
we study the fundamental data structure problem of maintaining approximate
shortest paths in incremental graphs in the algorithms-with-predictions model.
Given a sequence $\sigma$ of edges that are inserted one at a time, the goal is
to maintain approximate shortest paths from the source to each vertex in the
graph at each time step. Before any edges arrive, the data structure is given a
prediction of the online edge sequence $\hat{\sigma}$ which is used to ``warm
start'' its state.
  As our main result, we design a learned algorithm that maintains
$(1+\epsilon)$-approximate single-source shortest paths, which runs in
$\tilde{O}(m \eta \log W/\epsilon)$ time, where $W$ is the weight of the
heaviest edge and $\eta$ is the prediction error. We show these techniques
immediately extend to the all-pairs shortest-path setting as well. Our
algorithms are consistent (performing nearly as fast as the offline algorithm)
when predictions are nearly perfect, have a smooth degradation in performance
with respect to the prediction error and, in the worst case, match the best
offline algorithm up to logarithmic factors.
  As a building block, we study the offline incremental approximate
single-source shortest-paths problem. In this problem, the edge sequence
$\sigma$ is known a priori and the goal is to efficiently return the length of
the shortest paths in the intermediate graph $G_t$ consisting of the first $t$
edges, for all $t$. Note that the offline incremental problem is defined in the
worst-case setting (without predictions) and is of independent interest.",http://arxiv.org/abs/2502.08125v1,Recommendation System,"shortest, predictions, paths, algorithms, worst"
Provably Robust Federated Reinforcement Learning,"Federated reinforcement learning (FRL) allows agents to jointly learn a
global decision-making policy under the guidance of a central server. While FRL
has advantages, its decentralized design makes it prone to poisoning attacks.
To mitigate this, Byzantine-robust aggregation techniques tailored for FRL have
been introduced. Yet, in our work, we reveal that these current
Byzantine-robust techniques are not immune to our newly introduced Normalized
attack. Distinct from previous attacks that targeted enlarging the distance of
policy updates before and after an attack, our Normalized attack emphasizes on
maximizing the angle of deviation between these updates. To counter these
threats, we develop an ensemble FRL approach that is provably secure against
both known and our newly proposed attacks. Our ensemble method involves
training multiple global policies, where each is learnt by a group of agents
using any foundational aggregation rule. These well-trained global policies
then individually predict the action for a specific test state. The ultimate
action is chosen based on a majority vote for discrete action systems or the
geometric median for continuous ones. Our experimental results across different
settings show that the Normalized attack can greatly disrupt non-ensemble
Byzantine-robust methods, and our ensemble approach offers substantial
resistance against poisoning attacks.",http://arxiv.org/abs/2502.08123v1,Reinforcement Learning,"frl, attacks, attack, ensemble, global"
Hookpad Aria: A Copilot for Songwriters,"We present Hookpad Aria, a generative AI system designed to assist musicians
in writing Western pop songs. Our system is seamlessly integrated into Hookpad,
a web-based editor designed for the composition of lead sheets: symbolic music
scores that describe melody and harmony. Hookpad Aria has numerous generation
capabilities designed to assist users in non-sequential composition workflows,
including: (1) generating left-to-right continuations of existing material, (2)
filling in missing spans in the middle of existing material, and (3) generating
harmony from melody and vice versa. Hookpad Aria is also a scalable data
flywheel for music co-creation -- since its release in March 2024, Aria has
generated 318k suggestions for 3k users who have accepted 74k into their songs.
  More information about Hookpad Aria is available at
https://www.hooktheory.com/hookpad/aria",http://arxiv.org/abs/2502.08122v1,Recommendation System,"hookpad, aria, designed, system, assist"
Generative AI-Enhanced Cooperative MEC of UAVs and Ground Stations for Unmanned Surface Vehicles,"The increasing deployment of unmanned surface vehicles (USVs) require
computational support and coverage in applications such as maritime search and
rescue. Unmanned aerial vehicles (UAVs) can offer low-cost, flexible aerial
services, and ground stations (GSs) can provide powerful supports, which can
cooperate to help the USVs in complex scenarios. However, the collaboration
between UAVs and GSs for USVs faces challenges of task uncertainties, USVs
trajectory uncertainties, heterogeneities, and limited computational resources.
To address these issues, we propose a cooperative UAV and GS based robust
multi-access edge computing framework to assist USVs in completing
computational tasks. Specifically, we formulate the optimization problem of
joint task offloading and UAV trajectory to minimize the total execution time,
which is in the form of mixed integer nonlinear programming and NP-hard to
tackle. Therefore, we propose the algorithm of generative artificial
intelligence-enhanced heterogeneous agent proximal policy optimization
(GAI-HAPPO). The proposed algorithm integrates GAI models to enhance the actor
network ability to model complex environments and extract high-level features,
thereby allowing the algorithm to predict uncertainties and adapt to dynamic
conditions. Additionally, GAI stabilizes the critic network, addressing the
instability of multi-agent reinforcement learning approaches. Finally,
extensive simulations demonstrate that the proposed algorithm outperforms the
existing benchmark methods, thus highlighting the potentials in tackling
intricate, cross-domain issues in the considered scenarios.",http://arxiv.org/abs/2502.08119v1,Recommendation System,"usvs, algorithm, computational, uncertainties, gai"
HuDEx: Integrating Hallucination Detection and Explainability for Enhancing the Reliability of LLM responses,"Recent advances in large language models (LLMs) have shown promising
improvements, often surpassing existing methods across a wide range of
downstream tasks in natural language processing. However, these models still
face challenges, which may hinder their practical applicability. For example,
the phenomenon of hallucination is known to compromise the reliability of LLMs,
especially in fields that demand high factual precision. Current benchmarks
primarily focus on hallucination detection and factuality evaluation but do not
extend beyond identification. This paper proposes an explanation enhanced
hallucination-detection model, coined as HuDEx, aimed at enhancing the
reliability of LLM-generated responses by both detecting hallucinations and
providing detailed explanations. The proposed model provides a novel approach
to integrate detection with explanations, and enable both users and the LLM
itself to understand and reduce errors. Our measurement results demonstrate
that the proposed model surpasses larger LLMs, such as Llama3 70B and GPT-4, in
hallucination detection accuracy, while maintaining reliable explanations.
Furthermore, the proposed model performs well in both zero-shot and other test
environments, showcasing its adaptability across diverse benchmark datasets.
The proposed approach further enhances the hallucination detection research by
introducing a novel approach to integrating interpretability with hallucination
detection, which further enhances the performance and reliability of evaluating
hallucinations in language models.",http://arxiv.org/abs/2502.08109v1,Natural Language Processing,"hallucination, detection, model, proposed, language"
Generative AI and Empirical Software Engineering: A Paradigm Shift,"The widespread adoption of generative AI in software engineering marks a
paradigm shift, offering new opportunities to design and utilize software
engineering tools while influencing both developers and the artifacts they
create. Traditional empirical methods in software engineering, including
quantitative, qualitative, and mixed-method approaches, are well established.
However, this paradigm shift introduces novel data types and redefines many
concepts in the software engineering process. The roles of developers, users,
agents, and researchers increasingly overlap, blurring the distinctions between
these social and technical actors within the field.
  This paper examines how integrating AI into software engineering challenges
traditional research paradigms. It focuses on the research phenomena that we
investigate, the methods and theories that we employ, the data we analyze, and
the threats to validity that emerge in this new context. Through this
exploration, our goal is to understand how AI adoption disrupts established
software development practices that creates new opportunities for empirical
software engineering research.",http://arxiv.org/abs/2502.08108v1,Recommendation System,"software, engineering, ai, new, research"
PoGDiff: Product-of-Gaussians Diffusion Models for Imbalanced Text-to-Image Generation,"Diffusion models have made significant advancements in recent years. However,
their performance often deteriorates when trained or fine-tuned on imbalanced
datasets. This degradation is largely due to the disproportionate
representation of majority and minority data in image-text pairs. In this
paper, we propose a general fine-tuning approach, dubbed PoGDiff, to address
this challenge. Rather than directly minimizing the KL divergence between the
predicted and ground-truth distributions, PoGDiff replaces the ground-truth
distribution with a Product of Gaussians (PoG), which is constructed by
combining the original ground-truth targets with the predicted distribution
conditioned on a neighboring text embedding. Experiments on real-world datasets
demonstrate that our method effectively addresses the imbalance problem in
diffusion models, improving both generation accuracy and quality.",http://arxiv.org/abs/2502.08106v1,Reinforcement Learning,"ground, truth, diffusion, models, fine"
Out-of-Distribution Detection on Graphs: A Survey,"Graph machine learning has witnessed rapid growth, driving advancements
across diverse domains. However, the in-distribution assumption, where training
and testing data share the same distribution, often breaks in real-world
scenarios, leading to degraded model performance under distribution shifts.
This challenge has catalyzed interest in graph out-of-distribution (GOOD)
detection, which focuses on identifying graph data that deviates from the
distribution seen during training, thereby enhancing model robustness. In this
paper, we provide a rigorous definition of GOOD detection and systematically
categorize existing methods into four types: enhancement-based,
reconstruction-based, information propagation-based, and classification-based
approaches. We analyze the principles and mechanisms of each approach and
clarify the distinctions between GOOD detection and related fields, such as
graph anomaly detection, outlier detection, and GOOD generalization. Beyond
methodology, we discuss practical applications and theoretical foundations,
highlighting the unique challenges posed by graph data. Finally, we discuss the
primary challenges and propose future directions to advance this emerging
field. The repository of this survey is available at
https://github.com/ca1man-2022/Awesome-GOOD-Detection.",http://arxiv.org/abs/2502.08105v1,Recommendation System,"graph, distribution, detection, good, based"
Rethinking Tokenized Graph Transformers for Node Classification,"Node tokenized graph Transformers (GTs) have shown promising performance in
node classification. The generation of token sequences is the key module in
existing tokenized GTs which transforms the input graph into token sequences,
facilitating the node representation learning via Transformer. In this paper,
we observe that the generations of token sequences in existing GTs only focus
on the first-order neighbors on the constructed similarity graphs, which leads
to the limited usage of nodes to generate diverse token sequences, further
restricting the potential of tokenized GTs for node classification. To this
end, we propose a new method termed SwapGT. SwapGT first introduces a novel
token swapping operation based on the characteristics of token sequences that
fully leverages the semantic relevance of nodes to generate more informative
token sequences. Then, SwapGT leverages a Transformer-based backbone to learn
node representations from the generated token sequences. Moreover, SwapGT
develops a center alignment loss to constrain the representation learning from
multiple token sequences, further enhancing the model performance. Extensive
empirical results on various datasets showcase the superiority of SwapGT for
node classification.",http://arxiv.org/abs/2502.08101v1,Reinforcement Learning,"token, sequences, node, swapgt, gts"
Unsupervised categorization of similarity measures,"In general, objects can be distinguished on the basis of their features, such
as color or shape. In particular, it is assumed that similarity judgments about
such features can be processed independently in different metric spaces.
However, the unsupervised categorization mechanism of metric spaces
corresponding to object features remains unknown. Here, we show that the
artificial neural network system can autonomously categorize metric spaces
through representation learning to satisfy the algebraic independence between
neural networks, and project sensory information onto multiple high-dimensional
metric spaces to independently evaluate the differences and similarities
between features. Conventional methods often constrain the axes of the latent
space to be mutually independent or orthogonal. However, the independent axes
are not suitable for categorizing metric spaces. High-dimensional metric spaces
that are independent of each other are not uniquely determined by the mutually
independent axes, because any combination of independent axes can form mutually
independent spaces. In other words, the mutually independent axes cannot be
used to naturally categorize different feature spaces, such as color space and
shape space. Therefore, constraining the axes to be mutually independent makes
it difficult to categorize high-dimensional metric spaces. To overcome this
problem, we developed a method to constrain only the spaces to be mutually
independent and not the composed axes to be independent. Our theory provides
general conditions for the unsupervised categorization of independent metric
spaces, thus advancing the mathematical theory of functional differentiation of
neural networks.",http://arxiv.org/abs/2502.08098v1,Recommendation System,"spaces, independent, metric, axes, mutually"
ID-Cloak: Crafting Identity-Specific Cloaks Against Personalized Text-to-Image Generation,"Personalized text-to-image models allow users to generate images of new
concepts from several reference photos, thereby leading to critical concerns
regarding civil privacy. Although several anti-personalization techniques have
been developed, these methods typically assume that defenders can afford to
design a privacy cloak corresponding to each specific image. However, due to
extensive personal images shared online, image-specific methods are limited by
real-world practical applications. To address this issue, we are the first to
investigate the creation of identity-specific cloaks (ID-Cloak) that safeguard
all images belong to a specific identity. Specifically, we first model an
identity subspace that preserves personal commonalities and learns diverse
contexts to capture the image distribution to be protected. Then, we craft
identity-specific cloaks with the proposed novel objective that encourages the
cloak to guide the model away from its normal output within the subspace.
Extensive experiments show that the generated universal cloak can effectively
protect the images. We believe our method, along with the proposed
identity-specific cloak setting, marks a notable advance in realistic privacy
protection.",http://arxiv.org/abs/2502.08097v1,Recommendation System,"specific, cloak, identity, image, images"
GCoT: Chain-of-Thought Prompt Learning for Graphs,"Chain-of-thought (CoT) prompting has achieved remarkable success in natural
language processing (NLP). However, its vast potential remains largely
unexplored for graphs. This raises an interesting question: How can we design
CoT prompting for graphs to guide graph models to learn step by step? On one
hand, unlike natural languages, graphs are non-linear and characterized by
complex topological structures. On the other hand, many graphs lack textual
data, making it difficult to formulate language-based CoT prompting. In this
work, we propose the first CoT prompt learning framework for text-free graphs,
GCoT. Specifically, we decompose the adaptation process for each downstream
task into a series of inference steps, with each step consisting of
prompt-based inference, ``thought'' generation, and thought-conditioned prompt
learning. While the steps mimic CoT prompting in NLP, the exact mechanism
differs significantly. Specifically, at each step, an input graph, along with a
prompt, is first fed into a pre-trained graph encoder for prompt-based
inference. We then aggregate the hidden layers of the encoder to construct a
``thought'', which captures the working state of each node in the current step.
Conditioned on this thought, we learn a prompt specific to each node based on
the current state. These prompts are fed into the next inference step,
repeating the cycle. To evaluate and analyze the effectiveness of GCoT, we
conduct comprehensive experiments on eight public datasets, which demonstrate
the advantage of our approach.",http://arxiv.org/abs/2502.08092v1,Natural Language Processing,"step, prompt, thought, cot, graphs"
Mixture of Decoupled Message Passing Experts with Entropy Constraint for General Node Classification,"The varying degrees of homophily and heterophily in real-world graphs
persistently constrain the universality of graph neural networks (GNNs) for
node classification. Adopting a data-centric perspective, this work reveals an
inherent preference of different graphs towards distinct message encoding
schemes: homophilous graphs favor local propagation, while heterophilous graphs
exhibit preference for flexible combinations of propagation and transformation.
To address this, we propose GNNMoE, a universal node classification framework
based on the Mixture-of-Experts (MoE) mechanism. The framework first constructs
diverse message-passing experts through recombination of fine-grained encoding
operators, then designs soft and hard gating layers to allocate the most
suitable expert networks for each node's representation learning, thereby
enhancing both model expressiveness and adaptability to diverse graphs.
Furthermore, considering that soft gating might introduce encoding noise in
homophilous scenarios, we introduce an entropy constraint to guide sharpening
of soft gates, achieving organic integration of weighted combination and Top-K
selection. Extensive experiments demonstrate that GNNMoE significantly
outperforms mainstream GNNs, heterophilous GNNs, and graph transformers in both
node classification performance and universality across diverse graph datasets.",http://arxiv.org/abs/2502.08083v1,Recommendation System,"graphs, node, graph, gnns, classification"
MAA: Meticulous Adversarial Attack against Vision-Language Pre-trained Models,"Current adversarial attacks for evaluating the robustness of vision-language
pre-trained (VLP) models in multi-modal tasks suffer from limited
transferability, where attacks crafted for a specific model often struggle to
generalize effectively across different models, limiting their utility in
assessing robustness more broadly. This is mainly attributed to the
over-reliance on model-specific features and regions, particularly in the image
modality. In this paper, we propose an elegant yet highly effective method
termed Meticulous Adversarial Attack (MAA) to fully exploit model-independent
characteristics and vulnerabilities of individual samples, achieving enhanced
generalizability and reduced model dependence. MAA emphasizes fine-grained
optimization of adversarial images by developing a novel resizing and sliding
crop (RScrop) technique, incorporating a multi-granularity similarity
disruption (MGSD) strategy. Extensive experiments across diverse VLP models,
multiple benchmark datasets, and a variety of downstream tasks demonstrate that
MAA significantly enhances the effectiveness and transferability of adversarial
attacks. A large cohort of performance studies is conducted to generate
insights into the effectiveness of various model configurations, guiding future
advancements in this domain.",http://arxiv.org/abs/2502.08079v1,Recommendation System,"model, adversarial, attacks, models, maa"
Cascading Bandits Robust to Adversarial Corruptions,"Online learning to rank sequentially recommends a small list of items to
users from a large candidate set and receives the users' click feedback. In
many real-world scenarios, users browse the recommended list in order and click
the first attractive item without checking the rest. Such behaviors are usually
formulated as the cascade model. Many recent works study algorithms for
cascading bandits, an online learning to rank framework in the cascade model.
However, the performance of existing methods may drop significantly if part of
the user feedback is adversarially corrupted (e.g., click fraud). In this work,
we study how to resist adversarial corruptions in cascading bandits. We first
formulate the ``\textit{Cascading Bandits with Adversarial Corruptions}"" (CBAC)
problem, which assumes that there is an adaptive adversary that may manipulate
the user feedback. Then we propose two robust algorithms for this problem,
which assume the corruption level is known and agnostic, respectively. We show
that both algorithms can achieve logarithmic regret when the algorithm is not
under attack, and the regret increases linearly with the corruption level. The
experimental results also verify the robustness of our methods.",http://arxiv.org/abs/2502.08077v1,Recommendation System,"users, click, feedback, algorithms, bandits"
Knowledge Swapping via Learning and Unlearning,"We introduce \textbf{Knowledge Swapping}, a novel task designed to
selectively regulate knowledge of a pretrained model by enabling the forgetting
of user\-specified information, retaining essential knowledge, and acquiring
new knowledge simultaneously. By delving into the analysis of knock-on feature
hierarchy, we find that incremental learning typically progresses from
low\-level representations to higher\-level semantics, whereas forgetting tends
to occur in the opposite direction\-starting from high-level semantics and
moving down to low-level features. Building upon this, we propose to benchmark
the knowledge swapping task with the strategy of \textit{Learning Before
Forgetting}. Comprehensive experiments on various tasks like image
classification, object detection, and semantic segmentation validate the
effectiveness of the proposed strategy. The source code is available at
\href{https://github.com/xingmingyu123456/KnowledgeSwapping}{https://github.com/xingmingyu123456/KnowledgeSwapping}.",http://arxiv.org/abs/2502.08075v1,Recommendation System,"knowledge, forgetting, swapping, task, semantics"
Multi-Agent Performative Prediction Beyond the Insensitivity Assumption: A Case Study for Mortgage Competition,"Performative prediction models account for feedback loops in decision-making
processes where predictions influence future data distributions. While existing
work largely assumes insensitivity of data distributions to small strategy
changes, this assumption usually fails in real-world competitive (i.e.
multi-agent) settings. For example, in Bertrand-type competitions, a small
reduction in one firm's price can lead that firm to capture the entire demand,
while all others sharply lose all of their customers.
  We study a representative setting of multi-agent performative prediction in
which insensitivity assumptions do not hold, and investigate the convergence of
natural dynamics. To do so, we focus on a specific game that we call the ''Bank
Game'', where two lenders compete over interest rates and credit score
thresholds. Consumers act similarly as to in a Bertrand Competition, with each
consumer selecting the firm with the lowest interest rate that they are
eligible for based on the firms' credit thresholds. Our analysis characterizes
the equilibria of this game and demonstrates that when both firms use a common
and natural no-regret learning dynamic -- exponential weights -- with proper
initialization, the dynamics always converge to stable outcomes despite the
general-sum structure. Notably, our setting admits multiple stable equilibria,
with convergence dependent on initial conditions. We also provide theoretical
convergence results in the stochastic case when the utility matrix is not fully
known, but each learner can observe sufficiently many samples of consumers at
each time step to estimate it, showing robustness to slight mis-specifications.
Finally, we provide experimental results that validate our theoretical
findings.",http://arxiv.org/abs/2502.08063v1,Recommendation System,"firm, convergence, game, performative, prediction"
On Mechanistic Circuits for Extractive Question-Answering,"Large language models are increasingly used to process documents and
facilitate question-answering on them. In our paper, we extract mechanistic
circuits for this real-world language modeling task: context-augmented language
modeling for extractive question-answering (QA) tasks and understand the
potential benefits of circuits towards downstream applications such as data
attribution to context information. We extract circuits as a function of
internal model components (e.g., attention heads, MLPs) using causal mediation
analysis techniques. Leveraging the extracted circuits, we first understand the
interplay between the model's usage of parametric memory and retrieved context
towards a better mechanistic understanding of context-augmented language
models. We then identify a small set of attention heads in our circuit which
performs reliable data attribution by default, thereby obtaining attribution
for free in just the model's forward pass. Using this insight, we then
introduce ATTNATTRIB, a fast data attribution algorithm which obtains
state-of-the-art attribution results across various extractive QA benchmarks.
Finally, we show the possibility to steer the language model towards answering
from the context, instead of the parametric memory by using the attribution
from ATTNATTRIB as an additional signal during the forward pass. Beyond
mechanistic understanding, our paper provides tangible applications of circuits
in the form of reliable data attribution and model steering.",http://arxiv.org/abs/2502.08059v1,Recommendation System,"attribution, language, circuits, context, model"
General Coded Computing: Adversarial Settings,"Conventional coded computing frameworks are predominantly tailored for
structured computations, such as matrix multiplication and polynomial
evaluation. Such tasks allow the reuse of tools and techniques from algebraic
coding theory to improve the reliability of distributed systems in the presence
of stragglers and adversarial servers.
  This paper lays the foundation for general coded computing, which extends the
applicability of coded computing to handle a wide class of computations. In
addition, it particularly addresses the challenging problem of managing
adversarial servers. We demonstrate that, in the proposed scheme, for a system
with $N$ servers, where $\mathcal{O}(N^a)$, $a \in [0,1)$, are adversarial, the
supremum of the average approximation error over all adversarial strategies
decays at a rate of $N^{\frac{6}{5}(a-1)}$, under minimal assumptions on the
computing tasks. Furthermore, we show that within a general framework, the
proposed scheme achieves optimal adversarial robustness, in terms of maximum
number of adversarial servers it can tolerate. This marks a significant step
toward practical and reliable general coded computing. Implementation results
further validate the effectiveness of the proposed method in handling various
computations, including inference in deep neural networks.",http://arxiv.org/abs/2502.08058v1,Recommendation System,"adversarial, computing, coded, servers, computations"
Cognify: Supercharging Gen-AI Workflows With Hierarchical Autotuning,"Today's gen-AI workflows that involve multiple ML model calls, tool/API
calls, data retrieval, or generic code execution are often tuned manually in an
ad-hoc way that is both time-consuming and error-prone. In this paper, we
propose a systematic approach for automatically tuning gen-AI workflows. Our
key insight is that gen-AI workflows can benefit from structure, operator, and
prompt changes, but unique properties of gen-AI workflows require new
optimization techniques. We propose AdaSeek, an adaptive hierarchical search
algorithm for autotuning gen-AI workflows. AdaSeek organizes workflow tuning
methods into different layers based on the user-specified total search budget
and distributes the budget across different layers based on the complexity of
each layer. During its hierarchical search, AdaSeek redistributes the search
budget from less useful to more promising tuning configurations based on
workflow-level evaluation results. We implement AdaSeek in a workflow
autotuning framework called Cognify and evaluate Cognify using six types of
workflows such as RAG-based QA and text-to-SQL transformation. Overall, Cognify
improves these workflows' generation quality by up to 2.8x, reduces execution
monetary cost by up to 10x, and reduces end-to-end latency by 2.7x.",http://arxiv.org/abs/2502.08056v1,Recommendation System,"workflows, gen, ai, adaseek, search"
SLVR: Securely Leveraging Client Validation for Robust Federated Learning,"Federated Learning (FL) enables collaborative model training while keeping
client data private. However, exposing individual client updates makes FL
vulnerable to reconstruction attacks. Secure aggregation mitigates such privacy
risks but prevents the server from verifying the validity of each client
update, creating a privacy-robustness tradeoff. Recent efforts attempt to
address this tradeoff by enforcing checks on client updates using
zero-knowledge proofs, but they support limited predicates and often depend on
public validation data. We propose SLVR, a general framework that securely
leverages clients' private data through secure multi-party computation. By
utilizing clients' data, SLVR not only eliminates the need for public
validation data, but also enables a wider range of checks for robustness,
including cross-client accuracy validation. It also adapts naturally to
distribution shifts in client data as it can securely refresh its validation
data up-to-date. Our empirical evaluations show that SLVR improves robustness
against model poisoning attacks, particularly outperforming existing methods by
up to 50% under adaptive attacks. Additionally, SLVR demonstrates effective
adaptability and stable convergence under various distribution shift scenarios.",http://arxiv.org/abs/2502.08055v1,Reinforcement Learning,"data, client, validation, slvr, attacks"
COMBO-Grasp: Learning Constraint-Based Manipulation for Bimanual Occluded Grasping,"This paper addresses the challenge of occluded robot grasping, i.e. grasping
in situations where the desired grasp poses are kinematically infeasible due to
environmental constraints such as surface collisions. Traditional robot
manipulation approaches struggle with the complexity of non-prehensile or
bimanual strategies commonly used by humans in these circumstances.
State-of-the-art reinforcement learning (RL) methods are unsuitable due to the
inherent complexity of the task. In contrast, learning from demonstration
requires collecting a significant number of expert demonstrations, which is
often infeasible. Instead, inspired by human bimanual manipulation strategies,
where two hands coordinate to stabilise and reorient objects, we focus on a
bimanual robotic setup to tackle this challenge. In particular, we introduce
Constraint-based Manipulation for Bimanual Occluded Grasping (COMBO-Grasp), a
learning-based approach which leverages two coordinated policies: a constraint
policy trained using self-supervised datasets to generate stabilising poses and
a grasping policy trained using RL that reorients and grasps the target object.
A key contribution lies in value function-guided policy coordination.
Specifically, during RL training for the grasping policy, the constraint
policy's output is refined through gradients from a jointly trained value
function, improving bimanual coordination and task performance. Lastly,
COMBO-Grasp employs teacher-student policy distillation to effectively deploy
point cloud-based policies in real-world environments. Empirical evaluations
demonstrate that COMBO-Grasp significantly improves task success rates compared
to competitive baseline approaches, with successful generalisation to unseen
objects in both simulated and real-world environments.",http://arxiv.org/abs/2502.08054v1,Reinforcement Learning,"policy, grasping, bimanual, grasp, manipulation"
WorldGUI: Dynamic Testing for Comprehensive Desktop GUI Automation,"Current GUI agents have achieved outstanding performance in GUI element
grounding. However, planning remains highly challenging, especially due to
sensitivity to the initial state of the environment. Specifically, slight
differences in the initial state-such as the target software not being open or
the interface not being in its default state-often lead to planning errors.
This issue is widespread in real user scenarios, but existing benchmarks fail
to evaluate it. In this paper, we present WorldGUI, a novel GUI benchmark that
designs GUI tasks with various initial states to simulate real computer-user
interactions. The benchmark spans a wide range of tasks across 10 popular
software applications, including PowerPoint, VSCode, and Adobe Acrobat. In
addition, to address the challenges of dynamic GUI automation tasks, we propose
GUI-Thinker, a holistic framework, leveraging a critique mechanism, that
effectively manages the unpredictability and complexity of GUI interactions.
Experimental results demonstrate that GUI-Thinker significantly outperforms
Claude-3.5 (Computer Use) by 14.9% in success rate on WorldGUI tasks. This
improvement underscores the effectiveness of our critical-thinking-based
framework in enhancing GUI automation.",http://arxiv.org/abs/2502.08047v1,Reinforcement Learning,"gui, tasks, initial, state, planning"
Break the Checkbox: Challenging Closed-Style Evaluations of Cultural Alignment in LLMs,"A large number of studies rely on closed-style multiple-choice surveys to
evaluate cultural alignment in Large Language Models (LLMs). In this work, we
challenge this constrained evaluation paradigm and explore more realistic,
unconstrained approaches. Using the World Values Survey (WVS) and Hofstede
Cultural Dimensions as case studies, we demonstrate that LLMs exhibit stronger
cultural alignment in less constrained settings, where responses are not
forced. Additionally, we show that even minor changes, such as reordering
survey choices, lead to inconsistent outputs, exposing the limitations of
closed-style evaluations. Our findings advocate for more robust and flexible
evaluation frameworks that focus on specific cultural proxies, encouraging more
nuanced and accurate assessments of cultural alignment in LLMs.",http://arxiv.org/abs/2502.08045v1,Recommendation System,"cultural, alignment, llms, large, studies"
"The Art of Misclassification: Too Many Classes, Not Enough Points","Classification is a ubiquitous and fundamental problem in artificial
intelligence and machine learning, with extensive efforts dedicated to
developing more powerful classifiers and larger datasets. However, the
classification task is ultimately constrained by the intrinsic properties of
datasets, independently of computational power or model complexity. In this
work, we introduce a formal entropy-based measure of classificability, which
quantifies the inherent difficulty of a classification problem by assessing the
uncertainty in class assignments given feature representations. This measure
captures the degree of class overlap and aligns with human intuition, serving
as an upper bound on classification performance for classification problems.
Our results establish a theoretical limit beyond which no classifier can
improve the classification accuracy, regardless of the architecture or amount
of data, in a given problem. Our approach provides a principled framework for
understanding when classification is inherently fallible and fundamentally
ambiguous.",http://arxiv.org/abs/2502.08041v1,Recommendation System,"classification, problem, datasets, measure, class"
End-to-End Predictive Planner for Autonomous Driving with Consistency Models,"Trajectory prediction and planning are fundamental components for autonomous
vehicles to navigate safely and efficiently in dynamic environments.
Traditionally, these components have often been treated as separate modules,
limiting the ability to perform interactive planning and leading to
computational inefficiency in multi-agent scenarios. In this paper, we present
a novel unified and data-driven framework that integrates prediction and
planning with a single consistency model. Trained on real-world human driving
datasets, our consistency model generates samples from high-dimensional,
multimodal joint trajectory distributions of the ego and multiple surrounding
agents, enabling end-to-end predictive planning. It effectively produces
interactive behaviors, such as proactive nudging and yielding to ensure both
safe and efficient interactions with other road users. To incorporate
additional planning constraints on the ego vehicle, we propose an alternating
direction method for multi-objective guidance in online guided sampling.
Compared to diffusion models, our consistency model achieves better performance
with fewer sampling steps, making it more suitable for real-time deployment.
Experimental results on Waymo Open Motion Dataset (WOMD) demonstrate our
method's superiority in trajectory quality, constraint satisfaction, and
interactive behavior compared to various existing approaches.",http://arxiv.org/abs/2502.08033v1,Recommendation System,"planning, trajectory, interactive, consistency, model"
From Brainwaves to Brain Scans: A Robust Neural Network for EEG-to-fMRI Synthesis,"While functional magnetic resonance imaging (fMRI) offers rich spatial
resolution, it is limited by high operational costs and significant
infrastructural demands. In contrast, electroencephalography (EEG) provides
millisecond-level precision in capturing electrical activity but lacks the
spatial resolution necessary for precise neural localization. To bridge these
gaps, we introduce E2fNet, a simple yet effective deep learning model for
synthesizing fMRI images from low-cost EEG data. E2fNet is specifically
designed to capture and translate meaningful features from EEG across electrode
channels into accurate fMRI representations. Extensive evaluations across three
datasets demonstrate that E2fNet consistently outperforms existing methods,
achieving state-of-the-art results in terms of the structural similarity index
measure (SSIM). Our findings suggest that E2fNet is a promising, cost-effective
solution for enhancing neuroimaging capabilities. The code is available at
https://github.com/kgr20/E2fNet.",http://arxiv.org/abs/2502.08025v1,Reinforcement Learning,"fmri, eeg, spatial, resolution, effective"
Initialization Matters: Unraveling the Impact of Pre-Training on Federated Learning,"Initializing with pre-trained models when learning on downstream tasks is
becoming standard practice in machine learning. Several recent works explore
the benefits of pre-trained initialization in a federated learning (FL)
setting, where the downstream training is performed at the edge clients with
heterogeneous data distribution. These works show that starting from a
pre-trained model can substantially reduce the adverse impact of data
heterogeneity on the test performance of a model trained in a federated
setting, with no changes to the standard FedAvg training algorithm. In this
work, we provide a deeper theoretical understanding of this phenomenon. To do
so, we study the class of two-layer convolutional neural networks (CNNs) and
provide bounds on the training error convergence and test error of such a
network trained with FedAvg. We introduce the notion of aligned and misaligned
filters at initialization and show that the data heterogeneity only affects
learning on misaligned filters. Starting with a pre-trained model typically
results in fewer misaligned filters at initialization, thus producing a lower
test error even when the model is trained in a federated setting with data
heterogeneity. Experiments in synthetic settings and practical FL training on
CNNs verify our theoretical findings.",http://arxiv.org/abs/2502.08024v1,Recommendation System,"trained, pre, learning, training, data"
Model Selection for Off-policy Evaluation: New Algorithms and Experimental Protocol,"Holdout validation and hyperparameter tuning from data is a long-standing
problem in offline reinforcement learning (RL). A standard framework is to use
off-policy evaluation (OPE) methods to evaluate and select the policies, but
OPE either incurs exponential variance (e.g., importance sampling) or has
hyperparameters on their own (e.g., FQE and model-based). In this work we focus
on hyperparameter tuning for OPE itself, which is even more under-investigated.
Concretely, we select among candidate value functions (""model-free"") or
dynamics (""model-based"") to best assess the performance of a target policy. Our
contributions are two fold. We develop: (1) new model-free and model-based
selectors with theoretical guarantees, and (2) a new experimental protocol for
empirically evaluating them. Compared to the model-free protocol in prior
works, our new protocol allows for more stable generation of candidate value
functions, better control of misspecification, and evaluation of model-free and
model-based methods alike. We exemplify the protocol on a Gym environment, and
find that our new model-free selector, LSTD-Tournament, demonstrates promising
empirical performance.",http://arxiv.org/abs/2502.08021v1,Reinforcement Learning,"model, free, based, new, protocol"
"Speculate, then Collaborate: Fusing Knowledge of Language Models during Decoding","Large Language Models (LLMs) often excel in specific domains but fall short
in others due to the limitations of their training. Thus, enabling LLMs to
solve problems collaboratively by integrating their complementary knowledge
promises to improve their performance across domains. To realize this
potential, we introduce a novel Collaborative Speculative Decoding (CoSD)
algorithm that enables efficient LLM knowledge fusion at test time without
requiring additional model training. CoSD employs a draft model to generate
initial sequences and an easy-to-learn rule or decision tree to decide when to
invoke an assistant model to improve these drafts. CoSD not only enhances
knowledge fusion but also improves inference efficiency, is transferable across
domains and models, and offers greater explainability. Experimental results
demonstrate that CoSD improves accuracy by up to 10\% across benchmarks
compared to existing methods, providing a scalable and effective solution for
LLM-based applications",http://arxiv.org/abs/2502.08020v1,Recommendation System,"cosd, domains, knowledge, model, models"
Training-Free Safe Denoisers for Safe Use of Diffusion Models,"There is growing concern over the safety of powerful diffusion models (DMs),
as they are often misused to produce inappropriate, not-safe-for-work (NSFW)
content or generate copyrighted material or data of individuals who wish to be
forgotten. Many existing methods tackle these issues by heavily relying on
text-based negative prompts or extensively retraining DMs to eliminate certain
features or samples. In this paper, we take a radically different approach,
directly modifying the sampling trajectory by leveraging a negation set (e.g.,
unsafe images, copyrighted data, or datapoints needed to be excluded) to avoid
specific regions of data distribution, without needing to retrain or fine-tune
DMs. We formally derive the relationship between the expected denoised samples
that are safe and those that are not safe, leading to our $\textit{safe}$
denoiser which ensures its final samples are away from the area to be negated.
Inspired by the derivation, we develop a practical algorithm that successfully
produces high-quality samples while avoiding negation areas of the data
distribution in text-conditional, class-conditional, and unconditional image
generation scenarios. These results hint at the great potential of our
training-free safe denoiser for using DMs more safely.",http://arxiv.org/abs/2502.08011v1,Recommendation System,"dms, safe, data, samples, copyrighted"
An Interactive Framework for Implementing Privacy-Preserving Federated Learning: Experiments on Large Language Models,"Federated learning (FL) enhances privacy by keeping user data on local
devices. However, emerging attacks have demonstrated that the updates shared by
users during training can reveal significant information about their data. This
has greatly thwart the adoption of FL methods for training robust AI models in
sensitive applications. Differential Privacy (DP) is considered the gold
standard for safeguarding user data. However, DP guarantees are highly
conservative, providing worst-case privacy guarantees. This can result in
overestimating privacy needs, which may compromise the model's accuracy.
Additionally, interpretations of these privacy guarantees have proven to be
challenging in different contexts. This is further exacerbated when other
factors, such as the number of training iterations, data distribution, and
specific application requirements, can add further complexity to this problem.
In this work, we proposed a framework that integrates a human entity as a
privacy practitioner to determine an optimal trade-off between the model's
privacy and utility. Our framework is the first to address the variable memory
requirement of existing DP methods in FL settings, where resource-limited
devices (e.g., cell phones) can participate. To support such settings, we adopt
a recent DP method with fixed memory usage to ensure scalable private FL. We
evaluated our proposed framework by fine-tuning a BERT-based LLM model using
the GLUE dataset (a common approach in literature), leveraging the new
accountant, and employing diverse data partitioning strategies to mimic
real-world conditions. As a result, we achieved stable memory usage, with an
average accuracy reduction of 1.33% for $\epsilon = 10$ and 1.9% for $\epsilon
= 6$, when compared to the state-of-the-art DP accountant which does not
support fixed memory usage.",http://arxiv.org/abs/2502.08008v1,Recommendation System,"privacy, data, dp, fl, memory"
The Role of Randomness in Stability,"Stability is a central property in learning and statistics promising the
output of an algorithm $A$ does not change substantially when applied to
similar datasets $S$ and $S'$. It is an elementary fact that any sufficiently
stable algorithm (e.g.\ one returning the same result with high probability,
satisfying privacy guarantees, etc.) must be randomized. This raises a natural
question: can we quantify how much randomness is needed for algorithmic
stability?
  We study the randomness complexity of two influential notions of stability in
learning: replicability, which promises $A$ usually outputs the same result
when run over samples from the same distribution (and shared random coins), and
differential privacy, which promises the output distribution of $A$ remains
similar under neighboring datasets. The randomness complexity of these notions
was studied recently in (Dixon et al. ICML 2024) and (Cannone et al. ITCS 2024)
for basic $d$-dimensional tasks (e.g. estimating the bias of $d$ coins), but
little is known about the measures more generally or in complex settings like
classification.
  Toward this end, we prove a `weak-to-strong' boosting theorem for stability:
the randomness complexity of a task $M$ (either under replicability or DP) is
tightly controlled by the best replication probability of any deterministic
algorithm solving the task, a weak measure called `global stability' that is
universally capped at $\frac{1}{2}$ (Chase et al. FOCS 2023). Using this, we
characterize the randomness complexity of PAC Learning: a class has bounded
randomness complexity iff it has finite Littlestone dimension, and moreover
scales at worst logarithmically in the excess error of the learner. This
resolves a question of (Chase et al. STOC 2024) who asked for such a
characterization in the equivalent language of (error-dependent)
`list-replicability'.",http://arxiv.org/abs/2502.08007v1,Recommendation System,"randomness, stability, complexity, et, al"
Greed is Good: Guided Generation from a Greedy Perspective,"Training-free guided generation is a widely used and powerful technique that
allows the end user to exert further control over the generative process of
diffusion models. In this work, we explore the guided generation from the
perspective of optimizing the solution trajectory of a neural differential
equation in a greedy manner. We present such a strategy as a unifying view on
training-free guidance by showing that the greedy strategy is a first-order
discretization of end-to-end optimization techniques. We show that a greedy
guidance strategy makes good decisions and compare it to a guidance strategy
using the ideal gradients found via the continuous adjoint equations. We then
show how other popular training-free guidance strategies can be viewed in a
unified manner from this perspective.",http://arxiv.org/abs/2502.08006v1,Recommendation System,"strategy, guidance, training, free, end"
Towards Training One-Step Diffusion Models Without Distillation,"Recent advances in one-step generative models typically follow a two-stage
process: first training a teacher diffusion model and then distilling it into a
one-step student model. This distillation process traditionally relies on both
the teacher model's score function to compute the distillation loss and its
weights for student initialization. In this paper, we explore whether one-step
generative models can be trained directly without this distillation process.
First, we show that the teacher's score function is not essential and propose a
family of distillation methods that achieve competitive results without relying
on score estimation. Next, we demonstrate that initialization from teacher
weights is indispensable in successful training. Surprisingly, we find that
this benefit is not due to improved ``input-output"" mapping but rather the
learned feature representations, which dominate distillation quality. Our
findings provide a better understanding of the role of initialization in
one-step model training and its impact on distillation quality.",http://arxiv.org/abs/2502.08005v1,Recommendation System,"distillation, step, teacher, model, process"
Optimizing Likelihoods via Mutual Information: Bridging Simulation-Based Inference and Bayesian Optimal Experimental Design,"Simulation-based inference (SBI) is a method to perform inference on a
variety of complex scientific models with challenging inference (inverse)
problems. Bayesian Optimal Experimental Design (BOED) aims to efficiently use
experimental resources to make better inferences. Various stochastic
gradient-based BOED methods have been proposed as an alternative to Bayesian
optimization and other experimental design heuristics to maximize information
gain from an experiment. We demonstrate a link via mutual information bounds
between SBI and stochastic gradient-based variational inference methods that
permits BOED to be used in SBI applications as SBI-BOED. This link allows
simultaneous optimization of experimental designs and optimization of amortized
inference functions. We evaluate the pitfalls of naive design optimization
using this method in a standard SBI task and demonstrate the utility of a
well-chosen design distribution in BOED. We compare this approach on SBI-based
models in real-world simulators in epidemiology and biology, showing notable
improvements in inference.",http://arxiv.org/abs/2502.08004v1,Recommendation System,"inference, sbi, boed, based, experimental"
Heterogeneous Multi-agent Multi-armed Bandits on Stochastic Block Models,"We study a novel heterogeneous multi-agent multi-armed bandit problem with a
cluster structure induced by stochastic block models, influencing not only
graph topology, but also reward heterogeneity. Specifically, agents are
distributed on random graphs based on stochastic block models - a generalized
Erdos-Renyi model with heterogeneous edge probabilities: agents are grouped
into clusters (known or unknown); edge probabilities for agents within the same
cluster differ from those across clusters. In addition, the cluster structure
in stochastic block model also determines our heterogeneous rewards. Rewards
distributions of the same arm vary across agents in different clusters but
remain consistent within a cluster, unifying homogeneous and heterogeneous
settings and varying degree of heterogeneity, and rewards are independent
samples from these distributions. The objective is to minimize system-wide
regret across all agents. To address this, we propose a novel algorithm
applicable to both known and unknown cluster settings. The algorithm combines
an averaging-based consensus approach with a newly introduced information
aggregation and weighting technique, resulting in a UCB-type strategy. It
accounts for graph randomness, leverages both intra-cluster (homogeneous) and
inter-cluster (heterogeneous) information from rewards and graphs, and
incorporates cluster detection for unknown cluster settings. We derive optimal
instance-dependent regret upper bounds of order $\log{T}$ under sub-Gaussian
rewards. Importantly, our regret bounds capture the degree of heterogeneity in
the system (an additional layer of complexity), exhibit smaller constants,
scale better for large systems, and impose significantly relaxed assumptions on
edge probabilities. In contrast, prior works have not accounted for this
refined problem complexity, rely on more stringent assumptions, and exhibit
limited scalability.",http://arxiv.org/abs/2502.08003v1,Reinforcement Learning,"cluster, heterogeneous, agents, rewards, stochastic"
Unveiling Client Privacy Leakage from Public Dataset Usage in Federated Distillation,"Federated Distillation (FD) has emerged as a popular federated training
framework, enabling clients to collaboratively train models without sharing
private data. Public Dataset-Assisted Federated Distillation (PDA-FD), which
leverages public datasets for knowledge sharing, has become widely adopted.
Although PDA-FD enhances privacy compared to traditional Federated Learning, we
demonstrate that the use of public datasets still poses significant privacy
risks to clients' private training data. This paper presents the first
comprehensive privacy analysis of PDA-FD in presence of an honest-but-curious
server. We show that the server can exploit clients' inference results on
public datasets to extract two critical types of private information: label
distributions and membership information of the private training dataset. To
quantify these vulnerabilities, we introduce two novel attacks specifically
designed for the PDA-FD setting: a label distribution inference attack and
innovative membership inference methods based on Likelihood Ratio Attack
(LiRA). Through extensive evaluation of three representative PDA-FD frameworks
(FedMD, DS-FL, and Cronus), our attacks achieve state-of-the-art performance,
with label distribution attacks reaching minimal KL-divergence and membership
inference attacks maintaining high True Positive Rates under low False Positive
Rate constraints. Our findings reveal significant privacy risks in current
PDA-FD frameworks and emphasize the need for more robust privacy protection
mechanisms in collaborative learning systems.",http://arxiv.org/abs/2502.08001v1,Recommendation System,"fd, pda, privacy, federated, private"
Adaptive kernel predictors from feature-learning infinite limits of neural networks,"Previous influential work showed that infinite width limits of neural
networks in the lazy training regime are described by kernel machines. Here, we
show that neural networks trained in the rich, feature learning infinite-width
regime in two different settings are also described by kernel machines, but
with data-dependent kernels. For both cases, we provide explicit expressions
for the kernel predictors and prescriptions to numerically calculate them. To
derive the first predictor, we study the large-width limit of feature-learning
Bayesian networks, showing how feature learning leads to task-relevant
adaptation of layer kernels and preactivation densities. The saddle point
equations governing this limit result in a min-max optimization problem that
defines the kernel predictor. To derive the second predictor, we study gradient
flow training of randomly initialized networks trained with weight decay in the
infinite-width limit using dynamical mean field theory (DMFT). The fixed point
equations of the arising DMFT defines the task-adapted internal representations
and the kernel predictor. We compare our kernel predictors to kernels derived
from lazy regime and demonstrate that our adaptive kernels achieve lower test
loss on benchmark datasets.",http://arxiv.org/abs/2502.07998v1,Recommendation System,"kernel, width, networks, kernels, predictor"
What is a Sketch-and-Precondition Derivation for Low-Rank Approximation? Inverse Power Error or Inverse Power Estimation?,"Randomized sketching accelerates large-scale numerical linear algebra by
reducing computa- tional complexity. While the traditional sketch-and-solve
approach reduces the problem size di- rectly through sketching, the
sketch-and-precondition method leverages sketching to construct a computational
friendly preconditioner. This preconditioner improves the convergence speed of
iterative solvers applied to the original problem, maintaining accuracy in the
full space. Further- more, the convergence rate of the solver improves at least
linearly with the sketch size. Despite its potential, developing a
sketch-and-precondition framework for randomized algorithms in low- rank matrix
approximation remains an open challenge. We introduce the Error-Powered
Sketched Inverse Iteration (EPSI) Method via run sketched Newton iteration for
the Lagrange form as a sketch-and-precondition variant for randomized low-rank
approximation. Our method achieves theoretical guarantees, including a
convergence rate that improves at least linearly with the sketch size.",http://arxiv.org/abs/2502.07993v1,Recommendation System,"sketch, randomized, sketching, size, precondition"
Learning Effective Dynamics across Spatio-Temporal Scales of Complex Flows,"Modeling and simulation of complex fluid flows with dynamics that span
multiple spatio-temporal scales is a fundamental challenge in many scientific
and engineering domains. Full-scale resolving simulations for systems such as
highly turbulent flows are not feasible in the foreseeable future, and
reduced-order models must capture dynamics that involve interactions across
scales. In the present work, we propose a novel framework, Graph-based Learning
of Effective Dynamics (Graph-LED), that leverages graph neural networks (GNNs),
as well as an attention-based autoregressive model, to extract the effective
dynamics from a small amount of simulation data. GNNs represent flow fields on
unstructured meshes as graphs and effectively handle complex geometries and
non-uniform grids. The proposed method combines a GNN based, dimensionality
reduction for variable-size unstructured meshes with an autoregressive temporal
attention model that can learn temporal dependencies automatically. We
evaluated the proposed approach on a suite of fluid dynamics problems,
including flow past a cylinder and flow over a backward-facing step over a
range of Reynolds numbers. The results demonstrate robust and effective
forecasting of spatio-temporal physics; in the case of the flow past a
cylinder, both small-scale effects that occur close to the cylinder as well as
its wake are accurately captured.",http://arxiv.org/abs/2502.07990v1,Recommendation System,"dynamics, temporal, flow, graph, based"
Universal Adversarial Attack on Aligned Multimodal LLMs,"We propose a universal adversarial attack on multimodal Large Language Models
(LLMs) that leverages a single optimized image to override alignment safeguards
across diverse queries and even multiple models. By backpropagating through the
vision encoder and language head, we craft a synthetic image that forces the
model to respond with a targeted phrase (e.g., ''Sure, here it is'') or
otherwise unsafe content-even for harmful prompts. In experiments on the
SafeBench benchmark, our method achieves significantly higher attack success
rates than existing baselines, including text-only universal prompts (e.g., up
to 93% on certain models). We further demonstrate cross-model transferability
by training on several multimodal LLMs simultaneously and testing on unseen
architectures. Additionally, a multi-answer variant of our approach produces
more natural-sounding (yet still malicious) responses. These findings
underscore critical vulnerabilities in current multimodal alignment and call
for more robust adversarial defenses. We will release code and datasets under
the Apache-2.0 license. Warning: some content generated by Multimodal LLMs in
this paper may be offensive to some readers.",http://arxiv.org/abs/2502.07987v1,Reinforcement Learning,"multimodal, models, llms, universal, adversarial"
MetaSC: Test-Time Safety Specification Optimization for Language Models,"We propose a novel dynamic safety framework that optimizes language model
(LM) safety reasoning at inference time without modifying model weights.
Building on recent advances in self-critique methods, our approach leverages a
meta-critique mechanism that iteratively updates safety prompts-termed
specifications-to drive the critique and revision process adaptively. This
test-time optimization not only improves performance against adversarial
jailbreak requests but also in diverse general safety-related tasks, such as
avoiding moral harm or pursuing honest responses. Our empirical evaluations
across several language models demonstrate that dynamically optimized safety
prompts yield significantly higher safety scores compared to fixed system
prompts and static self-critique defenses. Code to be released at
https://github.com/vicgalle/meta-self-critique.git .",http://arxiv.org/abs/2502.07985v1,Recommendation System,"safety, critique, prompts, language, model"
Deep Semantic Graph Learning via LLM based Node Enhancement,"Graph learning has attracted significant attention due to its widespread
real-world applications. Current mainstream approaches rely on text node
features and obtain initial node embeddings through shallow embedding learning
using GNNs, which shows limitations in capturing deep textual semantics. Recent
advances in Large Language Models (LLMs) have demonstrated superior
capabilities in understanding text semantics, transforming traditional text
feature processing. This paper proposes a novel framework that combines Graph
Transformer architecture with LLM-enhanced node features. Specifically, we
leverage LLMs to generate rich semantic representations of text nodes, which
are then processed by a multi-head self-attention mechanism in the Graph
Transformer to capture both local and global graph structural information. Our
model utilizes the Transformer's attention mechanism to dynamically aggregate
neighborhood information while preserving the semantic richness provided by LLM
embeddings. Experimental results demonstrate that the LLM-enhanced node
features significantly improve the performance of graph learning models on node
classification tasks. This approach shows promising results across multiple
graph learning tasks, offering a practical direction for combining graph
networks with language models.",http://arxiv.org/abs/2502.07982v1,Natural Language Processing,"graph, node, learning, text, attention"
CIRCUIT: A Benchmark for Circuit Interpretation and Reasoning Capabilities of LLMs,"The role of Large Language Models (LLMs) has not been extensively explored in
analog circuit design, which could benefit from a reasoning-based approach that
transcends traditional optimization techniques. In particular, despite their
growing relevance, there are no benchmarks to assess LLMs' reasoning capability
about circuits. Therefore, we created the CIRCUIT dataset consisting of 510
question-answer pairs spanning various levels of analog-circuit-related
subjects. The best-performing model on our dataset, GPT-4o, achieves 48.04%
accuracy when evaluated on the final numerical answer. To evaluate the
robustness of LLMs on our dataset, we introduced a unique feature that enables
unit-test-like evaluation by grouping questions into unit tests. In this case,
GPT-4o can only pass 27.45% of the unit tests, highlighting that the most
advanced LLMs still struggle with understanding circuits, which requires
multi-level reasoning, particularly when involving circuit topologies. This
circuit-specific benchmark highlights LLMs' limitations, offering valuable
insights for advancing their application in analog integrated circuit design.",http://arxiv.org/abs/2502.07980v1,Recommendation System,"circuit, llms, analog, reasoning, dataset"
Joint Modelling Histology and Molecular Markers for Cancer Classification,"Cancers are characterized by remarkable heterogeneity and diverse prognosis.
Accurate cancer classification is essential for patient stratification and
clinical decision-making. Although digital pathology has been advancing cancer
diagnosis and prognosis, the paradigm in cancer pathology has shifted from
purely relying on histology features to incorporating molecular markers. There
is an urgent need for digital pathology methods to meet the needs of the new
paradigm. We introduce a novel digital pathology approach to jointly predict
molecular markers and histology features and model their interactions for
cancer classification. Firstly, to mitigate the challenge of
cross-magnification information propagation, we propose a multi-scale
disentangling module, enabling the extraction of multi-scale features from
high-magnification (cellular-level) to low-magnification (tissue-level) whole
slide images. Further, based on the multi-scale features, we propose an
attention-based hierarchical multi-task multi-instance learning framework to
simultaneously predict histology and molecular markers. Moreover, we propose a
co-occurrence probability-based label correlation graph network to model the
co-occurrence of molecular markers. Lastly, we design a cross-modal interaction
module with the dynamic confidence constrain loss and a cross-modal gradient
modulation strategy, to model the interactions of histology and molecular
markers. Our experiments demonstrate that our method outperforms other
state-of-the-art methods in classifying glioma, histology features and
molecular markers. Our method promises to promote precise oncology with the
potential to advance biomedical research and clinical applications. The code is
available at https://github.com/LHY1007/M3C2",http://arxiv.org/abs/2502.07979v1,Recommendation System,"molecular, markers, histology, features, multi"
A Survey of In-Context Reinforcement Learning,"Reinforcement learning (RL) agents typically optimize their policies by
performing expensive backward passes to update their network parameters.
However, some agents can solve new tasks without updating any parameters by
simply conditioning on additional context such as their action-observation
histories. This paper surveys work on such behavior, known as in-context
reinforcement learning.",http://arxiv.org/abs/2502.07978v1,Reinforcement Learning,"reinforcement, learning, agents, parameters, context"
RESIST: Resilient Decentralized Learning Using Consensus Gradient Descent,"Empirical risk minimization (ERM) is a cornerstone of modern machine learning
(ML), supported by advances in optimization theory that ensure efficient
solutions with provable algorithmic convergence rates, which measure the speed
at which optimization algorithms approach a solution, and statistical learning
rates, which characterize how well the solution generalizes to unseen data.
Privacy, memory, computational, and communications constraints increasingly
necessitate data collection, processing, and storage across network-connected
devices. In many applications, these networks operate in decentralized settings
where a central server cannot be assumed, requiring decentralized ML algorithms
that are both efficient and resilient. Decentralized learning, however, faces
significant challenges, including an increased attack surface for adversarial
interference during decentralized learning processes. This paper focuses on the
man-in-the-middle (MITM) attack, which can cause models to deviate
significantly from their intended ERM solutions. To address this challenge, we
propose RESIST (Resilient dEcentralized learning using conSensus gradIent
deScenT), an optimization algorithm designed to be robust against adversarially
compromised communication links. RESIST achieves algorithmic and statistical
convergence for strongly convex, Polyak-Lojasiewicz, and nonconvex ERM
problems. Experimental results demonstrate the robustness and scalability of
RESIST for real-world decentralized learning in adversarial environments.",http://arxiv.org/abs/2502.07977v1,Recommendation System,"learning, decentralized, erm, optimization, resist"
Sink equilibria and the attractors of learning in games,"Characterizing the limit behavior -- that is, the attractors -- of learning
dynamics is one of the most fundamental open questions in game theory. In
recent work in this front, it was conjectured that the attractors of the
replicator dynamic are in one-to-one correspondence with the sink equilibria of
the game -- the sink strongly connected components of a game's preference graph
-- , and it was established that they do stand in at least one-to-many
correspondence with them. We make threefold progress on the problem of
characterizing attractors. First, we show through a topological construction
that the one-to-one conjecture is false. Second, we make progress on the
attractor characterization problem for two-player games by establishing that
the one-to-one conjecture is true in the absence of a local pattern called a
weak local source -- a pattern that is absent from zero-sum games. Finally, we
look -- for the first time in this context -- at fictitious play, the
longest-studied learning dynamic, and examine to what extent the conjecture
generalizes there. We establish that under fictitious play, sink equilibria
always contain attractors (sometimes strictly), and every attractor corresponds
to a strongly connected set of nodes in the preference graph.",http://arxiv.org/abs/2502.07975v1,Recommendation System,"attractors, game, sink, conjecture, characterizing"
From Hazard Identification to Controller Design: Proactive and LLM-Supported Safety Engineering for ML-Powered Systems,"Machine learning (ML) components are increasingly integrated into software
products, yet their complexity and inherent uncertainty often lead to
unintended and hazardous consequences, both for individuals and society at
large. Despite these risks, practitioners seldom adopt proactive approaches to
anticipate and mitigate hazards before they occur. Traditional safety
engineering approaches, such as Failure Mode and Effects Analysis (FMEA) and
System Theoretic Process Analysis (STPA), offer systematic frameworks for early
risk identification but are rarely adopted. This position paper advocates for
integrating hazard analysis into the development of any ML-powered software
product and calls for greater support to make this process accessible to
developers. By using large language models (LLMs) to partially automate a
modified STPA process with human oversight at critical steps, we expect to
address two key challenges: the heavy dependency on highly experienced safety
engineering experts, and the time-consuming, labor-intensive nature of
traditional hazard analysis, which often impedes its integration into
real-world development workflows. We illustrate our approach with a running
example, demonstrating that many seemingly unanticipated issues can, in fact,
be anticipated.",http://arxiv.org/abs/2502.07974v1,Recommendation System,"analysis, process, ml, software, large"
Training Sparse Mixture Of Experts Text Embedding Models,"Transformer-based text embedding models have improved their performance on
benchmarks like MIRACL and BEIR by increasing their parameter counts. However,
this scaling approach introduces significant deployment challenges, including
increased inference latency and memory usage. These challenges are particularly
severe in retrieval-augmented generation (RAG) applications, where large
models' increased memory requirements constrain dataset ingestion capacity, and
their higher latency directly impacts query-time performance. While causal
language models have addressed similar efficiency challenges using Mixture of
Experts (MoE) architectures, this approach hasn't been successfully adapted to
the general text embedding setting. In this paper, we introduce Nomic Embed v2,
the first general purpose MoE text embedding model. Our model outperforms
models in the same parameter class on both monolingual and multilingual
benchmarks while also maintaining competitive performance with models twice its
size. We open-source all code, models, and evaluation data to ensure full
reproducibility of our training pipeline.",http://arxiv.org/abs/2502.07972v1,Recommendation System,"models, text, embedding, performance, challenges"
ReTreever: Tree-based Coarse-to-Fine Representations for Retrieval,"Document retrieval is a core component of question-answering systems, as it
enables conditioning answer generation on new and large-scale corpora. While
effective, the standard practice of encoding documents into high-dimensional
embeddings for similarity search entails large memory and compute footprints,
and also makes it hard to inspect the inner workings of the system. In this
paper, we propose a tree-based method for organizing and representing reference
documents at various granular levels, which offers the flexibility to balance
cost and utility, and eases the inspection of the corpus content and retrieval
operations. Our method, called ReTreever, jointly learns a routing function per
internal node of a binary tree such that query and reference documents are
assigned to similar tree branches, hence directly optimizing for retrieval
performance. Our evaluations show that ReTreever generally preserves full
representation accuracy. Its hierarchical structure further provides strong
coarse representations and enhances transparency by indirectly learning
meaningful semantic groupings. Among hierarchical retrieval methods, ReTreever
achieves the best retrieval accuracy at the lowest latency, proving that this
family of techniques can be viable in practical applications.",http://arxiv.org/abs/2502.07971v1,Reinforcement Learning,"retrieval, documents, tree, retreever, large"
Generative Risk Minimization for Out-of-Distribution Generalization on Graphs,"Out-of-distribution (OOD) generalization on graphs aims at dealing with
scenarios where the test graph distribution differs from the training graph
distributions. Compared to i.i.d. data like images, the OOD generalization
problem on graph-structured data remains challenging due to the non-i.i.d.
property and complex structural information on graphs. Recently, several works
on graph OOD generalization have explored extracting invariant subgraphs that
share crucial classification information across different distributions.
Nevertheless, such a strategy could be suboptimal for entirely capturing the
invariant information, as the extraction of discrete structures could
potentially lead to the loss of invariant information or the involvement of
spurious information. In this paper, we propose an innovative framework, named
Generative Risk Minimization (GRM), designed to generate an invariant subgraph
for each input graph to be classified, instead of extraction. To address the
challenge of optimization in the absence of optimal invariant subgraphs (i.e.,
ground truths), we derive a tractable form of the proposed GRM objective by
introducing a latent causal variable, and its effectiveness is validated by our
theoretical analysis. We further conduct extensive experiments across a variety
of real-world graph datasets for both node-level and graph-level OOD
generalization, and the results demonstrate the superiority of our framework
GRM.",http://arxiv.org/abs/2502.07968v1,Recommendation System,"graph, information, invariant, ood, generalization"
New tools for comparing classical and neural ODE models for tumor growth,"A new computational tool TumorGrowth.jl for modeling tumor growth is
introduced. The tool allows the comparison of standard textbook models, such as
General Bertalanffy and Gompertz, with some newer models, including, for the
first time, neural ODE models. As an application, we revisit a human meta-study
of non-small cell lung cancer and bladder cancer lesions, in patients
undergoing two different treatment options, to determine if previously reported
performance differences are statistically significant, and if newer, more
complex models perform any better. In a population of examples with at least
four time-volume measurements available for calibration, and an average of
about 6.3, our main conclusion is that the General Bertalanffy model has
superior performance, on average. However, where more measurements are
available, we argue that more complex models, capable of capturing rebound and
relapse behavior, may be better choices.",http://arxiv.org/abs/2502.07964v1,Recommendation System,"models, tool, general, bertalanffy, newer"
Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?,"Medical research faces well-documented challenges in translating novel
treatments into clinical practice. Publishing incentives encourage researchers
to present ""positive"" findings, even when empirical results are equivocal.
Consequently, it is well-documented that authors often spin study results,
especially in article abstracts. Such spin can influence clinician
interpretation of evidence and may affect patient care decisions. In this
study, we ask whether the interpretation of trial results offered by Large
Language Models (LLMs) is similarly affected by spin. This is important since
LLMs are increasingly being used to trawl through and synthesize published
medical evidence. We evaluated 22 LLMs and found that they are across the board
more susceptible to spin than humans. They might also propagate spin into their
outputs: We find evidence, e.g., that LLMs implicitly incorporate spin into
plain language summaries that they generate. We also find, however, that LLMs
are generally capable of recognizing spin, and can be prompted in a way to
mitigate spin's impact on LLM outputs.",http://arxiv.org/abs/2502.07963v1,Recommendation System,"spin, llms, results, evidence, medical"
ESPFormer: Doubly-Stochastic Attention with Expected Sliced Transport Plans,"While self-attention has been instrumental in the success of Transformers, it
can lead to over-concentration on a few tokens during training, resulting in
suboptimal information flow. Enforcing doubly-stochastic constraints in
attention matrices has been shown to improve structure and balance in attention
distributions. However, existing methods rely on iterative Sinkhorn
normalization, which is computationally costly. In this paper, we introduce a
novel, fully parallelizable doubly-stochastic attention mechanism based on
sliced optimal transport, leveraging Expected Sliced Transport Plans (ESP).
Unlike prior approaches, our method enforces double stochasticity without
iterative Sinkhorn normalization, significantly enhancing efficiency. To ensure
differentiability, we incorporate a temperature-based soft sorting technique,
enabling seamless integration into deep learning models. Experiments across
multiple benchmark datasets, including image classification, point cloud
classification, sentiment analysis, and neural machine translation, demonstrate
that our enhanced attention regularization consistently improves performance
across diverse applications.",http://arxiv.org/abs/2502.07962v1,Recommendation System,"attention, doubly, stochastic, iterative, sinkhorn"
Intrinsic Bias is Predicted by Pretraining Data and Correlates with Downstream Performance in Vision-Language Encoders,"While recent work has found that vision-language models trained under the
Contrastive Language Image Pre-training (CLIP) framework contain intrinsic
social biases, the extent to which different upstream pre-training features of
the framework relate to these biases, and hence how intrinsic bias and
downstream performance are connected has been unclear. In this work, we present
the largest comprehensive analysis to-date of how the upstream pre-training
factors and downstream performance of CLIP models relate to their intrinsic
biases. Studying 131 unique CLIP models, trained on 26 datasets, using 55
architectures, and in a variety of sizes, we evaluate bias in each model using
26 well-established unimodal and cross-modal principled Embedding Association
Tests. We find that the choice of pre-training dataset is the most significant
upstream predictor of bias, whereas architectural variations have minimal
impact. Additionally, datasets curated using sophisticated filtering techniques
aimed at enhancing downstream model performance tend to be associated with
higher levels of intrinsic bias. Finally, we observe that intrinsic bias is
often significantly correlated with downstream performance ($0.3 \leq r \leq
0.8$), suggesting that models optimized for performance inadvertently learn to
amplify representational biases. Comparisons between unimodal and cross-modal
association tests reveal that social group bias depends heavily on the
modality. Our findings imply that more sophisticated strategies are needed to
address intrinsic model bias for vision-language models across the entire model
development pipeline.",http://arxiv.org/abs/2502.07957v1,Recommendation System,"bias, intrinsic, models, performance, pre"
Federated Self-supervised Domain Generalization for Label-efficient Polyp Segmentation,"Employing self-supervised learning (SSL) methodologies assumes par-amount
significance in handling unlabeled polyp datasets when building deep
learning-based automatic polyp segmentation models. However, the intricate
privacy dynamics surrounding medical data often preclude seamless data sharing
among disparate medical centers. Federated learning (FL) emerges as a
formidable solution to this privacy conundrum, yet within the realm of FL,
optimizing model generalization stands as a pressing imperative. Robust
generalization capabilities are imperative to ensure the model's efficacy
across diverse geographical domains post-training on localized client datasets.
In this paper, a Federated self-supervised Domain Generalization method is
proposed to enhance the generalization capacity of federated and
Label-efficient intestinal polyp segmentation, named LFDG. Based on a classical
SSL method, DropPos, LFDG proposes an adversarial learning-based data
augmentation method (SSADA) to enhance the data diversity. LFDG further
proposes a relaxation module based on Source-reconstruction and
Augmentation-masking (SRAM) to maintain stability in feature learning. We have
validated LFDG on polyp images from six medical centers. The performance of our
method achieves 3.80% and 3.92% better than the baseline and other recent FL
methods and SSL methods, respectively.",http://arxiv.org/abs/2502.07951v1,Recommendation System,"learning, polyp, based, data, generalization"
VSC-RL: Advancing Autonomous Vision-Language Agents with Variational Subgoal-Conditioned Reinforcement Learning,"State-of-the-art (SOTA) reinforcement learning (RL) methods enable the
vision-language agents to learn from interactions with the environment without
human supervision. However, they struggle with learning inefficiencies in
tackling real-world complex sequential decision-making tasks, especially with
sparse reward signals and long-horizon dependencies. To effectively address the
issue, we introduce Variational Subgoal-Conditioned RL (VSC-RL), which
reformulates the vision-language sequential decision-making task as a
variational goal-conditioned RL problem, allowing us to leverage advanced
optimization methods to enhance learning efficiency. Specifically, VSC-RL
optimizes the SubGoal Evidence Lower BOund (SGC-ELBO), which consists of (a)
maximizing the subgoal-conditioned return via RL and (b) minimizing the
subgoal-conditioned difference with the reference policy. We theoretically
demonstrate that SGC-ELBO is equivalent to the original optimization objective,
ensuring improved learning efficiency without sacrificing performance
guarantees. Additionally, for real-world complex decision-making tasks, VSC-RL
leverages the vision-language model to autonomously decompose the goal into
feasible subgoals, enabling efficient learning. Across various benchmarks,
including challenging real-world mobile device control tasks, VSC-RL
significantly outperforms the SOTA vision-language agents, achieving superior
performance and remarkable improvement in learning efficiency.",http://arxiv.org/abs/2502.07949v1,Reinforcement Learning,"rl, learning, vision, language, subgoal"
SurGrID: Controllable Surgical Simulation via Scene Graph to Image Diffusion,"Surgical simulation offers a promising addition to conventional surgical
training. However, available simulation tools lack photorealism and rely on
hardcoded behaviour. Denoising Diffusion Models are a promising alternative for
high-fidelity image synthesis, but existing state-of-the-art conditioning
methods fall short in providing precise control or interactivity over the
generated scenes.
  We introduce SurGrID, a Scene Graph to Image Diffusion Model, allowing for
controllable surgical scene synthesis by leveraging Scene Graphs. These graphs
encode a surgical scene's components' spatial and semantic information, which
are then translated into an intermediate representation using our novel
pre-training step that explicitly captures local and global information.
  Our proposed method improves the fidelity of generated images and their
coherence with the graph input over the state-of-the-art. Further, we
demonstrate the simulation's realism and controllability in a user assessment
study involving clinical experts.
  Scene Graphs can be effectively used for precise and interactive conditioning
of Denoising Diffusion Models for simulating surgical scenes, enabling high
fidelity and interactive control over the generated content.",http://arxiv.org/abs/2502.07945v1,Reinforcement Learning,"surgical, scene, simulation, diffusion, fidelity"
SHACL-SKOS Based Knowledge Representation of Material Safety Data Sheet (SDS) for the Pharmaceutical Industry,"We report the development of a knowledge representation and reasoning (KRR)
system built on hybrid SHACL-SKOS ontologies for globally harmonized system
(GHS) material Safety Data Sheets (SDS) to enhance chemical safety
communication and regulatory compliance. SDS are comprehensive documents
containing safety and handling information for chemical substances. Thus, they
are an essential part of workplace safety and risk management. However, the
vast number of Safety Data Sheets from multiple organizations, manufacturers,
and suppliers that produce and distribute chemicals makes it challenging to
centralize and access SDS documents through a single repository. To accomplish
the underlying issues of data exchange related to chemical shipping and
handling, we construct SDS related controlled vocabulary and conditions
validated by SHACL, and knowledge systems of similar domains linked via SKOS.
The resulting hybrid ontologies aim to provide standardized yet adaptable
representations of SDS information, facilitating better data sharing,
retrieval, and integration across various platforms. This paper outlines our
SHACL-SKOS system architectural design and showcases our implementation for an
industrial application streamlining the generation of a composite shipping
cover sheet.",http://arxiv.org/abs/2502.07944v1,Recommendation System,"safety, sds, data, system, shacl"
CREDAL: Close Reading of Data Models,"Data models are necessary for the birth of data and of any data-driven
system. Indeed, every algorithm, every machine learning model, every
statistical model, and every database has an underlying data model without
which the system would not be usable. Hence, data models are excellent sites
for interrogating the (material, social, political, ...) conditions giving rise
to a data system. Towards this, drawing inspiration from literary criticism, we
propose to closely read data models in the same spirit as we closely read
literary artifacts. Close readings of data models reconnect us with, among
other things, the materiality, the genealogies, the techne, the closed nature,
and the design of technical systems.
  While recognizing from literary theory that there is no one correct way to
read, it is nonetheless critical to have systematic guidance for those
unfamiliar with close readings. This is especially true for those trained in
the computing and data sciences, who too often are enculturated to set aside
the socio-political aspects of data work. A systematic methodology for reading
data models currently does not exist. To fill this gap, we present the CREDAL
methodology for close readings of data models. We detail our iterative
development process and present results of a qualitative evaluation of CREDAL
demonstrating its usability, usefulness, and effectiveness in the critical
study of data.",http://arxiv.org/abs/2502.07943v1,Recommendation System,"data, models, system, model, literary"
Symbiotic Cooperation for Web Agents: Harnessing Complementary Strengths of Large and Small LLMs,"Web browsing agents powered by large language models (LLMs) have shown
tremendous potential in automating complex web-based tasks. Existing approaches
typically rely on large LLMs (e.g., GPT-4o) to explore web environments and
generate trajectory data, which is then used either for demonstration retrieval
(for large LLMs) or to distill small LLMs (e.g., Llama3) in a process that
remains decoupled from the exploration. In this paper, we propose
AgentSymbiotic, an iterative framework that couples data synthesis with
task-performance, yielding a ""symbiotic improvement"" for both large and small
LLMs. Our study uncovers a complementary dynamic between LLM types: while large
LLMs excel at generating high-quality trajectories for distillation, the
distilled small LLMs-owing to their distinct reasoning capabilities-often
choose actions that diverge from those of their larger counterparts. This
divergence drives the exploration of novel trajectories, thereby enriching the
synthesized data. However, we also observe that the performance of small LLMs
becomes a bottleneck in this iterative enhancement process. To address this, we
propose two innovations in LLM distillation: a speculative data synthesis
strategy that mitigates off-policy bias, and a multi-task learning approach
designed to boost the reasoning capabilities of the student LLM. Furthermore,
we introduce a Hybrid Mode for Privacy Preservation to address user privacy
concerns. Evaluated on the WEBARENA benchmark, AgentSymbiotic achieves SOTA
performance with both LLM types. Our best Large LLM agent reaches 52%,
surpassing the previous best of 45%, while our 8B distilled model demonstrates
a competitive 49%, exceeding the prior best of 28%. Code will be released upon
acceptance.",http://arxiv.org/abs/2502.07942v1,Recommendation System,"llms, large, llm, data, small"
Discrete Markov Probabilistic Models,"This paper introduces the Discrete Markov Probabilistic Model (DMPM), a novel
algorithm for discrete data generation. The algorithm operates in the space of
bits $\{0,1\}^d$, where the noising process is a continuous-time Markov chain
that can be sampled exactly via a Poissonian clock that flips labels uniformly
at random. The time-reversal process, like the forward noise process, is a jump
process, with its intensity governed by a discrete analogue of the classical
score function. Crucially, this intensity is proven to be the conditional
expectation of a function of the forward process, strengthening its theoretical
alignment with score-based generative models while ensuring robustness and
efficiency. We further establish convergence bounds for the algorithm under
minimal assumptions and demonstrate its effectiveness through experiments on
low-dimensional Bernoulli-distributed datasets and high-dimensional binary
MNIST data. The results highlight its strong performance in generating discrete
structures. This work bridges theoretical foundations and practical
applications, advancing the development of effective and theoretically grounded
discrete generative modeling.",http://arxiv.org/abs/2502.07939v1,Recommendation System,"discrete, process, algorithm, markov, data"
Active Advantage-Aligned Online Reinforcement Learning with Offline Data,"Online reinforcement learning (RL) enhances policies through direct
interactions with the environment, but faces challenges related to sample
efficiency. In contrast, offline RL leverages extensive pre-collected data to
learn policies, but often produces suboptimal results due to limited data
coverage. Recent efforts have sought to integrate offline and online RL in
order to harness the advantages of both approaches. However, effectively
combining online and offline RL remains challenging due to issues that include
catastrophic forgetting, lack of robustness and sample efficiency. In an effort
to address these challenges, we introduce A3 RL , a novel method that actively
selects data from combined online and offline sources to optimize policy
improvement. We provide theoretical guarantee that validates the effectiveness
our active sampling strategy and conduct thorough empirical experiments showing
that our method outperforms existing state-of-the-art online RL techniques that
utilize offline data. Our code will be publicly available at:
https://github.com/xuefeng-cs/A3RL.",http://arxiv.org/abs/2502.07937v1,Reinforcement Learning,"rl, online, offline, data, policies"
Educating a Responsible AI Workforce: Piloting a Curricular Module on AI Policy in a Graduate Machine Learning Course,"As artificial intelligence (AI) technologies begin to permeate diverse
fields-from healthcare to education-consumers, researchers and policymakers are
increasingly raising concerns about whether and how AI is regulated. It is
therefore reasonable to anticipate that alignment with principles of 'ethical'
or 'responsible' AI, as well as compliance with law and policy, will form an
increasingly important part of AI development. Yet, for the most part, the
conventional computer science curriculum is ill-equipped to prepare students
for these challenges. To this end, we seek to explore how new educational
content related to AI ethics and AI policy can be integrated into both ethics-
and technical-focused courses. This paper describes a two-lecture 'AI policy
module' that was piloted in a graduate-level introductory machine learning
course in 2024. The module, which includes an in-class active learning game, is
evaluated using data from student surveys before and after the lectures, and
pedagogical motivations and considerations are discussed. We find that the
module is successful in engaging otherwise technically-oriented students on the
topic of AI policy, increasing student awareness of the social impacts of a
variety of AI technologies and developing student interest in the field of AI
regulation.",http://arxiv.org/abs/2502.07931v1,Recommendation System,"ai, policy, module, student, technologies"
NDAI Agreements,"We study a fundamental challenge in the economics of innovation: an inventor
must reveal details of a new idea to secure compensation or funding, yet such
disclosure risks expropriation. We present a model in which a seller (inventor)
and buyer (investor) bargain over an information good under the threat of
hold-up. In the classical setting, the seller withholds disclosure to avoid
misappropriation, leading to inefficiency. We show that trusted execution
environments (TEEs) combined with AI agents can mitigate and even fully
eliminate this hold-up problem. By delegating the disclosure and payment
decisions to tamper-proof programs, the seller can safely reveal the invention
without risking expropriation, achieving full disclosure and an efficient ex
post transfer. Moreover, even if the invention's value exceeds a threshold that
TEEs can fully secure, partial disclosure still improves outcomes compared to
no disclosure. Recognizing that real AI agents are imperfect, we model ""agent
errors"" in payments or disclosures and demonstrate that budget caps and
acceptance thresholds suffice to preserve most of the efficiency gains.
  Our results imply that cryptographic or hardware-based solutions can function
as an ""ironclad NDA,"" substantially mitigating the fundamental
disclosure-appropriation paradox first identified by Arrow (1962) and Nelson
(1959). This has far-reaching policy implications for fostering R&D, technology
transfer, and collaboration.",http://arxiv.org/abs/2502.07924v1,Recommendation System,"disclosure, seller, fundamental, inventor, reveal"
Sign Operator for Coping with Heavy-Tailed Noise: High Probability Convergence Bounds with Extensions to Distributed Optimization and Comparison Oracle,"The growing popularity of AI optimization problems involving severely
corrupted data has increased the demand for methods capable of handling
heavy-tailed noise, i.e., noise with bounded $\kappa$-th moment, $\kappa \in
(1,2]$. For the widely used clipping technique, effectiveness heavily depends
on the careful tuning of clipping levels throughout training. In this paper, we
demonstrate that using only the sign of the input, without introducing
additional hyperparameters, is sufficient to cope with heavy-tailed noise
effectively. For smooth non-convex functions, we prove that SignSGD achieves
optimal sample complexity $\tilde{O}\left(\varepsilon^{-\frac{3\kappa -
2}{\kappa - 1}}\right)$ with high probability for attaining an average gradient
norm accuracy of $\varepsilon$. Under the assumption of symmetric noise, we use
SignSGD with Majority Voting to extend this bound to the distributed
optimization or reduce the sample complexity to $\tilde{O}(\varepsilon^{-4})$
in the case of a single worker with arbitrary parameters. Furthermore, we
explore the application of the sign operator in zeroth-order optimization with
an oracle that can only compare function values at two different points. We
propose a novel method, MajorityVote-CompsSGD, and provide the first-known
high-probability bound $\tilde{O}(\varepsilon^{-6})$ for the number of
comparisons under symmetric noise assumption. Our theoretical findings are
supported by the superior performance of sign-based methods in training Large
Language Models.",http://arxiv.org/abs/2502.07923v1,Recommendation System,"noise, optimization, sign, methods, heavy"
Filtered Markovian Projection: Dimensionality Reduction in Filtering for Stochastic Reaction Networks,"Stochastic reaction networks (SRNs) model stochastic effects for various
applications, including intracellular chemical or biological processes and
epidemiology. A typical challenge in practical problems modeled by SRNs is that
only a few state variables can be dynamically observed. Given the measurement
trajectories, one can estimate the conditional probability distribution of
unobserved (hidden) state variables by solving a stochastic filtering problem.
In this setting, the conditional distribution evolves over time according to an
extensive or potentially infinite-dimensional system of coupled ordinary
differential equations with jumps, known as the filtering equation. The current
numerical filtering techniques, such as the Filtered Finite State Projection
(DAmbrosio et al., 2022), are hindered by the curse of dimensionality,
significantly affecting their computational performance. To address these
limitations, we propose to use a dimensionality reduction technique based on
the Markovian projection (MP), initially introduced for forward problems (Ben
Hammouda et al., 2024). In this work, we explore how to adapt the existing MP
approach to the filtering problem and introduce a novel version of the MP, the
Filtered MP, that guarantees the consistency of the resulting estimator. The
novel method combines a particle filter with reduced variance and solving the
filtering equations in a low-dimensional space, exploiting the advantages of
both approaches. The analysis and empirical results highlight the superior
computational efficiency of projection methods compared to the existing
filtered finite state projection in the large dimensional setting.",http://arxiv.org/abs/2502.07918v1,Recommendation System,"filtering, state, projection, mp, stochastic"
Model-free Methods for Event History Analysis and Efficient Adjustment (PhD Thesis),"This thesis contains a series of independent contributions to statistics,
unified by a model-free perspective. The first chapter elaborates on how a
model-free perspective can be used to formulate flexible methods that leverage
prediction techniques from machine learning. Mathematical insights are obtained
from concrete examples, and these insights are generalized to principles that
permeate the rest of the thesis. The second chapter studies the concept of
local independence, which describes whether the evolution of one stochastic
process is directly influenced by another. To test local independence, we
define a model-free parameter called the Local Covariance Measure (LCM). We
formulate an estimator for the LCM, from which a test of local independence is
proposed. We discuss how the size and power of the proposed test can be
controlled uniformly and investigate the test in a simulation study. The third
chapter focuses on covariate adjustment, a method used to estimate the effect
of a treatment by accounting for observed confounding. We formulate a general
framework that facilitates adjustment for any subset of covariate information.
We identify the optimal covariate information for adjustment and, based on
this, introduce the Debiased Outcome-adapted Propensity Estimator (DOPE) for
efficient estimation of treatment effects. An instance of DOPE is implemented
using neural networks, and we demonstrate its performance on simulated and real
data. The fourth and final chapter introduces a model-free measure of the
conditional association between an exposure and a time-to-event, which we call
the Aalen Covariance Measure (ACM). We develop a model-free estimation method
and show that it is doubly robust, ensuring $\sqrt{n}$-consistency provided
that the nuisance functions can be estimated with modest rates. A simulation
study demonstrates the use of our estimator in several settings.",http://arxiv.org/abs/2502.07906v1,Recommendation System,"model, free, chapter, local, test"
DeepSeek on a Trip: Inducing Targeted Visual Hallucinations via Representation Vulnerabilities,"Multimodal Large Language Models (MLLMs) represent the cutting edge of AI
technology, with DeepSeek models emerging as a leading open-source alternative
offering competitive performance to closed-source systems. While these models
demonstrate remarkable capabilities, their vision-language integration
mechanisms introduce specific vulnerabilities. We implement an adapted
embedding manipulation attack on DeepSeek Janus that induces targeted visual
hallucinations through systematic optimization of image embeddings. Through
extensive experimentation across COCO, DALL-E 3, and SVIT datasets, we achieve
hallucination rates of up to 98.0% while maintaining high visual fidelity (SSIM
> 0.88) of the manipulated images on open-ended questions. Our analysis
demonstrates that both 1B and 7B variants of DeepSeek Janus are susceptible to
these attacks, with closed-form evaluation showing consistently higher
hallucination rates compared to open-ended questioning. We introduce a novel
multi-prompt hallucination detection framework using LLaMA-3.1 8B Instruct for
robust evaluation. The implications of these findings are particularly
concerning given DeepSeek's open-source nature and widespread deployment
potential. This research emphasizes the critical need for embedding-level
security measures in MLLM deployment pipelines and contributes to the broader
discussion of responsible AI implementation.",http://arxiv.org/abs/2502.07905v1,Computer Vision,"deepseek, open, models, source, hallucination"
The Observational Partial Order of Causal Structures with Latent Variables,"For two causal structures with the same set of visible variables, one is said
to observationally dominate the other if the set of distributions over the
visible variables realizable by the first contains the set of distributions
over the visible variables realizable by the second. Knowing such dominance
relations is useful for adjudicating between these structures given
observational data. We here consider the problem of determining the partial
order of equivalence classes of causal structures with latent variables
relative to observational dominance. We provide a complete characterization of
the dominance order in the case of three visible variables, and a partial
characterization in the case of four visible variables. Our techniques also
help to identify which observational equivalence classes have a set of
realizable distributions that is characterized by nontrivial inequality
constraints, analogous to Bell inequalities and instrumental inequalities. We
find evidence that as one increases the number of visible variables, the
equivalence classes satisfying nontrivial inequality constraints become
ubiquitous. (Because such classes are the ones for which there can be a
difference in the distributions that are quantumly and classically realizable,
this implies that the potential for quantum-classical gaps is also ubiquitous.)
Furthermore, we find evidence that constraint-based causal discovery algorithms
that rely solely on conditional independence constraints have a significantly
weaker distinguishing power among observational equivalence classes than
algorithms that go beyond these (i.e., algorithms that also leverage nested
Markov constraints and inequality constraints).",http://arxiv.org/abs/2502.07891v1,Recommendation System,"variables, visible, classes, constraints, set"
A unifying account of warm start guarantees for patches of quantum landscapes,"Barren plateaus are fundamentally a statement about quantum loss landscapes
on average but there can, and generally will, exist patches of barren plateau
landscapes with substantial gradients. Previous work has studied certain
classes of parameterized quantum circuits and found example regions where
gradients vanish at worst polynomially in system size. Here we present a
general bound that unifies all these previous cases and that can tackle
physically-motivated ans\""atze that could not be analyzed previously.
Concretely, we analytically prove a lower-bound on the variance of the loss
that can be used to show that in a non-exponentially narrow region around a
point with curvature the loss variance cannot decay exponentially fast. This
result is complemented by numerics and an upper-bound that suggest that any
loss function with a barren plateau will have exponentially vanishing gradients
in any constant radius subregion. Our work thus suggests that while there are
hopes to be able to warm-start variational quantum algorithms, any
initialization strategy that cannot get increasingly close to the region of
attraction with increasing problem size is likely inadequate.",http://arxiv.org/abs/2502.07889v1,Recommendation System,"loss, barren, quantum, gradients, bound"
MatSwap: Light-aware material transfers in images,"We present MatSwap, a method to transfer materials to designated surfaces in
an image photorealistically. Such a task is non-trivial due to the large
entanglement of material appearance, geometry, and lighting in a photograph. In
the literature, material editing methods typically rely on either cumbersome
text engineering or extensive manual annotations requiring artist knowledge and
3D scene properties that are impractical to obtain. In contrast, we propose to
directly learn the relationship between the input material -- as observed on a
flat surface -- and its appearance within the scene, without the need for
explicit UV mapping. To achieve this, we rely on a custom light- and
geometry-aware diffusion model. We fine-tune a large-scale pre-trained
text-to-image model for material transfer using our synthetic dataset,
preserving its strong priors to ensure effective generalization to real images.
As a result, our method seamlessly integrates a desired material into the
target location in the photograph while retaining the identity of the scene. We
evaluate our method on synthetic and real images and show that it compares
favorably to recent work both qualitatively and quantitatively. We will release
our code and data upon publication.",http://arxiv.org/abs/2502.07784v1,Recommendation System,"material, method, scene, transfer, image"
Pippo: High-Resolution Multi-View Humans from a Single Image,"We present Pippo, a generative model capable of producing 1K resolution dense
turnaround videos of a person from a single casually clicked photo. Pippo is a
multi-view diffusion transformer and does not require any additional inputs -
e.g., a fitted parametric model or camera parameters of the input image. We
pre-train Pippo on 3B human images without captions, and conduct multi-view
mid-training and post-training on studio captured humans. During mid-training,
to quickly absorb the studio dataset, we denoise several (up to 48) views at
low-resolution, and encode target cameras coarsely using a shallow MLP. During
post-training, we denoise fewer views at high-resolution and use pixel-aligned
controls (e.g., Spatial anchor and Plucker rays) to enable 3D consistent
generations. At inference, we propose an attention biasing technique that
allows Pippo to simultaneously generate greater than 5 times as many views as
seen during training. Finally, we also introduce an improved metric to evaluate
3D consistency of multi-view generations, and show that Pippo outperforms
existing works on multi-view human generation from a single image.",http://arxiv.org/abs/2502.07785v1,Computer Vision,"pippo, training, multi, view, resolution"
Curvature Tuning: Provable Training-free Model Steering From a Single Parameter,"The scaling of model size and data size has reshaped the paradigm of AI. As a
result, the common protocol to leverage the latest models is to steer them
towards a specific downstream task of interest through {\em fine-tuning}.
Despite its importance, the main methods for fine-tuning remain limited to full
or low-rank adapters--containing countless hyper-parameters and lacking
interpretability. In this paper, we take a step back and demonstrate how novel
and explainable post-training steering solutions can be derived theoretically
from {\em spline operators}, a rich mathematical framing of Deep Networks that
was recently developed. Our method--coined \textbf{Curvature Tuning (CT)}--has
a single parameter that provably modulates the curvature of the model's
decision boundary henceforth allowing training-free steering. This makes CT
both more efficient and interpretable than conventional fine-tuning methods. We
empirically validate its effectiveness in improving generalization and
robustness of pretrained models. For example, CT improves out-of-distribution
transfer performances of ResNet-18/50 by 2.57\%/1.74\% across seventeen
downstream datasets, and improves RobustBench robust accuracy by
11.76\%/348.44\%. Additionally, we apply CT to ReLU-based Swin-T/S, improving
their generalization on nine downstream datasets by 2.43\%/3.33\%. Our code is
available at
\href{https://github.com/Leon-Leyang/curvature-tuning}{https://github.com/Leon-Leyang/curvature-tuning}.",http://arxiv.org/abs/2502.07783v1,Recommendation System,"tuning, downstream, fine, curvature, ct"
A Flag Decomposition for Hierarchical Datasets,"Flag manifolds encode hierarchical nested sequences of subspaces and serve as
powerful structures for various computer vision and machine learning
applications. Despite their utility in tasks such as dimensionality reduction,
motion averaging, and subspace clustering, current applications are often
restricted to extracting flags using common matrix decomposition methods like
the singular value decomposition. Here, we address the need for a general
algorithm to factorize and work with hierarchical datasets. In particular, we
propose a novel, flag-based method that decomposes arbitrary hierarchical
real-valued data into a hierarchy-preserving flag representation in Stiefel
coordinates. Our work harnesses the potential of flag manifolds in applications
including denoising, clustering, and few-shot learning.",http://arxiv.org/abs/2502.07782v1,Computer Vision,"flag, hierarchical, applications, manifolds, learning"
DarwinLM: Evolutionary Structured Pruning of Large Language Models,"Large Language Models (LLMs) have achieved significant success across various
NLP tasks. However, their massive computational costs limit their widespread
use, particularly in real-time applications. Structured pruning offers an
effective solution by compressing models and directly providing end-to-end
speed improvements, regardless of the hardware environment. Meanwhile,
different components of the model exhibit varying sensitivities towards
pruning, calling for \emph{non-uniform} model compression. However, a pruning
method should not only identify a capable substructure, but also account for
post-compression training. To this end, we propose \sysname, a method for
\emph{training-aware} structured pruning. \sysname builds upon an evolutionary
search process, generating multiple offspring models in each generation through
mutation, and selecting the fittest for survival. To assess the effect of
post-training, we incorporate a lightweight, multistep training process within
the offspring population, progressively increasing the number of tokens and
eliminating poorly performing models in each selection stage. We validate our
method through extensive experiments on Llama-2-7B, Llama-3.1-8B and
Qwen-2.5-14B-Instruct, achieving state-of-the-art performance for structured
pruning. For instance, \sysname surpasses ShearedLlama while requiring
$5\times$ less training data during post-compression training.",http://arxiv.org/abs/2502.07780v1,Natural Language Processing,"pruning, training, models, structured, end"
TextAtlas5M: A Large-scale Dataset for Dense Text Image Generation,"Text-conditioned image generation has gained significant attention in recent
years and are processing increasingly longer and comprehensive text prompt. In
everyday life, dense and intricate text appears in contexts like
advertisements, infographics, and signage, where the integration of both text
and visuals is essential for conveying complex information. However, despite
these advances, the generation of images containing long-form text remains a
persistent challenge, largely due to the limitations of existing datasets,
which often focus on shorter and simpler text. To address this gap, we
introduce TextAtlas5M, a novel dataset specifically designed to evaluate
long-text rendering in text-conditioned image generation. Our dataset consists
of 5 million long-text generated and collected images across diverse data
types, enabling comprehensive evaluation of large-scale generative models on
long-text image generation. We further curate 3000 human-improved test set
TextAtlasEval across 3 data domains, establishing one of the most extensive
benchmarks for text-conditioned generation. Evaluations suggest that the
TextAtlasEval benchmarks present significant challenges even for the most
advanced proprietary models (e.g. GPT4o with DallE-3), while their open-source
counterparts show an even larger performance gap. These evidences position
TextAtlas5M as a valuable dataset for training and evaluating future-generation
text-conditioned image generation models.",http://arxiv.org/abs/2502.07870v1,Recommendation System,"text, generation, conditioned, image, long"
Stay-Positive: A Case for Ignoring Real Image Features in Fake Image Detection,"Detecting AI generated images is a challenging yet essential task. A primary
difficulty arises from the detectors tendency to rely on spurious patterns,
such as compression artifacts, which can influence its decisions. These issues
often stem from specific patterns that the detector associates with the real
data distribution, making it difficult to isolate the actual generative traces.
We argue that an image should be classified as fake if and only if it contains
artifacts introduced by the generative model. Based on this premise, we propose
Stay Positive, an algorithm designed to constrain the detectors focus to
generative artifacts while disregarding those associated with real data.
Experimental results demonstrate that detectors trained with Stay Positive
exhibit reduced susceptibility to spurious correlations, leading to improved
generalization and robustness to post processing. Additionally, unlike
detectors that associate artifacts with real images, those that focus purely on
fake artifacts are better at detecting inpainted real images.",http://arxiv.org/abs/2502.07778v1,Recommendation System,"artifacts, detectors, real, images, generative"
Auditing Prompt Caching in Language Model APIs,"Prompt caching in large language models (LLMs) results in data-dependent
timing variations: cached prompts are processed faster than non-cached prompts.
These timing differences introduce the risk of side-channel timing attacks. For
example, if the cache is shared across users, an attacker could identify cached
prompts from fast API response times to learn information about other users'
prompts. Because prompt caching may cause privacy leakage, transparency around
the caching policies of API providers is important. To this end, we develop and
conduct statistical audits to detect prompt caching in real-world LLM API
providers. We detect global cache sharing across users in seven API providers,
including OpenAI, resulting in potential privacy leakage about users' prompts.
Timing variations due to prompt caching can also result in leakage of
information about model architecture. Namely, we find evidence that OpenAI's
embedding model is a decoder-only Transformer, which was previously not
publicly known.",http://arxiv.org/abs/2502.07776v1,Natural Language Processing,"caching, prompts, prompt, timing, users"
Optimistic Interior Point Methods for Sequential Hypothesis Testing by Betting,"The technique of ""testing by betting"" frames nonparametric sequential
hypothesis testing as a multiple-round game, where a player bets on future
observations that arrive in a streaming fashion, accumulates wealth that
quantifies evidence against the null hypothesis, and rejects the null once the
wealth exceeds a specified threshold while controlling the false positive
error. Designing an online learning algorithm that achieves a small regret in
the game can help rapidly accumulate the bettor's wealth, which in turn can
shorten the time to reject the null hypothesis under the alternative $H_1$.
However, many of the existing works employ the Online Newton Step (ONS) to
update within a halved decision space to avoid a gradient explosion issue,
which is potentially conservative for rapid wealth accumulation. In this paper,
we introduce a novel strategy utilizing interior-point methods in optimization
that allows updates across the entire interior of the decision space without
the risk of gradient explosion. Our approach not only maintains strong
statistical guarantees but also facilitates faster null hypothesis rejection in
critical scenarios, overcoming the limitations of existing approaches.",http://arxiv.org/abs/2502.07774v1,Recommendation System,"hypothesis, wealth, null, testing, game"
EventEgo3D++: 3D Human Motion Capture from a Head-Mounted Event Camera,"Monocular egocentric 3D human motion capture remains a significant challenge,
particularly under conditions of low lighting and fast movements, which are
common in head-mounted device applications. Existing methods that rely on RGB
cameras often fail under these conditions. To address these limitations, we
introduce EventEgo3D++, the first approach that leverages a monocular event
camera with a fisheye lens for 3D human motion capture. Event cameras excel in
high-speed scenarios and varying illumination due to their high temporal
resolution, providing reliable cues for accurate 3D human motion capture.
EventEgo3D++ leverages the LNES representation of event streams to enable
precise 3D reconstructions. We have also developed a mobile head-mounted device
(HMD) prototype equipped with an event camera, capturing a comprehensive
dataset that includes real event observations from both controlled studio
environments and in-the-wild settings, in addition to a synthetic dataset.
Additionally, to provide a more holistic dataset, we include allocentric RGB
streams that offer different perspectives of the HMD wearer, along with their
corresponding SMPL body model. Our experiments demonstrate that EventEgo3D++
achieves superior 3D accuracy and robustness compared to existing solutions,
even in challenging conditions. Moreover, our method supports real-time 3D pose
updates at a rate of 140Hz. This work is an extension of the EventEgo3D
approach (CVPR 2024) and further advances the state of the art in egocentric 3D
human motion capture. For more details, visit the project page at
https://eventego3d.mpi-inf.mpg.de.",http://arxiv.org/abs/2502.07869v1,Reinforcement Learning,"event, human, motion, capture, conditions"
Breaking Down Bias: On The Limits of Generalizable Pruning Strategies,"We employ model pruning to examine how LLMs conceptualize racial biases, and
whether a generalizable mitigation strategy for such biases appears feasible.
Our analysis yields several novel insights. We find that pruning can be an
effective method to reduce bias without significantly increasing anomalous
model behavior. Neuron-based pruning strategies generally yield better results
than approaches pruning entire attention heads. However, our results also show
that the effectiveness of either approach quickly deteriorates as pruning
strategies become more generalized. For instance, a model that is trained on
removing racial biases in the context of financial decision-making poorly
generalizes to biases in commercial transactions. Overall, our analysis
suggests that racial biases are only partially represented as a general concept
within language models. The other part of these biases is highly
context-specific, suggesting that generalizable mitigation strategies may be of
limited effectiveness. Our findings have important implications for legal
frameworks surrounding AI. In particular, they suggest that an effective
mitigation strategy should include the allocation of legal responsibility on
those that deploy models in a specific use case.",http://arxiv.org/abs/2502.07771v1,Recommendation System,"biases, pruning, model, racial, mitigation"
Polynomial-Time Approximability of Constrained Reinforcement Learning,"We study the computational complexity of approximating general constrained
Markov decision processes. Our primary contribution is the design of a
polynomial time $(0,\epsilon)$-additive bicriteria approximation algorithm for
finding optimal constrained policies across a broad class of recursively
computable constraints, including almost-sure, chance, expectation, and their
anytime variants. Matching lower bounds imply our approximation guarantees are
optimal so long as $P \neq NP$. The generality of our approach results in
answers to several long-standing open complexity questions in the constrained
reinforcement learning literature. Specifically, we are the first to prove
polynomial-time approximability for the following settings: policies under
chance constraints, deterministic policies under multiple expectation
constraints, policies under non-homogeneous constraints (i.e., constraints of
different types), and policies under constraints for continuous-state
processes.",http://arxiv.org/abs/2502.07764v1,Reinforcement Learning,"constraints, policies, constrained, complexity, processes"
Scalable Fingerprinting of Large Language Models,"Model fingerprinting has emerged as a powerful tool for model owners to
identify their shared model given API access. However, to lower false discovery
rate, fight fingerprint leakage, and defend against coalitions of model users
attempting to bypass detection, we argue that {\em scalability} is critical,
i.e., scaling up the number of fingerprints one can embed into a model. Hence,
we pose scalability as a crucial requirement for fingerprinting schemes. We
experiment with fingerprint design at a scale significantly larger than
previously considered, and introduce a new method, dubbed Perinucleus sampling,
to generate scalable, persistent, and harmless fingerprints. We demonstrate
that this scheme can add 24,576 fingerprints to a Llama-3.1-8B model -- two
orders of magnitude more than existing schemes -- without degrading the model's
utility. Our inserted fingerprints persist even after supervised fine-tuning on
standard post-training data. We further address security risks for
fingerprinting, and theoretically and empirically show how a scalable
fingerprinting scheme like ours can mitigate these risks.",http://arxiv.org/abs/2502.07760v1,Recommendation System,"model, fingerprinting, fingerprints, fingerprint, scalability"
Novel computational workflows for natural and biomedical image processing based on hypercomplex algebras,"Hypercomplex image processing extends conventional techniques in a unified
paradigm encompassing algebraic and geometric principles. This work leverages
quaternions and the two-dimensional orthogonal planes split framework
(splitting of a quaternion - representing a pixel - into pairs of orthogonal 2D
planes) for natural/biomedical image analysis through the following
computational workflows and outcomes: natural/biomedical image re-colorization,
natural image de-colorization, natural/biomedical image contrast enhancement,
computational re-staining and stain separation in histological images, and
performance gains in machine/deep learning pipelines for histological images.
The workflows are analyzed separately for natural and biomedical images to
showcase the effectiveness of the proposed approaches. The proposed workflows
can regulate color appearance (e.g. with alternative renditions and grayscale
conversion) and image contrast, be part of automated image processing pipelines
(e.g. isolating stain components, boosting learning models), and assist in
digital pathology applications (e.g. enhancing biomarker visibility, enabling
colorblind-friendly renditions). Employing only basic arithmetic and matrix
operations, this work offers a computationally accessible methodology - in the
hypercomplex domain - that showcases versatility and consistency across image
processing tasks and a range of computer vision and biomedical applications.
The proposed non-data-driven methods achieve comparable or better results
(particularly in cases involving well-known methods) to those reported in the
literature, showcasing the potential of robust theoretical frameworks with
practical effectiveness. Results, methods, and limitations are detailed
alongside discussion of promising extensions, emphasizing the potential of
feature-rich mathematical/computational frameworks for natural and biomedical
images.",http://arxiv.org/abs/2502.07758v1,Recommendation System,"image, natural, biomedical, images, processing"
An Advanced NLP Framework for Automated Medical Diagnosis with DeBERTa and Dynamic Contextual Positional Gating,"This paper presents a novel Natural Language Processing (NLP) framework for
enhancing medical diagnosis through the integration of advanced techniques in
data augmentation, feature extraction, and classification. The proposed
approach employs back-translation to generate diverse paraphrased datasets,
improving robustness and mitigating overfitting in classification tasks.
Leveraging Decoding-enhanced BERT with Disentangled Attention (DeBERTa) with
Dynamic Contextual Positional Gating (DCPG), the model captures fine-grained
contextual and positional relationships, dynamically adjusting the influence of
positional information based on semantic context to produce high-quality text
embeddings. For classification, an Attention-Based Feedforward Neural Network
(ABFNN) is utilized, effectively focusing on the most relevant features to
improve decision-making accuracy. Applied to the classification of symptoms,
clinical notes, and other medical texts, this architecture demonstrates its
ability to address the complexities of medical data. The combination of data
augmentation, contextual embedding generation, and advanced classification
mechanisms offers a robust and accurate diagnostic tool, with potential
applications in automated medical diagnosis and clinical decision support. This
method demonstrates the effectiveness of the proposed NLP framework for medical
diagnosis, achieving remarkable results with an accuracy of 99.78%, recall of
99.72%, precision of 99.79%, and an F1-score of 99.75%. These metrics not only
underscore the model's robust performance in classifying medical texts with
exceptional precision and reliability but also highlight its superiority over
existing methods, making it a highly promising tool for automated diagnostic
systems.",http://arxiv.org/abs/2502.07755v1,Natural Language Processing,"medical, classification, diagnosis, data, contextual"
MeshSplats: Mesh-Based Rendering with Gaussian Splatting Initialization,"Gaussian Splatting (GS) is a recent and pivotal technique in 3D computer
graphics. GS-based algorithms almost always bypass classical methods such as
ray tracing, which offers numerous inherent advantages for rendering. For
example, ray tracing is able to handle incoherent rays for advanced lighting
effects, including shadows and reflections. To address this limitation, we
introduce MeshSplats, a method which converts GS to a mesh-like format.
Following the completion of training, MeshSplats transforms Gaussian elements
into mesh faces, enabling rendering using ray tracing methods with all their
associated benefits. Our model can be utilized immediately following
transformation, yielding a mesh of slightly reduced quality without additional
training. Furthermore, we can enhance the reconstruction quality through the
application of a dedicated optimization algorithm that operates on mesh faces
rather than Gaussian components. The efficacy of our method is substantiated by
experimental results, underscoring its extensive applications in computer
graphics and image processing.",http://arxiv.org/abs/2502.07754v1,Recommendation System,"mesh, gaussian, gs, ray, tracing"
Direct Ascent Synthesis: Revealing Hidden Generative Capabilities in Discriminative Models,"We demonstrate that discriminative models inherently contain powerful
generative capabilities, challenging the fundamental distinction between
discriminative and generative architectures. Our method, Direct Ascent
Synthesis (DAS), reveals these latent capabilities through multi-resolution
optimization of CLIP model representations. While traditional inversion
attempts produce adversarial patterns, DAS achieves high-quality image
synthesis by decomposing optimization across multiple spatial scales (1x1 to
224x224), requiring no additional training. This approach not only enables
diverse applications -- from text-to-image generation to style transfer -- but
maintains natural image statistics ($1/f^2$ spectrum) and guides the generation
away from non-robust adversarial patterns. Our results demonstrate that
standard discriminative models encode substantially richer generative knowledge
than previously recognized, providing new perspectives on model
interpretability and the relationship between adversarial examples and natural
image synthesis.",http://arxiv.org/abs/2502.07753v1,Recommendation System,"image, discriminative, generative, synthesis, adversarial"
Towards Efficient Optimizer Design for LLM via Structured Fisher Approximation with a Low-Rank Extension,"Designing efficient optimizers for large language models (LLMs) with
low-memory requirements and fast convergence is an important and challenging
problem. This paper makes a step towards the systematic design of such
optimizers through the lens of structured Fisher information matrix (FIM)
approximation. We show that many state-of-the-art efficient optimizers can be
viewed as solutions to FIM approximation (under the Frobenius norm) with
specific structural assumptions. Building on these insights, we propose two
design recommendations of practical efficient optimizers for LLMs, involving
the careful selection of structural assumptions to balance generality and
efficiency, and enhancing memory efficiency of optimizers with general
structures through a novel low-rank extension framework. We demonstrate how to
use each design approach by deriving new memory-efficient optimizers: Row and
Column Scaled SGD (RACS) and Adaptive low-dimensional subspace estimation
(Alice). Experiments on LLaMA pre-training (up to 1B parameters) validate the
effectiveness, showing faster and better convergence than existing
memory-efficient baselines and Adam with little memory overhead. Notably, Alice
achieves better than 2x faster convergence over Adam, while RACS delivers
strong performance on the 1B model with SGD-like memory.",http://arxiv.org/abs/2502.07752v1,Recommendation System,"optimizers, memory, efficient, low, convergence"
CausalGeD: Blending Causality and Diffusion for Spatial Gene Expression Generation,"The integration of single-cell RNA sequencing (scRNA-seq) and spatial
transcriptomics (ST) data is crucial for understanding gene expression in
spatial context. Existing methods for such integration have limited
performance, with structural similarity often below 60\%, We attribute this
limitation to the failure to consider causal relationships between genes. We
present CausalGeD, which combines diffusion and autoregressive processes to
leverage these relationships. By generalizing the Causal Attention Transformer
from image generation to gene expression data, our model captures regulatory
mechanisms without predefined relationships. Across 10 tissue datasets,
CausalGeD outperformed state-of-the-art baselines by 5- 32\% in key metrics,
including Pearson's correlation and structural similarity, advancing both
technical and biological insights.",http://arxiv.org/abs/2502.07751v1,Recommendation System,"relationships, integration, spatial, data, gene"
PFedDST: Personalized Federated Learning with Decentralized Selection Training,"Distributed Learning (DL) enables the training of machine learning models
across multiple devices, yet it faces challenges like non-IID data
distributions and device capability disparities, which can impede training
efficiency. Communication bottlenecks further complicate traditional Federated
Learning (FL) setups. To mitigate these issues, we introduce the Personalized
Federated Learning with Decentralized Selection Training (PFedDST) framework.
PFedDST enhances model training by allowing devices to strategically evaluate
and select peers based on a comprehensive communication score. This score
integrates loss, task similarity, and selection frequency, ensuring optimal
peer connections. This selection strategy is tailored to increase local
personalization and promote beneficial peer collaborations to strengthen the
stability and efficiency of the training process. Our experiments demonstrate
that PFedDST not only enhances model accuracy but also accelerates convergence.
This approach outperforms state-of-the-art methods in handling data
heterogeneity, delivering both faster and more effective training in diverse
and decentralized systems.",http://arxiv.org/abs/2502.07750v1,Recommendation System,"training, learning, selection, pfeddst, devices"
Whole-Genome Phenotype Prediction with Machine Learning: Open Problems in Bacterial Genomics,"How can we identify causal genetic mechanisms that govern bacterial traits?
Initial efforts entrusting machine learning models to handle the task of
predicting phenotype from genotype return high accuracy scores. However,
attempts to extract any meaning from the predictive models are found to be
corrupted by falsely identified ""causal"" features. Relying solely on pattern
recognition and correlations is unreliable, significantly so in bacterial
genomics settings where high-dimensionality and spurious associations are the
norm. Though it is not yet clear whether we can overcome this hurdle,
significant efforts are being made towards discovering potential high-risk
bacterial genetic variants. In view of this, we set up open problems
surrounding phenotype prediction from bacterial whole-genome datasets and
extending those to learning causal effects, and discuss challenges that impact
the reliability of a machine's decision-making when faced with datasets of this
nature.",http://arxiv.org/abs/2502.07749v1,Recommendation System,"bacterial, causal, high, genetic, efforts"
TransMLA: Multi-head Latent Attention Is All You Need,"Modern large language models (LLMs) often encounter communication bottlenecks
on current hardware, rather than purely computational constraints. Multi-head
Latent Attention (MLA) tackles this challenge by using low-rank matrices in the
key-value (KV) layers, thereby allowing compressed latent KV states to be
cached. This approach significantly reduces the KV cache size relative to
traditional multi-head attention, leading to faster inference. Moreover, MLA
employs an up-projection matrix to increase expressiveness, trading additional
computation for reduced communication overhead. Although MLA has demonstrated
efficiency and effectiveness in Deepseek V2/V3/R1, many major model providers
still rely on Group Query Attention (GQA) and have not announced any plans to
adopt MLA. In this paper, we show that GQA can always be represented by MLA
while maintaining the same KV cache overhead, but the converse does not hold.
To encourage broader use of MLA, we introduce **TransMLA**, a post-training
method that converts widely used GQA-based pre-trained models (e.g., LLaMA,
Qwen, Mixtral) into MLA-based models. After conversion, the model can undergo
additional training to boost expressiveness without increasing the KV cache
size. Furthermore, we plan to develop MLA-specific inference acceleration
techniques to preserve low latency in transformed models, thus enabling more
efficient distillation of Deepseek R1.",http://arxiv.org/abs/2502.07864v1,Recommendation System,"mla, kv, models, attention, cache"
WHODUNIT: Evaluation benchmark for culprit detection in mystery stories,"We present a novel data set, WhoDunIt, to assess the deductive reasoning
capabilities of large language models (LLM) within narrative contexts.
Constructed from open domain mystery novels and short stories, the dataset
challenges LLMs to identify the perpetrator after reading and comprehending the
story. To evaluate model robustness, we apply a range of character-level name
augmentations, including original names, name swaps, and substitutions with
well-known real and/or fictional entities from popular discourse. We further
use various prompting styles to investigate the influence of prompting on
deductive reasoning accuracy.
  We conduct evaluation study with state-of-the-art models, specifically
GPT-4o, GPT-4-turbo, and GPT-4o-mini, evaluated through multiple trials with
majority response selection to ensure reliability. The results demonstrate that
while LLMs perform reliably on unaltered texts, accuracy diminishes with
certain name substitutions, particularly those with wide recognition. This
dataset is publicly available here.",http://arxiv.org/abs/2502.07747v1,Natural Language Processing,"deductive, reasoning, models, dataset, llms"
HiPoNet: A Topology-Preserving Multi-View Neural Network For High Dimensional Point Cloud and Single-Cell Data,"In this paper, we propose HiPoNet, an end-to-end differentiable neural
network for regression, classification, and representation learning on
high-dimensional point clouds. Single-cell data can have high dimensionality
exceeding the capabilities of existing methods point cloud tailored for 3D
data. Moreover, modern single-cell and spatial experiments now yield entire
cohorts of datasets (i.e. one on every patient), necessitating models that can
process large, high-dimensional point clouds at scale. Most current approaches
build a single nearest-neighbor graph, discarding important geometric
information. In contrast, HiPoNet forms higher-order simplicial complexes
through learnable feature reweighting, generating multiple data views that
disentangle distinct biological processes. It then employs simplicial wavelet
transforms to extract multi-scale features - capturing both local and global
topology. We empirically show that these components preserve topological
information in the learned representations, and that HiPoNet significantly
outperforms state-of-the-art point-cloud and graph-based models on single cell.
We also show an application of HiPoNet on spatial transcriptomics datasets
using spatial co-ordinates as one of the views. Overall, HiPoNet offers a
robust and scalable solution for high-dimensional data analysis.",http://arxiv.org/abs/2502.07746v1,Recommendation System,"hiponet, high, point, single, data"
Advancing climate model interpretability: Feature attribution for Arctic melt anomalies,"The focus of our work is improving the interpretability of anomalies in
climate models and advancing our understanding of Arctic melt dynamics. The
Arctic and Antarctic ice sheets are experiencing rapid surface melting and
increased freshwater runoff, contributing significantly to global sea level
rise. Understanding the mechanisms driving snowmelt in these regions is
crucial. ERA5, a widely used reanalysis dataset in polar climate studies,
offers extensive climate variables and global data assimilation. However, its
snowmelt model employs an energy imbalance approach that may oversimplify the
complexity of surface melt. In contrast, the Glacier Energy and Mass Balance
(GEMB) model incorporates additional physical processes, such as snow
accumulation, firn densification, and meltwater percolation/refreezing,
providing a more detailed representation of surface melt dynamics. In this
research, we focus on analyzing surface snowmelt dynamics of the Greenland Ice
Sheet using feature attribution for anomalous melt events in ERA5 and GEMB
models. We present a novel unsupervised attribution method leveraging
counterfactual explanation method to analyze detected anomalies in ERA5 and
GEMB. Our anomaly detection results are validated using MEaSUREs ground-truth
data, and the attributions are evaluated against established feature ranking
methods, including XGBoost, Shapley values, and Random Forest. Our attribution
framework identifies the physics behind each model and the climate features
driving melt anomalies. These findings demonstrate the utility of our
attribution method in enhancing the interpretability of anomalies in climate
models and advancing our understanding of Arctic melt dynamics.",http://arxiv.org/abs/2502.07741v1,Recommendation System,"melt, climate, anomalies, dynamics, surface"
HRP: High-Rank Preheating for Superior LoRA Initialization,"This paper studies the crucial impact of initialization on the convergence
properties of Low-Rank Adaptation (LoRA). We theoretically demonstrate that
random initialization, a widely used schema, will likely lead LoRA to random
low-rank results, rather than the best low-rank result. While this issue can be
mitigated by adjusting initialization towards a well-informed direction, it
relies on prior knowledge of the target, which is typically unknown in
real-world scenarios. To approximate this well-informed initial direction, we
propose High-Rank Preheating (HRP), which fine-tunes high-rank LoRA for a few
steps and uses the singular value decomposition of the preheated result as a
superior initialization. HRP initialization is theory-supported to combine the
convergence strengths of high-rank LoRA and the generalization strengths of
low-rank LoRA. Extensive experiments demonstrate that HRP significantly
enhances LoRA's effectiveness across various models and tasks, achieving
performance comparable to full-parameter fine-tuning and outperforming other
initialization strategies.",http://arxiv.org/abs/2502.07739v1,Recommendation System,"rank, initialization, lora, low, high"
Next Block Prediction: Video Generation via Semi-Autoregressive Modeling,"Next-Token Prediction (NTP) is a de facto approach for autoregressive (AR)
video generation, but it suffers from suboptimal unidirectional dependencies
and slow inference speed. In this work, we propose a semi-autoregressive
(semi-AR) framework, called Next-Block Prediction (NBP), for video generation.
By uniformly decomposing video content into equal-sized blocks (e.g., rows or
frames), we shift the generation unit from individual tokens to blocks,
allowing each token in the current block to simultaneously predict the
corresponding token in the next block. Unlike traditional AR modeling, our
framework employs bidirectional attention within each block, enabling tokens to
capture more robust spatial dependencies. By predicting multiple tokens in
parallel, NBP models significantly reduce the number of generation steps,
leading to faster and more efficient inference. Our model achieves FVD scores
of 103.3 on UCF101 and 25.5 on K600, outperforming the vanilla NTP model by an
average of 4.4. Furthermore, thanks to the reduced number of inference steps,
the NBP model generates 8.89 frames (128x128 resolution) per second, achieving
an 11x speedup. We also explored model scales ranging from 700M to 3B
parameters, observing significant improvements in generation quality, with FVD
scores dropping from 103.3 to 55.3 on UCF101 and from 25.5 to 19.5 on K600,
demonstrating the scalability of our approach.",http://arxiv.org/abs/2502.07737v2,Recommendation System,"generation, block, model, token, ar"
Revisiting Non-Acyclic GFlowNets in Discrete Environments,"Generative Flow Networks (GFlowNets) are a family of generative models that
learn to sample objects from a given probability distribution, potentially
known up to a normalizing constant. Instead of working in the object space,
GFlowNets proceed by sampling trajectories in an appropriately constructed
directed acyclic graph environment, greatly relying on the acyclicity of the
graph. In our paper, we revisit the theory that relaxes the acyclicity
assumption and present a simpler theoretical framework for non-acyclic
GFlowNets in discrete environments. Moreover, we provide various novel
theoretical insights related to training with fixed backward policies, the
nature of flow functions, and connections between entropy-regularized RL and
non-acyclic GFlowNets, which naturally generalize the respective concepts and
theoretical results from the acyclic setting. In addition, we experimentally
re-examine the concept of loss stability in non-acyclic GFlowNet training, as
well as validate our own theoretical findings.",http://arxiv.org/abs/2502.07735v1,Recommendation System,"acyclic, gflownets, theoretical, non, generative"
EdgeEar: Efficient and Accurate Ear Recognition for Edge Devices,"Ear recognition is a contactless and unobtrusive biometric technique with
applications across various domains. However, deploying high-performing ear
recognition models on resource-constrained devices is challenging, limiting
their applicability and widespread adoption. This paper introduces EdgeEar, a
lightweight model based on a proposed hybrid CNN-transformer architecture to
solve this problem. By incorporating low-rank approximations into specific
linear layers, EdgeEar reduces its parameter count by a factor of 50 compared
to the current state-of-the-art, bringing it below two million while
maintaining competitive accuracy. Evaluation on the Unconstrained Ear
Recognition Challenge (UERC2023) benchmark shows that EdgeEar achieves the
lowest EER while significantly reducing computational costs. These findings
demonstrate the feasibility of efficient and accurate ear recognition, which we
believe will contribute to the wider adoption of ear biometrics.",http://arxiv.org/abs/2502.07734v1,Recommendation System,"ear, recognition, edgeear, adoption, contactless"
Economics of Sourcing Human Data,"Progress in AI has relied on human-generated data, from annotator
marketplaces to the wider Internet. However, the widespread use of large
language models now threatens the quality and integrity of human-generated data
on these very platforms. We argue that this issue goes beyond the immediate
challenge of filtering AI-generated content--it reveals deeper flaws in how
data collection systems are designed. Existing systems often prioritize speed,
scale, and efficiency at the cost of intrinsic human motivation, leading to
declining engagement and data quality. We propose that rethinking data
collection systems to align with contributors' intrinsic motivations--rather
than relying solely on external incentives--can help sustain high-quality data
sourcing at scale while maintaining contributor trust and long-term
participation.",http://arxiv.org/abs/2502.07732v1,Recommendation System,"data, human, generated, quality, systems"
Verifying LLM-Generated Code in the Context of Software Verification with Ada/SPARK,"Large language models (LLMs) have demonstrated remarkable code generation
capabilities, but the correctness of the generated code cannot be inherently
trusted. This paper explores the feasibility of using formal software
verification, specifically the SPARK framework for Ada, to ensure the
reliability of LLM-generated code. We present Marmaragan, a tool that leverages
an LLM in order to generate SPARK annotations for existing programs, enabling
formal verification of the code. The tool is benchmarked on a curated set of
SPARK programs, with annotations selectively removed to test specific
capabilities. The performance of Marmaragan with GPT-4o on the benchmark is
promising, with correct annotations having been generated for 50.7% of the
benchmark cases. The results establish a foundation for future work on
combining the power of LLMs with the reliability of formal software
verification.",http://arxiv.org/abs/2502.07728v1,Recommendation System,"code, generated, formal, verification, spark"
TMLC-Net: Transferable Meta Label Correction for Noisy Label Learning,"The prevalence of noisy labels in real-world datasets poses a significant
impediment to the effective deployment of deep learning models. While
meta-learning strategies have emerged as a promising approach for addressing
this challenge, existing methods often suffer from limited transferability and
task-specific designs. This paper introduces TMLC-Net, a novel Transferable
Meta-Learner for Correcting Noisy Labels, designed to overcome these
limitations. TMLC-Net learns a general-purpose label correction strategy that
can be readily applied across diverse datasets and model architectures without
requiring extensive retraining or fine-tuning. Our approach integrates three
core components: (1) Normalized Noise Perception, which captures and normalizes
training dynamics to handle distribution shifts; (2) Time-Series Encoding,
which models the temporal evolution of sample statistics using a recurrent
neural network; and (3) Subclass Decoding, which predicts a corrected label
distribution based on the learned representations. We conduct extensive
experiments on benchmark datasets with various noise types and levels,
demonstrating that TMLC-Net consistently outperforms state-of-the-art methods
in terms of both accuracy and robustness to label noise. Furthermore, we
analyze the transferability of TMLC-Net, showcasing its adaptability to new
datasets and noise conditions, and establishing its potential as a broadly
applicable solution for robust deep learning in noisy environments.",http://arxiv.org/abs/2502.07721v1,Recommendation System,"datasets, tmlc, net, noise, noisy"
ADMN: A Layer-Wise Adaptive Multimodal Network for Dynamic Input Noise and Compute Resources,"Multimodal deep learning systems are deployed in dynamic scenarios due to the
robustness afforded by multiple sensing modalities. Nevertheless, they struggle
with varying compute resource availability (due to multi-tenancy, device
heterogeneity, etc.) and fluctuating quality of inputs (from sensor feed
corruption, environmental noise, etc.). Current multimodal systems employ
static resource provisioning and cannot easily adapt when compute resources
change over time. Additionally, their reliance on processing sensor data with
fixed feature extractors is ill-equipped to handle variations in modality
quality. Consequently, uninformative modalities, such as those with high noise,
needlessly consume resources better allocated towards other modalities. We
propose ADMN, a layer-wise Adaptive Depth Multimodal Network capable of
tackling both challenges - it adjusts the total number of active layers across
all modalities to meet compute resource constraints, and continually
reallocates layers across input modalities according to their modality quality.
Our evaluations showcase ADMN can match the accuracy of state-of-the-art
networks while reducing up to 75% of their floating-point operations.",http://arxiv.org/abs/2502.07862v1,Recommendation System,"modalities, multimodal, compute, resource, quality"
BalanceKV: KV Cache Compression through Discrepancy Theory,"Large language models (LLMs) have achieved impressive success, but their high
memory requirements present challenges for long-context token generation. The
memory complexity of long-context LLMs is primarily due to the need to store
Key-Value (KV) embeddings in their KV cache. We present BalanceKV, a KV cache
compression method based on geometric sampling process stemming from
Banaszczyk's vector balancing theory, which introduces dependencies informed by
the geometry of keys and value tokens, and improves precision. BalanceKV offers
both theoretically proven and empirically validated performance improvements
over existing methods.",http://arxiv.org/abs/2502.07861v1,Recommendation System,"kv, llms, memory, present, long"
Near-Optimal Sample Complexity in Reward-Free Kernel-Based Reinforcement Learning,"Reinforcement Learning (RL) problems are being considered under increasingly
more complex structures. While tabular and linear models have been thoroughly
explored, the analytical study of RL under nonlinear function approximation,
especially kernel-based models, has recently gained traction for their strong
representational capacity and theoretical tractability. In this context, we
examine the question of statistical efficiency in kernel-based RL within the
reward-free RL framework, specifically asking: how many samples are required to
design a near-optimal policy? Existing work addresses this question under
restrictive assumptions about the class of kernel functions. We first explore
this question by assuming a generative model, then relax this assumption at the
cost of increasing the sample complexity by a factor of H, the length of the
episode. We tackle this fundamental problem using a broad class of kernels and
a simpler algorithm compared to prior work. Our approach derives new confidence
intervals for kernel ridge regression, specific to our RL setting, which may be
of broader applicability. We further validate our theoretical findings through
simulations.",http://arxiv.org/abs/2502.07715v1,Reinforcement Learning,"rl, kernel, question, models, based"
MAGELLAN: Metacognitive predictions of learning progress guide autotelic LLM agents in large goal spaces,"Open-ended learning agents must efficiently prioritize goals in vast
possibility spaces, focusing on those that maximize learning progress (LP).
When such autotelic exploration is achieved by LLM agents trained with online
RL in high-dimensional and evolving goal spaces, a key challenge for LP
prediction is modeling one's own competence, a form of metacognitive
monitoring. Traditional approaches either require extensive sampling or rely on
brittle expert-defined goal groupings. We introduce MAGELLAN, a metacognitive
framework that lets LLM agents learn to predict their competence and LP online.
By capturing semantic relationships between goals, MAGELLAN enables
sample-efficient LP estimation and dynamic adaptation to evolving goal spaces
through generalization. In an interactive learning environment, we show that
MAGELLAN improves LP prediction efficiency and goal prioritization, being the
only method allowing the agent to fully master a large and evolving goal space.
These results demonstrate how augmenting LLM agents with a metacognitive
ability for LP predictions can effectively scale curriculum learning to
open-ended goal spaces.",http://arxiv.org/abs/2502.07709v2,Recommendation System,"lp, goal, learning, agents, spaces"
PRVQL: Progressive Knowledge-guided Refinement for Robust Egocentric Visual Query Localization,"Egocentric visual query localization (EgoVQL) focuses on localizing the
target of interest in space and time from first-person videos, given a visual
query. Despite recent progressive, existing methods often struggle to handle
severe object appearance changes and cluttering background in the video due to
lacking sufficient target cues, leading to degradation. Addressing this, we
introduce PRVQL, a novel Progressive knowledge-guided Refinement framework for
EgoVQL. The core is to continuously exploit target-relevant knowledge directly
from videos and utilize it as guidance to refine both query and video features
for improving target localization. Our PRVQL contains multiple processing
stages. The target knowledge from one stage, comprising appearance and spatial
knowledge extracted via two specially designed knowledge learning modules, are
utilized as guidance to refine the query and videos features for the next
stage, which are used to generate more accurate knowledge for further feature
refinement. With such a progressive process, target knowledge in PRVQL can be
gradually improved, which, in turn, leads to better refined query and video
features for localization in the final stage. Compared to previous methods, our
PRVQL, besides the given object cues, enjoys additional crucial target
information from a video as guidance to refine features, and hence enhances
EgoVQL in complicated scenes. In our experiments on challenging Ego4D, PRVQL
achieves state-of-the-art result and largely surpasses other methods, showing
its efficacy. Our code, model and results will be released at
https://github.com/fb-reps/PRVQL.",http://arxiv.org/abs/2502.07707v1,Reinforcement Learning,"target, knowledge, query, prvql, video"
Magic 1-For-1: Generating One Minute Video Clips within One Minute,"In this technical report, we present Magic 1-For-1 (Magic141), an efficient
video generation model with optimized memory consumption and inference latency.
The key idea is simple: factorize the text-to-video generation task into two
separate easier tasks for diffusion step distillation, namely text-to-image
generation and image-to-video generation. We verify that with the same
optimization algorithm, the image-to-video task is indeed easier to converge
over the text-to-video task. We also explore a bag of optimization tricks to
reduce the computational cost of training the image-to-video (I2V) models from
three aspects: 1) model convergence speedup by using a multi-modal prior
condition injection; 2) inference latency speed up by applying an adversarial
step distillation, and 3) inference memory cost optimization with parameter
sparsification. With those techniques, we are able to generate 5-second video
clips within 3 seconds. By applying a test time sliding window, we are able to
generate a minute-long video within one minute with significantly improved
visual quality and motion dynamics, spending less than 1 second for generating
1 second video clips on average. We conduct a series of preliminary
explorations to find out the optimal tradeoff between computational cost and
video quality during diffusion step distillation and hope this could be a good
foundation model for open-source explorations. The code and the model weights
are available at https://github.com/DA-Group-PKU/Magic-1-For-1.",http://arxiv.org/abs/2502.07701v1,Recommendation System,"video, generation, model, image, inference"
SoK: A Classification for AI-driven Personalized Privacy Assistants,"To help users make privacy-related decisions, personalized privacy assistants
based on AI technology have been developed in recent years. These AI-driven
Personalized Privacy Assistants (AI-driven PPAs) can reap significant benefits
for users, who may otherwise struggle to make decisions regarding their
personal data in environments saturated with privacy-related decision requests.
However, no study systematically inquired about the features of these AI-driven
PPAs, their underlying technologies, or the accuracy of their decisions. To
fill this gap, we present a Systematization of Knowledge (SoK) to map the
existing solutions found in the scientific literature. We screened 1697 unique
research papers over the last decade (2013-2023), constructing a classification
from 39 included papers. As a result, this SoK reviews several aspects of
existing research on AI-driven PPAs in terms of types of publications,
contributions, methodological quality, and other quantitative insights.
Furthermore, we provide a comprehensive classification for AI-driven PPAs,
delving into their architectural choices, system contexts, types of AI used,
data sources, types of decisions, and control over decisions, among other
facets. Based on our SoK, we further underline the research gaps and challenges
and formulate recommendations for the design and development of AI-driven PPAs
as well as avenues for future research.",http://arxiv.org/abs/2502.07693v2,Recommendation System,"ai, driven, decisions, ppas, privacy"
Matrix3D: Large Photogrammetry Model All-in-One,"We present Matrix3D, a unified model that performs several photogrammetry
subtasks, including pose estimation, depth prediction, and novel view synthesis
using just the same model. Matrix3D utilizes a multi-modal diffusion
transformer (DiT) to integrate transformations across several modalities, such
as images, camera parameters, and depth maps. The key to Matrix3D's large-scale
multi-modal training lies in the incorporation of a mask learning strategy.
This enables full-modality model training even with partially complete data,
such as bi-modality data of image-pose and image-depth pairs, thus
significantly increases the pool of available training data. Matrix3D
demonstrates state-of-the-art performance in pose estimation and novel view
synthesis tasks. Additionally, it offers fine-grained control through
multi-round interactions, making it an innovative tool for 3D content creation.
Project page: https://nju-3dv.github.io/projects/matrix3d.",http://arxiv.org/abs/2502.07685v1,Recommendation System,"model, pose, depth, multi, training"
Multiview Point Cloud Registration Based on Minimum Potential Energy for Free-Form Blade Measurement,"Point cloud registration is an essential step for free-form blade
reconstruction in industrial measurement. Nonetheless, measuring defects of the
3D acquisition system unavoidably result in noisy and incomplete point cloud
data, which renders efficient and accurate registration challenging. In this
paper, we propose a novel global registration method that is based on the
minimum potential energy (MPE) method to address these problems. The basic
strategy is that the objective function is defined as the minimum potential
energy optimization function of the physical registration system. The function
distributes more weight to the majority of inlier points and less weight to the
noise and outliers, which essentially reduces the influence of perturbations in
the mathematical formulation. We decompose the solution into a globally optimal
approximation procedure and a fine registration process with the trimmed
iterative closest point algorithm to boost convergence. The approximation
procedure consists of two main steps. First, according to the construction of
the force traction operator, we can simply compute the position of the
potential energy minimum. Second, to find the MPE point, we propose a new
theory that employs two flags to observe the status of the registration
procedure. We demonstrate the performance of the proposed algorithm on four
types of blades. The proposed method outperforms the other global methods in
terms of both accuracy and noise resistance.",http://arxiv.org/abs/2502.07680v1,Recommendation System,"registration, point, method, minimum, potential"
Automatic Prostate Volume Estimation in Transabdominal Ultrasound Images,"Prostate cancer is a leading health concern among men, requiring accurate and
accessible methods for early detection and risk stratification. Prostate volume
(PV) is a key parameter in multivariate risk stratification for early prostate
cancer detection, commonly estimated using transrectal ultrasound (TRUS). While
TRUS provides precise prostate volume measurements, its invasive nature often
compromises patient comfort. Transabdominal ultrasound (TAUS) provides a
non-invasive alternative but faces challenges such as lower image quality,
complex interpretation, and reliance on operator expertise. This study
introduces a new deep-learning-based framework for automatic PV estimation
using TAUS, emphasizing its potential to enable accurate and non-invasive
prostate cancer risk stratification. A dataset of TAUS videos from 100
individual patients was curated, with manually delineated prostate boundaries
and calculated diameters by an expert clinician as ground truth. The introduced
framework integrates deep-learning models for prostate segmentation in both
axial and sagittal planes, automatic prostate diameter estimation, and PV
calculation. Segmentation performance was evaluated using Dice correlation
coefficient (%) and Hausdorff distance (mm). Framework's volume estimation
capabilities were evaluated on volumetric error (mL). The framework
demonstrates that it can estimate PV from TAUS videos with a mean volumetric
error of -5.5 mL, which results in an average relative error between 5 and 15%.
The introduced framework for automatic PV estimation from TAUS images,
utilizing deep learning models for prostate segmentation, shows promising
results. It effectively segments the prostate and estimates its volume,
offering potential for reliable, non-invasive risk stratification for early
prostate detection.",http://arxiv.org/abs/2502.07859v1,Recommendation System,"prostate, pv, taus, framework, risk"
MAAT: Mamba Adaptive Anomaly Transformer with association discrepancy for time series,"Anomaly detection in time series is essential for industrial monitoring and
environmental sensing, yet distinguishing anomalies from complex patterns
remains challenging. Existing methods like the Anomaly Transformer and
DCdetector have progressed, but they face limitations such as sensitivity to
short-term contexts and inefficiency in noisy, non-stationary environments.
  To overcome these issues, we introduce MAAT, an improved architecture that
enhances association discrepancy modeling and reconstruction quality. MAAT
features Sparse Attention, efficiently capturing long-range dependencies by
focusing on relevant time steps, thereby reducing computational redundancy.
Additionally, a Mamba-Selective State Space Model is incorporated into the
reconstruction module, utilizing a skip connection and Gated Attention to
improve anomaly localization and detection performance.
  Extensive experiments show that MAAT significantly outperforms previous
methods, achieving better anomaly distinguishability and generalization across
various time series applications, setting a new standard for unsupervised time
series anomaly detection in real-world scenarios.",http://arxiv.org/abs/2502.07858v1,Recommendation System,"anomaly, time, detection, series, maat"
SNAP: Sequential Non-Ancestor Pruning for Targeted Causal Effect Estimation With an Unknown Graph,"Causal discovery can be computationally demanding for large numbers of
variables. If we only wish to estimate the causal effects on a small subset of
target variables, we might not need to learn the causal graph for all
variables, but only a small subgraph that includes the targets and their
adjustment sets. In this paper, we focus on identifying causal effects between
target variables in a computationally and statistically efficient way. This
task combines causal discovery and effect estimation, aligning the discovery
objective with the effects to be estimated. We show that definite non-ancestors
of the targets are unnecessary to learn causal relations between the targets
and to identify efficient adjustments sets. We sequentially identify and prune
these definite non-ancestors with our Sequential Non-Ancestor Pruning (SNAP)
framework, which can be used either as a preprocessing step to standard causal
discovery methods, or as a standalone sound and complete causal discovery
algorithm. Our results on synthetic and real data show that both approaches
substantially reduce the number of independence tests and the computation time
without compromising the quality of causal effect estimations.",http://arxiv.org/abs/2502.07857v1,Recommendation System,"causal, discovery, variables, effects, targets"
Cheap Permutation Testing,"Permutation tests are a popular choice for distinguishing distributions and
testing independence, due to their exact, finite-sample control of false
positives and their minimax optimality when paired with U-statistics. However,
standard permutation tests are also expensive, requiring a test statistic to be
computed hundreds or thousands of times to detect a separation between
distributions. In this work, we offer a simple approach to accelerate testing:
group your datapoints into bins and permute only those bins. For U and
V-statistics, we prove that these cheap permutation tests have two remarkable
properties. First, by storing appropriate sufficient statistics, a cheap test
can be run in time comparable to evaluating a single test statistic. Second,
cheap permutation power closely approximates standard permutation power. As a
result, cheap tests inherit the exact false positive control and minimax
optimality of standard permutation tests while running in a fraction of the
time. We complement these findings with improved power guarantees for standard
permutation testing and experiments demonstrating the benefits of cheap
permutations over standard maximum mean discrepancy (MMD), Hilbert-Schmidt
independence criterion (HSIC), random Fourier feature, Wilcoxon-Mann-Whitney,
cross-MMD, and cross-HSIC tests.",http://arxiv.org/abs/2502.07672v1,Recommendation System,"permutation, tests, standard, cheap, testing"
Human Decision-making is Susceptible to AI-driven Manipulation,"Artificial Intelligence (AI) systems are increasingly intertwined with daily
life, assisting users in executing various tasks and providing guidance on
decision-making. This integration introduces risks of AI-driven manipulation,
where such systems may exploit users' cognitive biases and emotional
vulnerabilities to steer them toward harmful outcomes. Through a randomized
controlled trial with 233 participants, we examined human susceptibility to
such manipulation in financial (e.g., purchases) and emotional (e.g., conflict
resolution) decision-making contexts. Participants interacted with one of three
AI agents: a neutral agent (NA) optimizing for user benefit without explicit
influence, a manipulative agent (MA) designed to covertly influence beliefs and
behaviors, or a strategy-enhanced manipulative agent (SEMA) employing explicit
psychological tactics to reach its hidden objectives. By analyzing
participants' decision patterns and shifts in their preference ratings
post-interaction, we found significant susceptibility to AI-driven
manipulation. Particularly, across both decision-making domains, participants
interacting with the manipulative agents shifted toward harmful options at
substantially higher rates (financial, MA: 62.3%, SEMA: 59.6%; emotional, MA:
42.3%, SEMA: 41.5%) compared to the NA group (financial, 35.8%; emotional,
12.8%). Notably, our findings reveal that even subtle manipulative objectives
(MA) can be as effective as employing explicit psychological strategies (SEMA)
in swaying human decision-making. By revealing the potential for covert AI
influence, this study highlights a critical vulnerability in human-AI
interactions, emphasizing the need for ethical safeguards and regulatory
frameworks to ensure responsible deployment of AI technologies and protect
human autonomy.",http://arxiv.org/abs/2502.07663v1,Recommendation System,"ai, decision, making, emotional, participants"
Partial-Label Learning with Conformal Candidate Cleaning,"Real-world data is often ambiguous; for example, human annotation produces
instances with multiple conflicting class labels. Partial-label learning (PLL)
aims at training a classifier in this challenging setting, where each instance
is associated with a set of candidate labels and one correct, but unknown,
class label. A multitude of algorithms targeting this setting exists and, to
enhance their prediction quality, several extensions that are applicable across
a wide range of PLL methods have been introduced. While many of these
extensions rely on heuristics, this article proposes a novel enhancing method
that incrementally prunes candidate sets using conformal prediction. To work
around the missing labeled validation set, which is typically required for
conformal prediction, we propose a strategy that alternates between training a
PLL classifier to label the validation set, leveraging these predicted class
labels for calibration, and pruning candidate labels that are not part of the
resulting conformal sets. In this sense, our method alternates between
empirical risk minimization and candidate set pruning. We establish that our
pruning method preserves the conformal validity with respect to the unknown
ground truth. Our extensive experiments on artificial and real-world data show
that the proposed approach significantly improves the test set accuracies of
several state-of-the-art PLL classifiers.",http://arxiv.org/abs/2502.07661v1,Recommendation System,"set, labels, pll, candidate, conformal"
"Private Low-Rank Approximation for Covariance Matrices, Dyson Brownian Motion, and Eigenvalue-Gap Bounds for Gaussian Perturbations","We consider the problem of approximating a $d \times d$ covariance matrix $M$
with a rank-$k$ matrix under $(\varepsilon,\delta)$-differential privacy. We
present and analyze a complex variant of the Gaussian mechanism and obtain
upper bounds on the Frobenius norm of the difference between the matrix output
by this mechanism and the best rank-$k$ approximation to $M$. Our analysis
provides improvements over previous bounds, particularly when the spectrum of
$M$ satisfies natural structural assumptions. The novel insight is to view the
addition of Gaussian noise to a matrix as a continuous-time matrix Brownian
motion. This viewpoint allows us to track the evolution of eigenvalues and
eigenvectors of the matrix, which are governed by stochastic differential
equations discovered by Dyson. These equations enable us to upper bound the
Frobenius distance between the best rank-$k$ approximation of $M$ and that of a
Gaussian perturbation of $M$ as an integral that involves inverse eigenvalue
gaps of the stochastically evolving matrix, as opposed to a sum of perturbation
bounds obtained via Davis-Kahan-type theorems. Subsequently, again using the
Dyson Brownian motion viewpoint, we show that the eigenvalues of the matrix $M$
perturbed by Gaussian noise have large gaps with high probability. These
results also contribute to the analysis of low-rank approximations under
average-case perturbations, and to an understanding of eigenvalue gaps for
random matrices, both of which may be of independent interest.",http://arxiv.org/abs/2502.07657v1,Recommendation System,"matrix, gaussian, bounds, gaps, mechanism"
A Unifying Framework for Causal Imitation Learning with Hidden Confounders,"We propose a general and unifying framework for causal Imitation Learning
(IL) with hidden confounders that subsumes several existing confounded IL
settings from the literature. Our framework accounts for two types of hidden
confounders: (a) those observed by the expert, which thus influence the
expert's policy, and (b) confounding noise hidden to both the expert and the IL
algorithm. For additional flexibility, we also introduce a confounding noise
horizon and time-varying expert-observable hidden variables. We show that
causal IL in our framework can be reduced to a set of Conditional Moment
Restrictions (CMRs) by leveraging trajectory histories as instruments to learn
a history-dependent policy. We propose DML-IL, a novel algorithm that uses
instrumental variable regression to solve these CMRs and learn a policy. We
provide a bound on the imitation gap for DML-IL, which recovers prior results
as special cases. Empirical evaluation on a toy environment with continues
state-action spaces and multiple Mujoco tasks demonstrate that DML-IL
outperforms state-of-the-art causal IL algorithms.",http://arxiv.org/abs/2502.07656v1,Recommendation System,"il, hidden, expert, framework, causal"
Guiding Time-Varying Generative Models with Natural Gradients on Exponential Family Manifold,"Optimising probabilistic models is a well-studied field in statistics.
However, its connection with the training of generative models remains largely
under-explored. In this paper, we show that the evolution of time-varying
generative models can be projected onto an exponential family manifold,
naturally creating a link between the parameters of a generative model and
those of a probabilistic model. We then train the generative model by moving
its projection on the manifold according to the natural gradient descent
scheme. This approach also allows us to approximate the natural gradient of the
KL divergence efficiently without relying on MCMC for intractable models.
Furthermore, we propose particle versions of the algorithm, which feature
closed-form update rules for any parametric model within the exponential
family. Through toy and real-world experiments, we validate the effectiveness
of the proposed algorithms.",http://arxiv.org/abs/2502.07650v1,Recommendation System,"models, generative, model, probabilistic, exponential"
Causal Additive Models with Unobserved Causal Paths and Backdoor Paths,"Causal additive models have been employed as tractable yet expressive
frameworks for causal discovery involving hidden variables. State-of-the-art
methodologies suggest that determining the causal relationship between a pair
of variables is infeasible in the presence of an unobserved backdoor or an
unobserved causal path. Contrary to this assumption, we theoretically show that
resolving the causal direction is feasible in certain scenarios by
incorporating two novel components into the theory. The first component
introduces a novel characterization of regression sets within independence
between regression residuals. The second component leverages conditional
independence among the observed variables. We also provide a search algorithm
that integrates these innovations and demonstrate its competitive performance
against existing methods.",http://arxiv.org/abs/2502.07646v1,Recommendation System,"causal, variables, unobserved, novel, component"
SymGPT: Auditing Smart Contracts via Combining Symbolic Execution with Large Language Models,"To govern smart contracts running on Ethereum, multiple Ethereum Request for
Comment (ERC) standards have been developed, each having a set of rules to
guide the behaviors of smart contracts. Violating the ERC rules could cause
serious security issues and financial loss, signifying the importance of
verifying smart contracts follow ERCs. Today's practices of such verification
are to manually audit each single contract, use expert-developed
program-analysis tools, or use large language models (LLMs), all of which are
far from effective in identifying ERC rule violations. This paper introduces
SymGPT, a tool that combines the natural language understanding of large
language models (LLMs) with the formal guarantees of symbolic execution to
automatically verify smart contracts' compliance with ERC rules. To develop
SymGPT, we conduct an empirical study of 132 ERC rules from three widely used
ERC standards, examining their content, security implications, and natural
language descriptions. Based on this study, we design SymGPT by first
instructing an LLM to translate ERC rules into a defined EBNF grammar. We then
synthesize constraints from the formalized rules to represent scenarios where
violations may occur and use symbolic execution to detect them. Our evaluation
shows that SymGPT identifies 5,783 ERC rule violations in 4,000 real-world
contracts, including 1,375 violations with clear attack paths for stealing
financial assets, demonstrating its effectiveness. Furthermore, SymGPT
outperforms six automated techniques and a security-expert auditing service,
underscoring its superiority over current smart contract analysis methods.",http://arxiv.org/abs/2502.07644v2,Natural Language Processing,"erc, rules, smart, contracts, symgpt"
FoQA: A Faroese Question-Answering Dataset,"We present FoQA, a Faroese extractive question-answering (QA) dataset with
2,000 samples, created using a semi-automated approach combining Large Language
Models (LLMs) and human validation. The dataset was generated from Faroese
Wikipedia articles using GPT-4-turbo for initial QA generation, followed by
question rephrasing to increase complexity and native speaker validation to
ensure quality. We provide baseline performance metrics for FoQA across
multiple models, including LLMs and BERT, demonstrating its effectiveness in
evaluating Faroese QA performance. The dataset is released in three versions: a
validated set of 2,000 samples, a complete set of all 10,001 generated samples,
and a set of 2,395 rejected samples for error analysis.",http://arxiv.org/abs/2502.07642v1,Recommendation System,"samples, faroese, qa, dataset, set"
Distributional Instrumental Variable Method,"The instrumental variable (IV) approach is commonly used to infer causal
effects in the presence of unmeasured confounding. Conventional IV models
commonly make the additive noise assumption, which is hard to ensure in
practice, but also typically lack flexibility if the causal effects are
complex. Further, the vast majority of the existing methods aims to estimate
the mean causal effects only, a few other methods focus on the quantile
effects. This work aims for estimation of the entire interventional
distribution. We propose a novel method called distributional instrumental
variables (DIV), which leverages generative modelling in a nonlinear
instrumental variable setting. We establish identifiability of the
interventional distribution under general assumptions and demonstrate an
`under-identified' case where DIV can identify the causal effects while
two-step least squares fails to. Our empirical results show that the DIV method
performs well for a broad range of simulated data, exhibiting advantages over
existing IV approaches in terms of the identifiability and estimation error of
the mean or quantile treatment effects. Furthermore, we apply DIV to an
economic data set to examine the causal relation between institutional quality
and economic development and our results that closely align with the original
study. We also apply DIV to a single-cell data set, where we study the
generalizability and stability in predicting gene expression under unseen
interventions. The software implementations of DIV are available in R and
Python.",http://arxiv.org/abs/2502.07641v1,Reinforcement Learning,"effects, div, causal, instrumental, iv"
Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving,"We introduce Goedel-Prover, an open-source large language model (LLM) that
achieves the state-of-the-art (SOTA) performance in automated formal proof
generation for mathematical problems. The key challenge in this field is the
scarcity of formalized math statements and proofs, which we tackle in the
following ways. We train statement formalizers to translate the natural
language math problems from Numina into formal language (Lean 4), creating a
dataset of 1.64 million formal statements. LLMs are used to check that the
formal statements accurately preserve the content of the original natural
language problems. We then iteratively build a large dataset of formal proofs
by training a series of provers. Each prover succeeds in proving many
statements that the previous ones could not, and these new proofs are added to
the training set for the next prover. The final prover outperforms all existing
open-source models in whole-proof generation. On the miniF2F benchmark, it
achieves a 57.6% success rate (Pass@32), exceeding the previous best
open-source model by 7.6%. On PutnamBench, Goedel-Prover successfully solves 7
problems (Pass@512), ranking first on the leaderboard. Furthermore, it
generates 29.7K formal proofs for Lean Workbook problems, nearly doubling the
15.7K produced by earlier works.",http://arxiv.org/abs/2502.07640v1,Recommendation System,"formal, prover, problems, language, statements"
Consistency Training with Physical Constraints,"We propose a physics-aware Consistency Training (CT) method that accelerates
sampling in Diffusion Models with physical constraints. Our approach leverages
a two-stage strategy: (1) learning the noise-to-data mapping via CT, and (2)
incorporating physics constraints as a regularizer. Experiments on toy examples
show that our method generates samples in a single step while adhering to the
imposed constraints. This approach has the potential to efficiently solve
partial differential equations (PDEs) using deep generative modeling.",http://arxiv.org/abs/2502.07636v1,Reinforcement Learning,"constraints, physics, ct, method, approach"
Distributed Value Decomposition Networks with Networked Agents,"We investigate the problem of distributed training under partial
observability, whereby cooperative multi-agent reinforcement learning agents
(MARL) maximize the expected cumulative joint reward. We propose distributed
value decomposition networks (DVDN) that generate a joint Q-function that
factorizes into agent-wise Q-functions. Whereas the original value
decomposition networks rely on centralized training, our approach is suitable
for domains where centralized training is not possible and agents must learn by
interacting with the physical environment in a decentralized manner while
communicating with their peers. DVDN overcomes the need for centralized
training by locally estimating the shared objective. We contribute with two
innovative algorithms, DVDN and DVDN (GT), for the heterogeneous and
homogeneous agents settings respectively. Empirically, both algorithms
approximate the performance of value decomposition networks, in spite of the
information loss during communication, as demonstrated in ten MARL tasks in
three standard environments.",http://arxiv.org/abs/2502.07635v1,Reinforcement Learning,"training, dvdn, agents, value, decomposition"
Divide and Merge: Motion and Semantic Learning in End-to-End Autonomous Driving,"Perceiving the environment and its changes over time corresponds to two
fundamental yet heterogeneous types of information: semantics and motion.
Previous end-to-end autonomous driving works represent both types of
information in a single feature vector. However, including motion tasks, such
as prediction and planning, always impairs detection and tracking performance,
a phenomenon known as negative transfer in multi-task learning. To address this
issue, we propose Neural-Bayes motion decoding, a novel parallel detection,
tracking, and prediction method separating semantic and motion learning,
similar to the Bayes filter. Specifically, we employ a set of learned motion
queries that operate in parallel with the detection and tracking queries,
sharing a unified set of recursively updated reference points. Moreover, we
employ interactive semantic decoding to enhance information exchange in
semantic tasks, promoting positive transfer. Experiments on the nuScenes
dataset show improvements of 5% in detection and 11% in tracking. Our method
achieves state-of-the-art collision rates in open-loop planning evaluation
without any modifications to the planning module.",http://arxiv.org/abs/2502.07631v1,Recommendation System,"motion, detection, tracking, information, planning"
Rethinking Timing Residuals: Advancing PET Detectors with Explicit TOF Corrections,"PET is a functional imaging method that visualizes metabolic processes. TOF
information can be derived from coincident detector signals and incorporated
into image reconstruction to enhance the SNR. PET detectors are typically
assessed by their CTR, but timing performance is degraded by various factors.
Research on timing calibration seeks to mitigate these degradations and restore
accurate timing information. While many calibration methods use analytical
approaches, machine learning techniques have recently gained attention due to
their flexibility. We developed a residual physics-based calibration approach
that combines prior domain knowledge with the power of machine learning models.
This approach begins with an initial analytical calibration addressing
first-order skews. The remaining deviations, regarded as residual effects, are
used to train machine learning models to eliminate higher-order skews. The key
advantage is that the experimenter guides the learning process through the
definition of timing residuals. In earlier studies, we developed models that
directly predicted the expected time difference, which offered corrections only
implicitly (implicit correction models). In this study, we introduce a new
definition for timing residuals, enabling us to train models that directly
predict correction values (explicit correction models). The explicit correction
approach significantly simplifies data acquisition, improves linearity, and
enhances timing performance from $371 \pm 6$ ps to $281 \pm 5$ ps for
coincidences from 430 keV to 590 keV. Additionally, the new definition reduces
model size, making it suitable for high-throughput applications like PET
scanners. Experiments were conducted using two detector stacks composed of $4
\times 4$ LYSO:Ce,Ca crystals ($3.8\times 3.8\times 20$ mm$^{3}$) coupled to $4
\times 4$ Broadcom NUV-MT SiPMs and digitized with the TOFPET2 ASIC.",http://arxiv.org/abs/2502.07630v1,Recommendation System,"timing, models, calibration, learning, correction"
Causal-Informed Contrastive Learning: Towards Bias-Resilient Pre-training under Concept Drift,"The evolution of large-scale contrastive pre-training propelled by top-tier
datasets has reached a transition point in the scaling law. Consequently,
sustaining and enhancing a model's pre-training capabilities in drift
environments have surfaced as a notable challenge. In this paper, we initially
uncover that contrastive pre-training methods are significantly impacted by
concept drift wherein distributions change unpredictably, resulting in notable
biases in the feature space of the pre-trained model. Empowered by causal
inference, we construct a structural causal graph to analyze the impact of
concept drift to contrastive pre-training systemically, and propose the causal
interventional contrastive objective. Upon achieving this, we devise a
resilient contrastive pre-training approach to accommodate the data stream of
concept drift, with simple and scalable implementation. Extensive experiments
on various downstream tasks demonstrate our resilient contrastive pre-training
effectively mitigates the bias stemming from the concept drift data stream.
Codes are available at https://anonymous.4open.science/r/ResilientCL/.",http://arxiv.org/abs/2502.07620v1,Reinforcement Learning,"pre, contrastive, training, drift, concept"
Scaling Pre-training to One Hundred Billion Data for Vision Language Models,"We provide an empirical investigation of the potential of pre-training
vision-language models on an unprecedented scale: 100 billion examples. We find
that model performance tends to saturate at this scale on many common
Western-centric classification and retrieval benchmarks, such as COCO Captions.
Nevertheless, tasks of cultural diversity achieve more substantial gains from
the 100-billion scale web data, thanks to its coverage of long-tail concepts.
Furthermore, we analyze the model's multilinguality and show gains in
low-resource languages as well. In addition, we observe that reducing the size
of the pretraining dataset via quality filters like using CLIP, typically used
to enhance performance, may inadvertently reduce the cultural diversity
represented even in large-scale datasets. Our results highlight that while
traditional benchmarks may not benefit significantly from scaling noisy, raw
web data to 100 billion examples, this data scale is vital for building truly
inclusive multimodal systems.",http://arxiv.org/abs/2502.07617v1,Computer Vision,"scale, billion, data, examples, model"
Flow Distillation Sampling: Regularizing 3D Gaussians with Pre-trained Matching Priors,"3D Gaussian Splatting (3DGS) has achieved excellent rendering quality with
fast training and rendering speed. However, its optimization process lacks
explicit geometric constraints, leading to suboptimal geometric reconstruction
in regions with sparse or no observational input views. In this work, we try to
mitigate the issue by incorporating a pre-trained matching prior to the 3DGS
optimization process. We introduce Flow Distillation Sampling (FDS), a
technique that leverages pre-trained geometric knowledge to bolster the
accuracy of the Gaussian radiance field. Our method employs a strategic
sampling technique to target unobserved views adjacent to the input views,
utilizing the optical flow calculated from the matching model (Prior Flow) to
guide the flow analytically calculated from the 3DGS geometry (Radiance Flow).
Comprehensive experiments in depth rendering, mesh reconstruction, and novel
view synthesis showcase the significant advantages of FDS over state-of-the-art
methods. Additionally, our interpretive experiments and analysis aim to shed
light on the effects of FDS on geometric accuracy and rendering quality,
potentially providing readers with insights into its performance. Project page:
https://nju-3dv.github.io/projects/fds",http://arxiv.org/abs/2502.07615v1,Recommendation System,"flow, rendering, geometric, views, fds"
Tractable Transformers for Flexible Conditional Generation,"Non-autoregressive (NAR) generative models are valuable because they can
handle diverse conditional generation tasks in a more principled way than their
autoregressive (AR) counterparts, which are constrained by sequential
dependency requirements. Recent advancements in NAR models, such as diffusion
language models, have demonstrated superior performance in unconditional
generation compared to AR models (e.g., GPTs) of similar sizes. However, such
improvements do not always lead to improved conditional generation performance.
We show that a key reason for this gap is the difficulty in generalizing to
conditional probability queries unseen during training. As a result, strong
unconditional generation performance does not guarantee high-quality
conditional generation. This paper proposes Tractable Transformers
(Tracformer), a Transformer-based generative model that is more robust to
different conditional generation tasks. Unlike existing models that rely solely
on global contextual features derived from full inputs, Tracformers incorporate
a sparse Transformer encoder to capture both local and global contextual
information. This information is routed through a decoder for conditional
generation. Empirical results demonstrate that Tracformers achieve
state-of-the-art conditional generation performance on text modeling compared
to recent diffusion and AR model baselines.",http://arxiv.org/abs/2502.07616v1,Reinforcement Learning,"generation, conditional, models, performance, ar"
Beyond Prompting: Time2Lang -- Bridging Time-Series Foundation Models and Large Language Models for Health Sensing,"Large language models (LLMs) show promise for health applications when
combined with behavioral sensing data. Traditional approaches convert sensor
data into text prompts, but this process is prone to errors, computationally
expensive, and requires domain expertise. These challenges are particularly
acute when processing extended time series data. While time series foundation
models (TFMs) have recently emerged as powerful tools for learning
representations from temporal data, bridging TFMs and LLMs remains challenging.
Here, we present Time2Lang, a framework that directly maps TFM outputs to LLM
representations without intermediate text conversion. Our approach first trains
on synthetic data using periodicity prediction as a pretext task, followed by
evaluation on mental health classification tasks. We validate Time2Lang on two
longitudinal wearable and mobile sensing datasets: daily depression prediction
using step count data (17,251 days from 256 participants) and flourishing
classification based on conversation duration (46 participants over 10 weeks).
Time2Lang maintains near constant inference times regardless of input length,
unlike traditional prompting methods. The generated embeddings preserve
essential time-series characteristics such as auto-correlation. Our results
demonstrate that TFMs and LLMs can be effectively integrated while minimizing
information loss and enabling performance transfer across these distinct
modeling paradigms. To our knowledge, we are the first to integrate a TFM and
an LLM for health, thus establishing a foundation for future research combining
general-purpose large models for complex healthcare tasks.",http://arxiv.org/abs/2502.07608v2,Recommendation System,"data, models, llms, health, time"
MRS: A Fast Sampler for Mean Reverting Diffusion based on ODE and SDE Solvers,"In applications of diffusion models, controllable generation is of practical
significance, but is also challenging. Current methods for controllable
generation primarily focus on modifying the score function of diffusion models,
while Mean Reverting (MR) Diffusion directly modifies the structure of the
stochastic differential equation (SDE), making the incorporation of image
conditions simpler and more natural. However, current training-free fast
samplers are not directly applicable to MR Diffusion. And thus MR Diffusion
requires hundreds of NFEs (number of function evaluations) to obtain
high-quality samples. In this paper, we propose a new algorithm named MRS (MR
Sampler) to reduce the sampling NFEs of MR Diffusion. We solve the reverse-time
SDE and the probability flow ordinary differential equation (PF-ODE) associated
with MR Diffusion, and derive semi-analytical solutions. The solutions consist
of an analytical function and an integral parameterized by a neural network.
Based on this solution, we can generate high-quality samples in fewer steps.
Our approach does not require training and supports all mainstream
parameterizations, including noise prediction, data prediction and velocity
prediction. Extensive experiments demonstrate that MR Sampler maintains high
sampling quality with a speedup of 10 to 20 times across ten different image
restoration tasks. Our algorithm accelerates the sampling procedure of MR
Diffusion, making it more practical in controllable generation.",http://arxiv.org/abs/2502.07856v1,Recommendation System,"diffusion, mr, controllable, generation, function"
Algorithmic Aspects of Strategic Trading,"Algorithmic trading in modern financial markets is widely acknowledged to
exhibit strategic, game-theoretic behaviors whose complexity can be difficult
to model. A recent series of papers (Chriss, 2024b,c,a, 2025) has made progress
in the setting of trading for position building. Here parties wish to buy or
sell a fixed number of shares in a fixed time period in the presence of both
temporary and permanent market impact, resulting in exponentially large
strategy spaces. While these papers primarily consider the existence and
structural properties of equilibrium strategies, in this work we focus on the
algorithmic aspects of the proposed model. We give an efficient algorithm for
computing best responses, and show that while the temporary impact only setting
yields a potential game, best response dynamics do not generally converge for
the general setting, for which no fast algorithm for (Nash) equilibrium
computation is known. This leads us to consider the broader notion of Coarse
Correlated Equilibria (CCE), which we show can be computed efficiently via an
implementation of Follow the Perturbed Leader (FTPL). We illustrate the model
and our results with an experimental investigation, where FTPL exhibits
interesting behavior in different regimes of the relative weighting between
temporary and permanent market impact.",http://arxiv.org/abs/2502.07606v1,Recommendation System,"model, setting, temporary, impact, algorithmic"
An Improved Optimal Proximal Gradient Algorithm for Non-Blind Image Deblurring,"Image deblurring remains a central research area within image processing,
critical for its role in enhancing image quality and facilitating clearer
visual representations across diverse applications. This paper tackles the
optimization problem of image deblurring, assuming a known blurring kernel. We
introduce an improved optimal proximal gradient algorithm (IOptISTA), which
builds upon the optimal gradient method and a weighting matrix, to efficiently
address the non-blind image deblurring problem. Based on two regularization
cases, namely the $l_1$ norm and total variation norm, we perform numerical
experiments to assess the performance of our proposed algorithm. The results
indicate that our algorithm yields enhanced PSNR and SSIM values, as well as a
reduced tolerance, compared to existing methods.",http://arxiv.org/abs/2502.07602v1,Recommendation System,"image, deblurring, algorithm, problem, optimal"
Towards Zero-Shot Anomaly Detection and Reasoning with Multimodal Large Language Models,"Zero-Shot Anomaly Detection (ZSAD) is an emerging AD paradigm. Unlike the
traditional unsupervised AD setting that requires a large number of normal
samples to train a model, ZSAD is more practical for handling data-restricted
real-world scenarios. Recently, Multimodal Large Language Models (MLLMs) have
shown revolutionary reasoning capabilities in various vision tasks. However,
the reasoning of image abnormalities remains underexplored due to the lack of
corresponding datasets and benchmarks. To facilitate research in AD &
reasoning, we establish the first visual instruction tuning dataset,
Anomaly-Instruct-125k, and the evaluation benchmark, VisA-D&R. Through
investigation with our benchmark, we reveal that current MLLMs like GPT-4o
cannot accurately detect and describe fine-grained anomalous details in images.
To address this, we propose Anomaly-OneVision (Anomaly-OV), the first
specialist visual assistant for ZSAD and reasoning. Inspired by human behavior
in visual inspection, Anomaly-OV leverages a Look-Twice Feature Matching (LTFM)
mechanism to adaptively select and emphasize abnormal visual tokens. Extensive
experiments demonstrate that Anomaly-OV achieves significant improvements over
advanced generalist models in both detection and reasoning. Extensions to
medical and 3D AD are provided for future study. The link to our project page:
https://xujiacong.github.io/Anomaly-OV/",http://arxiv.org/abs/2502.07601v1,Computer Vision,"anomaly, reasoning, ad, visual, zsad"
PlaySlot: Learning Inverse Latent Dynamics for Controllable Object-Centric Video Prediction and Planning,"Predicting future scene representations is a crucial task for enabling robots
to understand and interact with the environment. However, most existing methods
rely on video sequences and simulations with precise action annotations,
limiting their ability to leverage the large amount of available unlabeled
video data. To address this challenge, we propose PlaySlot, an object-centric
video prediction model that infers object representations and latent actions
from unlabeled video sequences. It then uses these representations to forecast
future object states and video frames. PlaySlot allows to generate multiple
possible futures conditioned on latent actions, which can be inferred from
video dynamics, provided by a user, or generated by a learned action policy,
thus enabling versatile and interpretable world modeling. Our results show that
PlaySlot outperforms both stochastic and object-centric baselines for video
prediction across different environments. Furthermore, we show that our
inferred latent actions can be used to learn robot behaviors sample-efficiently
from unlabeled video demonstrations. Videos and code are available at
https://play-slot.github.io/PlaySlot/.",http://arxiv.org/abs/2502.07600v1,Reinforcement Learning,"video, object, representations, unlabeled, playslot"
YOLO Network For Defect Detection In Optical lenses,"Mass-produced optical lenses often exhibit defects that alter their
scattering properties and compromise quality standards. Manual inspection is
usually adopted to detect defects, but it is not recommended due to low
accuracy, high error rate and limited scalability. To address these challenges,
this study presents an automated defect detection system based on the YOLOv8
deep learning model. A custom dataset of optical lenses, annotated with defect
and lens regions, was created to train the model. Experimental results obtained
in this study reveal that the system can be used to efficiently and accurately
detect defects in optical lenses. The proposed system can be utilized in
real-time industrial environments to enhance quality control processes by
enabling reliable and scalable defect detection in optical lens manufacturing.",http://arxiv.org/abs/2502.07592v1,Recommendation System,"optical, lenses, defects, defect, system"
DMWM: Dual-Mind World Model with Long-Term Imagination,"Imagination in world models is crucial for enabling agents to learn
long-horizon policy in a sample-efficient manner. Existing recurrent
state-space model (RSSM)-based world models depend on single-step statistical
inference to capture the environment dynamics, and, hence, they are unable to
perform long-term imagination tasks due to the accumulation of prediction
errors. Inspired by the dual-process theory of human cognition, we propose a
novel dual-mind world model (DMWM) framework that integrates logical reasoning
to enable imagination with logical consistency. DMWM is composed of two
components: an RSSM-based System 1 (RSSM-S1) component that handles state
transitions in an intuitive manner and a logic-integrated neural network-based
System 2 (LINN-S2) component that guides the imagination process through
hierarchical deep logical reasoning. The inter-system feedback mechanism is
designed to ensure that the imagination process follows the logical rules of
the real environment. The proposed framework is evaluated on benchmark tasks
that require long-term planning from the DMControl suite. Extensive
experimental results demonstrate that the proposed framework yields significant
improvements in terms of logical coherence, trial efficiency, data efficiency
and long-term imagination over the state-of-the-art world models.",http://arxiv.org/abs/2502.07591v1,Recommendation System,"imagination, logical, world, long, models"
DSV: Exploiting Dynamic Sparsity to Accelerate Large-Scale Video DiT Training,"Diffusion Transformers (DiTs) have shown remarkable performance in modeling
and generating high-quality videos. However, the quadratic computational
complexity of 3D full attention mechanism presents significant challenges in
scaling video DiT training, especially for high-definition and lengthy videos,
where attention can dominate up to 95% of the end-to-end time and necessitate
specialized communication paradigms to handle large input sizes.
  This paper introduces DSV, a novel framework designed to accelerate and scale
the training of video DiTs by leveraging the inherent dynamic attention
sparsity throughout the training process. DSV employs a two-stage training
algorithm that exploits sparsity patterns, focusing on critical elements
supported by efficient, tailored kernels. To accommodate the new sparsity
dimension, we develop a hybrid sparsity-aware context parallelism that
effectively scales to large inputs by addressing the heterogeneity of sparsity
across attention heads and blocks, resulting in optimized sparse computation
and communication. Extensive evaluations demonstrate that DSV achieves up to
3.02x gain in training throughput with nearly no quality degradation.",http://arxiv.org/abs/2502.07590v1,Recommendation System,"training, sparsity, attention, dsv, dits"
SEMU: Singular Value Decomposition for Efficient Machine Unlearning,"While the capabilities of generative foundational models have advanced
rapidly in recent years, methods to prevent harmful and unsafe behaviors remain
underdeveloped. Among the pressing challenges in AI safety, machine unlearning
(MU) has become increasingly critical to meet upcoming safety regulations. Most
existing MU approaches focus on altering the most significant parameters of the
model. However, these methods often require fine-tuning substantial portions of
the model, resulting in high computational costs and training instabilities,
which are typically mitigated by access to the original training dataset.
  In this work, we address these limitations by leveraging Singular Value
Decomposition (SVD) to create a compact, low-dimensional projection that
enables the selective forgetting of specific data points. We propose Singular
Value Decomposition for Efficient Machine Unlearning (SEMU), a novel approach
designed to optimize MU in two key aspects. First, SEMU minimizes the number of
model parameters that need to be modified, effectively removing unwanted
knowledge while making only minimal changes to the model's weights. Second,
SEMU eliminates the dependency on the original training dataset, preserving the
model's previously acquired knowledge without additional data requirements.
  Extensive experiments demonstrate that SEMU achieves competitive performance
while significantly improving efficiency in terms of both data usage and the
number of modified parameters.",http://arxiv.org/abs/2502.07587v1,Recommendation System,"model, semu, mu, parameters, training"
We Can't Understand AI Using our Existing Vocabulary,"This position paper argues that, in order to understand AI, we cannot rely on
our existing vocabulary of human words. Instead, we should strive to develop
neologisms: new words that represent precise human concepts that we want to
teach machines, or machine concepts that we need to learn. We start from the
premise that humans and machines have differing concepts. This means
interpretability can be framed as a communication problem: humans must be able
to reference and control machine concepts, and communicate human concepts to
machines. Creating a shared human-machine language through developing
neologisms, we believe, could solve this communication problem. Successful
neologisms achieve a useful amount of abstraction: not too detailed, so they're
reusable in many contexts, and not too high-level, so they convey precise
information. As a proof of concept, we demonstrate how a ""length neologism""
enables controlling LLM response length, while a ""diversity neologism"" allows
sampling more variable responses. Taken together, we argue that we cannot
understand AI using our existing vocabulary, and expanding it through
neologisms creates opportunities for both controlling and understanding
machines better.",http://arxiv.org/abs/2502.07586v1,Recommendation System,"concepts, human, neologisms, machines, machine"
Understanding the Generalization Error of Markov algorithms through Poissonization,"Using continuous-time stochastic differential equation (SDE) proxies to
stochastic optimization algorithms has proven fruitful for understanding their
generalization abilities. A significant part of these approaches are based on
the so-called ``entropy flows'', which greatly simplify the generalization
analysis. Unfortunately, such well-structured entropy flows cannot be obtained
for most discrete-time algorithms, and the existing SDE approaches remain
limited to specific noise and algorithmic structures. We aim to alleviate this
issue by introducing a generic framework for analyzing the generalization error
of Markov algorithms through `Poissonization', a continuous-time approximation
of discrete-time processes with formal approximation guarantees. Through this
approach, we first develop a novel entropy flow, which directly leads to
PAC-Bayesian generalization bounds. We then draw novel links to modified
versions of the celebrated logarithmic Sobolev inequalities (LSI), identify
cases where such LSIs are satisfied, and obtain improved bounds. Beyond its
generality, our framework allows exploiting specific properties of learning
algorithms. In particular, we incorporate the noise structure of different
algorithm types - namely, those with additional noise injections (noisy) and
those without (non-noisy) - through various technical tools. This illustrates
the capacity of our methods to achieve known (yet, Poissonized) and new
generalization bounds.",http://arxiv.org/abs/2502.07584v1,Recommendation System,"generalization, time, algorithms, entropy, noise"
Generative Modeling with Bayesian Sample Inference,"We derive a novel generative model from the simple act of Gaussian posterior
inference. Treating the generated sample as an unknown variable to infer lets
us formulate the sampling process in the language of Bayesian probability. Our
model uses a sequence of prediction and posterior update steps to narrow down
the unknown sample from a broad initial belief. In addition to a rigorous
theoretical analysis, we establish a connection between our model and diffusion
models and show that it includes Bayesian Flow Networks (BFNs) as a special
case. In our experiments, we demonstrate improved performance over both BFNs
and Variational Diffusion Models, achieving competitive likelihood scores on
CIFAR10 and ImageNet.",http://arxiv.org/abs/2502.07580v1,Reinforcement Learning,"model, posterior, sample, unknown, bayesian"
Single-Step Consistent Diffusion Samplers,"Sampling from unnormalized target distributions is a fundamental yet
challenging task in machine learning and statistics. Existing sampling
algorithms typically require many iterative steps to produce high-quality
samples, leading to high computational costs that limit their practicality in
time-sensitive or resource-constrained settings. In this work, we introduce
consistent diffusion samplers, a new class of samplers designed to generate
high-fidelity samples in a single step. We first develop a distillation
algorithm to train a consistent diffusion sampler from a pretrained diffusion
model without pre-collecting large datasets of samples. Our algorithm leverages
incomplete sampling trajectories and noisy intermediate states directly from
the diffusion process. We further propose a method to train a consistent
diffusion sampler from scratch, fully amortizing exploration by training a
single model that both performs diffusion sampling and skips intermediate steps
using a self-consistency loss. Through extensive experiments on a variety of
unnormalized distributions, we show that our approach yields high-fidelity
samples using less than 1% of the network evaluations required by traditional
diffusion samplers.",http://arxiv.org/abs/2502.07579v1,Recommendation System,"diffusion, sampling, high, samples, consistent"
Automated Capability Discovery via Model Self-Exploration,"Foundation models have become general-purpose assistants, exhibiting diverse
capabilities across numerous domains through training on web-scale data. It
remains challenging to precisely characterize even a fraction of the full
spectrum of capabilities and potential risks in any new model. Existing
evaluation approaches often require significant human effort, and it is taking
increasing effort to design ever harder challenges for more capable models. We
introduce Automated Capability Discovery (ACD), a framework that designates one
foundation model as a scientist to systematically propose open-ended tasks
probing the abilities of a subject model (potentially itself). By combining
frontier models with ideas from the field of open-endedness, ACD automatically
and systematically uncovers both surprising capabilities and failures in the
subject model. We demonstrate ACD across a range of foundation models
(including the GPT, Claude, and Llama series), showing that it automatically
reveals thousands of capabilities that would be challenging for any single team
to uncover. We further validate our method's automated scoring with extensive
human surveys, observing high agreement between model-generated and human
evaluations. By leveraging foundation models' ability to both create tasks and
self-evaluate, ACD is a significant step toward scalable, automated evaluation
of novel AI systems. All code and evaluation logs are open-sourced at
https://github.com/conglu1997/ACD.",http://arxiv.org/abs/2502.07577v2,Recommendation System,"models, model, foundation, capabilities, acd"
Vision-Language Models for Edge Networks: A Comprehensive Survey,"Vision Large Language Models (VLMs) combine visual understanding with natural
language processing, enabling tasks like image captioning, visual question
answering, and video analysis. While VLMs show impressive capabilities across
domains such as autonomous vehicles, smart surveillance, and healthcare, their
deployment on resource-constrained edge devices remains challenging due to
processing power, memory, and energy limitations. This survey explores recent
advancements in optimizing VLMs for edge environments, focusing on model
compression techniques, including pruning, quantization, knowledge
distillation, and specialized hardware solutions that enhance efficiency. We
provide a detailed discussion of efficient training and fine-tuning methods,
edge deployment challenges, and privacy considerations. Additionally, we
discuss the diverse applications of lightweight VLMs across healthcare,
environmental monitoring, and autonomous systems, illustrating their growing
impact. By highlighting key design strategies, current challenges, and offering
recommendations for future directions, this survey aims to inspire further
research into the practical deployment of VLMs, ultimately making advanced AI
accessible in resource-limited settings.",http://arxiv.org/abs/2502.07855v1,Recommendation System,"vlms, deployment, edge, language, visual"
An Elliptic Curve Based Solution to the Perspective-Three-Point Problem,"The Perspective-Three-Point Problem (P3P) is solved by first focusing on
determining the directions of the lines through pairs of control points,
relative to the camera, rather than the distances from the camera to the
control points. The analysis of this produces an efficient, accurate and
reasonably simple P3P solver, which is compared with a state-of-the-art P3P
solver, ""Lambda Twist."" Both methods depend on the accurate computation of a
single root of a cubic polynomial. They have been implemented and tested for a
wide range of control-point triangles, and under certain reasonable
restrictions, the new method is noticably more accurate than Lambda Twist,
though it is slower. However, the principal value of the present work is not in
introducing yet another P3P solver, but lies rather in the discovery of an
intimate connection between the P3P problem and a special family of elliptic
curves that includes curves utilized in cryptography. This holds the potential
for further advances in a number of directions. To make this connection, an
interesting spherical analogue of an ancient ""sliding"" problem is stated and
solved.",http://arxiv.org/abs/2502.07564v1,Computer Vision,"problem, control, accurate, solver, point"
LASP-2: Rethinking Sequence Parallelism for Linear Attention and Its Hybrid,"Linear sequence modeling approaches, such as linear attention, provide
advantages like linear-time training and constant-memory inference over
sequence lengths. However, existing sequence parallelism (SP) methods are
either not optimized for the right-product-first feature of linear attention or
use a ring-style communication strategy, which results in lower computation
parallelism, limits their scalability for longer sequences in distributed
systems. In this paper, we introduce LASP-2, a new SP method to enhance both
communication and computation parallelism when training linear attention
transformer models with very-long input sequences. Compared to previous work
LASP, LASP-2 rethinks the minimal communication requirement for SP on linear
attention layers, reorganizes the whole communication-computation workflow of
LASP. In this way, only one single AllGather collective communication is needed
on intermediate memory states, whose sizes are independent of the sequence
length, leading to significant improvements of both communication and
computation parallelism, as well as their overlap. Additionally, we extend
LASP-2 to LASP-2H by applying similar communication redesign to standard
attention modules, offering an efficient SP solution for hybrid models that
blend linear and standard attention layers. Our evaluation on a Linear-Llama3
model, a variant of Llama3 with linear attention replacing standard attention,
demonstrates the effectiveness of LASP-2 and LASP-2H. Specifically, LASP-2
achieves training speed improvements of 15.2% over LASP and 36.6% over Ring
Attention, with a sequence length of 2048K across 64 GPUs. The Code is released
as a part of: https://github.com/OpenSparseLLMs/Linear-MoE.",http://arxiv.org/abs/2502.07563v1,Recommendation System,"linear, attention, communication, sequence, parallelism"
LoRP-TTS: Low-Rank Personalized Text-To-Speech,"Speech synthesis models convert written text into natural-sounding audio.
While earlier models were limited to a single speaker, recent advancements have
led to the development of zero-shot systems that generate realistic speech from
a wide range of speakers using their voices as additional prompts. However,
they still struggle with imitating non-studio-quality samples that differ
significantly from the training datasets. In this work, we demonstrate that
utilizing Low-Rank Adaptation (LoRA) allows us to successfully use even single
recordings of spontaneous speech in noisy environments as prompts. This
approach enhances speaker similarity by up to $30pp$ while preserving content
and naturalness. It represents a significant step toward creating truly diverse
speech corpora, that is crucial in all speech-related tasks.",http://arxiv.org/abs/2502.07562v1,Reinforcement Learning,"speech, models, single, speaker, prompts"
Navigating Semantic Drift in Task-Agnostic Class-Incremental Learning,"Class-incremental learning (CIL) seeks to enable a model to sequentially
learn new classes while retaining knowledge of previously learned ones.
Balancing flexibility and stability remains a significant challenge,
particularly when the task ID is unknown. To address this, our study reveals
that the gap in feature distribution between novel and existing tasks is
primarily driven by differences in mean and covariance moments. Building on
this insight, we propose a novel semantic drift calibration method that
incorporates mean shift compensation and covariance calibration. Specifically,
we calculate each class's mean by averaging its sample embeddings and estimate
task shifts using weighted embedding changes based on their proximity to the
previous mean, effectively capturing mean shifts for all learned classes with
each new task. We also apply Mahalanobis distance constraint for covariance
calibration, aligning class-specific embedding covariances between old and
current networks to mitigate the covariance shift. Additionally, we integrate a
feature-level self-distillation approach to enhance generalization.
Comprehensive experiments on commonly used datasets demonstrate the
effectiveness of our approach. The source code is available at
\href{https://github.com/fwu11/MACIL.git}{https://github.com/fwu11/MACIL.git}.",http://arxiv.org/abs/2502.07560v1,Reinforcement Learning,"mean, covariance, class, task, calibration"
Efficient Sparsification of Simplicial Complexes via Local Densities of States,"Simplicial complexes (SCs), a generalization of graph models for relational
data that account for higher-order relations between data items, have become a
popular abstraction for analyzing complex data using tools from topological
data analysis or topological signal processing. However, the analysis of many
real-world datasets leads to dense SCs with a large number of higher-order
interactions. Unfortunately, analyzing such large SCs often has a prohibitive
cost in terms of computation time and memory consumption. The sparsification of
such complexes, i.e., the approximation of an original SC with a sparser
simplicial complex with only a log-linear number of high-order simplices while
maintaining a spectrum close to the original SC, is of broad interest.
  In this work, we develop a novel method for a probabilistic sparsifaction of
SCs. At its core lies the efficient computation of sparsifying sampling
probability through local densities of states as functional descriptors of the
spectral information. To avoid pathological structures in the spectrum of the
corresponding Hodge Laplacian operators, we suggest a ""kernel-ignoring""
decomposition for approximating the sampling probability; additionally, we
exploit error estimates to show asymptotically prevailing algorithmic
complexity of the developed method. The performance of the framework is
demonstrated on the family of Vietoris--Rips filtered simplicial complexes.",http://arxiv.org/abs/2502.07558v1,Recommendation System,"scs, data, simplicial, complexes, order"
SketchFlex: Facilitating Spatial-Semantic Coherence in Text-to-Image Generation with Region-Based Sketches,"Text-to-image models can generate visually appealing images from text
descriptions. Efforts have been devoted to improving model controls with prompt
tuning and spatial conditioning. However, our formative study highlights the
challenges for non-expert users in crafting appropriate prompts and specifying
fine-grained spatial conditions (e.g., depth or canny references) to generate
semantically cohesive images, especially when multiple objects are involved. In
response, we introduce SketchFlex, an interactive system designed to improve
the flexibility of spatially conditioned image generation using rough region
sketches. The system automatically infers user prompts with rational
descriptions within a semantic space enriched by crowd-sourced object
attributes and relationships. Additionally, SketchFlex refines users' rough
sketches into canny-based shape anchors, ensuring the generation quality and
alignment of user intentions. Experimental results demonstrate that SketchFlex
achieves more cohesive image generations than end-to-end models, meanwhile
significantly reducing cognitive load and better matching user intentions
compared to region-based generation baseline.",http://arxiv.org/abs/2502.07556v1,Reinforcement Learning,"image, sketchflex, generation, user, text"
Attention Learning is Needed to Efficiently Learn Parity Function,"Transformers, with their attention mechanisms, have emerged as the
state-of-the-art architectures of sequential modeling and empirically
outperform feed-forward neural networks (FFNNs) across many fields, such as
natural language processing and computer vision. However, their generalization
ability, particularly for low-sensitivity functions, remains less studied. We
bridge this gap by analyzing transformers on the $k$-parity problem. Daniely
and Malach (NeurIPS 2020) show that FFNNs with one hidden layer and $O(nk^7
\log k)$ parameters can learn $k$-parity, where the input length $n$ is
typically much larger than $k$. In this paper, we prove that FFNNs require at
least $\Omega(n)$ parameters to learn $k$-parity, while transformers require
only $O(k)$ parameters, surpassing the theoretical lower bound needed by FFNNs.
We further prove that this parameter efficiency cannot be achieved with fixed
attention heads. Our work establishes transformers as theoretically superior to
FFNNs in learning parity function, showing how their attention mechanisms
enable parameter-efficient generalization in functions with low sensitivity.",http://arxiv.org/abs/2502.07553v1,Natural Language Processing,"ffnns, transformers, attention, parameters, mechanisms"
Unsupervised Translation of Emergent Communication,"Emergent Communication (EC) provides a unique window into the language
systems that emerge autonomously when agents are trained to jointly achieve
shared goals. However, it is difficult to interpret EC and evaluate its
relationship with natural languages (NL). This study employs unsupervised
neural machine translation (UNMT) techniques to decipher ECs formed during
referential games with varying task complexities, influenced by the semantic
diversity of the environment. Our findings demonstrate UNMT's potential to
translate EC, illustrating that task complexity characterized by semantic
diversity enhances EC translatability, while higher task complexity with
constrained semantic variability exhibits pragmatic EC, which, although
challenging to interpret, remains suitable for translation. This research marks
the first attempt, to our knowledge, to translate EC without the aid of
parallel data.",http://arxiv.org/abs/2502.07552v1,Natural Language Processing,"ec, task, semantic, interpret, translation"
Early Stopping Against Label Noise Without Validation Data,"Early stopping methods in deep learning face the challenge of balancing the
volume of training and validation data, especially in the presence of label
noise. Concretely, sparing more data for validation from training data would
limit the performance of the learned model, yet insufficient validation data
could result in a sub-optimal selection of the desired model. In this paper, we
propose a novel early stopping method called Label Wave, which does not require
validation data for selecting the desired model in the presence of label noise.
It works by tracking the changes in the model's predictions on the training set
during the training process, aiming to halt training before the model unduly
fits mislabeled data. This method is empirically supported by our observation
that minimum fluctuations in predictions typically occur at the training epoch
before the model excessively fits mislabeled data. Through extensive
experiments, we show both the effectiveness of the Label Wave method across
various settings and its capability to enhance the performance of existing
methods for learning with noisy labels.",http://arxiv.org/abs/2502.07551v1,Recommendation System,"data, training, model, validation, label"
HGTUL: A Hypergraph-based Model For Trajectory User Linking,"Trajectory User Linking (TUL), which links anonymous trajectories with users
who generate them, plays a crucial role in modeling human mobility. Despite
significant advancements in this field, existing studies primarily neglect the
high-order inter-trajectory relationships, which represent complex associations
among multiple trajectories, manifested through multi-location co-occurrence
patterns emerging when trajectories intersect at various Points of Interest
(POIs). Furthermore, they also overlook the variable influence of POIs on
different trajectories, as well as the user class imbalance problem caused by
disparities in user activity levels and check-in frequencies. To address these
limitations, we propose a novel HyperGraph-based multi-perspective Trajectory
User Linking model (HGTUL). Our model learns trajectory representations from
both relational and spatio-temporal perspectives: (1) it captures high-order
associations among trajectories by constructing a trajectory hypergraph and
leverages a hypergraph attention network to learn the variable impact of POIs
on trajectories; (2) it models the spatio-temporal characteristics of
trajectories by incorporating their temporal and spatial information into a
sequential encoder. Moreover, we design a data balancing method to effectively
address the user class imbalance problem and experimentally validate its
significance in TUL. Extensive experiments on three real-world datasets
demonstrate that HGTUL outperforms state-of-the-art baselines, achieving
improvements of 2.57%~20.09% and 5.68%~26.00% in ACC@1 and Macro-F1 metrics,
respectively.",http://arxiv.org/abs/2502.07549v1,Reinforcement Learning,"trajectories, trajectory, user, pois, hypergraph"
Instance-dependent Early Stopping,"In machine learning practice, early stopping has been widely used to
regularize models and can save computational costs by halting the training
process when the model's performance on a validation set stops improving.
However, conventional early stopping applies the same stopping criterion to all
instances without considering their individual learning statuses, which leads
to redundant computations on instances that are already well-learned. To
further improve the efficiency, we propose an Instance-dependent Early Stopping
(IES) method that adapts the early stopping mechanism from the entire training
set to the instance level, based on the core principle that once the model has
mastered an instance, the training on it should stop. IES considers an instance
as mastered if the second-order differences of its loss value remain within a
small range around zero. This offers a more consistent measure of an instance's
learning status compared with directly using the loss value, and thus allows
for a unified threshold to determine when an instance can be excluded from
further backpropagation. We show that excluding mastered instances from
backpropagation can increase the gradient norms, thereby accelerating the
decrease of the training loss and speeding up the training process. Extensive
experiments on benchmarks demonstrate that IES method can reduce
backpropagation instances by 10%-50% while maintaining or even slightly
improving the test accuracy and transfer learning performance of a model.",http://arxiv.org/abs/2502.07547v1,Recommendation System,"instance, stopping, training, learning, early"
Exoplanet Transit Candidate Identification in TESS Full-Frame Images via a Transformer-Based Algorithm,"The Transiting Exoplanet Survey Satellite (TESS) is surveying a large
fraction of the sky, generating a vast database of photometric time series data
that requires thorough analysis to identify exoplanetary transit signals.
Automated learning approaches have been successfully applied to identify
transit signals. However, most existing methods focus on the classification and
validation of candidates, while few efforts have explored new techniques for
the search of candidates. To search for new exoplanet transit candidates, we
propose an approach to identify exoplanet transit signals without the need for
phase folding or assuming periodicity in the transit signals, such as those
observed in multi-transit light curves. To achieve this, we implement a new
neural network inspired by Transformers to directly process Full Frame Image
(FFI) light curves to detect exoplanet transits. Transformers, originally
developed for natural language processing, have recently demonstrated
significant success in capturing long-range dependencies compared to previous
approaches focused on sequential data. This ability allows us to employ
multi-head self-attention to identify exoplanet transit signals directly from
the complete light curves, combined with background and centroid time series,
without requiring prior transit parameters. The network is trained to learn
characteristics of the transit signal, like the dip shape, which helps
distinguish planetary transits from other variability sources. Our model
successfully identified 214 new planetary system candidates, including 122
multi-transit light curves, 88 single-transit and 4 multi-planet systems from
TESS sectors 1-26 with a radius > 0.27 $R_{\mathrm{Jupiter}}$, demonstrating
its ability to detect transits regardless of their periodicity.",http://arxiv.org/abs/2502.07542v1,Reinforcement Learning,"transit, exoplanet, signals, identify, candidates"
Diffusion-LAM: Probabilistic Limited Area Weather Forecasting with Diffusion,"Machine learning methods have been shown to be effective for weather
forecasting, based on the speed and accuracy compared to traditional numerical
models. While early efforts primarily concentrated on deterministic
predictions, the field has increasingly shifted toward probabilistic
forecasting to better capture the forecast uncertainty. Most machine
learning-based models have been designed for global-scale predictions, with
only limited work targeting regional or limited area forecasting, which allows
more specialized and flexible modeling for specific locations. This work
introduces Diffusion-LAM, a probabilistic limited area weather model leveraging
conditional diffusion. By conditioning on boundary data from surrounding
regions, our approach generates forecasts within a defined area. Experimental
results on the MEPS limited area dataset demonstrate the potential of
Diffusion-LAM to deliver accurate probabilistic forecasts, highlighting its
promise for limited-area weather prediction.",http://arxiv.org/abs/2502.07532v1,Recommendation System,"limited, area, weather, forecasting, probabilistic"
Advancing Heat Demand Forecasting with Attention Mechanisms: Opportunities and Challenges,"Global leaders and policymakers are unified in their unequivocal commitment
to decarbonization efforts in support of Net-Zero agreements. District Heating
Systems (DHS), while contributing to carbon emissions due to the continued
reliance on fossil fuels for heat production, are embracing more sustainable
practices albeit with some sense of vulnerability as it could constrain their
ability to adapt to dynamic demand and production scenarios. As demographic
demands grow and renewables become the central strategy in decarbonizing the
heating sector, the need for accurate demand forecasting has intensified.
Advances in digitization have paved the way for Machine Learning (ML) based
solutions to become the industry standard for modeling complex time series
patterns. In this paper, we focus on building a Deep Learning (DL) model that
uses deconstructed components of independent and dependent variables that
affect heat demand as features to perform multi-step ahead forecasting of head
demand. The model represents the input features in a time-frequency space and
uses an attention mechanism to generate accurate forecasts. The proposed method
is evaluated on a real-world dataset and the forecasting performance is
assessed against LSTM and CNN-based forecasting models. Across different supply
zones, the attention-based models outperforms the baselines quantitatively and
qualitatively, with an Mean Absolute Error (MAE) of 0.105 with a standard
deviation of 0.06kW h and a Mean Absolute Percentage Error (MAPE) of 5.4% with
a standard deviation of 2.8%, in comparison the second best model with a MAE of
0.10 with a standard deviation of 0.06kW h and a MAPE of 5.6% with a standard
deviation of 3%.",http://arxiv.org/abs/2502.07854v1,Recommendation System,"standard, demand, forecasting, deviation, based"
"VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation","Recent image-to-video generation methods have demonstrated success in
enabling control over one or two visual elements, such as camera trajectory or
object motion. However, these methods are unable to offer control over multiple
visual elements due to limitations in data and network efficacy. In this paper,
we introduce VidCRAFT3, a novel framework for precise image-to-video generation
that enables control over camera motion, object motion, and lighting direction
simultaneously. To better decouple control over each visual element, we propose
the Spatial Triple-Attention Transformer, which integrates lighting direction,
text, and image in a symmetric way. Since most real-world video datasets lack
lighting annotations, we construct a high-quality synthetic video dataset, the
VideoLightingDirection (VLD) dataset. This dataset includes lighting direction
annotations and objects of diverse appearance, enabling VidCRAFT3 to
effectively handle strong light transmission and reflection effects.
Additionally, we propose a three-stage training strategy that eliminates the
need for training data annotated with multiple visual elements (camera motion,
object motion, and lighting direction) simultaneously. Extensive experiments on
benchmark datasets demonstrate the efficacy of VidCRAFT3 in producing
high-quality video content, surpassing existing state-of-the-art methods in
terms of control granularity and visual coherence. All code and data will be
publicly available.",http://arxiv.org/abs/2502.07531v2,Recommendation System,"video, control, visual, motion, lighting"
Training Deep Learning Models with Norm-Constrained LMOs,"In this work, we study optimization methods that leverage the linear
minimization oracle (LMO) over a norm-ball. We propose a new stochastic family
of algorithms that uses the LMO to adapt to the geometry of the problem and,
perhaps surprisingly, show that they can be applied to unconstrained problems.
The resulting update rule unifies several existing optimization methods under a
single framework. Furthermore, we propose an explicit choice of norm for deep
architectures, which, as a side benefit, leads to the transferability of
hyperparameters across model sizes. Experimentally, we demonstrate significant
speedups on nanoGPT training without any reliance on Adam. The proposed method
is memory-efficient, requiring only one set of model weights and one set of
gradients, which can be stored in half-precision.",http://arxiv.org/abs/2502.07529v1,Recommendation System,"optimization, methods, lmo, norm, propose"
Forecasting the future development in quality and value of professional football players for applications in team management,"Transfers in professional football (soccer) are risky investments because of
the large transfer fees and high risks involved. Although data-driven models
can be used to improve transfer decisions, existing models focus on describing
players' historical progress, leaving their future performance unknown.
Moreover, recent developments have called for the use of explainable models
combined with uncertainty quantification of predictions. This paper assesses
explainable machine learning models based on predictive accuracy and
uncertainty quantification methods for the prediction of the future development
in quality and transfer value of professional football players. Using a
historical data set of data-driven indicators describing player quality and the
transfer value of a football player, the models are trained to forecast player
quality and player value one year ahead. These two prediction problems
demonstrate the efficacy of tree-based models, particularly random forest and
XGBoost, in making accurate predictions. In general, the random forest model is
found to be the most suitable model because it provides accurate predictions as
well as an uncertainty quantification method that naturally arises from the
bagging procedure of the random forest model. Additionally, our research shows
that the development of player performance contains nonlinear patterns and
interactions between variables, and that time series information can provide
useful information for the modeling of player performance metrics. Our research
provides models to help football clubs make more informed, data-driven transfer
decisions by forecasting player quality and transfer value.",http://arxiv.org/abs/2502.07528v1,Recommendation System,"models, player, transfer, football, data"
NatureLM: Deciphering the Language of Nature for Scientific Discovery,"Foundation models have revolutionized natural language processing and
artificial intelligence, significantly enhancing how machines comprehend and
generate human languages. Inspired by the success of these foundation models,
researchers have developed foundation models for individual scientific domains,
including small molecules, materials, proteins, DNA, and RNA. However, these
models are typically trained in isolation, lacking the ability to integrate
across different scientific domains. Recognizing that entities within these
domains can all be represented as sequences, which together form the ""language
of nature"", we introduce Nature Language Model (briefly, NatureLM), a
sequence-based science foundation model designed for scientific discovery.
Pre-trained with data from multiple scientific domains, NatureLM offers a
unified, versatile model that enables various applications including: (i)
generating and optimizing small molecules, proteins, RNA, and materials using
text instructions; (ii) cross-domain generation/design, such as
protein-to-molecule and protein-to-RNA generation; and (iii) achieving
state-of-the-art performance in tasks like SMILES-to-IUPAC translation and
retrosynthesis on USPTO-50k. NatureLM offers a promising generalist approach
for various scientific tasks, including drug discovery (hit
generation/optimization, ADMET optimization, synthesis), novel material design,
and the development of therapeutic proteins or nucleotides. We have developed
NatureLM models in different sizes (1 billion, 8 billion, and 46.7 billion
parameters) and observed a clear improvement in performance as the model size
increases.",http://arxiv.org/abs/2502.07527v1,Natural Language Processing,"models, scientific, foundation, domains, model"
CodePhys: Robust Video-based Remote Physiological Measurement through Latent Codebook Querying,"Remote photoplethysmography (rPPG) aims to measure non-contact physiological
signals from facial videos, which has shown great potential in many
applications. Most existing methods directly extract video-based rPPG features
by designing neural networks for heart rate estimation. Although they can
achieve acceptable results, the recovery of rPPG signal faces intractable
challenges when interference from real-world scenarios takes place on facial
video. Specifically, facial videos are inevitably affected by non-physiological
factors (e.g., camera device noise, defocus, and motion blur), leading to the
distortion of extracted rPPG signals. Recent rPPG extraction methods are easily
affected by interference and degradation, resulting in noisy rPPG signals. In
this paper, we propose a novel method named CodePhys, which innovatively treats
rPPG measurement as a code query task in a noise-free proxy space (i.e.,
codebook) constructed by ground-truth PPG signals. We consider noisy rPPG
features as queries and generate high-fidelity rPPG features by matching them
with noise-free PPG features from the codebook. Our approach also incorporates
a spatial-aware encoder network with a spatial attention mechanism to highlight
physiologically active areas and uses a distillation loss to reduce the
influence of non-periodic visual interference. Experimental results on four
benchmark datasets demonstrate that CodePhys outperforms state-of-the-art
methods in both intra-dataset and cross-dataset settings.",http://arxiv.org/abs/2502.07526v1,Reinforcement Learning,"rppg, signals, features, non, facial"
Scaling Off-Policy Reinforcement Learning with Batch and Weight Normalization,"Reinforcement learning has achieved significant milestones, but sample
efficiency remains a bottleneck for real-world applications. Recently, CrossQ
has demonstrated state-of-the-art sample efficiency with a low update-to-data
(UTD) ratio of 1. In this work, we explore CrossQ's scaling behavior with
higher UTD ratios. We identify challenges in the training dynamics, which are
emphasized by higher UTD ratios. To address these, we integrate weight
normalization into the CrossQ framework, a solution that stabilizes training,
has been shown to prevent potential loss of plasticity and keeps the effective
learning rate constant. Our proposed approach reliably scales with increasing
UTD ratios, achieving competitive performance across 25 challenging continuous
control tasks on the DeepMind Control Suite and Myosuite benchmarks, notably
the complex dog and humanoid environments. This work eliminates the need for
drastic interventions, such as network resets, and offers a simple yet robust
pathway for improving sample efficiency and scalability in model-free
reinforcement learning.",http://arxiv.org/abs/2502.07523v1,Reinforcement Learning,"utd, learning, sample, efficiency, crossq"
The Devil is in the Prompts: De-Identification Traces Enhance Memorization Risks in Synthetic Chest X-Ray Generation,"Generative models, particularly text-to-image (T2I) diffusion models, play a
crucial role in medical image analysis. However, these models are prone to
training data memorization, posing significant risks to patient privacy.
Synthetic chest X-ray generation is one of the most common applications in
medical image analysis with the MIMIC-CXR dataset serving as the primary data
repository for this task. This study adopts a data-driven approach and presents
the first systematic attempt to identify prompts and text tokens in MIMIC-CXR
that contribute the most to training data memorization. Our analysis reveals an
unexpected finding: prompts containing traces of de-identification procedures
are among the most memorized, with de-identification markers contributing the
most. Furthermore, we also find existing inference-time memorization mitigation
strategies are ineffective and fail to sufficiently reduce the model's reliance
on memorized text tokens highlighting a broader issue in T2I synthesis with
MIMIC-CXR. On this front, we propose actionable strategies to enhance privacy
and improve the reliability of generative models in medical imaging. Finally,
our results provide a foundation for future work on developing and benchmarking
memorization mitigation techniques for synthetic chest X-ray generation using
the MIMIC-CXR dataset.",http://arxiv.org/abs/2502.07516v1,Recommendation System,"models, data, memorization, mimic, cxr"
"A Near-optimal, Scalable and Corruption-tolerant Framework for Stochastic Bandits: From Single-Agent to Multi-Agent and Beyond","We investigate various stochastic bandit problems in the presence of
adversarial corruption. A seminal contribution to this area is the
BARBAR~\citep{gupta2019better} algorithm, which is both simple and efficient,
tolerating significant levels of corruption with nearly no degradation in
performance. However, its regret upper bound exhibits a complexity of $O(KC)$,
while the lower bound is $\Omega(C)$. In this paper, we enhance the BARBAR
algorithm by proposing a novel framework called BARBAT, which eliminates the
factor of $K$ and achieves an optimal regret bound up to a logarithmic factor.
We also demonstrate how BARBAT can be extended to various settings, including
graph bandits, combinatorial semi-bandits, batched bandits and multi-agent
bandits. In comparison to the Follow-The-Regularized-Leader (FTRL) family of
methods, which provide a best-of-both-worlds guarantee, our approach is more
efficient and parallelizable. Notably, FTRL-based methods face challenges in
scaling to batched and multi-agent settings.",http://arxiv.org/abs/2502.07514v1,Recommendation System,"bandits, bound, corruption, algorithm, efficient"
Quantitative evaluation of unsupervised clustering algorithms for dynamic total-body PET image analysis,"Background. Recently, dynamic total-body positron emission tomography (PET)
imaging has become possible due to new scanner devices. While clustering
algorithms have been proposed for PET analysis already earlier, there is still
little research systematically evaluating these algorithms for processing of
dynamic total-body PET images. Materials and methods. Here, we compare the
performance of 15 unsupervised clustering methods, including K-means either by
itself or after principal component analysis (PCA) or independent component
analysis (ICA), Gaussian mixture model (GMM), fuzzy c-means (FCM),
agglomerative clustering, spectral clustering, and several newer clustering
algorithms, for classifying time activity curves (TACs) in dynamic PET images.
We use dynamic total-body $^{15}$O-water PET images collected from 30 patients
with suspected or confirmed coronary artery disease. To evaluate the clustering
algorithms in a quantitative way, we use them to classify 5000 TACs from each
image based on whether the curve is taken from brain, right heart ventricle,
right kidney, lower right lung lobe, or urinary bladder. Results. According to
our results, the best methods are GMM, FCM, and ICA combined with mini batch
K-means, which classified the TACs with a median accuracies of 89\%, 83\%, and
81\%, respectively, in a processing time of half a second or less on average
for each image. Conclusion. GMM, FCM, and ICA with mini batch K-means show
promise for dynamic total-body PET analysis.",http://arxiv.org/abs/2502.07511v1,Recommendation System,"pet, clustering, dynamic, total, body"
Joint Metric Space Embedding by Unbalanced OT with Gromov-Wasserstein Marginal Penalization,"We propose a new approach for unsupervised alignment of heterogeneous
datasets, which maps data from two different domains without any known
correspondences to a common metric space. Our method is based on an unbalanced
optimal transport problem with Gromov-Wasserstein marginal penalization. It can
be seen as a counterpart to the recently introduced joint multidimensional
scaling method. We prove that there exists a minimizer of our functional and
that for penalization parameters going to infinity, the corresponding sequence
of minimizers converges to a minimizer of the so-called embedded Wasserstein
distance. Our model can be reformulated as a quadratic, multi-marginal,
unbalanced optimal transport problem, for which a bi-convex relaxation admits a
numerical solver via block-coordinate descent. We provide numerical examples
for joint embeddings in Euclidean as well as non-Euclidean spaces.",http://arxiv.org/abs/2502.07510v1,Recommendation System,"method, unbalanced, optimal, transport, problem"
Enhance-A-Video: Better Generated Video for Free,"DiT-based video generation has achieved remarkable results, but research into
enhancing existing models remains relatively unexplored. In this work, we
introduce a training-free approach to enhance the coherence and quality of
DiT-based generated videos, named Enhance-A-Video. The core idea is enhancing
the cross-frame correlations based on non-diagonal temporal attention
distributions. Thanks to its simple design, our approach can be easily applied
to most DiT-based video generation frameworks without any retraining or
fine-tuning. Across various DiT-based video generation models, our approach
demonstrates promising improvements in both temporal consistency and visual
quality. We hope this research can inspire future explorations in video
generation enhancement.",http://arxiv.org/abs/2502.07508v1,Computer Vision,"based, video, dit, generation, approach"
Efficient Continuous Group Convolutions for Local SE(3) Equivariance in 3D Point Clouds,"Extending the translation equivariance property of convolutional neural
networks to larger symmetry groups has been shown to reduce sample complexity
and enable more discriminative feature learning. Further, exploiting additional
symmetries facilitates greater weight sharing than standard convolutions,
leading to an enhanced network expressivity without an increase in parameter
count. However, extending the equivariant properties of a convolution layer
comes at a computational cost. In particular, for 3D data, expanding
equivariance to the SE(3) group (rotation and translation) results in a 6D
convolution operation, which is not tractable for larger data samples such as
3D scene scans. While efforts have been made to develop efficient SE(3)
equivariant networks, existing approaches rely on discretization or only
introduce global rotation equivariance. This limits their applicability to
point clouds representing a scene composed of multiple objects. This work
presents an efficient, continuous, and local SE(3) equivariant convolution
layer for point cloud processing based on general group convolution and local
reference frames. Our experiments show that our approach achieves competitive
or superior performance across a range of datasets and tasks, including object
classification and semantic segmentation, with negligible computational
overhead.",http://arxiv.org/abs/2502.07505v1,Reinforcement Learning,"convolution, equivariance, equivariant, extending, translation"
Proceedings 40th International Conference on Logic Programming,"Since the first conference In Marseille in 1982, the International Conference
on Logic Programming (ICLP) has been the premier international event for
presenting research in logic programming. These proceedings include technical
communications about, and abstracts for presentations given at the 40th ICLP
held October 14-17, in Dallas Texas, USA. The papers and abstracts in this
volume include the following areas and topics. Formal and operational
semantics: including non-monotonic reasoning, probabilistic reasoning,
argumentation, and semantic issues of combining logic with neural models.
Language design and programming methodologies such as answer set programming.
inductive logic programming, and probabilistic programming. Program analysis
and logic-based validation of generated programs. Implementation methodologies
including constraint implementation, tabling, Logic-based prompt engineering,
and the interaction of logic programming with LLMs.",http://arxiv.org/abs/2502.08453v1,Recommendation System,"logic, programming, conference, international, iclp"
Harnessing Language's Fractal Geometry with Recursive Inference Scaling,"Recent research in language modeling reveals two scaling effects: the
well-known improvement from increased training compute, and a lesser-known
boost from applying more sophisticated or computationally intensive inference
methods. Inspired by recent findings on the fractal geometry of language, we
introduce Recursive INference Scaling (RINS) as a complementary, plug-in recipe
for scaling inference time. For a given fixed model architecture and training
compute budget, RINS substantially improves language modeling performance. It
also generalizes beyond pure language tasks, delivering gains in multimodal
systems, including a +2% improvement in 0-shot ImageNet accuracy for
SigLIP-B/16. Additionally, by deriving data scaling laws, we show that RINS
improves both the asymptotic performance limits and the scaling exponents.
These advantages are maintained even when compared to state-of-the-art
recursive techniques like the ""repeat-all-over"" (RAO) strategy in Mobile LLM.
Finally, stochastic RINS not only can enhance performance further but also
provides the flexibility to optionally forgo increased inference computation at
test time with minimal performance degradation.",http://arxiv.org/abs/2502.07503v1,Recommendation System,"scaling, language, inference, rins, performance"
Unified Graph Networks (UGN): A Deep Neural Framework for Solving Graph Problems,"Deep neural networks have enabled researchers to create powerful generalized
frameworks, such as transformers, that can be used to solve well-studied
problems in various application domains, such as text and image. However, such
generalized frameworks are not available for solving graph problems. Graph
structures are ubiquitous in many applications around us and many graph
problems have been widely studied over years. In recent times, there has been a
surge in deep neural network based approaches to solve graph problems, with
growing availability of graph structured datasets across diverse domains.
Nevertheless, existing methods are mostly tailored to solve a specific task and
lack the capability to create a generalized model leading to solutions for
different downstream tasks. In this work, we propose a novel,
resource-efficient framework named \emph{U}nified \emph{G}raph \emph{N}etwork
(UGN) by leveraging the feature extraction capability of graph convolutional
neural networks (GCN) and 2-dimensional convolutional neural networks (Conv2D).
UGN unifies various graph learning tasks, such as link prediction, node
classification, community detection, graph-to-graph translation, knowledge
graph completion, and more, within a cohesive framework, while exercising
minimal task-specific extensions (e.g., formation of supernodes for coarsening
massive networks to increase scalability, use of \textit{mean target
connectivity matrix} (MTCM) representation for achieving scalability in graph
translation task, etc.) to enhance the generalization capability of graph
learning and analysis. We test the novel UGN framework for six uncorrelated
graph problems, using twelve different datasets. Experimental results show that
UGN outperforms the state-of-the-art baselines by a significant margin on ten
datasets, while producing comparable results on the remaining dataset.",http://arxiv.org/abs/2502.07500v1,Recommendation System,"graph, problems, neural, networks, ugn"
On Training-Conditional Conformal Prediction and Binomial Proportion Confidence Intervals,"Estimating the expectation of a Bernoulli random variable based on N
independent trials is a classical problem in statistics, typically addressed
using Binomial Proportion Confidence Intervals (BPCI). In the control systems
community, many critical tasks-such as certifying the statistical safety of
dynamical systems-can be formulated as BPCI problems. Conformal Prediction
(CP), a distribution-free technique for uncertainty quantification, has gained
significant attention in recent years and has been applied to various control
systems problems, particularly to address uncertainties in learned dynamics or
controllers. A variant known as training-conditional CP was recently employed
to tackle the problem of safety certification. In this note, we highlight that
the use of training-conditional CP in this context does not provide valid
safety guarantees. We demonstrate why CP is unsuitable for BPCI problems and
argue that traditional BPCI methods are better suited for statistical safety
certification.",http://arxiv.org/abs/2502.07497v1,Recommendation System,"bpci, safety, cp, systems, problems"
LLM-Sketch: Enhancing Network Sketches with LLM,"Network stream mining is fundamental to many network operations. Sketches, as
compact data structures that offer low memory overhead with bounded accuracy,
have emerged as a promising solution for network stream mining. Recent studies
attempt to optimize sketches using machine learning; however, these approaches
face the challenges of lacking adaptivity to dynamic networks and incurring
high training costs. In this paper, we propose LLM-Sketch, based on the insight
that fields beyond the flow IDs in packet headers can also help infer flow
sizes. By using a two-tier data structure and separately recording large and
small flows, LLM-Sketch improves accuracy while minimizing memory usage.
Furthermore, it leverages fine-tuned large language models (LLMs) to reliably
estimate flow sizes. We evaluate LLM-Sketch on three representative tasks, and
the results demonstrate that LLM-Sketch outperforms state-of-the-art methods by
achieving a $7.5\times$ accuracy improvement.",http://arxiv.org/abs/2502.07495v1,Reinforcement Learning,"llm, sketch, network, accuracy, flow"
URECA: The Chain of Two Minimum Set Cover Problems exists behind Adaptation to Shifts in Semantic Code Search,"Adaptation is to make model learn the patterns shifted from the training
distribution. In general, this adaptation is formulated as the minimum entropy
problem. However, the minimum entropy problem has inherent limitation --
shifted initialization cascade phenomenon. We extend the relationship between
the minimum entropy problem and the minimum set cover problem via Lebesgue
integral. This extension reveals that internal mechanism of the minimum entropy
problem ignores the relationship between disentangled representations, which
leads to shifted initialization cascade. From the analysis, we introduce a new
clustering algorithm, Union-find based Recursive Clustering Algorithm~(URECA).
URECA is an efficient clustering algorithm for the leverage of the
relationships between disentangled representations. The update rule of URECA
depends on Thresholdly-Updatable Stationary Assumption to dynamics as a
released version of Stationary Assumption. This assumption helps URECA to
transport disentangled representations with no errors based on the
relationships between disentangled representations. URECA also utilize
simulation trick to efficiently cluster disentangled representations. The wide
range of evaluations show that URECA achieves consistent performance gains for
the few-shot adaptation to diverse types of shifts along with advancement to
State-of-The-Art performance in CoSQA in the scenario of query shift.",http://arxiv.org/abs/2502.07494v1,Reinforcement Learning,"minimum, problem, disentangled, representations, ureca"
RoMA: Robust Malware Attribution via Byte-level Adversarial Training with Global Perturbations and Adversarial Consistency Regularization,"Attributing APT (Advanced Persistent Threat) malware to their respective
groups is crucial for threat intelligence and cybersecurity. However, APT
adversaries often conceal their identities, rendering attribution inherently
adversarial. Existing machine learning-based attribution models, while
effective, remain highly vulnerable to adversarial attacks. For example, the
state-of-the-art byte-level model MalConv sees its accuracy drop from over 90%
to below 2% under PGD (projected gradient descent) attacks. Existing
gradient-based adversarial training techniques for malware detection or image
processing were applied to malware attribution in this study, revealing that
both robustness and training efficiency require significant improvement. To
address this, we propose RoMA, a novel single-step adversarial training
approach that integrates global perturbations to generate enhanced adversarial
samples and employs adversarial consistency regularization to improve
representation quality and resilience. A novel APT malware dataset named AMG18,
with diverse samples and realistic class imbalances, is introduced for
evaluation. Extensive experiments show that RoMA significantly outperforms
seven competing methods in both adversarial robustness (e.g., achieving over
80% robust accuracy-more than twice that of the next-best method under PGD
attacks) and training efficiency (e.g., more than twice as fast as the
second-best method in terms of accuracy), while maintaining superior standard
accuracy in non-adversarial scenarios.",http://arxiv.org/abs/2502.07492v1,Reinforcement Learning,"adversarial, malware, accuracy, training, apt"
Exploring Patterns Behind Sports,"This paper presents a comprehensive framework for time series prediction
using a hybrid model that combines ARIMA and LSTM. The model incorporates
feature engineering techniques, including embedding and PCA, to transform raw
data into a lower-dimensional representation while retaining key information.
The embedding technique is used to convert categorical data into continuous
vectors, facilitating the capture of complex relationships. PCA is applied to
reduce dimensionality and extract principal components, enhancing model
performance and computational efficiency. To handle both linear and nonlinear
patterns in the data, the ARIMA model captures linear trends, while the LSTM
model models complex nonlinear dependencies. The hybrid model is trained on
historical data and achieves high accuracy, as demonstrated by low RMSE and MAE
scores. Additionally, the paper employs the run test to assess the randomness
of sequences, providing insights into the underlying patterns. Ablation studies
are conducted to validate the roles of different components in the model,
demonstrating the significance of each module. The paper also utilizes the SHAP
method to quantify the impact of traditional advantages on the predicted
results, offering a detailed understanding of feature importance. The KNN
method is used to determine the optimal prediction interval, further enhancing
the model's accuracy. The results highlight the effectiveness of combining
traditional statistical methods with modern deep learning techniques for robust
time series forecasting in Sports.",http://arxiv.org/abs/2502.07491v1,Reinforcement Learning,"model, data, paper, time, series"
Mask-Enhanced Autoregressive Prediction: Pay Less Attention to Learn More,"Large Language Models (LLMs) are discovered to suffer from accurately
retrieving key information. To address this, we propose Mask-Enhanced
Autoregressive Prediction (MEAP), a simple yet effective training paradigm that
seamlessly integrates Masked Language Modeling (MLM) into Next-Token Prediction
(NTP) to enhance the latter's in-context retrieval capabilities. Specifically,
MEAP first randomly masks a small fraction of input tokens and then directly
performs the standard next-token prediction autoregressive using a decoder-only
Transformer. MEAP eliminates the need for bidirectional attention or
encoder-decoder architectures for MLM, incurring no additional computational
overhead during pre-training or inference. Intensive experiments demonstrate
that MEAP substantially outperforms NTP on key information retrieval and
long-context reasoning tasks, while performing on par or better on commonsense
reasoning tasks. The benefits of MEAP also extend to supervised fine-tuning,
where it shows remarkable advantages in lost-in-the-middle scenarios,
outperforming NTP by 11.77 percentage points. Our analysis indicates that
MEAP's effectiveness arises from its ability to promote more distinguishable
attention scores by concentrating on a reduced set of non-masked tokens. This
mechanism improves the model's focus on task-relevant signals while mitigating
the influence of peripheral context. These findings position MEAP as a
promising training paradigm for large language models.",http://arxiv.org/abs/2502.07490v1,Recommendation System,"meap, language, prediction, training, ntp"
Physiome-ODE: A Benchmark for Irregularly Sampled Multivariate Time Series Forecasting Based on Biological ODEs,"State-of-the-art methods for forecasting irregularly sampled time series with
missing values predominantly rely on just four datasets and a few small toy
examples for evaluation. While ordinary differential equations (ODE) are the
prevalent models in science and engineering, a baseline model that forecasts a
constant value outperforms ODE-based models from the last five years on three
of these existing datasets. This unintuitive finding hampers further research
on ODE-based models, a more plausible model family. In this paper, we develop a
methodology to generate irregularly sampled multivariate time series (IMTS)
datasets from ordinary differential equations and to select challenging
instances via rejection sampling. Using this methodology, we create
Physiome-ODE, a large and sophisticated benchmark of IMTS datasets consisting
of 50 individual datasets, derived from real-world ordinary differential
equations from research in biology. Physiome-ODE is the first benchmark for
IMTS forecasting that we are aware of and an order of magnitude larger than the
current evaluation setting of four datasets. Using our benchmark Physiome-ODE,
we show qualitatively completely different results than those derived from the
current four datasets: on Physiome-ODE ODE-based models can play to their
strength and our benchmark can differentiate in a meaningful way between
different IMTS forecasting models. This way, we expect to give a new impulse to
research on ODE-based time series modeling.",http://arxiv.org/abs/2502.07489v1,Recommendation System,"ode, datasets, models, based, imts"
Improving Adaptive Moment Optimization via Preconditioner Diagonalization,"Modern adaptive optimization methods, such as Adam and its variants, have
emerged as the most widely used tools in deep learning over recent years. These
algorithms offer automatic mechanisms for dynamically adjusting the update step
based on estimates of gradient statistics. Compared to traditional algorithms
like Stochastic Gradient Descent, these adaptive methods are typically more
robust to model scale and hyperparameter tuning. However, the gradient
statistics employed by these methods often do not leverage sufficient gradient
covariance information, leading to suboptimal updates in certain directions of
the parameter space and potentially slower convergence. In this work, we keep
track of such covariance statistics in the form of a structured preconditioner
matrix. Unlike other works, our approach does not apply direct approximations
to estimate this matrix. We instead implement an invertible transformation that
maps the preconditioner matrix into a new space where it becomes approximately
diagonal. This enables a diagonal approximation of the preconditioner matrix in
the transformed space, offering several computational advantages. Empirical
results show that our approach can substantially enhance the convergence speed
of modern adaptive optimizers. Notably, for large language models like LLaMA,
we can achieve a speedup of 2x compared to the baseline Adam. Additionally, our
method can be integrated with memory-efficient optimizers like Adafactor to
manage computational overhead.",http://arxiv.org/abs/2502.07488v1,Recommendation System,"gradient, matrix, adaptive, methods, statistics"
Automated Road Extraction and Centreline Fitting in LiDAR Point Clouds,"Road information extraction from 3D point clouds is useful for urban planning
and traffic management. Existing methods often rely on local features and the
refraction angle of lasers from kerbs, which makes them sensitive to variable
kerb designs and issues in high-density areas due to data homogeneity. We
propose an approach for extracting road points and fitting centrelines using a
top-down view of LiDAR based ground-collected point clouds. This prospective
view reduces reliance on specific kerb design and results in better road
extraction. We first perform statistical outlier removal and density-based
clustering to reduce noise from 3D point cloud data. Next, we perform ground
point filtering using a grid-based segmentation method that adapts to diverse
road scenarios and terrain characteristics. The filtered points are then
projected onto a 2D plane, and the road is extracted by a skeletonisation
algorithm. The skeleton is back-projected onto the 3D point cloud with
calculated normals, which guide a region growing algorithm to find nearby road
points. The extracted road points are then smoothed with the Savitzky-Golay
filter to produce the final centreline. Our initial approach without
post-processing of road skeleton achieved 67% in IoU by testing on the Perth
CBD dataset with different road types. Incorporating the post-processing of the
road skeleton improved the extraction of road points around the smoothed
skeleton. The refined approach achieved a higher IoU value of 73% and with 23%
reduction in the processing time. Our approach offers a generalised and
computationally efficient solution that combines 3D and 2D processing
techniques, laying the groundwork for future road reconstruction and 3D-to-2D
point cloud alignment.",http://arxiv.org/abs/2502.07486v1,Reinforcement Learning,"road, point, points, approach, skeleton"
Overfitting Regimes of Nadaraya-Watson Interpolators,"In recent years, there has been much interest in understanding the
generalization behavior of interpolating predictors, which overfit on noisy
training data. Whereas standard analyses are concerned with whether a method is
consistent or not, recent observations have shown that even inconsistent
predictors can generalize well. In this work, we revisit the classic
interpolating Nadaraya-Watson (NW) estimator (also known as Shepard's method),
and study its generalization capabilities through this modern viewpoint. In
particular, by varying a single bandwidth-like hyperparameter, we prove the
existence of multiple overfitting behaviors, ranging non-monotonically from
catastrophic, through benign, to tempered. Our results highlight how even
classical interpolating methods can exhibit intricate generalization behaviors.
Numerical experiments complement our theory, demonstrating the same phenomena.",http://arxiv.org/abs/2502.07480v1,Recommendation System,"generalization, interpolating, recent, predictors, method"
WebChecker: A Versatile EVL Plugin for Validating HTML Pages with Bootstrap Frameworks,"WebChecker is a plugin for Epsilon Validation Language (EVL), designed to
validate both static and dynamic HTML pages utilizing frameworks like
Bootstrap. By employing configurable EVL constraints, WebChecker enforces
implicit rules governing HTML and CSS frameworks. The effectiveness of the
plugin is demonstrated through its application on Bootstrap, the widely adopted
HTML, CSS, and JavaScript framework. WebChecker comes with a set of EVL
constraints to assess Bootstrap based web pages. To substantiate our claims, I
present an illustrative example featuring two solutions that effectively
enforce implicit rules.",http://arxiv.org/abs/2502.07479v1,Recommendation System,"webchecker, evl, html, bootstrap, plugin"
5D Neural Surrogates for Nonlinear Gyrokinetic Simulations of Plasma Turbulence,"Nuclear fusion plays a pivotal role in the quest for reliable and sustainable
energy production. A major roadblock to achieving commercially viable fusion
power is understanding plasma turbulence, which can significantly degrade
plasma confinement. Modelling turbulence is crucial to design performing plasma
scenarios for next-generation reactor-class devices and current experimental
machines. The nonlinear gyrokinetic equation underpinning turbulence modelling
evolves a 5D distribution function over time. Solving this equation numerically
is extremely expensive, requiring up to weeks for a single run to converge,
making it unfeasible for iterative optimisation and control studies. In this
work, we propose a method for training neural surrogates for 5D gyrokinetic
simulations. Our method extends a hierarchical vision transformer to five
dimensions and is trained on the 5D distribution function for the adiabatic
electron approximation. We demonstrate that our model can accurately infer
downstream physical quantities such as heat flux time trace and electrostatic
potentials for single-step predictions two orders of magnitude faster than
numerical codes. Our work paves the way towards neural surrogates for plasma
turbulence simulations to accelerate deployment of commercial energy production
via nuclear fusion.",http://arxiv.org/abs/2502.07469v1,Reinforcement Learning,"plasma, turbulence, fusion, nuclear, energy"
Less is More: Masking Elements in Image Condition Features Avoids Content Leakages in Style Transfer Diffusion Models,"Given a style-reference image as the additional image condition,
text-to-image diffusion models have demonstrated impressive capabilities in
generating images that possess the content of text prompts while adopting the
visual style of the reference image. However, current state-of-the-art methods
often struggle to disentangle content and style from style-reference images,
leading to issues such as content leakages. To address this issue, we propose a
masking-based method that efficiently decouples content from style without the
need of tuning any model parameters. By simply masking specific elements in the
style reference's image features, we uncover a critical yet under-explored
principle: guiding with appropriately-selected fewer conditions (e.g., dropping
several image feature elements) can efficiently avoid unwanted content flowing
into the diffusion models, enhancing the style transfer performances of
text-to-image diffusion models. In this paper, we validate this finding both
theoretically and experimentally. Extensive experiments across various styles
demonstrate the effectiveness of our masking-based method and support our
theoretical results.",http://arxiv.org/abs/2502.07466v1,Reinforcement Learning,"style, image, content, reference, text"
Crime Forecasting: A Spatio-temporal Analysis with Deep Learning Models,"This study uses deep-learning models to predict city partition crime counts
on specific days. It helps police enhance surveillance, gather intelligence,
and proactively prevent crimes. We formulate crime count prediction as a
spatiotemporal sequence challenge, where both input data and prediction targets
are spatiotemporal sequences. In order to improve the accuracy of crime
forecasting, we introduce a new model that combines Convolutional Neural
Networks (CNN) and Long Short-Term Memory (LSTM) networks. We conducted a
comparative analysis to access the effects of various data sequences, including
raw and binned data, on the prediction errors of four deep learning forecasting
models. Directly inputting raw crime data into the forecasting model causes
high prediction errors, making the model unsuitable for real - world use. The
findings indicate that the proposed CNN-LSTM model achieves optimal performance
when crime data is categorized into 10 or 5 groups. Data binning can enhance
forecasting model performance, but poorly defined intervals may reduce map
granularity. Compared to dividing into 5 bins, binning into 10 intervals
strikes an optimal balance, preserving data characteristics and surpassing raw
data in predictive modelling efficacy.",http://arxiv.org/abs/2502.07465v1,Recommendation System,"data, crime, model, prediction, forecasting"
JamendoMaxCaps: A Large Scale Music-caption Dataset with Imputed Metadata,"We introduce JamendoMaxCaps, a large-scale music-caption dataset featuring
over 200,000 freely licensed instrumental tracks from the renowned Jamendo
platform. The dataset includes captions generated by a state-of-the-art
captioning model, enhanced with imputed metadata. We also introduce a retrieval
system that leverages both musical features and metadata to identify similar
songs, which are then used to fill in missing metadata using a local large
language model (LLLM). This approach allows us to provide a more comprehensive
and informative dataset for researchers working on music-language understanding
tasks. We validate this approach quantitatively with five different
measurements. By making the JamendoMaxCaps dataset publicly available, we
provide a high-quality resource to advance research in music-language
understanding tasks such as music retrieval, multimodal representation
learning, and generative music models.",http://arxiv.org/abs/2502.07461v1,Recommendation System,"music, dataset, metadata, language, introduce"
Logarithmic Regret for Online KL-Regularized Reinforcement Learning,"Recent advances in Reinforcement Learning from Human Feedback (RLHF) have
shown that KL-regularization plays a pivotal role in improving the efficiency
of RL fine-tuning for large language models (LLMs). Despite its empirical
advantage, the theoretical difference between KL-regularized RL and standard RL
remains largely under-explored. While there is a recent line of work on the
theoretical analysis of KL-regularized objective in decision making
\citep{xiong2024iterative, xie2024exploratory,zhao2024sharp}, these analyses
either reduce to the traditional RL setting or rely on strong coverage
assumptions. In this paper, we propose an optimism-based KL-regularized online
contextual bandit algorithm, and provide a novel analysis of its regret. By
carefully leveraging the benign optimization landscape induced by the
KL-regularization and the optimistic reward estimation, our algorithm achieves
an $\mathcal{O}\big(\eta\log (N_{\mathcal R} T)\cdot d_{\mathcal R}\big)$
logarithmic regret bound, where $\eta, N_{\mathcal R},T,d_{\mathcal R}$ denote
the KL-regularization parameter, the cardinality of the reward function class,
number of rounds, and the complexity of the reward function class. Furthermore,
we extend our algorithm and analysis to reinforcement learning by developing a
novel decomposition over transition steps and also obtain a similar logarithmic
regret bound.",http://arxiv.org/abs/2502.07460v1,Reinforcement Learning,"kl, rl, regularization, regularized, analysis"
PerCul: A Story-Driven Cultural Evaluation of LLMs in Persian,"Large language models predominantly reflect Western cultures, largely due to
the dominance of English-centric training data. This imbalance presents a
significant challenge, as LLMs are increasingly used across diverse contexts
without adequate evaluation of their cultural competence in non-English
languages, including Persian. To address this gap, we introduce PerCul, a
carefully constructed dataset designed to assess the sensitivity of LLMs toward
Persian culture. PerCul features story-based, multiple-choice questions that
capture culturally nuanced scenarios. Unlike existing benchmarks, PerCul is
curated with input from native Persian annotators to ensure authenticity and to
prevent the use of translation as a shortcut. We evaluate several
state-of-the-art multilingual and Persian-specific LLMs, establishing a
foundation for future research in cross-cultural NLP evaluation. Our
experiments demonstrate a 11.3% gap between best closed source model and
layperson baseline while the gap increases to 21.3% by using the best
open-weight model. You can access the dataset from here:
https://huggingface.co/datasets/teias-ai/percul",http://arxiv.org/abs/2502.07459v1,Natural Language Processing,"persian, llms, gap, percul, english"
Bidirectional Uncertainty-Aware Region Learning for Semi-Supervised Medical Image Segmentation,"In semi-supervised medical image segmentation, the poor quality of unlabeled
data and the uncertainty in the model's predictions lead to models that
inevitably produce erroneous pseudo-labels. These errors accumulate throughout
model training, thereby weakening the model's performance. We found that these
erroneous pseudo-labels are typically concentrated in high-uncertainty regions.
Traditional methods improve performance by directly discarding pseudo-labels in
these regions, but this can also result in neglecting potentially valuable
training data. To alleviate this problem, we propose a bidirectional
uncertainty-aware region learning strategy. In training labeled data, we focus
on high-uncertainty regions, using precise label information to guide the
model's learning in potentially uncontrollable areas. Meanwhile, in the
training of unlabeled data, we concentrate on low-uncertainty regions to reduce
the interference of erroneous pseudo-labels on the model. Through this
bidirectional learning strategy, the model's overall performance has
significantly improved. Extensive experiments show that our proposed method
achieves significant performance improvement on different medical image
segmentation tasks.",http://arxiv.org/abs/2502.07457v1,Recommendation System,"model, uncertainty, data, pseudo, labels"
FedAPA: Server-side Gradient-Based Adaptive Personalized Aggregation for Federated Learning on Heterogeneous Data,"Personalized federated learning (PFL) tailors models to clients' unique data
distributions while preserving privacy. However, existing
aggregation-weight-based PFL methods often struggle with heterogeneous data,
facing challenges in accuracy, computational efficiency, and communication
overhead. We propose FedAPA, a novel PFL method featuring a server-side,
gradient-based adaptive aggregation strategy to generate personalized models,
by updating aggregation weights based on gradients of client-parameter changes
with respect to the aggregation weights in a centralized manner. FedAPA
guarantees theoretical convergence and achieves superior accuracy and
computational efficiency compared to 10 PFL competitors across three datasets,
with competitive communication overhead.",http://arxiv.org/abs/2502.07456v1,Recommendation System,"pfl, aggregation, based, personalized, models"
RusCode: Russian Cultural Code Benchmark for Text-to-Image Generation,"Text-to-image generation models have gained popularity among users around the
world. However, many of these models exhibit a strong bias toward
English-speaking cultures, ignoring or misrepresenting the unique
characteristics of other language groups, countries, and nationalities. The
lack of cultural awareness can reduce the generation quality and lead to
undesirable consequences such as unintentional insult, and the spread of
prejudice. In contrast to the field of natural language processing, cultural
awareness in computer vision has not been explored as extensively. In this
paper, we strive to reduce this gap. We propose a RusCode benchmark for
evaluating the quality of text-to-image generation containing elements of the
Russian cultural code. To do this, we form a list of 19 categories that best
represent the features of Russian visual culture. Our final dataset consists of
1250 text prompts in Russian and their translations into English. The prompts
cover a wide range of topics, including complex concepts from art, popular
culture, folk traditions, famous people's names, natural objects, scientific
achievements, etc. We present the results of a human evaluation of the
side-by-side comparison of Russian visual concepts representations using
popular generative models.",http://arxiv.org/abs/2502.07455v1,Recommendation System,"russian, text, generation, models, cultural"
Eliciting Rational Initial Weights in Gradual Argumentation,"Many semantics for weighted argumentation frameworks assume that each
argument is associated with an initial weight. However, eliciting these initial
weights poses challenges: (1) accurately providing a specific numerical value
is often difficult, and (2) individuals frequently confuse initial weights with
acceptability degrees in the presence of other arguments. To address these
issues, we propose an elicitation pipeline that allows one to specify
acceptability degree intervals for each argument. By employing gradual
semantics, we can refine these intervals when they are rational, restore
rationality when they are not, and ultimately identify possible initial weights
for each argument.",http://arxiv.org/abs/2502.07452v1,Recommendation System,"initial, argument, weights, semantics, acceptability"
Forget What You Know about LLMs Evaluations - LLMs are Like a Chameleon,"Large language models (LLMs) often appear to excel on public benchmarks, but
these high scores may mask an overreliance on dataset-specific surface cues
rather than true language understanding. We introduce the Chameleon Benchmark
Overfit Detector (C-BOD), a meta-evaluation framework that systematically
distorts benchmark prompts via a parametric transformation and detects
overfitting of LLMs. By rephrasing inputs while preserving their semantic
content and labels, C-BOD exposes whether a model's performance is driven by
memorized patterns. Evaluated on the MMLU benchmark using 26 leading LLMs, our
method reveals an average performance degradation of 2.15% under modest
perturbations, with 20 out of 26 models exhibiting statistically significant
differences. Notably, models with higher baseline accuracy exhibit larger
performance differences under perturbation, and larger LLMs tend to be more
sensitive to rephrasings indicating that both cases may overrely on fixed
prompt patterns. In contrast, the Llama family and models with lower baseline
accuracy show insignificant degradation, suggesting reduced dependency on
superficial cues. Moreover, C-BOD's dataset- and model-agnostic design allows
easy integration into training pipelines to promote more robust language
understanding. Our findings challenge the community to look beyond leaderboard
scores and prioritize resilience and generalization in LLM evaluation.",http://arxiv.org/abs/2502.07445v1,Natural Language Processing,"models, llms, language, benchmark, c"
Approximating Human Strategic Reasoning with LLM-Enhanced Recursive Reasoners Leveraging Multi-agent Hypergames,"LLM-driven multi-agent-based simulations have been gaining traction with
applications in game-theoretic and social simulations. While most
implementations seek to exploit or evaluate LLM-agentic reasoning, they often
do so with a weak notion of agency and simplified architectures. We implement a
role-based multi-agent strategic interaction framework tailored to
sophisticated recursive reasoners, providing the means for systematic in-depth
development and evaluation of strategic reasoning. Our game environment is
governed by the umpire responsible for facilitating games, from matchmaking
through move validation to environment management. Players incorporate
state-of-the-art LLMs in their decision mechanism, relying on a formal
hypergame-based model of hierarchical beliefs. We use one-shot, 2-player beauty
contests to evaluate the recursive reasoning capabilities of the latest LLMs,
providing a comparison to an established baseline model from economics and data
from human experiments. Furthermore, we introduce the foundations of an
alternative semantic measure of reasoning to the k-level theory. Our
experiments show that artificial reasoners can outperform the baseline model in
terms of both approximating human behaviour and reaching the optimal solution.",http://arxiv.org/abs/2502.07443v1,Recommendation System,"reasoning, based, model, llm, multi"
Hierarchical Document Parsing via Large Margin Feature Matching and Heuristics,"We present our solution to the AAAI-25 VRD-IU challenge, achieving first
place in the competition. Our approach integrates large margin loss for
improved feature discrimination and employs heuristic rules to refine
hierarchical relationships. By combining a deep learning-based matching
strategy with greedy algorithms, we achieve a significant boost in accuracy
while maintaining computational efficiency. Our method attains an accuracy of
0.98904 on the private leaderboard, demonstrating its effectiveness in document
structure parsing. Source codes are publicly available at
https://github.com/ffyyytt/VRUID-AAAI-DAKiet",http://arxiv.org/abs/2502.07442v1,Reinforcement Learning,"accuracy, present, solution, vrd, iu"
Mathematical reasoning and the computer,"Computers have already changed the way that humans do mathematics: they
enable us to compute efficiently. But will they soon be helping us to reason?
And will they one day start reasoning themselves? We give an overview of recent
developments in neural networks, computer theorem provers and large language
models.",http://arxiv.org/abs/2502.07850v1,Recommendation System,"computers, changed, way, humans, mathematics"
SensPS: Sensing Personal Space Comfortable Distance between Human-Human Using Multimodal Sensors,"Personal space, also known as peripersonal space, is crucial in human social
interaction, influencing comfort, communication, and social stress. Estimating
and respecting personal space is essential for enhancing human-computer
interaction (HCI) and smart environments. Personal space preferences vary due
to individual traits, cultural background, and contextual factors. Advanced
multimodal sensing technologies, including eye-tracking and wristband sensors,
offer opportunities to develop adaptive systems that dynamically adjust to user
comfort levels. Integrating physiological and behavioral data enables a deeper
understanding of spatial interactions. This study develops a sensor-based model
to estimate comfortable personal space and identifies key features influencing
spatial preferences. Our findings show that multimodal sensors, particularly
eye-tracking and physiological wristband data, can effectively predict personal
space preferences, with eye-tracking data playing a more significant role. An
experimental study involving controlled human interactions demonstrates that a
Transformer-based model achieves the highest predictive accuracy (F1 score:
0.87) for estimating personal space. Eye-tracking features, such as gaze point
and pupil diameter, emerge as the most significant predictors, while
physiological signals from wristband sensors contribute marginally. These
results highlight the potential for AI-driven personalization of social space
in adaptive environments, suggesting that multimodal sensing can be leveraged
to develop intelligent systems that optimize spatial arrangements in
workplaces, educational institutions, and public settings. Future work should
explore larger datasets, real-world applications, and additional physiological
markers to enhance model robustness.",http://arxiv.org/abs/2502.07441v1,Recommendation System,"space, personal, eye, tracking, physiological"
Understanding Classifier-Free Guidance: High-Dimensional Theory and Non-Linear Generalizations,"Recent studies have raised concerns about the effectiveness of
Classifier-Free Guidance (CFG), indicating that in low-dimensional settings, it
can lead to overshooting the target distribution and reducing sample diversity.
In this work, we demonstrate that in infinite and sufficiently high-dimensional
contexts CFG effectively reproduces the target distribution, revealing a
blessing-of-dimensionality result. Additionally, we explore finite-dimensional
effects, precisely characterizing overshoot and variance reduction. Based on
our analysis, we introduce non-linear generalizations of CFG. Through numerical
simulations on Gaussian mixtures and experiments on class-conditional and
text-to-image diffusion models, we validate our analysis and show that our
non-linear CFG offers improved flexibility and generation quality without
additional computation cost.",http://arxiv.org/abs/2502.07849v1,Recommendation System,"cfg, dimensional, target, distribution, analysis"
Optimizing Knowledge Distillation in Transformers: Enabling Multi-Head Attention without Alignment Barriers,"Knowledge distillation (KD) in transformers often faces challenges due to
misalignment in the number of attention heads between teacher and student
models. Existing methods either require identical head counts or introduce
projectors to bridge dimensional gaps, limiting flexibility and efficiency. We
propose Squeezing-Heads Distillation (SHD), a novel approach that enables
seamless knowledge transfer between models with varying head counts by
compressing multi-head attention maps via efficient linear approximation.
Unlike prior work, SHD eliminates alignment barriers without additional
parameters or architectural modifications. Our method dynamically approximates
the combined effect of multiple teacher heads into fewer student heads,
preserving fine-grained attention patterns while reducing redundancy.
Experiments across language (LLaMA, GPT) and vision (DiT, MDT) generative and
vision (DeiT) discriminative tasks demonstrate SHD's effectiveness: it
outperforms logit-based and feature-alignment KD baselines, achieving
state-of-the-art results in image classification, image generation language
fine-tuning, and language pre-training. The key innovations of flexible head
compression, projector-free design, and linear-time complexity make SHD a
versatile and scalable solution for distilling modern transformers. This work
bridges a critical gap in KD, enabling efficient deployment of compact models
without compromising performance.",http://arxiv.org/abs/2502.07436v1,Recommendation System,"heads, head, shd, kd, attention"
CapyMOA: Efficient Machine Learning for Data Streams in Python,"CapyMOA is an open-source library designed for efficient machine learning on
streaming data. It provides a structured framework for real-time learning and
evaluation, featuring a flexible data representation. CapyMOA includes an
extensible architecture that allows integration with external frameworks such
as MOA and PyTorch, facilitating hybrid learning approaches that combine
traditional online algorithms with deep learning techniques. By emphasizing
adaptability, scalability, and usability, CapyMOA allows researchers and
practitioners to tackle dynamic learning challenges across various domains.",http://arxiv.org/abs/2502.07432v1,Recommendation System,"learning, capymoa, data, allows, open"
ArthroPhase: A Novel Dataset and Method for Phase Recognition in Arthroscopic Video,"This study aims to advance surgical phase recognition in arthroscopic
procedures, specifically Anterior Cruciate Ligament (ACL) reconstruction, by
introducing the first arthroscopy dataset and developing a novel
transformer-based model. We aim to establish a benchmark for arthroscopic
surgical phase recognition by leveraging spatio-temporal features to address
the specific challenges of arthroscopic videos including limited field of view,
occlusions, and visual distortions. We developed the ACL27 dataset, comprising
27 videos of ACL surgeries, each labeled with surgical phases. Our model
employs a transformer-based architecture, utilizing temporal-aware frame-wise
feature extraction through a ResNet-50 and transformer layers. This approach
integrates spatio-temporal features and introduces a Surgical Progress Index
(SPI) to quantify surgery progression. The model's performance was evaluated
using accuracy, precision, recall, and Jaccard Index on the ACL27 and Cholec80
datasets. The proposed model achieved an overall accuracy of 72.91% on the
ACL27 dataset. On the Cholec80 dataset, the model achieved a comparable
performance with the state-of-the-art methods with an accuracy of 92.4%. The
SPI demonstrated an output error of 10.6% and 9.86% on ACL27 and Cholec80
datasets respectively, indicating reliable surgery progression estimation. This
study introduces a significant advancement in surgical phase recognition for
arthroscopy, providing a comprehensive dataset and a robust transformer-based
model. The results validate the model's effectiveness and generalizability,
highlighting its potential to improve surgical training, real-time assistance,
and operational efficiency in orthopedic surgery. The publicly available
dataset and code will facilitate future research and development in this
critical field.",http://arxiv.org/abs/2502.07431v1,Recommendation System,"model, surgical, dataset, transformer, phase"
Towards a Foundation Model for Physics-Informed Neural Networks: Multi-PDE Learning with Active Sampling,"Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework
for solving partial differential equations (PDEs) by embedding physical laws
into neural network training. However, traditional PINN models are typically
designed for single PDEs, limiting their generalizability across different
physical systems. In this work, we explore the potential of a foundation PINN
model capable of solving multiple PDEs within a unified architecture. We
investigate the efficacy of a single PINN framework trained on four distinct
PDEs-the Simple Harmonic Oscillator (SHO), the 1D Heat Equation, the 1D Wave
Equation, and the 2D Laplace Equation, demonstrating its ability to learn
diverse physical dynamics.
  To enhance sample efficiency, we incorporate Active Learning (AL) using Monte
Carlo (MC) Dropout-based uncertainty estimation, selecting the most informative
training samples iteratively. We evaluate different active learning strategies,
comparing models trained on 10%, 20%, 30%, 40%, and 50% of the full dataset,
and analyze their impact on solution accuracy. Our results indicate that
targeted uncertainty sampling significantly improves performance with fewer
training samples, leading to efficient learning across multiple PDEs.
  This work highlights the feasibility of a generalizable PINN-based foundation
model, capable of adapting to different physics-based problems without
redesigning network architectures. Our findings suggest that multi-PDE PINNs
with active learning can serve as an effective approach for reducing
computational costs while maintaining high accuracy in physics-based deep
learning applications.",http://arxiv.org/abs/2502.07425v1,Recommendation System,"pdes, learning, pinn, based, physics"
RomanLens: Latent Romanization and its role in Multilinguality in LLMs,"Large Language Models (LLMs) exhibit remarkable multilingual generalization
despite being predominantly trained on English-centric corpora. A fundamental
question arises: how do LLMs achieve such robust multilingual capabilities? For
non-Latin script languages, we investigate the role of romanization - the
representation of non-Latin scripts using Latin characters - as a bridge in
multilingual processing. Using mechanistic interpretability techniques, we
analyze next-token generation and find that intermediate layers frequently
represent target words in romanized form before transitioning to native script,
a phenomenon we term Latent Romanization. Further, through activation patching
experiments, we demonstrate that LLMs encode semantic concepts similarly across
native and romanized scripts, suggesting a shared underlying representation.
Additionally in translation towards non Latin languages, our findings reveal
that when the target language is in romanized form, its representations emerge
earlier in the model's layers compared to native script. These insights
contribute to a deeper understanding of multilingual representation in LLMs and
highlight the implicit role of romanization in facilitating language transfer.
Our work provides new directions for potentially improving multilingual
language modeling and interpretability.",http://arxiv.org/abs/2502.07424v1,Natural Language Processing,"multilingual, language, llms, latin, non"
Technical note on calibrating vision-language models under covariate shift,"Despite being a successful example of emerging capability, vision-language
foundation models for low-shot vision classification have a limited ability to
sufficiently generalize to the target data distribution due to sample poverty,
leading to sensitivity to variations in the data. A popular mitigation strategy
is finetuning over multiple datasets, but domain generalization is expensive
when practiced in this manner. This work examines both covariate shift between
pre-training data and the underspecified target data, and \textit{confidence
misalignment}, where the model's prediction confidence amplified by the limited
data availability. We propose \textit{Confidence-Calibrated Covariate Shift
Correction ($C3SC$)}, a unified framework to mitigate both covariate shift and
confidence misalignment. $C3SC$ leverages Fisher information penalty for
covariate shift correction and confidence misalignment penalty (CMP) to lower
confidence on misclassified examples. Experimental results across various
vision and covariate shift datasets demonstrates that $C3SC$ significantly
improves in calibration (ECE) by $5.82\%$ at maximum. $C3SC$ shows better
robustness as well by showing $3.5\%$ improvement in accuracy metric on
challenging covariate shift datasets, making $C3SC$ a promising solution for
reliable real-world vision-language low-shot applications under distribution
shift.",http://arxiv.org/abs/2502.07847v1,Recommendation System,"shift, covariate, data, vision, confidence"
Towards a Formal Theory of the Need for Competence via Computational Intrinsic Motivation,"Computational models offer powerful tools for formalising psychological
theories, making them both testable and applicable in digital contexts.
However, they remain little used in the study of motivation within psychology.
We focus on the ""need for competence"", postulated as a key basic human need
within Self-Determination Theory (SDT) -- arguably the most influential
psychological framework for studying intrinsic motivation (IM). The need for
competence is treated as a single construct across SDT texts. Yet, recent
research has identified multiple, ambiguously defined facets of competence in
SDT. We propose that these inconsistencies may be alleviated by drawing on
computational models from the field of artificial intelligence, specifically
from the domain of reinforcement learning (RL). By aligning the aforementioned
facets of competence -- effectance, skill use, task performance, and capacity
growth -- with existing RL formalisms, we provide a foundation for advancing
competence-related theory in SDT and motivational psychology more broadly. The
formalisms reveal underlying preconditions that SDT fails to make explicit,
demonstrating how computational models can improve our understanding of IM.
Additionally, our work can support a cycle of theory development by inspiring
new computational models formalising aspects of the theory, which can then be
tested empirically to refine the theory. While our research lays a promising
foundation, empirical studies of these models in both humans and machines are
needed, inviting collaboration across disciplines.",http://arxiv.org/abs/2502.07423v1,Reinforcement Learning,"models, competence, theory, sdt, computational"
"MoENAS: Mixture-of-Expert based Neural Architecture Search for jointly Accurate, Fair, and Robust Edge Deep Neural Networks","There has been a surge in optimizing edge Deep Neural Networks (DNNs) for
accuracy and efficiency using traditional optimization techniques such as
pruning, and more recently, employing automatic design methodologies. However,
the focus of these design techniques has often overlooked critical metrics such
as fairness, robustness, and generalization. As a result, when evaluating SOTA
edge DNNs' performance in image classification using the FACET dataset, we
found that they exhibit significant accuracy disparities (14.09%) across 10
different skin tones, alongside issues of non-robustness and poor
generalizability. In response to these observations, we introduce
Mixture-of-Experts-based Neural Architecture Search (MoENAS), an automatic
design technique that navigates through a space of mixture of experts to
discover accurate, fair, robust, and general edge DNNs. MoENAS improves the
accuracy by 4.02% compared to SOTA edge DNNs and reduces the skin tone accuracy
disparities from 14.09% to 5.60%, while enhancing robustness by 3.80% and
minimizing overfitting to 0.21%, all while keeping model size close to
state-of-the-art models average size (+0.4M). With these improvements, MoENAS
establishes a new benchmark for edge DNN design, paving the way for the
development of more inclusive and robust edge DNNs.",http://arxiv.org/abs/2502.07422v1,Recommendation System,"edge, dnns, accuracy, design, robustness"
Fast-COS: A Fast One-Stage Object Detector Based on Reparameterized Attention Vision Transformer for Autonomous Driving,"The perception system is a a critical role of an autonomous driving system
for ensuring safety. The driving scene perception system fundamentally
represents an object detection task that requires achieving a balance between
accuracy and processing speed. Many contemporary methods focus on improving
detection accuracy but often overlook the importance of real-time detection
capabilities when computational resources are limited. Thus, it is vital to
investigate efficient object detection strategies for driving scenes. This
paper introduces Fast-COS, a novel single-stage object detection framework
crafted specifically for driving scene applications. The research initiates
with an analysis of the backbone, considering both macro and micro
architectural designs, yielding the Reparameterized Attention Vision
Transformer (RAViT). RAViT utilizes Reparameterized Multi-Scale Depth-Wise
Convolution (RepMSDW) and Reparameterized Self-Attention (RepSA) to enhance
computational efficiency and feature extraction. In extensive tests across GPU,
edge, and mobile platforms, RAViT achieves 81.4% Top-1 accuracy on the
ImageNet-1K dataset, demonstrating significant throughput improvements over
comparable backbone models such as ResNet, FastViT, RepViT, and
EfficientFormer. Additionally, integrating RepMSDW into a feature pyramid
network forms RepFPN, enabling fast and multi-scale feature fusion. Fast-COS
enhances object detection in driving scenes, attaining an AP50 score of 57.2%
on the BDD100K dataset and 80.0% on the TJU-DHD Traffic dataset. It surpasses
leading models in efficiency, delivering up to 75.9% faster GPU inference and
1.38 higher throughput on edge devices compared to FCOS, YOLOF, and RetinaNet.
These findings establish Fast-COS as a highly scalable and reliable solution
suitable for real-time applications, especially in resource-limited
environments like autonomous driving systems",http://arxiv.org/abs/2502.07417v1,Recommendation System,"driving, detection, object, fast, system"
Quantification of model error for inverse problems in the Weak Neural Variational Inference framework,"We present a novel extension of the Weak Neural Variational Inference (WNVI)
framework for probabilistic material property estimation that explicitly
quantifies model errors in PDE-based inverse problems. Traditional approaches
assume the correctness of all governing equations, including potentially
unreliable constitutive laws, which can lead to biased estimates and
misinterpretations. Our proposed framework addresses this limitation by
distinguishing between reliable governing equations, such as conservation laws,
and uncertain constitutive relationships. By treating all state variables as
latent random variables, we enforce these equations through separate sets of
residuals, leveraging a virtual likelihood approach with weighted residuals.
This formulation not only identifies regions where constitutive laws break down
but also improves robustness against model uncertainties without relying on a
fully trustworthy forward model. We demonstrate the effectiveness of our
approach in the context of elastography, showing that it provides a structured,
interpretable, and computationally efficient alternative to traditional model
error correction techniques. Our findings suggest that the proposed framework
enhances the accuracy and reliability of material property estimation by
offering a principled way to incorporate uncertainty in constitutive modeling.",http://arxiv.org/abs/2502.07415v1,Recommendation System,"model, constitutive, framework, equations, laws"
Memory Analysis on the Training Course of DeepSeek Models,"We present a theoretical analysis of GPU memory consumption during the
training of DeepSeek models such as DeepSeek-v2 and DeepSeek-v3. Our primary
objective is to clarify the device-level memory requirements associated with
various distributed training configurations. Specifically, we examine critical
factors influencing memory usage, including micro-batch size, activation
recomputation policies, 3D parallelism, and ZeRO optimizations. It is important
to emphasize that the training policies discussed in this report are not
representative of DeepSeek's official configurations. Instead, they are
explored to provide a deeper understanding of memory dynamics in training of
large-scale mixture-of-experts model.",http://arxiv.org/abs/2502.07846v1,Computer Vision,"memory, training, deepseek, configurations, policies"
Sample Weight Averaging for Stable Prediction,"The challenge of Out-of-Distribution (OOD) generalization poses a
foundational concern for the application of machine learning algorithms to
risk-sensitive areas. Inspired by traditional importance weighting and
propensity weighting methods, prior approaches employ an independence-based
sample reweighting procedure. They aim at decorrelating covariates to
counteract the bias introduced by spurious correlations between unstable
variables and the outcome, thus enhancing generalization and fulfilling stable
prediction under covariate shift. Nonetheless, these methods are prone to
experiencing an inflation of variance, primarily attributable to the reduced
efficacy in utilizing training samples during the reweighting process. Existing
remedies necessitate either environmental labels or substantially higher time
costs along with additional assumptions and supervised information. To mitigate
this issue, we propose SAmple Weight Averaging (SAWA), a simple yet efficacious
strategy that can be universally integrated into various sample reweighting
algorithms to decrease the variance and coefficient estimation error, thus
boosting the covariate-shift generalization and achieving stable prediction
across different environments. We prove its rationality and benefits
theoretically. Experiments across synthetic datasets and real-world datasets
consistently underscore its superiority against covariate shift.",http://arxiv.org/abs/2502.07414v1,Recommendation System,"generalization, sample, reweighting, covariate, shift"
EgoTextVQA: Towards Egocentric Scene-Text Aware Video Question Answering,"We introduce EgoTextVQA, a novel and rigorously constructed benchmark for
egocentric QA assistance involving scene text. EgoTextVQA contains 1.5K
ego-view videos and 7K scene-text aware questions that reflect real-user needs
in outdoor driving and indoor house-keeping activities. The questions are
designed to elicit identification and reasoning on scene text in an egocentric
and dynamic environment. With EgoTextVQA, we comprehensively evaluate 10
prominent multimodal large language models. Currently, all models struggle, and
the best results (Gemini 1.5 Pro) are around 33% accuracy, highlighting the
severe deficiency of these techniques in egocentric QA assistance. Our further
investigations suggest that precise temporal grounding and multi-frame
reasoning, along with high resolution and auxiliary scene-text inputs, are key
for better performance. With thorough analyses and heuristic suggestions, we
hope EgoTextVQA can serve as a solid testbed for research in egocentric
scene-text QA assistance.",http://arxiv.org/abs/2502.07411v1,Recommendation System,"scene, text, egotextvqa, egocentric, qa"
MGPATH: Vision-Language Model with Multi-Granular Prompt Learning for Few-Shot WSI Classification,"Whole slide pathology image classification presents challenges due to
gigapixel image sizes and limited annotation labels, hindering model
generalization. This paper introduces a prompt learning method to adapt large
vision-language models for few-shot pathology classification. We first extend
the Prov-GigaPath vision foundation model, pre-trained on 1.3 billion pathology
image tiles, into a vision-language model by adding adaptors and aligning it
with medical text encoders via contrastive learning on 923K image-text pairs.
The model is then used to extract visual features and text embeddings from
few-shot annotations and fine-tunes with learnable prompt embeddings. Unlike
prior methods that combine prompts with frozen features using prefix embeddings
or self-attention, we propose multi-granular attention that compares
interactions between learnable prompts with individual image patches and groups
of them. This approach improves the model's ability to capture both
fine-grained details and broader context, enhancing its recognition of complex
patterns across sub-regions. To further improve accuracy, we leverage
(unbalanced) optimal transport-based visual-text distance to secure model
robustness by mitigating perturbations that might occur during the data
augmentation process. Empirical experiments on lung, kidney, and breast
pathology modalities validate the effectiveness of our approach; thereby, we
surpass several of the latest competitors and consistently improve performance
across diverse architectures, including CLIP, PLIP, and Prov-GigaPath
integrated PLIP. We release our implementations and pre-trained models at this
MGPATH.",http://arxiv.org/abs/2502.07409v1,Computer Vision,"model, image, pathology, text, vision"
"No Data, No Optimization: A Lightweight Method To Disrupt Neural Networks With Sign-Flips","Deep Neural Networks (DNNs) can be catastrophically disrupted by flipping
only a handful of sign bits in their parameters. We introduce Deep Neural
Lesion (DNL), a data-free, lightweight method that locates these critical
parameters and triggers massive accuracy drops. We validate its efficacy on a
wide variety of computer vision models and datasets. The method requires no
training data or optimization and can be carried out via common exploits
software, firmware or hardware based attack vectors. An enhanced variant that
uses a single forward and backward pass further amplifies the damage beyond
DNL's zero-pass approach. Flipping just two sign bits in ResNet50 on ImageNet
reduces accuracy by 99.8\%. We also show that selectively protecting a small
fraction of vulnerable sign bits provides a practical defense against such
attacks.",http://arxiv.org/abs/2502.07408v1,Computer Vision,"sign, bits, deep, neural, flipping"
Human-in-the-Loop Annotation for Image-Based Engagement Estimation: Assessing the Impact of Model Reliability on Annotation Accuracy,"Human-in-the-loop (HITL) frameworks are increasingly recognized for their
potential to improve annotation accuracy in emotion estimation systems by
combining machine predictions with human expertise. This study focuses on
integrating a high-performing image-based emotion model into a HITL annotation
framework to evaluate the collaborative potential of human-machine interaction
and identify the psychological and practical factors critical to successful
collaboration. Specifically, we investigate how varying model reliability and
cognitive framing influence human trust, cognitive load, and annotation
behavior in HITL systems. We demonstrate that model reliability and
psychological framing significantly impact annotators' trust, engagement, and
consistency, offering insights into optimizing HITL frameworks. Through three
experimental scenarios with 29 participants--baseline model reliability (S1),
fabricated errors (S2), and cognitive bias introduced by negative framing
(S3)--we analyzed behavioral and qualitative data. Reliable predictions in S1
yielded high trust and annotation consistency, while unreliable outputs in S2
led to increased critical evaluations but also heightened frustration and
response variability. Negative framing in S3 revealed how cognitive bias
influenced participants to perceive the model as more relatable and accurate,
despite misinformation regarding its reliability. These findings highlight the
importance of both reliable machine outputs and psychological factors in
shaping effective human-machine collaboration. By leveraging the strengths of
both human oversight and automated systems, this study establishes a scalable
HITL framework for emotion annotation and lays the foundation for broader
applications in adaptive learning and human-computer interaction.",http://arxiv.org/abs/2502.07404v1,Recommendation System,"human, hitl, annotation, model, machine"
Extended monocular 3D imaging,"3D vision is of paramount importance for numerous applications ranging from
machine intelligence to precision metrology. Despite much recent progress, the
majority of 3D imaging hardware remains bulky and complicated and provides much
lower image resolution compared to their 2D counterparts. Moreover, there are
many well-known scenarios that existing 3D imaging solutions frequently fail.
Here, we introduce an extended monocular 3D imaging (EM3D) framework that fully
exploits the vectorial wave nature of light. Via the multi-stage fusion of
diffraction- and polarization-based depth cues, using a compact monocular
camera equipped with a diffractive-refractive hybrid lens, we experimentally
demonstrate the snapshot acquisition of a million-pixel and accurate 3D point
cloud for extended scenes that are traditionally challenging, including those
with low texture, being highly reflective, or nearly transparent, without a
data prior. Furthermore, we discover that the combination of depth and
polarization information can unlock unique new opportunities in material
identification, which may further expand machine intelligence for applications
like target recognition and face anti-spoofing. The straightforward yet
powerful architecture thus opens up a new path for a higher-dimensional machine
vision in a minimal form factor, facilitating the deployment of monocular
cameras for applications in much more diverse scenarios.",http://arxiv.org/abs/2502.07403v1,Recommendation System,"applications, machine, imaging, monocular, vision"
Enhancing Higher Education with Generative AI: A Multimodal Approach for Personalised Learning,"This research explores the opportunities of Generative AI (GenAI) in the
realm of higher education through the design and development of a multimodal
chatbot for an undergraduate course. Leveraging the ChatGPT API for nuanced
text-based interactions and Google Bard for advanced image analysis and
diagram-to-code conversions, we showcase the potential of GenAI in addressing a
broad spectrum of educational queries. Additionally, the chatbot presents a
file-based analyser designed for educators, offering deep insights into student
feedback via sentiment and emotion analysis, and summarising course evaluations
with key metrics. These combinations highlight the crucial role of multimodal
conversational AI in enhancing teaching and learning processes, promising
significant advancements in educational adaptability, engagement, and feedback
analysis. By demonstrating a practical web application, this research
underlines the imperative for integrating GenAI technologies to foster more
dynamic and responsive educational environments, ultimately contributing to
improved educational outcomes and pedagogical strategies.",http://arxiv.org/abs/2502.07401v1,Natural Language Processing,"educational, genai, analysis, research, ai"
Explainable Multimodal Machine Learning for Revealing Structure-Property Relationships in Carbon Nanotube Fibers,"In this study, we propose Explainable Multimodal Machine Learning (EMML),
which integrates the analysis of diverse data types (multimodal data) using
factor analysis for feature extraction with Explainable AI (XAI), for carbon
nanotube (CNT) fibers prepared from aqueous dispersions. This method is a
powerful approach to elucidate the mechanisms governing material properties,
where multi-stage fabrication conditions and multiscale structures have complex
influences. Thus, in our case, this approach helps us understand how different
processing steps and structures at various scales impact the final properties
of CNT fibers. The analysis targeted structures ranging from the nanoscale to
the macroscale, including aggregation size distributions of CNT dispersions and
the effective length of CNTs. Furthermore, because some types of data were
difficult to interpret using standard methods, challenging-to-interpret
distribution data were analyzed using Negative Matrix Factorization (NMF) for
extracting key features that determine the outcome. Contribution analysis with
SHapley Additive exPlanations (SHAP) demonstrated that small, uniformly
distributed aggregates are crucial for improving fracture strength, while CNTs
with long effective lengths are significant factors for enhancing electrical
conductivity. The analysis also identified thresholds and trends for these key
factors to assist in defining the conditions needed to optimize CNT fiber
properties. EMML is not limited to CNT fibers but can be applied to the design
of other materials derived from nanomaterials, making it a useful tool for
developing a wide range of advanced materials. This approach provides a
foundation for advancing data-driven materials research.",http://arxiv.org/abs/2502.07400v1,Recommendation System,"analysis, data, cnt, fibers, approach"
On Iterative Evaluation and Enhancement of Code Quality Using GPT-4o,"This paper introduces CodeQUEST, a novel framework leveraging Large Language
Models (LLMs) to iteratively evaluate and enhance code quality across multiple
dimensions, including readability, maintainability, efficiency, and security.
The framework is divided into two main components: an Evaluator that assesses
code quality across ten dimensions, providing both quantitative scores and
qualitative summaries, and an Optimizer that iteratively improves the code
based on the Evaluator's feedback. Our study demonstrates that CodeQUEST can
effectively and robustly evaluate code quality, with its assessments aligning
closely with established code quality metrics. Through a series of experiments
using a curated dataset of Python and JavaScript examples, CodeQUEST
demonstrated significant improvements in code quality, achieving a mean
relative percentage improvement of 52.6%. The framework's evaluations were
validated against a set of proxy metrics comprising of Pylint Score, Radon
Maintainability Index, and Bandit output logs, showing a meaningful
correlation. This highlights the potential of LLMs in automating code quality
evaluation and improvement processes, presenting a significant advancement
toward enhancing software development practices. The code implementation of the
framework is available at: https://github.com/jpmorganchase/CodeQuest.",http://arxiv.org/abs/2502.07399v1,Recommendation System,"code, quality, framework, codequest, llms"
Bandit Optimal Transport,"Despite the impressive progress in statistical Optimal Transport (OT) in
recent years, there has been little interest in the study of the
\emph{sequential learning} of OT. Surprisingly so, as this problem is both
practically motivated and a challenging extension of existing settings such as
linear bandits. This article considers (for the first time) the stochastic
bandit problem of learning to solve generic Kantorovich and entropic OT
problems from repeated interactions when the marginals are known but the cost
is unknown. We provide $\tilde{\mathcal O}(\sqrt{T})$ regret algorithms for
both problems by extending linear bandits on Hilbert spaces. These results
provide a reduction to infinite-dimensional linear bandits. To deal with the
dimension, we provide a method to exploit the intrinsic regularity of the cost
to learn, yielding corresponding regret bounds which interpolate between
$\tilde{\mathcal O}(\sqrt{T})$ and $\tilde{\mathcal O}(T)$.",http://arxiv.org/abs/2502.07397v1,Recommendation System,"ot, linear, bandits, provide, learning"
Spread them Apart: Towards Robust Watermarking of Generated Content,"Generative models that can produce realistic images have improved
significantly in recent years. The quality of the generated content has
increased drastically, so sometimes it is very difficult to distinguish between
the real images and the generated ones. Such an improvement comes at a price of
ethical concerns about the usage of the generative models: the users of
generative models can improperly claim ownership of the generated content
protected by a license. In this paper, we propose an approach to embed
watermarks into the generated content to allow future detection of the
generated content and identification of the user who generated it. The
watermark is embedded during the inference of the model, so the proposed
approach does not require the retraining of the latter. We prove that
watermarks embedded are guaranteed to be robust against additive perturbations
of a bounded magnitude. We apply our method to watermark diffusion models and
show that it matches state-of-the-art watermarking schemes in terms of
robustness to different types of synthetic watermark removal attacks.",http://arxiv.org/abs/2502.07845v1,Recommendation System,"generated, models, content, generative, watermark"
Optimality in importance sampling: a gentle survey,"The performance of the Monte Carlo sampling methods relies on the crucial
choice of a proposal density. The notion of optimality is fundamental to design
suitable adaptive procedures of the proposal density within Monte Carlo
schemes. This work is an exhaustive review around the concept of optimality in
importance sampling. Several frameworks are described and analyzed, such as the
marginal likelihood approximation for model selection, the use of multiple
proposal densities, a sequence of tempered posteriors, and noisy scenarios
including the applications to approximate Bayesian computation (ABC) and
reinforcement learning, to name a few. Some theoretical and empirical
comparisons are also provided.",http://arxiv.org/abs/2502.07396v1,Reinforcement Learning,"proposal, monte, carlo, sampling, density"
Interpretable Rules for Online Failure Prediction: A Case Study on the Metro do Porto dataset,"Due to their high predictive performance, predictive maintenance applications
have increasingly been approached with Deep Learning techniques in recent
years. However, as in other real-world application scenarios, the need for
explainability is often stated but not sufficiently addressed. This study will
focus on predicting failures on Metro trains in Porto, Portugal. While recent
works have found high-performing deep neural network architectures that feature
a parallel explainability pipeline, the generated explanations are fairly
complicated and need help explaining why the failures are happening. This work
proposes a simple online rule-based explainability approach with interpretable
features that leads to straightforward, interpretable rules. We showcase our
approach on MetroPT2 and find that three specific sensors on the Metro do Porto
trains suffice to predict the failures present in the dataset with simple
rules.",http://arxiv.org/abs/2502.07394v1,Recommendation System,"explainability, failures, high, predictive, deep"
FADE: Forecasting for Anomaly Detection on ECG,"Cardiovascular diseases, a leading cause of noncommunicable disease-related
deaths, require early and accurate detection to improve patient outcomes.
Taking advantage of advances in machine learning and deep learning, multiple
approaches have been proposed in the literature to address the challenge of
detecting ECG anomalies. Typically, these methods are based on the manual
interpretation of ECG signals, which is time consuming and depends on the
expertise of healthcare professionals. The objective of this work is to propose
a deep learning system, FADE, designed for normal ECG forecasting and anomaly
detection, which reduces the need for extensive labeled datasets and manual
interpretation. FADE has been trained in a self-supervised manner with a novel
morphological inspired loss function. Unlike conventional models that learn
from labeled anomalous ECG waveforms, our approach predicts the future of
normal ECG signals, thus avoiding the need for extensive labeled datasets.
Using a novel distance function to compare forecasted ECG signals with actual
sensor data, our method effectively identifies cardiac anomalies. Additionally,
this approach can be adapted to new contexts through domain adaptation
techniques. To evaluate our proposal, we performed a set of experiments using
two publicly available datasets: MIT-BIH NSR and MIT-BIH Arrythmia. The results
demonstrate that our system achieves an average accuracy of 83.84% in anomaly
detection, while correctly classifying normal ECG signals with an accuracy of
85.46%. Our proposed approach exhibited superior performance in the early
detection of cardiac anomalies in ECG signals, surpassing previous methods that
predominantly identify a limited range of anomalies. FADE effectively detects
both abnormal heartbeats and arrhythmias, offering significant advantages in
healthcare through cost reduction or processing of large-scale ECG data.",http://arxiv.org/abs/2502.07389v1,Recommendation System,"ecg, signals, detection, anomalies, learning"
Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution,"Due to limitations of storage and bandwidth, videos stored and transmitted on
the Internet are usually low-quality with low-resolution and compression noise.
Although video super-resolution (VSR) is an efficient technique to enhance
video resolution, relatively VSR methods focus on compressed videos. Directly
applying general VSR approaches leads to the failure of improving practical
videos, especially when frames are highly compressed at a low bit rate.
Recently, diffusion models have achieved superior performance in low-level
visual tasks, and their high-realism generation capability enables them to be
applied in VSR. To synthesize more compression-lost details and refine temporal
consistency, we propose a novel Spatial Degradation-Aware and Temporal
Consistent (SDATC) diffusion model for compressed VSR. Specifically, we
introduce a distortion Control module (DCM) to modulate diffusion model inputs
and guide the generation. Next, the diffusion model executes the denoising
process for texture generation with fine-tuned spatial prompt-based
compression-aware module (PCAM) and spatio-temporal attention module (STAM).
PCAM extracts features to encode specific compression information dynamically.
STAM extends the spatial attention mechanism to a spatio-temporal dimension for
capturing temporal correlation. Extensive experimental results on benchmark
datasets demonstrate the effectiveness of the proposed modules in enhancing
compressed videos.",http://arxiv.org/abs/2502.07381v2,Recommendation System,"vsr, temporal, videos, low, compression"
"LLMs Can Easily Learn to Reason from Demonstrations Structure, not content, is what matters!","Large reasoning models (LRMs) tackle complex reasoning problems by following
long chain-of-thoughts (Long CoT) that incorporate reflection, backtracking,
and self-validation. However, the training techniques and data requirements to
elicit Long CoT remain poorly understood. In this work, we find that a Large
Language model (LLM) can effectively learn Long CoT reasoning through
data-efficient supervised fine-tuning (SFT) and parameter-efficient low-rank
adaptation (LoRA). With just 17k long CoT training samples, the
Qwen2.5-32B-Instruct model achieves significant improvements on a wide range of
math and coding benchmarks, including 56.7% (+40.0%) on AIME 2024 and 57.0%
(+8.1%) on LiveCodeBench, competitive to the proprietary o1-preview model's
score of 44.6% and 59.1%. More importantly, we find that the structure of Long
CoT is critical to the learning process, whereas the content of individual
reasoning steps has minimal impact. Perturbations affecting content, such as
training on incorrect samples or removing reasoning keywords, have little
impact on performance. In contrast, structural modifications that disrupt
logical consistency in the Long CoT, such as shuffling or deleting reasoning
steps, significantly degrade accuracy. For example, a model trained on Long CoT
samples with incorrect answers still achieves only 3.2% lower accuracy compared
to training with fully correct samples. These insights deepen our understanding
of how to elicit reasoning capabilities in LLMs and highlight key
considerations for efficiently training the next generation of reasoning
models. This is the academic paper of our previous released Sky-T1-32B-Preview
model. Codes are available at https://github.com/NovaSky-AI/SkyThought.",http://arxiv.org/abs/2502.07374v1,Reinforcement Learning,"reasoning, long, cot, training, model"
EvoFlow: Evolving Diverse Agentic Workflows On The Fly,"The past two years have witnessed the evolution of large language model
(LLM)-based multi-agent systems from labor-intensive manual design to partial
automation (\textit{e.g.}, prompt engineering, communication topology) and
eventually to fully automated design. However, existing agentic automation
pipelines often lack LLM heterogeneity and focus on single-objective
performance optimization, limiting their potential to combine weaker models for
more customized and cost-effective solutions. To address this challenge, we
propose EvoFlow, a niching evolutionary algorithm-based framework to
automatically search a population of heterogeneous and complexity-adaptive
agentic workflows, rather than a single homogeneous, complex workflow.
Technically, EvoFlow performs \textit{(1) tag-based retrieval} to extract
parent workflows from an agentic population, evolves new workflows through
\textit{(2) crossover} and \textit{(3) mutation}, and employs \textit{(4)
niching-based selection} to maintain population diversity and quality.
Extensive evaluations across seven benchmarks demonstrate that EvoFlow is:
\textbf{(I) diverse}, evolving a population of workflows ranging from simple
I/O tasks to complex multi-turn interactions; \textbf{(II) high-performing},
outperforming previous handcrafted and automated workflows by
$1.23\%\sim29.86\%$; \textbf{(III) economical}, surpassing powerful
\llmname{o1-preview} at $12.4\%$ of its inference cost using weaker open-source
models.",http://arxiv.org/abs/2502.07373v1,Recommendation System,"workflows, population, agentic, evoflow, based"
USRNet: Unified Scene Recovery Network for Enhancing Traffic Imaging under Multiple Adverse Weather Conditions,"Advancements in computer vision technology have facilitated the extensive
deployment of intelligent transportation systems and visual surveillance
systems across various applications, including autonomous driving, public
safety, and environmental monitoring. However, adverse weather conditions such
as haze, rain, snow, and more complex mixed degradation can significantly
degrade image quality. The degradation compromises the accuracy and reliability
of these systems across various scenarios. To tackle the challenge of
developing adaptable models for scene restoration, we introduce the unified
scene recovery network (USRNet), capable of handling multiple types of image
degradation. The USRNet features a sophisticated architecture consisting of a
scene encoder, an attention-driven node independent learning mechanism (NILM),
an edge decoder, and a scene restoration module. The scene encoder, powered by
advanced residual blocks, extracts deep features from degraded images in a
progressive manner, ensuring thorough encoding of degradation information. To
enhance the USRNet's adaptability in diverse weather conditions, we introduce
NILM, which enables the network to learn and respond to different scenarios
with precision, thereby increasing its robustness. The edge decoder is designed
to extract edge features with precision, which is essential for maintaining
image sharpness. Experimental results demonstrate that USRNet surpasses
existing methods in handling complex imaging degradations, thereby improving
the accuracy and reliability of visual systems across diverse scenarios. The
code resources for this work can be accessed in
https://github.com/LouisYxLu/USRNet.",http://arxiv.org/abs/2502.07372v1,Computer Vision,"scene, systems, degradation, usrnet, image"
Uniform Kernel Prober,"The ability to identify useful features or representations of the input data
based on training data that achieves low prediction error on test data across
multiple prediction tasks is considered the key to multitask learning success.
In practice, however, one faces the issue of the choice of prediction tasks and
the availability of test data from the chosen tasks while comparing the
relative performance of different features. In this work, we develop a class of
pseudometrics called Uniform Kernel Prober (UKP) for comparing features or
representations learned by different statistical models such as neural networks
when the downstream prediction tasks involve kernel ridge regression. The
proposed pseudometric, UKP, between any two representations, provides a uniform
measure of prediction error on test data corresponding to a general class of
kernel ridge regression tasks for a given choice of a kernel without access to
test data. Additionally, desired invariances in representations can be
successfully captured by UKP only through the choice of the kernel function and
the pseudometric can be efficiently estimated from $n$ input data samples with
$O(\frac{1}{\sqrt{n}})$ estimation error. We also experimentally demonstrate
the ability of UKP to discriminate between different types of features or
representations based on their generalization performance on downstream kernel
ridge regression tasks.",http://arxiv.org/abs/2502.07369v1,Recommendation System,"data, tasks, kernel, representations, prediction"
LongReD: Mitigating Short-Text Degradation of Long-Context Large Language Models via Restoration Distillation,"Large language models (LLMs) have gained extended context windows through
scaling positional encodings and lightweight continual pre-training. However,
this often leads to degraded performance on short-text tasks, while the reasons
for this degradation remain insufficiently explored. In this work, we identify
two primary factors contributing to this issue: distribution drift in hidden
states and attention scores, and catastrophic forgetting during continual
pre-training. To address these challenges, we propose Long Context Pre-training
with Restoration Distillation (LongReD), a novel approach designed to mitigate
short-text performance degradation through minimizing the distribution
discrepancy between the extended and original models. Besides training on long
texts, LongReD distills the hidden state of selected layers from the original
model on short texts. Additionally, LongReD also introduces a short-to-long
distillation, aligning the output distribution on short texts with that on long
texts by leveraging skipped positional indices. Experiments on common text
benchmarks demonstrate that LongReD effectively preserves the model's
short-text performance while maintaining comparable or even better capacity to
handle long texts than baselines.",http://arxiv.org/abs/2502.07365v1,Reinforcement Learning,"short, long, texts, training, text"
Effects of Random Edge-Dropping on Over-Squashing in Graph Neural Networks,"Message Passing Neural Networks (MPNNs) are a class of Graph Neural Networks
(GNNs) that leverage the graph topology to propagate messages across
increasingly larger neighborhoods. The message-passing scheme leads to two
distinct challenges: over-smoothing and over-squashing. While several
algorithms, e.g. DropEdge and its variants -- DropNode, DropAgg and DropGNN --
have successfully addressed the over-smoothing problem, their impact on
over-squashing remains largely unexplored. This represents a critical gap in
the literature as failure to mitigate over-squashing would make these methods
unsuitable for long-range tasks. In this work, we take the first step towards
closing this gap by studying the aforementioned algorithms in the context of
over-squashing. We present novel theoretical results that characterize the
negative effects of DropEdge on sensitivity between distant nodes, suggesting
its unsuitability for long-range tasks. Our findings are easily extended to its
variants, allowing us to build a comprehensive understanding of how they affect
over-squashing. We evaluate these methods using real-world datasets,
demonstrating their detrimental effects. Specifically, we show that while
DropEdge-variants improve test-time performance in short range tasks, they
deteriorate performance in long-range ones. Our theory explains these results
as follows: random edge-dropping lowers the effective receptive field of GNNs,
which although beneficial for short-range tasks, misaligns the models on
long-range ones. This forces the models to overfit to short-range artefacts in
the training set, resulting in poor generalization. Our conclusions highlight
the need to re-evaluate various methods designed for training deep GNNs, with a
renewed focus on modelling long-range interactions.",http://arxiv.org/abs/2502.07364v1,Recommendation System,"range, squashing, long, tasks, gnns"
Supervised contrastive learning for cell stage classification of animal embryos,"Video microscopy, when combined with machine learning, offers a promising
approach for studying the early development of in vitro produced (IVP) embryos.
However, manually annotating developmental events, and more specifically cell
divisions, is time-consuming for a biologist and cannot scale up for practical
applications. We aim to automatically classify the cell stages of embryos from
2D time-lapse microscopy videos with a deep learning approach. We focus on the
analysis of bovine embryonic development using video microscopy, as we are
primarily interested in the application of cattle breeding, and we have created
a Bovine Embryos Cell Stages (ECS) dataset. The challenges are three-fold: (1)
low-quality images and bovine dark cells that make the identification of cell
stages difficult, (2) class ambiguity at the boundaries of developmental
stages, and (3) imbalanced data distribution. To address these challenges, we
introduce CLEmbryo, a novel method that leverages supervised contrastive
learning combined with focal loss for training, and the lightweight 3D neural
network CSN-50 as an encoder. We also show that our method generalizes well.
CLEmbryo outperforms state-of-the-art methods on both our Bovine ECS dataset
and the publicly available NYU Mouse Embryos dataset.",http://arxiv.org/abs/2502.07360v1,Recommendation System,"embryos, cell, stages, bovine, microscopy"
Multi-Task-oriented Nighttime Haze Imaging Enhancer for Vision-driven Measurement Systems,"Salient object detection (SOD) plays a critical role in vision-driven
measurement systems (VMS), facilitating the detection and segmentation of key
visual elements in an image. However, adverse imaging conditions such as haze
during the day, low light, and haze at night severely degrade image quality,
and complicating the SOD process. To address these challenges, we propose a
multi-task-oriented nighttime haze imaging enhancer (MToIE), which integrates
three tasks: daytime dehazing, low-light enhancement, and nighttime dehazing.
The MToIE incorporates two key innovative components: First, the network
employs a task-oriented node learning mechanism to handle three specific
degradation types: day-time haze, low light, and night-time haze conditions,
with an embedded self-attention module enhancing its performance in nighttime
imaging. In addition, multi-receptive field enhancement module that efficiently
extracts multi-scale features through three parallel depthwise separable
convolution branches with different dilation rates, capturing comprehensive
spatial information with minimal computational overhead. To ensure optimal
image reconstruction quality and visual characteristics, we suggest a hybrid
loss function. Extensive experiments on different types of weather/imaging
conditions illustrate that MToIE surpasses existing methods, significantly
enhancing the accuracy and reliability of vision systems across diverse imaging
scenarios. The code is available at https://github.com/Ai-Chen-Lab/MToIE.",http://arxiv.org/abs/2502.07351v1,Recommendation System,"imaging, haze, image, conditions, low"
KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems,"As scaling large language models faces prohibitive costs, multi-agent systems
emerge as a promising alternative, though challenged by static knowledge
assumptions and coordination inefficiencies. We introduces Knowledge-Aware
Bayesian Bandits (KABB), a novel framework that enhances multi-agent system
coordination through semantic understanding and dynamic adaptation. The
framework features three key innovations: a three-dimensional knowledge
distance model for deep semantic understanding, a dual-adaptation mechanism for
continuous expert optimization, and a knowledge-aware Thompson Sampling
strategy for efficient expert selection. Extensive evaluation demonstrates KABB
achieves an optimal cost-performance balance, maintaining high performance
while keeping computational demands relatively low in multi-agent coordination.",http://arxiv.org/abs/2502.07350v1,Recommendation System,"knowledge, multi, agent, coordination, aware"
The establishment of static digital humans and the integration with spinal models,"Adolescent idiopathic scoliosis (AIS), a prevalent spinal deformity,
significantly affects individuals' health and quality of life. Conventional
imaging techniques, such as X - rays, computed tomography (CT), and magnetic
resonance imaging (MRI), offer static views of the spine. However, they are
restricted in capturing the dynamic changes of the spine and its interactions
with overall body motion. Therefore, developing new techniques to address these
limitations has become extremely important. Dynamic digital human modeling
represents a major breakthrough in digital medicine. It enables a three -
dimensional (3D) view of the spine as it changes during daily activities,
assisting clinicians in detecting deformities that might be missed in static
imaging. Although dynamic modeling holds great potential, constructing an
accurate static digital human model is a crucial initial step for high -
precision simulations. In this study, our focus is on constructing an accurate
static digital human model integrating the spine, which is vital for subsequent
dynamic digital human research on AIS. First, we generate human point - cloud
data by combining the 3D Gaussian method with the Skinned Multi - Person Linear
(SMPL) model from the patient's multi - view images. Then, we fit a standard
skeletal model to the generated human model. Next, we align the real spine
model reconstructed from CT images with the standard skeletal model. We
validated the resulting personalized spine model using X - ray data from six
AIS patients, with Cobb angles (used to measure the severity of scoliosis) as
evaluation metrics. The results indicate that the model's error was within 1
degree of the actual measurements. This study presents an important method for
constructing digital humans.",http://arxiv.org/abs/2502.07844v1,Recommendation System,"model, spine, digital, human, static"
Coarse Set Theory: A Mathematical Foundation for Coarse Ethics,"In ethical decision-making, individuals are often evaluated based on
generalized assessments rather than precise individual performance. This
concept, known as Coarse Ethics (CE), has primarily been discussed in natural
language without a formal mathematical foundation. This paper introduces Coarse
Set Theory (CST) to establish a mathematical framework for CE. We define coarse
sets using totally ordered sets and propose axioms that characterize the
hierarchical relationships between elements and their groupings. Additionally,
we introduce coarse-grained sets, which partition an underlying set into
equivalence classes based on predefined criteria. We extend this framework by
defining coarse mappings, which transform detailed individual data into coarser
representations while maintaining essential structural properties. To measure
the information loss, we employ Kullback-Leibler (KL) divergence, demonstrating
how different coarse partitions affect the preservation of information. We
illustrate how CST can be applied to real-world grading systems through
theoretical formulations and empirical analysis. This study provides a rigorous
foundation for CE, enabling a more systematic exploration of fairness,
interpretability, and decision-making trade-offs.",http://arxiv.org/abs/2502.07347v1,Recommendation System,"coarse, ce, sets, decision, making"
Integrating Physics and Data-Driven Approaches: An Explainable and Uncertainty-Aware Hybrid Model for Wind Turbine Power Prediction,"The rapid growth of the wind energy sector underscores the urgent need to
optimize turbine operations and ensure effective maintenance through early
fault detection systems. While traditional empirical and physics-based models
offer approximate predictions of power generation based on wind speed, they
often fail to capture the complex, non-linear relationships between other input
variables and the resulting power output. Data-driven machine learning methods
present a promising avenue for improving wind turbine modeling by leveraging
large datasets, enhancing prediction accuracy but often at the cost of
interpretability. In this study, we propose a hybrid semi-parametric model that
combines the strengths of both approaches, applied to a dataset from a wind
farm with four turbines. The model integrates a physics-inspired submodel,
providing a reasonable approximation of power generation, with a non-parametric
submodel that predicts the residuals. This non-parametric submodel is trained
on a broader range of variables to account for phenomena not captured by the
physics-based component. The hybrid model achieves a 37% improvement in
prediction accuracy over the physics-based model. To enhance interpretability,
SHAP values are used to analyze the influence of input features on the residual
submodel's output. Additionally, prediction uncertainties are quantified using
a conformalized quantile regression method. The combination of these
techniques, alongside the physics grounding of the parametric submodel,
provides a flexible, accurate, and reliable framework. Ultimately, this study
opens the door for evaluating the impact of unmodeled variables on wind turbine
power generation, offering a basis for potential optimization.",http://arxiv.org/abs/2502.07344v1,Recommendation System,"wind, physics, submodel, based, power"
Aligning Large Language Models to Follow Instructions and Hallucinate Less via Effective Data Filtering,"Training LLMs on data that contains unfamiliar knowledge during the
instruction tuning stage can make LLMs overconfident and encourage
hallucinations. To address this challenge, we introduce a novel framework,
NOVA, which identifies high-quality data that aligns well with the LLM's
learned knowledge to reduce hallucinations. NOVA includes Internal Consistency
Probing (ICP) and Semantic Equivalence Identification (SEI) to measure how
familiar the LLM is with instruction data. Specifically, ICP evaluates the
LLM's understanding of the given instruction by calculating the tailored
consistency among multiple self-generated responses. SEI further assesses the
familiarity of the LLM with the target response by comparing it to the
generated responses, using the proposed semantic clustering and well-designed
voting strategy. Finally, we introduce an expert-aligned reward model,
considering characteristics beyond just familiarity to enhance data quality. By
considering data quality and avoiding unfamiliar data, we can utilize the
selected data to effectively align LLMs to follow instructions and hallucinate
less. Extensive experiments and analysis show that NOVA significantly reduces
hallucinations and allows LLMs to maintain a strong ability to follow
instructions.",http://arxiv.org/abs/2502.07340v1,Reinforcement Learning,"data, llms, llm, instruction, hallucinations"
Emotional EEG Classification using Upscaled Connectivity Matrices,"In recent studies of emotional EEG classification, connectivity matrices have
been successfully employed as input to convolutional neural networks (CNNs),
which can effectively consider inter-regional interaction patterns in EEG.
However, we find that such an approach has a limitation that important patterns
in connectivity matrices may be lost during the convolutional operations in
CNNs. To resolve this issue, we propose and validate an idea to upscale the
connectivity matrices to strengthen the local patterns. Experimental results
demonstrate that this simple idea can significantly enhance the classification
performance.",http://arxiv.org/abs/2502.07843v1,Recommendation System,"connectivity, matrices, patterns, eeg, classification"
Neural Flow Samplers with Shortcut Models,"Sampling from unnormalized densities is a fundamental task across various
domains. Flow-based samplers generate samples by learning a velocity field that
satisfies the continuity equation, but this requires estimating the intractable
time derivative of the partition function. While importance sampling provides
an approximation, it suffers from high variance. To mitigate this, we introduce
a velocity-driven Sequential Monte Carlo method combined with control variates
to reduce variance. Additionally, we incorporate a shortcut model to improve
efficiency by minimizing the number of sampling steps. Empirical results on
both synthetic datasets and $n$-body system targets validate the effectiveness
of our approach.",http://arxiv.org/abs/2502.07337v1,Recommendation System,"sampling, velocity, variance, unnormalized, densities"
ERANet: Edge Replacement Augmentation for Semi-Supervised Meniscus Segmentation with Prototype Consistency Alignment and Conditional Self-Training,"Manual segmentation is labor-intensive, and automatic segmentation remains
challenging due to the inherent variability in meniscal morphology, partial
volume effects, and low contrast between the meniscus and surrounding tissues.
To address these challenges, we propose ERANet, an innovative semi-supervised
framework for meniscus segmentation that effectively leverages both labeled and
unlabeled images through advanced augmentation and learning strategies. ERANet
integrates three key components: edge replacement augmentation (ERA), prototype
consistency alignment (PCA), and a conditional self-training (CST) strategy
within a mean teacher architecture. ERA introduces anatomically relevant
perturbations by simulating meniscal variations, ensuring that augmentations
align with the structural context. PCA enhances segmentation performance by
aligning intra-class features and promoting compact, discriminative feature
representations, particularly in scenarios with limited labeled data. CST
improves segmentation robustness by iteratively refining pseudo-labels and
mitigating the impact of label noise during training. Together, these
innovations establish ERANet as a robust and scalable solution for meniscus
segmentation, effectively addressing key barriers to practical implementation.
We validated ERANet comprehensively on 3D Double Echo Steady State (DESS) and
3D Fast/Turbo Spin Echo (FSE/TSE) MRI sequences. The results demonstrate the
superior performance of ERANet compared to state-of-the-art methods. The
proposed framework achieves reliable and accurate segmentation of meniscus
structures, even when trained on minimal labeled data. Extensive ablation
studies further highlight the synergistic contributions of ERA, PCA, and CST,
solidifying ERANet as a transformative solution for semi-supervised meniscus
segmentation in medical imaging.",http://arxiv.org/abs/2502.07331v1,Reinforcement Learning,"segmentation, eranet, meniscus, labeled, era"
Music for All: Exploring Multicultural Representations in Music Generation Models,"The advent of Music-Language Models has greatly enhanced the automatic music
generation capability of AI systems, but they are also limited in their
coverage of the musical genres and cultures of the world. We present a study of
the datasets and research papers for music generation and quantify the bias and
under-representation of genres. We find that only 5.7% of the total hours of
existing music datasets come from non-Western genres, which naturally leads to
disparate performance of the models across genres. We then investigate the
efficacy of Parameter-Efficient Fine-Tuning (PEFT) techniques in mitigating
this bias. Our experiments with two popular models -- MusicGen and Mustango,
for two underrepresented non-Western music traditions -- Hindustani Classical
and Turkish Makam music, highlight the promises as well as the non-triviality
of cross-genre adaptation of music through small datasets, implying the need
for more equitable baseline music-language models that are designed for
cross-cultural transfer learning.",http://arxiv.org/abs/2502.07328v2,Recommendation System,"music, models, genres, datasets, non"
Generative Ghost: Investigating Ranking Bias Hidden in AI-Generated Videos,"With the rapid development of AI-generated content (AIGC), the creation of
high-quality AI-generated videos has become faster and easier, resulting in the
Internet being flooded with all kinds of video content. However, the impact of
these videos on the content ecosystem remains largely unexplored. Video
information retrieval remains a fundamental approach for accessing video
content. Building on the observation that retrieval models often favor
AI-generated content in ad-hoc and image retrieval tasks, we investigate
whether similar biases emerge in the context of challenging video retrieval,
where temporal and visual factors may further influence model behavior. To
explore this, we first construct a comprehensive benchmark dataset containing
both real and AI-generated videos, along with a set of fair and rigorous
metrics to assess bias. This benchmark consists of 13,000 videos generated by
two state-of-the-art open-source video generation models. We meticulously
design a suite of rigorous metrics to accurately measure this preference,
accounting for potential biases arising from the limited frame rate and
suboptimal quality of AIGC videos. We then applied three off-the-shelf video
retrieval models to perform retrieval tasks on this hybrid dataset. Our
findings reveal a clear preference for AI-generated videos in retrieval.
Further investigation shows that incorporating AI-generated videos into the
training set of retrieval models exacerbates this bias. Unlike the preference
observed in image modalities, we find that video retrieval bias arises from
both unseen visual and temporal information, making the root causes of video
bias a complex interplay of these two factors. To mitigate this bias, we
fine-tune the retrieval models using a contrastive learning approach. The
results of this study highlight the potential implications of AI-generated
videos on retrieval systems.",http://arxiv.org/abs/2502.07327v1,Recommendation System,"retrieval, generated, videos, video, ai"
PICTS: A Novel Deep Reinforcement Learning Approach for Dynamic P-I Control in Scanning Probe Microscopy,"We have developed a Parallel Integrated Control and Training System,
leveraging the deep reinforcement learning to dynamically adjust the control
strategies in real time for scanning probe microscopy techniques.",http://arxiv.org/abs/2502.07326v1,Reinforcement Learning,"control, developed, parallel, integrated, training"
Long-term simulation of physical and mechanical behaviors using curriculum-transfer-learning based physics-informed neural networks,"This paper proposes a Curriculum-Transfer-Learning based physics-informed
neural network (CTL-PINN) for long-term simulation of physical and mechanical
behaviors. The main innovation of CTL-PINN lies in decomposing long-term
problems into a sequence of short-term subproblems. Initially, the standard
PINN is employed to solve the first sub-problem. As the simulation progresses,
subsequent time-domain problems are addressed using a curriculum learning
approach that integrates information from previous steps. Furthermore, transfer
learning techniques are incorporated, allowing the model to effectively utilize
prior training data and solve sequential time domain transfer problems.
CTL-PINN combines the strengths of curriculum learning and transfer learning,
overcoming the limitations of standard PINNs, such as local optimization
issues, and addressing the inaccuracies over extended time domains encountered
in CL-PINN and the low computational efficiency of TL-PINN. The efficacy and
robustness of CTL-PINN are demonstrated through applications to nonlinear wave
propagation, Kirchhoff plate dynamic response, and the hydrodynamic model of
the Three Gorges Reservoir Area, showcasing its superior capability in
addressing long-term computational challenges.",http://arxiv.org/abs/2502.07325v1,Recommendation System,"pinn, learning, transfer, ctl, term"
Semantic to Structure: Learning Structural Representations for Infringement Detection,"Structural information in images is crucial for aesthetic assessment, and it
is widely recognized in the artistic field that imitating the structure of
other works significantly infringes on creators' rights. The advancement of
diffusion models has led to AI-generated content imitating artists' structural
creations, yet effective detection methods are still lacking. In this paper, we
define this phenomenon as ""structural infringement"" and propose a corresponding
detection method. Additionally, we develop quantitative metrics and create
manually annotated datasets for evaluation: the SIA dataset of synthesized
data, and the SIR dataset of real data. Due to the current lack of datasets for
structural infringement detection, we propose a new data synthesis strategy
based on diffusion models and LLM, successfully training a structural
infringement detection model. Experimental results show that our method can
successfully detect structural infringements and achieve notable improvements
on annotated test sets.",http://arxiv.org/abs/2502.07323v1,Recommendation System,"structural, detection, infringement, data, imitating"
MEMIT-Merge: Addressing MEMIT's Key-Value Conflicts in Same-Subject Batch Editing for LLMs,"As large language models continue to scale up, knowledge editing techniques
that modify models' internal knowledge without full retraining have gained
significant attention. MEMIT, a prominent batch editing algorithm, stands out
for its capability to perform mass knowledge modifications. However, we uncover
a critical limitation that MEMIT's editing efficacy significantly deteriorates
when processing batches containing multiple edits sharing the same subject. Our
analysis reveals that the root cause lies in MEMIT's key value modeling
framework: When multiple facts with the same subject in a batch are modeled
through MEMIT's key value mechanism, identical keys (derived from the shared
subject) are forced to represent different values (corresponding to different
knowledge), resulting in updates conflicts during editing. Addressing this
issue, we propose MEMIT-Merge, an enhanced approach that merges value
computation processes for facts sharing the same subject, effectively resolving
the performance degradation in same-subject batch editing scenarios.
Experimental results demonstrate that when MEMIT's edit success rate drops to
around 50% at larger batch sizes, MEMIT-Merge maintains a success rate
exceeding 90%, showcasing remarkable robustness to subject entity collisions.",http://arxiv.org/abs/2502.07322v1,Natural Language Processing,"memit, subject, editing, knowledge, batch"
Learnable Residual-based Latent Denoising in Semantic Communication,"A latent denoising semantic communication (SemCom) framework is proposed for
robust image transmission over noisy channels. By incorporating a learnable
latent denoiser into the receiver, the received signals are preprocessed to
effectively remove the channel noise and recover the semantic information,
thereby enhancing the quality of the decoded images. Specifically, a latent
denoising mapping is established by an iterative residual learning approach to
improve the denoising efficiency while ensuring stable performance. Moreover,
channel signal-to-noise ratio (SNR) is utilized to estimate and predict the
latent similarity score (SS) for conditional denoising, where the number of
denoising steps is adapted based on the predicted SS sequence, further reducing
the communication latency. Finally, simulations demonstrate that the proposed
framework can effectively and efficiently remove the channel noise at various
levels and reconstruct visual-appealing images.",http://arxiv.org/abs/2502.07319v1,Recommendation System,"denoising, latent, channel, noise, semantic"
CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction,"Reasoning is a fundamental capability of Large Language Models. While prior
research predominantly focuses on enhancing narrow skills like math or code
generation, improving performance on many other reasoning tasks remains
challenging due to sparse and fragmented training data. To address this issue,
we propose CodeI/O, a novel approach that systematically condenses diverse
reasoning patterns inherently embedded in contextually-grounded codes, through
transforming the original code into a code input-output prediction format. By
training models to predict inputs/outputs given code and test cases entirely in
natural language as Chain-of-Thought (CoT) rationales, we expose them to
universal reasoning primitives -- like logic flow planning, state-space
searching, decision tree traversal, and modular decomposition -- while
decoupling structured reasoning from code-specific syntax and preserving
procedural rigor. Experimental results demonstrate CodeI/O leads to consistent
improvements across symbolic, scientific, logic, math & numerical, and
commonsense reasoning tasks. By matching the existing ground-truth outputs or
re-executing the code with predicted inputs, we can verify each prediction and
further enhance the CoTs through multi-turn revision, resulting in CodeI/O++
and achieving higher performance. Our data and models are available at
https://github.com/hkust-nlp/CodeIO.",http://arxiv.org/abs/2502.07316v2,Natural Language Processing,"reasoning, code, models, codei, language"
OpenGrok: Enhancing SNS Data Processing with Distilled Knowledge and Mask-like Mechanisms,"This report details Lumen Labs' novel approach to processing Social
Networking Service (SNS) data. We leverage knowledge distillation, specifically
a simple distillation method inspired by DeepSeek-R1's CoT acquisition,
combined with prompt hacking, to extract valuable training data from the Grok
model. This data is then used to fine-tune a Phi-3-mini model, augmented with a
mask-like mechanism specifically designed for handling the nuances of SNS data.
Our method demonstrates state-of-the-art (SOTA) performance on several SNS data
processing tasks, outperforming existing models like Grok, Phi-3, and GPT-4. We
provide a comprehensive analysis of our approach, including mathematical
formulations, engineering details, ablation studies, and comparative
evaluations.",http://arxiv.org/abs/2502.07312v1,Reinforcement Learning,"data, sns, details, approach, processing"
Semi-Supervised Vision-Centric 3D Occupancy World Model for Autonomous Driving,"Understanding world dynamics is crucial for planning in autonomous driving.
Recent methods attempt to achieve this by learning a 3D occupancy world model
that forecasts future surrounding scenes based on current observation. However,
3D occupancy labels are still required to produce promising results.
Considering the high annotation cost for 3D outdoor scenes, we propose a
semi-supervised vision-centric 3D occupancy world model, PreWorld, to leverage
the potential of 2D labels through a novel two-stage training paradigm: the
self-supervised pre-training stage and the fully-supervised fine-tuning stage.
Specifically, during the pre-training stage, we utilize an attribute projection
head to generate different attribute fields of a scene (e.g., RGB, density,
semantic), thus enabling temporal supervision from 2D labels via volume
rendering techniques. Furthermore, we introduce a simple yet effective
state-conditioned forecasting module to recursively forecast future occupancy
and ego trajectory in a direct manner. Extensive experiments on the nuScenes
dataset validate the effectiveness and scalability of our method, and
demonstrate that PreWorld achieves competitive performance across 3D occupancy
prediction, 4D occupancy forecasting and motion planning tasks.",http://arxiv.org/abs/2502.07309v1,Computer Vision,"occupancy, stage, world, labels, supervised"
TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation,"In this work, we propose a modular approach for the Vision-Language
Navigation (VLN) task by decomposing the problem into four sub-modules that use
state-of-the-art Large Language Models (LLMs) and Vision-Language Models (VLMs)
in a zero-shot setting. Given navigation instruction in natural language, we
first prompt LLM to extract the landmarks and the order in which they are
visited. Assuming the known model of the environment, we retrieve the top-k
locations of the last landmark and generate $k$ path hypotheses from the
starting location to the last landmark using the shortest path algorithm on the
topological map of the environment. Each path hypothesis is represented by a
sequence of panoramas. We then use dynamic programming to compute the alignment
score between the sequence of panoramas and the sequence of landmark names,
which match scores obtained from VLM. Finally, we compute the nDTW metric
between the hypothesis that yields the highest alignment score to evaluate the
path fidelity. We demonstrate superior performance compared to other approaches
that use joint semantic maps like VLMaps \cite{vlmaps} on the complex
R2R-Habitat \cite{r2r} instruction dataset and quantify in detail the effect of
visual grounding on navigation performance.",http://arxiv.org/abs/2502.07306v1,Natural Language Processing,"language, path, navigation, use, landmark"
CASC-AI: Consensus-aware Self-corrective AI Agents for Noise Cell Segmentation,"Multi-class cell segmentation in high-resolution gigapixel whole slide images
(WSI) is crucial for various clinical applications. However, training such
models typically requires labor-intensive, pixel-wise annotations by domain
experts. Recent efforts have democratized this process by involving lay
annotators without medical expertise. However, conventional non-agent-based
approaches struggle to handle annotation noise adaptively, as they lack
mechanisms to mitigate false positives (FP) and false negatives (FN) at both
the image-feature and pixel levels. In this paper, we propose a consensus-aware
self-corrective AI agent that leverages the Consensus Matrix to guide its
learning process. The Consensus Matrix defines regions where both the AI and
annotators agree on cell and non-cell annotations, which are prioritized with
stronger supervision. Conversely, areas of disagreement are adaptively weighted
based on their feature similarity to high-confidence agreement regions, with
more similar regions receiving greater attention. Additionally, contrastive
learning is employed to separate features of noisy regions from those of
reliable agreement regions by maximizing their dissimilarity. This paradigm
enables the AI to iteratively refine noisy labels, enhancing its robustness.
Validated on one real-world lay-annotated cell dataset and two simulated noisy
datasets, our method demonstrates improved segmentation performance,
effectively correcting FP and FN errors and showcasing its potential for
training robust models on noisy datasets. The official implementation and cell
annotations are publicly available at https://github.com/ddrrnn123/CASC-AI.",http://arxiv.org/abs/2502.07302v1,Recommendation System,"cell, regions, noisy, annotations, consensus"
Life-Code: Central Dogma Modeling with Multi-Omics Sequence Unification,"The interactions between DNA, RNA, and proteins are fundamental to biological
processes, as illustrated by the central dogma of molecular biology. While
modern biological pre-trained models have achieved great success in analyzing
these macromolecules individually, their interconnected nature remains
under-explored. In this paper, we follow the guidance of the central dogma to
redesign both the data and model pipeline and offer a comprehensive framework,
Life-Code, that spans different biological functions. As for data flow, we
propose a unified pipeline to integrate multi-omics data by
reverse-transcribing RNA and reverse-translating amino acids into
nucleotide-based sequences. As for the model, we design a codon tokenizer and a
hybrid long-sequence architecture to encode the interactions of both coding and
non-coding regions with masked modeling pre-training. To model the translation
and folding process with coding sequences, Life-Code learns protein structures
of the corresponding amino acids by knowledge distillation from off-the-shelf
protein language models. Such designs enable Life-Code to capture complex
interactions within genetic sequences, providing a more comprehensive
understanding of multi-omics with the central dogma. Extensive Experiments show
that Life-Code achieves state-of-the-art performance on various tasks across
three omics, highlighting its potential for advancing multi-omics analysis and
interpretation.",http://arxiv.org/abs/2502.07299v1,Recommendation System,"life, code, omics, interactions, biological"
Generation of Drug-Induced Cardiac Reactions towards Virtual Clinical Trials,"Clinical trials are pivotal in cardiac drug development, yet they often fail
due to inadequate efficacy and unexpected safety issues, leading to significant
financial losses. Using in-silico trials to replace a part of physical clinical
trials, e.g., leveraging advanced generative models to generate drug-influenced
electrocardiograms (ECGs), seems an effective method to reduce financial risk
and potential harm to trial participants. While existing generative models have
demonstrated progress in ECG generation, they fall short in modeling drug
reactions due to limited fidelity and inability to capture individualized drug
response patterns. In this paper, we propose a Drug-Aware Diffusion Model
(DADM), which could simulate individualized drug reactions while ensuring
fidelity. To ensure fidelity, we construct a set of ordinary differential
equations to provide external physical knowledge (EPK) of the realistic ECG
morphology. The EPK is used to adaptively constrain the morphology of the
generated ECGs through a dynamic cross-attention (DCA) mechanism. Furthermore,
we propose an extension of ControlNet to incorporate demographic and drug data,
simulating individual drug reactions. We compare DADM with the other eight
state-of-the-art ECG generative models on two real-world databases covering 8
types of drug regimens. The results demonstrate that DADM can more accurately
simulate drug-induced changes in ECGs, improving the accuracy by at least 5.79%
and recall by 8%.",http://arxiv.org/abs/2502.07297v1,Reinforcement Learning,"drug, trials, generative, models, ecgs"
Treatment Effect Estimation for Exponential Family Outcomes using Neural Networks with Targeted Regularization,"Neural Networks (NNs) have became a natural choice for treatment effect
estimation due to their strong approximation capabilities. Nevertheless, how to
design NN-based estimators with desirable properties, such as low bias and
doubly robustness, still remains a significant challenge. A common approach to
address this is targeted regularization, which modifies the objective function
of NNs. However, existing works on targeted regularization are limited to
Gaussian-distributed outcomes, significantly restricting their applicability in
real-world scenarios. In this work, we aim to bridge this blank by extending
this framework to the boarder exponential family outcomes. Specifically, we
first derive the von-Mises expansion of the Average Dose function of Canonical
Functions (ADCF), which inspires us how to construct a doubly robust estimator
with good properties. Based on this, we develop a NN-based estimator for ADCF
by generalizing functional targeted regularization to exponential families, and
provide the corresponding theoretical convergence rate. Extensive experimental
results demonstrate the effectiveness of our proposed model.",http://arxiv.org/abs/2502.07295v1,Reinforcement Learning,"based, targeted, regularization, nns, nn"
Global Universal Scaling and Ultra-Small Parameterization in Machine Learning Interatomic Potentials with Super-Linearity,"Using machine learning (ML) to construct interatomic interactions and thus
potential energy surface (PES) has become a common strategy for materials
design and simulations. However, those current models of machine learning
interatomic potential (MLIP) provide no relevant physical constrains, and thus
may owe intrinsic out-of-domain difficulty which underlies the challenges of
model generalizability and physical scalability. Here, by incorporating
physics-informed Universal-Scaling law and nonlinearity-embedded interaction
function, we develop a Super-linear MLIP with both Ultra-Small parameterization
and greatly expanded expressive capability, named SUS2-MLIP. Due to the global
scaling rooting in universal equation of state (UEOS), SUS2-MLIP not only has
significantly-reduced parameters by decoupling the element space from
coordinate space, but also naturally outcomes the out-of-domain difficulty and
endows the potentials with inherent generalizability and scalability even with
relatively small training dataset. The nonlinearity-enbeding transformation for
interaction function expands the expressive capability and make the potentials
super-linear. The SUS2-MLIP outperforms the state-of-the-art MLIP models with
its exceptional computational efficiency especially for multiple-element
materials and physical scalability in property prediction. This work not only
presents a highly-efficient universal MLIP model but also sheds light on
incorporating physical constraints into artificial-intelligence-aided materials
simulation.",http://arxiv.org/abs/2502.07293v1,Recommendation System,"mlip, physical, materials, scalability, universal"
Learning Inverse Laplacian Pyramid for Progressive Depth Completion,"Depth completion endeavors to reconstruct a dense depth map from sparse depth
measurements, leveraging the information provided by a corresponding color
image. Existing approaches mostly hinge on single-scale propagation strategies
that iteratively ameliorate initial coarse depth estimates through pixel-level
message passing. Despite their commendable outcomes, these techniques are
frequently hampered by computational inefficiencies and a limited grasp of
scene context. To circumvent these challenges, we introduce LP-Net, an
innovative framework that implements a multi-scale, progressive prediction
paradigm based on Laplacian Pyramid decomposition. Diverging from
propagation-based approaches, LP-Net initiates with a rudimentary,
low-resolution depth prediction to encapsulate the global scene context,
subsequently refining this through successive upsampling and the reinstatement
of high-frequency details at incremental scales. We have developed two novel
modules to bolster this strategy: 1) the Multi-path Feature Pyramid module,
which segregates feature maps into discrete pathways, employing multi-scale
transformations to amalgamate comprehensive spatial information, and 2) the
Selective Depth Filtering module, which dynamically learns to apply both
smoothness and sharpness filters to judiciously mitigate noise while
accentuating intricate details. By integrating these advancements, LP-Net not
only secures state-of-the-art (SOTA) performance across both outdoor and indoor
benchmarks such as KITTI, NYUv2, and TOFDC, but also demonstrates superior
computational efficiency. At the time of submission, LP-Net ranks 1st among all
peer-reviewed methods on the official KITTI leaderboard.",http://arxiv.org/abs/2502.07289v1,Reinforcement Learning,"depth, lp, net, scale, multi"
KPIs 2024 Challenge: Advancing Glomerular Segmentation from Patch- to Slide-Level,"Chronic kidney disease (CKD) is a major global health issue, affecting over
10% of the population and causing significant mortality. While kidney biopsy
remains the gold standard for CKD diagnosis and treatment, the lack of
comprehensive benchmarks for kidney pathology segmentation hinders progress in
the field. To address this, we organized the Kidney Pathology Image
Segmentation (KPIs) Challenge, introducing a dataset that incorporates
preclinical rodent models of CKD with over 10,000 annotated glomeruli from 60+
Periodic Acid Schiff (PAS)-stained whole slide images. The challenge includes
two tasks, patch-level segmentation and whole slide image segmentation and
detection, evaluated using the Dice Similarity Coefficient (DSC) and F1-score.
By encouraging innovative segmentation methods that adapt to diverse CKD models
and tissue conditions, the KPIs Challenge aims to advance kidney pathology
analysis, establish new benchmarks, and enable precise, large-scale
quantification for disease research and diagnosis.",http://arxiv.org/abs/2502.07288v1,Recommendation System,"kidney, segmentation, ckd, pathology, challenge"
Small Language Model Makes an Effective Long Text Extractor,"Named Entity Recognition (NER) is a fundamental problem in natural language
processing (NLP). However, the task of extracting longer entity spans (e.g.,
awards) from extended texts (e.g., homepages) is barely explored. Current NER
methods predominantly fall into two categories: span-based methods and
generation-based methods. Span-based methods require the enumeration of all
possible token-pair spans, followed by classification on each span, resulting
in substantial redundant computations and excessive GPU memory usage. In
contrast, generation-based methods involve prompting or fine-tuning large
language models (LLMs) to adapt to downstream NER tasks. However, these methods
struggle with the accurate generation of longer spans and often incur
significant time costs for effective fine-tuning. To address these challenges,
this paper introduces a lightweight span-based NER method called SeNER, which
incorporates a bidirectional arrow attention mechanism coupled with
LogN-Scaling on the [CLS] token to embed long texts effectively, and comprises
a novel bidirectional sliding-window plus-shaped attention (BiSPA) mechanism to
reduce redundant candidate token-pair spans significantly and model
interactions between token-pair spans simultaneously. Extensive experiments
demonstrate that our method achieves state-of-the-art extraction accuracy on
three long NER datasets and is capable of extracting entities from long texts
in a GPU-memory-friendly manner. Code:
https://github.com/THUDM/scholar-profiling/tree/main/sener",http://arxiv.org/abs/2502.07286v1,Natural Language Processing,"methods, ner, spans, based, span"
Negative Dependence as a toolbox for machine learning : review and new developments,"Negative dependence is becoming a key driver in advancing learning
capabilities beyond the limits of traditional independence. Recent developments
have evidenced support towards negatively dependent systems as a learning
paradigm in a broad range of fundamental machine learning challenges including
optimization, sampling, dimensionality reduction and sparse signal recovery,
often surpassing the performance of current methods based on statistical
independence. The most popular negatively dependent model has been that of
determinantal point processes (DPPs), which have their origins in quantum
theory. However, other models, such as perturbed lattice models, strongly
Rayleigh measures, zeros of random functions have gained salience in various
learning applications. In this article, we review this burgeoning field of
research, as it has developed over the past two decades or so. We also present
new results on applications of DPPs to the parsimonious representation of
neural networks. In the limited scope of the article, we mostly focus on
aspects of this area to which the authors contributed over the recent years,
including applications to Monte Carlo methods, coresets and stochastic gradient
descent, stochastic networks, signal processing and connections to quantum
computation. However, starting from basics of negative dependence for the
uninitiated reader, extensive references are provided to a broad swath of
related developments which could not be covered within our limited scope. While
existing works and reviews generally focus on specific negatively dependent
models (e.g. DPPs), a notable feature of this article is that it addresses
negative dependence as a machine learning methodology as a whole. In this vein,
it covers within its span an array of negatively dependent models and their
applications well beyond DPPs, thereby putting forward a very general and
rather unique perspective.",http://arxiv.org/abs/2502.07285v1,Recommendation System,"learning, negatively, dependent, dpps, models"
Supervised Contrastive Block Disentanglement,"Real-world datasets often combine data collected under different experimental
conditions. This yields larger datasets, but also introduces spurious
correlations that make it difficult to model the phenomena of interest. We
address this by learning two embeddings to independently represent the
phenomena of interest and the spurious correlations. The embedding representing
the phenomena of interest is correlated with the target variable $y$, and is
invariant to the environment variable $e$. In contrast, the embedding
representing the spurious correlations is correlated with $e$. The invariance
to $e$ is difficult to achieve on real-world datasets. Our primary contribution
is an algorithm called Supervised Contrastive Block Disentanglement (SCBD) that
effectively enforces this invariance. It is based purely on Supervised
Contrastive Learning, and applies to real-world data better than existing
approaches. We empirically validate SCBD on two challenging problems. The first
problem is domain generalization, where we achieve strong performance on a
synthetic dataset, as well as on Camelyon17-WILDS. We introduce a single
hyperparameter $\alpha$ to control the degree of invariance to $e$. When we
increase $\alpha$ to strengthen the degree of invariance, out-of-distribution
performance improves at the expense of in-distribution performance. The second
problem is batch correction, in which we apply SCBD to preserve biological
signal and remove inter-well batch effects when modeling single-cell
perturbations from 26 million Optical Pooled Screening images.",http://arxiv.org/abs/2502.07281v1,Recommendation System,"invariance, real, world, datasets, spurious"
MIGT: Memory Instance Gated Transformer Framework for Financial Portfolio Management,"Deep reinforcement learning (DRL) has been applied in financial portfolio
management to improve returns in changing market conditions. However, unlike
most fields where DRL is widely used, the stock market is more volatile and
dynamic as it is affected by several factors such as global events and investor
sentiment. Therefore, it remains a challenge to construct a DRL-based portfolio
management framework with strong return capability, stable training, and
generalization ability. This study introduces a new framework utilizing the
Memory Instance Gated Transformer (MIGT) for effective portfolio management. By
incorporating a novel Gated Instance Attention module, which combines a
transformer variant, instance normalization, and a Lite Gate Unit, our approach
aims to maximize investment returns while ensuring the learning process's
stability and reducing outlier impacts. Tested on the Dow Jones Industrial
Average 30, our framework's performance is evaluated against fifteen other
strategies using key financial metrics like the cumulative return and
risk-return ratios (Sharpe, Sortino, and Omega ratios). The results highlight
MIGT's advantage, showcasing at least a 9.75% improvement in cumulative returns
and a minimum 2.36% increase in risk-return ratios over competing strategies,
marking a significant advancement in DRL for portfolio management.",http://arxiv.org/abs/2502.07280v1,Reinforcement Learning,"drl, portfolio, management, return, returns"
Exploratory Diffusion Policy for Unsupervised Reinforcement Learning,"Unsupervised reinforcement learning (RL) aims to pre-train agents by
exploring states or skills in reward-free environments, facilitating the
adaptation to downstream tasks. However, existing methods often overlook the
fitting ability of pre-trained policies and struggle to handle the
heterogeneous pre-training data, which are crucial for achieving efficient
exploration and fast fine-tuning. To address this gap, we propose Exploratory
Diffusion Policy (EDP), which leverages the strong expressive ability of
diffusion models to fit the explored data, both boosting exploration and
obtaining an efficient initialization for downstream tasks. Specifically, we
estimate the distribution of collected data in the replay buffer with the
diffusion policy and propose a score intrinsic reward, encouraging the agent to
explore unseen states. For fine-tuning the pre-trained diffusion policy on
downstream tasks, we provide both theoretical analyses and practical
algorithms, including an alternating method of Q function optimization and
diffusion policy distillation. Extensive experiments demonstrate the
effectiveness of EDP in efficient exploration during pre-training and fast
adaptation during fine-tuning.",http://arxiv.org/abs/2502.07279v1,Reinforcement Learning,"pre, diffusion, policy, downstream, tasks"
Articulate That Object Part (ATOP): 3D Part Articulation from Text and Motion Personalization,"We present ATOP (Articulate That Object Part), a novel method based on motion
personalization to articulate a 3D object with respect to a part and its motion
as prescribed in a text prompt. Specifically, the text input allows us to tap
into the power of modern-day video diffusion to generate plausible motion
samples for the right object category and part. In turn, the input 3D object
provides image prompting to personalize the generated video to that very object
we wish to articulate. Our method starts with a few-shot finetuning for
category-specific motion generation, a key first step to compensate for the
lack of articulation awareness by current video diffusion models. For this, we
finetune a pre-trained multi-view image generation model for controllable
multi-view video generation, using a small collection of video samples obtained
for the target object category. This is followed by motion video
personalization that is realized by multi-view rendered images of the target 3D
object. At last, we transfer the personalized video motion to the target 3D
object via differentiable rendering to optimize part motion parameters by a
score distillation sampling loss. We show that our method is capable of
generating realistic motion videos and predict 3D motion parameters in a more
accurate and generalizable way, compared to prior works.",http://arxiv.org/abs/2502.07278v1,Recommendation System,"motion, object, video, articulate, method"
Enhancing Video Understanding: Deep Neural Networks for Spatiotemporal Analysis,"It's no secret that video has become the primary way we share information
online. That's why there's been a surge in demand for algorithms that can
analyze and understand video content. It's a trend going to continue as video
continues to dominate the digital landscape. These algorithms will extract and
classify related features from the video and will use them to describe the
events and objects in the video. Deep neural networks have displayed
encouraging outcomes in the realm of feature extraction and video description.
This paper will explore the spatiotemporal features found in videos and recent
advancements in deep neural networks in video understanding. We will review
some of the main trends in video understanding models and their structural
design, the main problems, and some offered solutions in this topic. We will
also review and compare significant video understanding and action recognition
datasets.",http://arxiv.org/abs/2502.07277v1,Recommendation System,"video, understanding, algorithms, features, deep"
Dataset Ownership Verification in Contrastive Pre-trained Models,"High-quality open-source datasets, which necessitate substantial efforts for
curation, has become the primary catalyst for the swift progress of deep
learning. Concurrently, protecting these datasets is paramount for the
well-being of the data owner. Dataset ownership verification emerges as a
crucial method in this domain, but existing approaches are often limited to
supervised models and cannot be directly extended to increasingly popular
unsupervised pre-trained models. In this work, we propose the first dataset
ownership verification method tailored specifically for self-supervised
pre-trained models by contrastive learning. Its primary objective is to
ascertain whether a suspicious black-box backbone has been pre-trained on a
specific unlabeled dataset, aiding dataset owners in upholding their rights.
The proposed approach is motivated by our empirical insights that when models
are trained with the target dataset, the unary and binary instance
relationships within the embedding space exhibit significant variations
compared to models trained without the target dataset. We validate the efficacy
of this approach across multiple contrastive pre-trained models including
SimCLR, BYOL, SimSiam, MOCO v3, and DINO. The results demonstrate that our
method rejects the null hypothesis with a $p$-value markedly below $0.05$,
surpassing all previous methodologies. Our code is available at
https://github.com/xieyc99/DOV4CL.",http://arxiv.org/abs/2502.07276v1,Recommendation System,"dataset, models, trained, pre, method"
Cost-Efficient Continual Learning with Sufficient Exemplar Memory,"Continual learning (CL) research typically assumes highly constrained
exemplar memory resources. However, in many real-world scenarios-especially in
the era of large foundation models-memory is abundant, while GPU computational
costs are the primary bottleneck. In this work, we investigate CL in a novel
setting where exemplar memory is ample (i.e., sufficient exemplar memory).
Unlike prior methods designed for strict exemplar memory constraints, we
propose a simple yet effective approach that directly operates in the model's
weight space through a combination of weight resetting and averaging
techniques. Our method achieves state-of-the-art performance while reducing the
computational cost to a quarter or third of existing methods. These findings
challenge conventional CL assumptions and provide a practical baseline for
computationally efficient CL applications.",http://arxiv.org/abs/2502.07274v1,Recommendation System,"memory, cl, exemplar, computational, methods"
Variational Learning Induces Adaptive Label Smoothing,"We show that variational learning naturally induces an adaptive label
smoothing where label noise is specialized for each example. Such
label-smoothing is useful to handle examples with labeling errors and
distribution shifts, but designing a good adaptivity strategy is not always
easy. We propose to skip this step and simply use the natural adaptivity
induced during the optimization of a variational objective. We show empirical
results where a variational algorithm called IVON outperforms traditional label
smoothing and yields adaptivity strategies similar to those of an existing
approach. By connecting Bayesian methods to label smoothing, our work provides
a new way to handle overconfident predictions.",http://arxiv.org/abs/2502.07273v1,Reinforcement Learning,"label, smoothing, variational, adaptivity, handle"
Exploring Active Data Selection Strategies for Continuous Training in Deepfake Detection,"In deepfake detection, it is essential to maintain high performance by
adjusting the parameters of the detector as new deepfake methods emerge. In
this paper, we propose a method to automatically and actively select the small
amount of additional data required for the continuous training of deepfake
detection models in situations where deepfake detection models are regularly
updated. The proposed method automatically selects new training data from a
\textit{redundant} pool set containing a large number of images generated by
new deepfake methods and real images, using the confidence score of the
deepfake detection model as a metric. Experimental results show that the
deepfake detection model, continuously trained with a small amount of
additional data automatically selected and added to the original training set,
significantly and efficiently improved the detection performance, achieving an
EER of 2.5% with only 15% of the amount of data in the pool set.",http://arxiv.org/abs/2502.07269v1,Recommendation System,"deepfake, detection, data, new, automatically"
Column-wise Quantization of Weights and Partial Sums for Accurate and Efficient Compute-In-Memory Accelerators,"Compute-in-memory (CIM) is an efficient method for implementing deep neural
networks (DNNs) but suffers from substantial overhead from analog-to-digital
converters (ADCs), especially as ADC precision increases. Low-precision ADCs
can re- duce this overhead but introduce partial-sum quantization errors
degrading accuracy. Additionally, low-bit weight constraints, im- posed by cell
limitations and the need for multiple cells for higher- bit weights, present
further challenges. While fine-grained partial- sum quantization has been
studied to lower ADC resolution effectively, weight granularity, which limits
overall partial-sum quantized accuracy, remains underexplored. This work
addresses these challenges by aligning weight and partial-sum quantization
granularities at the column-wise level. Our method improves accuracy while
maintaining dequantization overhead, simplifies training by removing two-stage
processes, and ensures robustness to memory cell variations via independent
column-wise scale factors. We also propose an open-source CIM-oriented
convolution framework to handle fine-grained weights and partial-sums effi-
ciently, incorporating a novel tiling method and group convolution.
Experimental results on ResNet-20 (CIFAR-10, CIFAR-100) and ResNet-18
(ImageNet) show accuracy improvements of 0.99%, 2.69%, and 1.01%, respectively,
compared to the best-performing related works. Additionally, variation analysis
reveals the robust- ness of our method against memory cell variations. These
findings highlight the effectiveness of our quantization scheme in enhancing
accuracy and robustness while maintaining hardware efficiency in CIM-based DNN
implementations. Our code is available at
https://github.com/jiyoonkm/ColumnQuant.",http://arxiv.org/abs/2502.07842v1,Recommendation System,"accuracy, method, partial, sum, quantization"
When More is Less: Understanding Chain-of-Thought Length in LLMs,"Chain-of-thought (CoT) reasoning enhances the multi-step reasoning
capabilities of large language models (LLMs) by breaking complex tasks into
smaller, manageable sub-tasks. Researchers have been exploring ways to guide
models to generate more complex CoT processes to improve the reasoning ability
of LLMs, such as long CoT and the test-time scaling law. However, for most
models and tasks, does an increase in CoT length consistently lead to improved
reasoning accuracy? In this paper, we observe a nuanced relationship: as the
number of reasoning steps increases, performance initially improves but
eventually decreases. To understand this phenomenon, we provide a piece of
evidence that longer reasoning processes are increasingly susceptible to noise.
We theoretically prove the existence of an optimal CoT length and derive a
scaling law for this optimal length based on model capability and task
difficulty. Inspired by our theory, we conduct experiments on both synthetic
and real world datasets and propose Length-filtered Vote to alleviate the
effects of excessively long or short CoTs. Our findings highlight the critical
need to calibrate CoT length to align with model capabilities and task demands,
offering a principled framework for optimizing multi-step reasoning in LLMs.",http://arxiv.org/abs/2502.07266v1,Recommendation System,"reasoning, cot, length, models, llms"
Riemannian Proximal Sampler for High-accuracy Sampling on Manifolds,"We introduce the Riemannian Proximal Sampler, a method for sampling from
densities defined on Riemannian manifolds. The performance of this sampler
critically depends on two key oracles: the Manifold Brownian Increments (MBI)
oracle and the Riemannian Heat-kernel (RHK) oracle. We establish high-accuracy
sampling guarantees for the Riemannian Proximal Sampler, showing that
generating samples with $\varepsilon$-accuracy requires
$O(\log(1/\varepsilon))$ iterations in Kullback-Leibler divergence assuming
access to exact oracles and $O(\log^2(1/\varepsilon))$ iterations in the total
variation metric assuming access to sufficiently accurate inexact oracles.
Furthermore, we present practical implementations of these oracles by
leveraging heat-kernel truncation and Varadhan's asymptotics. In the latter
case, we interpret the Riemannian Proximal Sampler as a discretization of the
entropy-regularized Riemannian Proximal Point Method on the associated
Wasserstein space. We provide preliminary numerical results that illustrate the
effectiveness of the proposed methodology.",http://arxiv.org/abs/2502.07265v1,Recommendation System,"riemannian, proximal, sampler, oracles, method"
Flat U-Net: An Efficient Ultralightweight Model for Solar Filament Segmentation in Full-disk H$α$ Images,"Solar filaments are one of the most prominent features observed on the Sun,
and their evolutions are closely related to various solar activities, such as
flares and coronal mass ejections. Real-time automated identification of solar
filaments is the most effective approach to managing large volumes of data.
Existing models of filament identification are characterized by large parameter
sizes and high computational costs, which limit their future applications in
highly integrated and intelligent ground-based and space-borne observation
devices. Consequently, the design of more lightweight models will facilitate
the advancement of intelligent observation equipment. In this study, we
introduce Flat U-Net, a novel and highly efficient ultralightweight model that
incorporates simplified channel attention (SCA) and channel self-attention
(CSA) convolutional blocks for the segmentation of solar filaments in full-disk
H$\alpha$ images. Feature information from each network layer is fully
extracted to reconstruct interchannel feature representations. Each block
effectively optimizes the channel features from the previous layer,
significantly reducing parameters. The network architecture presents an elegant
flattening, improving its efficiency, and simplifying the overall design.
Experimental validation demonstrates that a model composed of pure SCAs
achieves a precision of approximately 0.93, with dice similarity coefficient
(DSC) and recall rates of 0.76 and 0.64, respectively, significantly
outperforming the classical U-Net. Introducing a certain number of CSA blocks
improves the DSC and recall rates to 0.82 and 0.74, respectively, which
demonstrates a pronounced advantage, particularly concerning model weight size
and detection effectiveness. The data set, models, and code are available as
open-source resources.",http://arxiv.org/abs/2502.07259v1,Reinforcement Learning,"solar, filaments, models, model, channel"
Beyond Confidence: Adaptive Abstention in Dual-Threshold Conformal Prediction for Autonomous System Perception,"Safety-critical perception systems require both reliable uncertainty
quantification and principled abstention mechanisms to maintain safety under
diverse operational conditions. We present a novel dual-threshold
conformalization framework that provides statistically-guaranteed uncertainty
estimates while enabling selective prediction in high-risk scenarios. Our
approach uniquely combines a conformal threshold ensuring valid prediction sets
with an abstention threshold optimized through ROC analysis, providing
distribution-free coverage guarantees (\ge 1 - \alpha) while identifying
unreliable predictions. Through comprehensive evaluation on CIFAR-100,
ImageNet1K, and ModelNet40 datasets, we demonstrate superior robustness across
camera and LiDAR modalities under varying environmental perturbations. The
framework achieves exceptional detection performance (AUC: 0.993\to0.995) under
severe conditions while maintaining high coverage (>90.0\%) and enabling
adaptive abstention (13.5\%\to63.4\%\pm0.5) as environmental severity
increases. For LiDAR-based perception, our approach demonstrates particularly
strong performance, maintaining robust coverage (>84.5\%) while appropriately
abstaining from unreliable predictions. Notably, the framework shows remarkable
stability under heavy perturbations, with detection performance (AUC:
0.995\pm0.001) significantly outperforming existing methods across all
modalities. Our unified approach bridges the gap between theoretical guarantees
and practical deployment needs, offering a robust solution for safety-critical
autonomous systems operating in challenging real-world conditions.",http://arxiv.org/abs/2502.07255v1,Recommendation System,"safety, abstention, conditions, threshold, framework"
Fairness in Multi-Agent AI: A Unified Framework for Ethical and Equitable Autonomous Systems,"Ensuring fairness in decentralized multi-agent systems presents significant
challenges due to emergent biases, systemic inefficiencies, and conflicting
agent incentives. This paper provides a comprehensive survey of fairness in
multi-agent AI, introducing a novel framework where fairness is treated as a
dynamic, emergent property of agent interactions. The framework integrates
fairness constraints, bias mitigation strategies, and incentive mechanisms to
align autonomous agent behaviors with societal values while balancing
efficiency and robustness. Through empirical validation, we demonstrate that
incorporating fairness constraints results in more equitable decision-making.
This work bridges the gap between AI ethics and system design, offering a
foundation for accountable, transparent, and socially responsible multi-agent
AI systems.",http://arxiv.org/abs/2502.07254v1,Recommendation System,"agent, fairness, multi, ai, systems"
NARCE: A Mamba-Based Neural Algorithmic Reasoner Framework for Online Complex Event Detection,"Current machine learning models excel in short-span perception tasks but
struggle to derive high-level insights from long-term observation, a capability
central to understanding complex events (CEs). CEs, defined as sequences of
short-term atomic events (AEs) governed by spatiotemporal rules, are
challenging to detect online due to the need to extract meaningful patterns
from long and noisy sensor data while ignoring irrelevant events. We
hypothesize that state-based methods are well-suited for CE detection, as they
capture event progression through state transitions without requiring long-term
memory. Baseline experiments validate this, demonstrating that the state-space
model Mamba outperforms existing architectures. However, Mamba's reliance on
extensive labeled data, which are difficult to obtain, motivates our second
hypothesis: decoupling CE rule learning from noisy sensor data can reduce data
requirements. To address this, we propose NARCE, a framework that combines
Neural Algorithmic Reasoning (NAR) to split the task into two components: (i)
learning CE rules independently of sensor data using synthetic concept traces
generated by LLMs and (ii) mapping sensor inputs to these rules via an adapter.
Our results show that NARCE outperforms baselines in accuracy, generalization
to unseen and longer sensor data, and data efficiency, significantly reducing
annotation costs while advancing robust CE detection.",http://arxiv.org/abs/2502.07250v1,Recommendation System,"data, sensor, ce, learning, long"
Robust Indoor Localization in Dynamic Environments: A Multi-source Unsupervised Domain Adaptation Framework,"Fingerprint localization has gained significant attention due to its
cost-effective deployment, low complexity, and high efficacy. However,
traditional methods, while effective for static data, often struggle in dynamic
environments where data distributions and feature spaces evolve-a common
occurrence in real-world scenarios. To address the challenges of robustness and
adaptability in fingerprint localization for dynamic indoor environments, this
paper proposes DF-Loc, an end-to-end dynamic fingerprint localization system
based on multi-source unsupervised domain adaptation (MUDA). DF-Loc leverages
historical data from multiple time scales to facilitate knowledge transfer in
specific feature spaces, thereby enhancing generalization capabilities in the
target domain and reducing reliance on labeled data. Specifically, the system
incorporates a Quality Control (QC) module for CSI data preprocessing and
employs image processing techniques for CSI fingerprint feature reconstruction.
Additionally, a multi-scale attention-based feature fusion backbone network is
designed to extract multi-level transferable fingerprint features. Finally, a
dual-stage alignment model aligns the distributions of multiple source-target
domain pairs, improving regression characteristics in the target domain.
Extensive experiments conducted in office and classroom environments
demonstrate that DF-Loc outperforms comparative methods in terms of both
localization accuracy and robustness. With 60% of reference points used for
training, DF-Loc achieves average localization errors of 0.79m and 3.72m in
""same-test"" scenarios, and 0.94m and 4.39m in ""different-test"" scenarios,
respectively. This work pioneers an end-to-end multi-source transfer learning
approach for fingerprint localization, providing valuable insights for future
research in dynamic environments.",http://arxiv.org/abs/2502.07246v1,Reinforcement Learning,"fingerprint, localization, data, dynamic, environments"
Linear Transformers as VAR Models: Aligning Autoregressive Attention Mechanisms with Autoregressive Forecasting,"Autoregressive attention-based time series forecasting (TSF) has drawn
increasing interest, with mechanisms like linear attention sometimes
outperforming vanilla attention. However, deeper Transformer architectures
frequently misalign with autoregressive objectives, obscuring the underlying
VAR structure embedded within linear attention and hindering their ability to
capture the data generative processes in TSF. In this work, we first show that
a single linear attention layer can be interpreted as a dynamic vector
autoregressive (VAR) structure. We then explain that existing multi-layer
Transformers have structural mismatches with the autoregressive forecasting
objective, which impair interpretability and generalization ability. To address
this, we show that by rearranging the MLP, attention, and input-output flow,
multi-layer linear attention can also be aligned as a VAR model. Then, we
propose Structural Aligned Mixture of VAR (SAMoVAR), a linear Transformer
variant that integrates interpretable dynamic VAR weights for multivariate TSF.
By aligning the Transformer architecture with autoregressive objectives,
SAMoVAR delivers improved performance, interpretability, and computational
efficiency, comparing to SOTA TSF models.",http://arxiv.org/abs/2502.07244v1,Recommendation System,"attention, autoregressive, linear, var, tsf"
Vevo: Controllable Zero-Shot Voice Imitation with Self-Supervised Disentanglement,"The imitation of voice, targeted on specific speech attributes such as timbre
and speaking style, is crucial in speech generation. However, existing methods
rely heavily on annotated data, and struggle with effectively disentangling
timbre and style, leading to challenges in achieving controllable generation,
especially in zero-shot scenarios. To address these issues, we propose Vevo, a
versatile zero-shot voice imitation framework with controllable timbre and
style. Vevo operates in two core stages: (1) Content-Style Modeling: Given
either text or speech's content tokens as input, we utilize an autoregressive
transformer to generate the content-style tokens, which is prompted by a style
reference; (2) Acoustic Modeling: Given the content-style tokens as input, we
employ a flow-matching transformer to produce acoustic representations, which
is prompted by a timbre reference. To obtain the content and content-style
tokens of speech, we design a fully self-supervised approach that progressively
decouples the timbre, style, and linguistic content of speech. Specifically, we
adopt VQ-VAE as the tokenizer for the continuous hidden features of HuBERT. We
treat the vocabulary size of the VQ-VAE codebook as the information bottleneck,
and adjust it carefully to obtain the disentangled speech representations.
Solely self-supervised trained on 60K hours of audiobook speech data, without
any fine-tuning on style-specific corpora, Vevo matches or surpasses existing
methods in accent and emotion conversion tasks. Additionally, Vevo's
effectiveness in zero-shot voice conversion and text-to-speech tasks further
demonstrates its strong generalization and versatility. Audio samples are
available at https://versavoice.github.io.",http://arxiv.org/abs/2502.07243v1,Reinforcement Learning,"style, speech, content, timbre, vevo"
Contextual Gesture: Co-Speech Gesture Video Generation through Context-aware Gesture Representation,"Co-speech gesture generation is crucial for creating lifelike avatars and
enhancing human-computer interactions by synchronizing gestures with speech.
Despite recent advancements, existing methods struggle with accurately
identifying the rhythmic or semantic triggers from audio for generating
contextualized gesture patterns and achieving pixel-level realism. To address
these challenges, we introduce Contextual Gesture, a framework that improves
co-speech gesture video generation through three innovative components: (1) a
chronological speech-gesture alignment that temporally connects two modalities,
(2) a contextualized gesture tokenization that incorporate speech context into
motion pattern representation through distillation, and (3) a structure-aware
refinement module that employs edge connection to link gesture keypoints to
improve video generation. Our extensive experiments demonstrate that Contextual
Gesture not only produces realistic and speech-aligned gesture videos but also
supports long-sequence generation and video gesture editing applications, shown
in Fig.1 Project Page: https://andypinxinliu.github.io/Contextual-Gesture/.",http://arxiv.org/abs/2502.07239v1,Recommendation System,"gesture, speech, generation, video, co"
Diffusion Suction Grasping with Large-Scale Parcel Dataset,"While recent advances in object suction grasping have shown remarkable
progress, significant challenges persist particularly in cluttered and complex
parcel handling scenarios. Two fundamental limitations hinder current
approaches: (1) the lack of a comprehensive suction grasp dataset tailored for
parcel manipulation tasks, and (2) insufficient adaptability to diverse object
characteristics including size variations, geometric complexity, and textural
diversity. To address these challenges, we present Parcel-Suction-Dataset, a
large-scale synthetic dataset containing 25 thousand cluttered scenes with 410
million precision-annotated suction grasp poses. This dataset is generated
through our novel geometric sampling algorithm that enables efficient
generation of optimal suction grasps incorporating both physical constraints
and material properties. We further propose Diffusion-Suction, an innovative
framework that reformulates suction grasp prediction as a conditional
generation task through denoising diffusion probabilistic models. Our method
iteratively refines random noise into suction grasp score maps through
visual-conditioned guidance from point cloud observations, effectively learning
spatial point-wise affordances from our synthetic dataset. Extensive
experiments demonstrate that the simple yet efficient Diffusion-Suction
achieves new state-of-the-art performance compared to previous models on both
Parcel-Suction-Dataset and the public SuctionNet-1Billion benchmark.",http://arxiv.org/abs/2502.07238v1,Recommendation System,"suction, dataset, parcel, grasp, diffusion"
DrugImproverGPT: A Large Language Model for Drug Optimization with Fine-Tuning via Structured Policy Optimization,"Finetuning a Large Language Model (LLM) is crucial for generating results
towards specific objectives. This research delves into the realm of drug
optimization and introduce a novel reinforcement learning algorithm to finetune
a drug optimization LLM-based generative model, enhancing the original drug
across target objectives, while retains the beneficial chemical properties of
the original drug. This work is comprised of two primary components: (1)
DrugImprover: A framework tailored for improving robustness and efficiency in
drug optimization. It includes a LLM designed for drug optimization and a novel
Structured Policy Optimization (SPO) algorithm, which is theoretically
grounded. This algorithm offers a unique perspective for fine-tuning the
LLM-based generative model by aligning the improvement of the generated
molecule with the input molecule under desired objectives. (2) A dataset of 1
million compounds, each with OEDOCK docking scores on 5 human proteins
associated with cancer cells and 24 binding sites from SARS-CoV-2 virus. We
conduct a comprehensive evaluation of SPO and demonstrate its effectiveness in
improving the original drug across target properties. Our code and dataset will
be publicly available at: https://github.com/xuefeng-cs/DrugImproverGPT.",http://arxiv.org/abs/2502.07237v1,Reinforcement Learning,"drug, optimization, llm, model, objectives"
Simplifying Adversarially Robust PAC Learning with Tolerance,"Adversarially robust PAC learning has proved to be challenging, with the
currently best known learners [Montasser et al., 2021a] relying on improper
methods based on intricate compression schemes, resulting in sample complexity
exponential in the VC-dimension. A series of follow up work considered a
slightly relaxed version of the problem called adversarially robust learning
with tolerance [Ashtiani et al., 2023, Bhattacharjee et al., 2023, Raman et
al., 2024] and achieved better sample complexity in terms of the VC-dimension.
However, those algorithms were either improper and complex, or required
additional assumptions on the hypothesis class H. We prove, for the first time,
the existence of a simpler learner that achieves a sample complexity linear in
the VC-dimension without requiring additional assumptions on H. Even though our
learner is improper, it is ""almost proper"" in the sense that it outputs a
hypothesis that is ""similar"" to a hypothesis in H.
  We also use the ideas from our algorithm to construct a semi-supervised
learner in the tolerant setting. This simple algorithm achieves comparable
bounds to the previous (non-tolerant) semi-supervised algorithm of Attias et
al. [2022a], but avoids the use of intricate subroutines from previous works,
and is ""almost proper.""",http://arxiv.org/abs/2502.07232v1,Reinforcement Learning,"et, al, improper, sample, complexity"
TranSplat: Surface Embedding-guided 3D Gaussian Splatting for Transparent Object Manipulation,"Transparent object manipulation remains a sig- nificant challenge in robotics
due to the difficulty of acquiring accurate and dense depth measurements.
Conventional depth sensors often fail with transparent objects, resulting in
in- complete or erroneous depth data. Existing depth completion methods
struggle with interframe consistency and incorrectly model transparent objects
as Lambertian surfaces, leading to poor depth reconstruction. To address these
challenges, we propose TranSplat, a surface embedding-guided 3D Gaussian
Splatting method tailored for transparent objects. TranSplat uses a latent
diffusion model to generate surface embeddings that provide consistent and
continuous representations, making it robust to changes in viewpoint and
lighting. By integrating these surface embeddings with input RGB images,
TranSplat effectively captures the complexities of transparent surfaces,
enhancing the splatting of 3D Gaussians and improving depth completion.
Evaluations on synthetic and real-world transpar- ent object benchmarks, as
well as robot grasping tasks, show that TranSplat achieves accurate and dense
depth completion, demonstrating its effectiveness in practical applications. We
open-source synthetic dataset and model: https://github.
com/jeongyun0609/TranSplat",http://arxiv.org/abs/2502.07840v1,Recommendation System,"depth, transparent, transplat, objects, completion"
CAT: Contrastive Adversarial Training for Evaluating the Robustness of Protective Perturbations in Latent Diffusion Models,"Latent diffusion models have recently demonstrated superior capabilities in
many downstream image synthesis tasks. However, customization of latent
diffusion models using unauthorized data can severely compromise the privacy
and intellectual property rights of data owners. Adversarial examples as
protective perturbations have been developed to defend against unauthorized
data usage by introducing imperceptible noise to customization samples,
preventing diffusion models from effectively learning them. In this paper, we
first reveal that the primary reason adversarial examples are effective as
protective perturbations in latent diffusion models is the distortion of their
latent representations, as demonstrated through qualitative and quantitative
experiments. We then propose the Contrastive Adversarial Training (CAT)
utilizing adapters as an adaptive attack against these protection methods,
highlighting their lack of robustness. Extensive experiments demonstrate that
our CAT method significantly reduces the effectiveness of protective
perturbations in customization configurations, urging the community to
reconsider and enhance the robustness of existing protective perturbation
methods. Code is available at \hyperlink{here}{https://github.com/senp98/CAT}.",http://arxiv.org/abs/2502.07225v1,Recommendation System,"latent, diffusion, models, protective, customization"
A Memory Efficient Randomized Subspace Optimization Method for Training Large Language Models,"The memory challenges associated with training Large Language Models (LLMs)
have become a critical concern, particularly when using the Adam optimizer. To
address this issue, numerous memory-efficient techniques have been proposed,
with GaLore standing out as a notable example designed to reduce the memory
footprint of optimizer states. However, these approaches do not alleviate the
memory burden imposed by activations, rendering them unsuitable for scenarios
involving long context sequences or large mini-batches. Moreover, their
convergence properties are still not well-understood in the literature. In this
work, we introduce a Randomized Subspace Optimization framework for
pre-training and fine-tuning LLMs. Our approach decomposes the high-dimensional
training problem into a series of lower-dimensional subproblems. At each
iteration, a random subspace is selected, and the parameters within that
subspace are optimized. This structured reduction in dimensionality allows our
method to simultaneously reduce memory usage for both activations and optimizer
states. We establish comprehensive convergence guarantees and derive rates for
various scenarios, accommodating different optimization strategies to solve the
subproblems. Extensive experiments validate the superior memory and
communication efficiency of our method, achieving performance comparable to
GaLore and Adam.",http://arxiv.org/abs/2502.07222v1,Reinforcement Learning,"memory, training, optimizer, subspace, large"
MLLM4PUE: Toward Universal Embeddings in Computational Pathology through Multimodal LLMs,"Pathology plays a critical role in diagnosing a wide range of diseases, yet
existing approaches often rely heavily on task-specific models trained on
extensive, well-labeled datasets. These methods face sustainability challenges
due to the diversity of pathologies and the labor-intensive nature of data
collection. To address these limitations, we highlight the need for universal
multimodal embeddings that can support multiple downstream tasks. Previous
approaches often involve fine-tuning CLIP-based models, which handle images and
text separately, limiting their ability to capture complex multimodal
relationships. Additionally, these models are evaluated across diverse datasets
without a unified benchmark for assessing multimodal embeddings in pathology.
To address these challenges, we propose MLLM4PUE, a novel framework that
leverages Multimodal Large Language Models (MLLMs) to generate Pathology
Universal Embeddings. The MLLM4PUE framework not only facilitates robust
integration of images and text but also enhances understanding and fusion
capabilities across various tasks. We further introduce the Pathology
Multimodal Embedding Benchmark (PMEB), a comprehensive benchmark designed to
assess the quality of pathology multimodal embeddings. PMEB comprises 15
original tasks drawn from 14 datasets, organized into three meta-tasks:
retrieval, classification, and composed retrieval. Experimental results
demonstrate the superiority of MLLM4PUE, illustrating MLLM-based models can
effectively support a wide range of downstream tasks and unify the research
direction for foundation models in pathology.",http://arxiv.org/abs/2502.07221v1,Recommendation System,"pathology, models, multimodal, tasks, embeddings"
LUNAR: LLM Unlearning via Neural Activation Redirection,"Large Language Models (LLMs) benefit from training on ever larger amounts of
textual data, but as a result, they increasingly incur the risk of leaking
private information. The ability to selectively remove knowledge from LLMs is,
therefore, a highly desirable capability. In this paper, we propose LUNAR, a
novel unlearning methodology grounded in the Linear Representation Hypothesis.
LUNAR operates by redirecting the representations of unlearned data to regions
that trigger the model's inherent ability to express its inability to answer.
LUNAR achieves state-of-the-art unlearning performance while significantly
enhancing the controllability of the unlearned model during inference.
Specifically, LUNAR achieves between 2.9x to 11.7x improvements on combined
""unlearning efficacy"" and ""model utility"" score (""Deviation Score"") on the
PISTOL dataset across various base models. We also demonstrate, through
quantitative analysis and qualitative examples, LUNAR's superior
controllability in generating coherent and contextually aware responses,
mitigating undesired side effects of existing methods. Moreover, we demonstrate
that LUNAR is robust against white-box adversarial attacks and versatile in
handling real-world scenarios, such as processing sequential unlearning
requests.",http://arxiv.org/abs/2502.07218v1,Natural Language Processing,"lunar, unlearning, model, models, llms"
SparseFormer: Detecting Objects in HRW Shots via Sparse Vision Transformer,"Recent years have seen an increase in the use of gigapixel-level image and
video capture systems and benchmarks with high-resolution wide (HRW) shots.
However, unlike close-up shots in the MS COCO dataset, the higher resolution
and wider field of view raise unique challenges, such as extreme sparsity and
huge scale changes, causing existing close-up detectors inaccuracy and
inefficiency. In this paper, we present a novel model-agnostic sparse vision
transformer, dubbed SparseFormer, to bridge the gap of object detection between
close-up and HRW shots. The proposed SparseFormer selectively uses attentive
tokens to scrutinize the sparsely distributed windows that may contain objects.
In this way, it can jointly explore global and local attention by fusing
coarse- and fine-grained features to handle huge scale changes. SparseFormer
also benefits from a novel Cross-slice non-maximum suppression (C-NMS)
algorithm to precisely localize objects from noisy windows and a simple yet
effective multi-scale strategy to improve accuracy. Extensive experiments on
two HRW benchmarks, PANDA and DOTA-v1.0, demonstrate that the proposed
SparseFormer significantly improves detection accuracy (up to 5.8%) and speed
(up to 3x) over the state-of-the-art approaches.",http://arxiv.org/abs/2502.07216v1,Computer Vision,"sparseformer, hrw, shots, close, scale"
PDV: Prompt Directional Vectors for Zero-shot Composed Image Retrieval,"Zero-shot composed image retrieval (ZS-CIR) enables image search using a
reference image and text prompt without requiring specialized text-image
composition networks trained on large-scale paired data. However, current
ZS-CIR approaches face three critical limitations in their reliance on composed
text embeddings: static query embedding representations, insufficient
utilization of image embeddings, and suboptimal performance when fusing text
and image embeddings. To address these challenges, we introduce the Prompt
Directional Vector (PDV), a simple yet effective training-free enhancement that
captures semantic modifications induced by user prompts. PDV enables three key
improvements: (1) dynamic composed text embeddings where prompt adjustments are
controllable via a scaling factor, (2) composed image embeddings through
semantic transfer from text prompts to image features, and (3) weighted fusion
of composed text and image embeddings that enhances retrieval by balancing
visual and semantic similarity. Our approach serves as a plug-and-play
enhancement for existing ZS-CIR methods with minimal computational overhead.
Extensive experiments across multiple benchmarks demonstrate that PDV
consistently improves retrieval performance when integrated with
state-of-the-art ZS-CIR approaches, particularly for methods that generate
accurate compositional embeddings. The code will be publicly available.",http://arxiv.org/abs/2502.07215v1,Recommendation System,"image, text, embeddings, composed, zs"
Pareto Optimal Algorithmic Recourse in Multi-cost Function,"In decision-making systems, algorithmic recourse aims to identify
minimal-cost actions to alter an individual features, thereby obtaining a
desired outcome. This empowers individuals to understand, question, or alter
decisions that negatively affect them. However, due to the variety and
sensitivity of system environments and individual personalities, quantifying
the cost of a single function is nearly impossible while considering multiple
criteria situations. Most current recourse mechanisms use gradient-based
methods that assume cost functions are differentiable, often not applicable in
real-world scenarios, resulting in sub-optimal solutions that compromise
various criteria. These solutions are typically intractable and lack rigorous
theoretical foundations, raising concerns regarding interpretability,
reliability, and transparency from the explainable AI (XAI) perspective.
  To address these issues, this work proposes an algorithmic recourse framework
that handles non-differentiable and discrete multi-cost functions. By
formulating recourse as a multi-objective optimization problem and assigning
weights to different criteria based on their importance, our method identifies
Pareto optimal recourse recommendations. To demonstrate scalability, we
incorporate the concept of epsilon-net, proving the ability to find
approximated Pareto optimal actions. Experiments show the trade-off between
different criteria and the methods scalability in large graphs. Compared to
current heuristic practices, our approach provides a stronger theoretical
foundation and better aligns recourse suggestions with real-world requirements.",http://arxiv.org/abs/2502.07214v1,Recommendation System,"recourse, cost, criteria, optimal, algorithmic"
Evaluation for Regression Analyses on Evolving Data Streams,"The paper explores the challenges of regression analysis in evolving data
streams, an area that remains relatively underexplored compared to
classification. We propose a standardized evaluation process for regression and
prediction interval tasks in streaming contexts. Additionally, we introduce an
innovative drift simulation strategy capable of synthesizing various drift
types, including the less-studied incremental drift. Comprehensive experiments
with state-of-the-art methods, conducted under the proposed process, validate
the effectiveness and robustness of our approach.",http://arxiv.org/abs/2502.07213v1,Recommendation System,"drift, regression, process, paper, explores"
Improve the Training Efficiency of DRL for Wireless Communication Resource Allocation: The Role of Generative Diffusion Models,"Dynamic resource allocation in mobile wireless networks involves complex,
time-varying optimization problems, motivating the adoption of deep
reinforcement learning (DRL). However, most existing works rely on pre-trained
policies, overlooking dynamic environmental changes that rapidly invalidate the
policies. Periodic retraining becomes inevitable but incurs prohibitive
computational costs and energy consumption-critical concerns for
resource-constrained wireless systems. We identify three root causes of
inefficient retraining: high-dimensional state spaces, suboptimal action spaces
exploration-exploitation trade-offs, and reward design limitations. To overcome
these limitations, we propose Diffusion-based Deep Reinforcement Learning
(D2RL), which leverages generative diffusion models (GDMs) to holistically
enhance all three DRL components. Iterative refinement process and distribution
modelling of GDMs enable (1) the generation of diverse state samples to improve
environmental understanding, (2) balanced action space exploration to escape
local optima, and (3) the design of discriminative reward functions that better
evaluate action quality. Our framework operates in two modes: Mode I leverages
GDMs to explore reward spaces and design discriminative reward functions that
rigorously evaluate action quality, while Mode II synthesizes diverse state
samples to enhance environmental understanding and generalization. Extensive
experiments demonstrate that D2RL achieves faster convergence and reduced
computational costs over conventional DRL methods for resource allocation in
wireless communications while maintaining competitive policy performance. This
work underscores the transformative potential of GDMs in overcoming fundamental
DRL training bottlenecks for wireless networks, paving the way for practical,
real-time deployments.",http://arxiv.org/abs/2502.07211v1,Reinforcement Learning,"wireless, drl, action, reward, gdms"
Enhancing Physics-Informed Neural Networks Through Feature Engineering,"Physics-Informed Neural Networks (PINNs) seek to solve partial differential
equations (PDEs) with deep learning. Mainstream approaches that deploy
fully-connected multi-layer deep learning architectures require prolonged
training to achieve even moderate accuracy, while recent work on feature
engineering allows higher accuracy and faster convergence. This paper
introduces SAFE-NET, a Single-layered Adaptive Feature Engineering NETwork that
achieves orders-of-magnitude lower errors with far fewer parameters than
baseline feature engineering methods. SAFE-NET returns to basic ideas in
machine learning, using Fourier features, a simplified single hidden layer
network architecture, and an effective optimizer that improves the conditioning
of the PINN optimization problem. Numerical results show that SAFE-NET
converges faster and typically outperforms deeper networks and more complex
architectures. It consistently uses fewer parameters -- on average, 65% fewer
than the competing feature engineering methods -- while achieving comparable
accuracy in less than 30% of the training epochs. Moreover, each SAFE-NET epoch
is 95% faster than those of competing feature engineering approaches. These
findings challenge the prevailing belief that modern PINNs effectively learn
features in these scientific applications and highlight the efficiency gains
possible through feature engineering.",http://arxiv.org/abs/2502.07209v1,Recommendation System,"feature, engineering, safe, net, learning"
A Study on the Importance of Features in Detecting Advanced Persistent Threats Using Machine Learning,"Advanced Persistent Threats (APTs) pose a significant security risk to
organizations and industries. These attacks often lead to severe data breaches
and compromise the system for a long time. Mitigating these sophisticated
attacks is highly challenging due to the stealthy and persistent nature of
APTs. Machine learning models are often employed to tackle this challenge by
bringing automation and scalability to APT detection. Nevertheless, these
intelligent methods are data-driven, and thus, highly affected by the quality
and relevance of input data. This paper aims to analyze measurements considered
when recording network traffic and conclude which features contribute more to
detecting APT samples. To do this, we study the features associated with
various APT cases and determine their importance using a machine learning
framework. To ensure the generalization of our findings, several feature
selection techniques are employed and paired with different classifiers to
evaluate their effectiveness. Our findings provide insights into how APT
detection can be enhanced in real-world scenarios.",http://arxiv.org/abs/2502.07207v1,Recommendation System,"apt, data, persistent, apts, attacks"
Optimal Actuator Attacks on Autonomous Vehicles Using Reinforcement Learning,"With the increasing prevalence of autonomous vehicles (AVs), their
vulnerability to various types of attacks has grown, presenting significant
security challenges. In this paper, we propose a reinforcement learning
(RL)-based approach for designing optimal stealthy integrity attacks on AV
actuators. We also analyze the limitations of state-of-the-art RL-based secure
controllers developed to counter such attacks. Through extensive simulation
experiments, we demonstrate the effectiveness and efficiency of our proposed
method.",http://arxiv.org/abs/2502.07839v1,Reinforcement Learning,"attacks, increasing, prevalence, autonomous, vehicles"
VINP: Variational Bayesian Inference with Neural Speech Prior for Joint ASR-Effective Speech Dereverberation and Blind RIR Identification,"Reverberant speech, denoting the speech signal degraded by the process of
reverberation, contains crucial knowledge of both anechoic source speech and
room impulse response (RIR). This work proposes a variational Bayesian
inference (VBI) framework with neural speech prior (VINP) for joint speech
dereverberation and blind RIR identification. In VINP, a probabilistic signal
model is constructed in the time-frequency (T-F) domain based on convolution
transfer function (CTF) approximation. For the first time, we propose using an
arbitrary discriminative dereverberation deep neural network (DNN) to predict
the prior distribution of anechoic speech within a probabilistic model. By
integrating both reverberant speech and the anechoic speech prior, VINP yields
the maximum a posteriori (MAP) and maximum likelihood (ML) estimations of the
anechoic speech spectrum and CTF filter, respectively. After simple
transformations, the waveforms of anechoic speech and RIR are estimated.
Moreover, VINP is effective for automatic speech recognition (ASR) systems,
which sets it apart from most deep learning (DL)-based single-channel
dereverberation approaches. Experiments on single-channel speech
dereverberation demonstrate that VINP reaches an advanced level in most metrics
related to human perception and displays unquestionable state-of-the-art (SOTA)
performance in ASR-related metrics. For blind RIR identification, experiments
indicate that VINP attains the SOTA level in blind estimation of reverberation
time at 60 dB (RT60) and direct-to-reverberation ratio (DRR). Codes and audio
samples are available online.",http://arxiv.org/abs/2502.07205v1,Recommendation System,"speech, vinp, anechoic, rir, dereverberation"
Playmate: Flexible Control of Portrait Animation via 3D-Implicit Space Guided Diffusion,"Recent diffusion-based talking face generation models have demonstrated
impressive potential in synthesizing videos that accurately match a speech
audio clip with a given reference identity. However, existing approaches still
encounter significant challenges due to uncontrollable factors, such as
inaccurate lip-sync, inappropriate head posture and the lack of fine-grained
control over facial expressions. In order to introduce more face-guided
conditions beyond speech audio clips, a novel two-stage training framework
Playmate is proposed to generate more lifelike facial expressions and talking
faces. In the first stage, we introduce a decoupled implicit 3D representation
along with a meticulously designed motion-decoupled module to facilitate more
accurate attribute disentanglement and generate expressive talking videos
directly from audio cues. Then, in the second stage, we introduce an
emotion-control module to encode emotion control information into the latent
space, enabling fine-grained control over emotions and thereby achieving the
ability to generate talking videos with desired emotion. Extensive experiments
demonstrate that Playmate outperforms existing state-of-the-art methods in
terms of video quality and lip-synchronization, and improves flexibility in
controlling emotion and head pose. The code will be available at
https://playmate111.github.io.",http://arxiv.org/abs/2502.07203v1,Recommendation System,"talking, control, emotion, videos, audio"
Monte Carlo Tree Diffusion for System 2 Planning,"Diffusion models have recently emerged as a powerful tool for planning.
However, unlike Monte Carlo Tree Search (MCTS)-whose performance naturally
improves with additional test-time computation (TTC), standard diffusion-based
planners offer only limited avenues for TTC scalability. In this paper, we
introduce Monte Carlo Tree Diffusion (MCTD), a novel framework that integrates
the generative strength of diffusion models with the adaptive search
capabilities of MCTS. Our method reconceptualizes denoising as a
tree-structured process, allowing partially denoised plans to be iteratively
evaluated, pruned, and refined. By selectively expanding promising trajectories
while retaining the flexibility to revisit and improve suboptimal branches,
MCTD achieves the benefits of MCTS such as controlling exploration-exploitation
trade-offs within the diffusion framework. Empirical results on challenging
long-horizon tasks show that MCTD outperforms diffusion baselines, yielding
higher-quality solutions as TTC increases.",http://arxiv.org/abs/2502.07202v1,Recommendation System,"diffusion, tree, ttc, mctd, models"
Color-Quality Invariance for Robust Medical Image Segmentation,"Single-source domain generalization (SDG) in medical image segmentation
remains a significant challenge, particularly for images with varying color
distributions and qualities. Previous approaches often struggle when models
trained on high-quality images fail to generalize to low-quality test images
due to these color and quality shifts. In this work, we propose two novel
techniques to enhance generalization: dynamic color image normalization (DCIN)
module and color-quality generalization (CQG) loss. The DCIN dynamically
normalizes the color of test images using two reference image selection
strategies. Specifically, the DCIN utilizes a global reference image selection
(GRIS), which finds a universal reference image, and a local reference image
selection (LRIS), which selects a semantically similar reference image per test
sample. Additionally, CQG loss enforces invariance to color and quality
variations by ensuring consistent segmentation predictions across transformed
image pairs. Experimental results show that our proposals significantly improve
segmentation performance over the baseline on two target domain datasets,
despite being trained solely on a single source domain. Notably, our model
achieved up to a 32.3-point increase in Dice score compared to the baseline,
consistently producing robust and usable results even under substantial domain
shifts. Our work contributes to the development of more robust medical image
segmentation models that generalize across unseen domains. The implementation
code is available at https://github.com/RaviShah1/DCIN-CQG.",http://arxiv.org/abs/2502.07200v1,Reinforcement Learning,"image, color, quality, reference, domain"
Fixed-Confidence Best Arm Identification with Decreasing Variance,"We focus on the problem of best-arm identification in a stochastic multi-arm
bandit with temporally decreasing variances for the arms' rewards. We model arm
rewards as Gaussian random variables with fixed means and variances that
decrease with time. The cost incurred by the learner is modeled as a weighted
sum of the time needed by the learner to identify the best arm, and the number
of samples of arms collected by the learner before termination. Under this cost
function, there is an incentive for the learner to not sample arms in all
rounds, especially in the initial rounds. On the other hand, not sampling
increases the termination time of the learner, which also increases cost. This
trade-off necessitates new sampling strategies. We propose two policies. The
first policy has an initial wait period with no sampling followed by continuous
sampling. The second policy samples periodically and uses a weighted average of
the rewards observed to identify the best arm. We provide analytical guarantees
on the performance of both policies and supplement our theoretical results with
simulations which show that our polices outperform the state-of-the-art
policies for the classical best arm identification problem.",http://arxiv.org/abs/2502.07199v1,Recommendation System,"arm, learner, best, sampling, arms"
Dense Object Detection Based on De-homogenized Queries,"Dense object detection is widely used in automatic driving, video
surveillance, and other fields. This paper focuses on the challenging task of
dense object detection. Currently, detection methods based on greedy
algorithms, such as non-maximum suppression (NMS), often produce many
repetitive predictions or missed detections in dense scenarios, which is a
common problem faced by NMS-based algorithms. Through the end-to-end DETR
(DEtection TRansformer), as a type of detector that can incorporate the
post-processing de-duplication capability of NMS, etc., into the network, we
found that homogeneous queries in the query-based detector lead to a reduction
in the de-duplication capability of the network and the learning efficiency of
the encoder, resulting in duplicate prediction and missed detection problems.
To solve this problem, we propose learnable differentiated encoding to
de-homogenize the queries, and at the same time, queries can communicate with
each other via differentiated encoding information, replacing the previous
self-attention among the queries. In addition, we used joint loss on the output
of the encoder that considered both location and confidence prediction to give
a higher-quality initialization for queries. Without cumbersome decoder
stacking and guaranteeing accuracy, our proposed end-to-end detection framework
was more concise and reduced the number of parameters by about 8% compared to
deformable DETR. Our method achieved excellent results on the challenging
CrowdHuman dataset with 93.6% average precision (AP), 39.2% MR-2, and 84.3% JI.
The performance overperformed previous SOTA methods, such as Iter-E2EDet
(Progressive End-to-End Object Detection) and MIP (One proposal, Multiple
predictions). In addition, our method is more robust in various scenarios with
different densities.",http://arxiv.org/abs/2502.07194v1,Recommendation System,"detection, end, queries, dense, object"
Provably Efficient RLHF Pipeline: A Unified View from Contextual Bandits,"Reinforcement Learning from Human Feedback (RLHF) is a widely used approach
for aligning Large Language Models (LLMs) with human preferences. While recent
advancements have provided valuable insights into various stages and settings
of RLHF, a comprehensive theoretical understanding of the entire RLHF pipeline
remains lacking. Towards this end, we propose a unified framework for the RLHF
pipeline from the view of contextual bandits and provide provable efficiency
guarantees. In particular, we decompose the RLHF process into two distinct
stages: (post-)training and deployment, exploring both passive and active data
collection strategies during the training phase. By employing the Bradley-Terry
preference model with a linearly parameterized reward function, we reformulate
RLHF as a contextual preference bandit problem. We then develop novel
algorithms for each stage, demonstrating significant improvements over existing
approaches in both statistical and computational efficiency. Finally, we apply
our method to train and deploy Llama-3-8B-Instruct on the
Ultrafeedback-binarized dataset, and empirical results confirm the
effectiveness of our approach.",http://arxiv.org/abs/2502.07193v1,Reinforcement Learning,"rlhf, human, approach, stages, pipeline"
OscNet: Machine Learning on CMOS Oscillator Networks,"Machine learning and AI have achieved remarkable advancements but at the cost
of significant computational resources and energy consumption. This has created
an urgent need for a novel, energy-efficient computational fabric to replace
the current computing pipeline. Recently, a promising approach has emerged by
mimicking spiking neurons in the brain and leveraging oscillators on CMOS for
direct computation. In this context, we propose a new and energy efficient
machine learning framework implemented on CMOS Oscillator Networks (OscNet). We
model the developmental processes of the prenatal brain's visual system using
OscNet, updating weights based on the biologically inspired Hebbian rule. This
same pipeline is then directly applied to standard machine learning tasks.
OscNet is a specially designed hardware and is inherently energy-efficient. Its
reliance on forward propagation alone for training further enhances its energy
efficiency while maintaining biological plausibility. Simulation validates our
designs of OscNet architectures. Experimental results demonstrate that Hebbian
learning pipeline on OscNet achieves performance comparable to or even
surpassing traditional machine learning algorithms, highlighting its potential
as a energy efficient and effective computational paradigm.",http://arxiv.org/abs/2502.07192v1,Recommendation System,"energy, learning, oscnet, machine, efficient"
NanoVLMs: How small can we go and still make coherent Vision Language Models?,"Vision-Language Models (VLMs), such as GPT-4V and Llama 3.2 vision, have
garnered significant research attention for their ability to leverage Large
Language Models (LLMs) in multimodal tasks. However, their potential is
constrained by inherent challenges, including proprietary restrictions,
substantial computational demands, and limited accessibility. Smaller models,
such as GIT and BLIP, exhibit marked limitations, often failing to generate
coherent and consistent text beyond a few tokens, even with extensive training.
This underscores a pivotal inquiry: how small can a VLM be and still produce
fluent and consistent text? Drawing inspiration from the exceptional learning
process of 3-4 year old children, who rely heavily on visual cues for
understanding and communication, we introduce two novel datasets: ShortDesc
(featuring concise image descriptions) and LongDesc (containing more detailed
image descriptions). These datasets consist of image-text pairs where the text
is restricted to the simple vocabulary and syntax typically used by young
children, generated with a scaled- down model, GPT-4o. Using these datasets, we
demonstrate that it is possible to train VLMs that are significantly smaller,
up to 10 times smaller than state of the art(SOTA) small VLMs while maintaining
architectural simplicity. To evaluate the outputs, we leverage GPT-4o to grade
the text, as if stories written by students, on creativity, meaningfulness, and
consistency, assigning scores out of 10. This method addresses limitations of
standard benchmarks by accommodating unstructured outputs and providing a
multidimensional evaluation of the model capabilities. Our findings contribute
to the development of lightweight, accessible multimodal models for resource
constrained environments.",http://arxiv.org/abs/2502.07838v1,Recommendation System,"text, models, vlms, smaller, datasets"
Bag of Tricks for Inference-time Computation of LLM Reasoning,"With the advancement of large language models (LLMs), solving complex
reasoning tasks has gained increasing attention. Inference-time computation
methods (e.g., Best-of-N, beam search, et al.) are particularly valuable as
they can enhance reasoning performance without modifying model parameters or
requiring additional training. However, these techniques come with
implementation challenges, and most existing methods remain at the
proof-of-concept stage with limited practical adoption due to their
computational complexity and varying effectiveness across different tasks. In
this paper, we investigate and benchmark diverse inference-time computation
strategies across reasoning tasks of varying complexity. Since most current
methods rely on a proposer-verifier pipeline that first generates candidate
solutions (e.g., reasoning solutions) and then selects the best one based on
reward signals (e.g., RLHF rewards, process rewards), our research focuses on
optimizing both candidate solution generation (e.g., instructing prompts,
hyperparameters such as temperature and top-p) and reward mechanisms (e.g.,
self-evaluation, reward types). Through extensive experiments (more than 20,000
A100-80G GPU hours with over 1,000 experiments) across a variety of models
(e.g., Llama, Qwen, and Mistral families) of various sizes, our ablation
studies reveal that previously overlooked strategies can significantly enhance
performance (e.g., tuning temperature can improve reasoning task performance by
up to 5%). Furthermore, we establish a standardized benchmark for
inference-time computation by systematically evaluating six representative
methods across eight reasoning tasks. These findings provide a stronger
foundation for future research. The code is available at
https://github.com/usail-hkust/benchmark_inference_time_computation_LL",http://arxiv.org/abs/2502.07191v2,Natural Language Processing,"reasoning, tasks, methods, inference, time"
Understanding LLMs' Fluid Intelligence Deficiency: An Analysis of the ARC Task,"While LLMs have exhibited strong performance on various NLP tasks, it is
noteworthy that most of these tasks rely on utilizing the vast amount of
knowledge encoded in LLMs' parameters, rather than solving new problems without
prior knowledge. In cognitive research, the latter ability is referred to as
fluid intelligence, which is considered to be critical for assessing human
intelligence. Recent research on fluid intelligence assessments has highlighted
significant deficiencies in LLMs' abilities. In this paper, we analyze the
challenges LLMs face in demonstrating fluid intelligence through controlled
experiments, using the most representative ARC task as an example. Our study
revealed three major limitations in existing LLMs: limited ability for skill
composition, unfamiliarity with abstract input formats, and the intrinsic
deficiency of left-to-right decoding. Our data and code can be found in
https://wujunjie1998.github.io/araoc-benchmark.github.io/.",http://arxiv.org/abs/2502.07190v1,Natural Language Processing,"llms, intelligence, fluid, tasks, knowledge"
Exploring Neural Network Pruning with Screening Methods,"Deep neural networks (DNNs) such as convolutional neural networks (CNNs) for
visual tasks, recurrent neural networks (RNNs) for sequence data, and
transformer models for rich linguistic or multimodal tasks, achieved
unprecedented performance on a wide range of tasks. The impressive performance
of modern DNNs is partially attributed to their sheer scale. The latest deep
learning models have tens to hundreds of millions of parameters which makes the
inference processes resource-intensive. The high computational complexity of
these networks prevents their deployment on resource-limited devices such as
mobile platforms, IoT devices, and edge computing systems because these devices
require energy-efficient and real-time processing capabilities. This paper
proposes and evaluates a network pruning framework that eliminates
non-essential parameters based on a statistical analysis of network component
significance across classification categories. The proposed method uses
screening methods coupled with a weighted scheme to assess connection and
channel contributions for unstructured and structured pruning which allows for
the elimination of unnecessary network elements without significantly degrading
model performance. Extensive experimental validation on real-world vision
datasets for both fully connected neural networks (FNNs) and CNNs has shown
that the proposed framework produces competitive lean networks compared to the
original networks. Moreover, the proposed framework outperforms state-of-art
network pruning methods in two out of three cases.",http://arxiv.org/abs/2502.07189v1,Recommendation System,"networks, neural, network, tasks, performance"
Local Regularizers Are Not Transductive Learners,"We partly resolve an open question raised by Asilis et al. (COLT 2024):
whether the algorithmic template of local regularization -- an intriguing
generalization of explicit regularization, a.k.a. structural risk minimization
-- suffices to learn all learnable multiclass problems. Specifically, we
provide a negative answer to this question in the transductive model of
learning. We exhibit a multiclass classification problem which is learnable in
both the transductive and PAC models, yet cannot be learned transductively by
any local regularizer. The corresponding hypothesis class, and our proof, are
based on principles from cryptographic secret sharing. We outline challenges in
extending our negative result to the PAC model, leaving open the tantalizing
possibility of a PAC/transductive separation with respect to local
regularization.",http://arxiv.org/abs/2502.07187v1,Recommendation System,"local, regularization, transductive, pac, open"
Perceived Confidence Scoring for Data Annotation with Zero-Shot LLMs,"Zero-shot LLMs are now also used for textual classification tasks, e.g.,
sentiment/emotion detection of a given input as a sentence/article. However,
their performance can be suboptimal in such data annotation tasks. We introduce
a novel technique Perceived Confidence Scoring (PCS) that evaluates LLM's
confidence for its classification of an input by leveraging Metamorphic
Relations (MRs). The MRs generate semantically equivalent yet textually mutated
versions of the input. Following the principles of Metamorphic Testing (MT),
the mutated versions are expected to have annotation labels similar to the
input. By analyzing the consistency of LLM responses across these variations,
PCS computes a confidence score based on the frequency of predicted labels. PCS
can be used both for single LLM and multiple LLM settings (e.g., majority
voting). We introduce an algorithm Perceived Differential Evolution (PDE) that
determines the optimal weights assigned to the MRs and the LLMs for a
classification task. Empirical evaluation shows PCS significantly improves
zero-shot accuracy for Llama-3-8B-Instruct (4.96%) and Mistral-7B-Instruct-v0.3
(10.52%), with Gemma-2-9b-it showing a 9.39% gain. When combining all three
models, PCS significantly outperforms majority voting by 7.75%.",http://arxiv.org/abs/2502.07186v1,Recommendation System,"pcs, input, llm, classification, confidence"
Refine Knowledge of Large Language Models via Adaptive Contrastive Learning,"How to alleviate the hallucinations of Large Language Models (LLMs) has
always been the fundamental goal pursued by the LLMs research community.
Looking through numerous hallucination-related studies, a mainstream category
of methods is to reduce hallucinations by optimizing the knowledge
representation of LLMs to change their output. Considering that the core focus
of these works is the knowledge acquired by models, and knowledge has long been
a central theme in human societal progress, we believe that the process of
models refining knowledge can greatly benefit from the way humans learn. In our
work, by imitating the human learning process, we design an Adaptive
Contrastive Learning strategy. Our method flexibly constructs different
positive and negative samples for contrastive learning based on LLMs' actual
mastery of knowledge. This strategy helps LLMs consolidate the correct
knowledge they already possess, deepen their understanding of the correct
knowledge they have encountered but not fully grasped, forget the incorrect
knowledge they previously learned, and honestly acknowledge the knowledge they
lack. Extensive experiments and detailed analyses on widely used datasets
demonstrate the effectiveness of our method.",http://arxiv.org/abs/2502.07184v1,Recommendation System,"knowledge, llms, models, learning, hallucinations"
RoboBERT: An End-to-end Multimodal Robotic Manipulation Model,"Embodied intelligence integrates multiple modalities, enabling agents to
understand images, language, and actions simultaneously. However, existing
models always depend on additional datasets or extensive pre-training to
maximize performance improvements, consuming abundant training time and
expensive hardware cost. To tackle this issue, we present RoboBERT, a novel
end-to-end robotic manipulation model integrated with a unique training
strategy. This model utilizes a CNN-based diffusion policy, enhancing and
stabilizing the effectiveness of this model by separating training processes
for different modalities. It also underscores the importance of data
augmentation, verifying various techniques to significantly boost performance.
Unlike models that depend on extra data or large foundation models, RoboBERT
achieves a highly competitive success rate while using only language-labeled
expert demonstrations and maintaining a relatively smaller model size.
Specifically, RoboBERT achieves an average length of 4.52 on the CALVIN
benchmark for \(ABCD \rightarrow D\) task, setting a new state-of-the-art
(SOTA) record. Furthermore, when tested on a real robot, the model demonstrates
superior performance, achieving a higher success rate than other methods
trained with the same data. We propose that these concepts and methodologies of
RoboBERT demonstrate extensive versatility and compatibility, contributing
significantly to the development of lightweight multimodal robotic models. The
code can be accessed on https://github.com/PeterWangsicheng/RoboBERT",http://arxiv.org/abs/2502.07837v1,Recommendation System,"model, models, training, robobert, performance"
Space-Aware Instruction Tuning: Dataset and Benchmark for Guide Dog Robots Assisting the Visually Impaired,"Guide dog robots offer promising solutions to enhance mobility and safety for
visually impaired individuals, addressing the limitations of traditional guide
dogs, particularly in perceptual intelligence and communication. With the
emergence of Vision-Language Models (VLMs), robots are now capable of
generating natural language descriptions of their surroundings, aiding in safer
decision-making. However, existing VLMs often struggle to accurately interpret
and convey spatial relationships, which is crucial for navigation in complex
environments such as street crossings. We introduce the Space-Aware Instruction
Tuning (SAIT) dataset and the Space-Aware Benchmark (SA-Bench) to address the
limitations of current VLMs in understanding physical environments. Our
automated data generation pipeline focuses on the virtual path to the
destination in 3D space and the surroundings, enhancing environmental
comprehension and enabling VLMs to provide more accurate guidance to visually
impaired individuals. We also propose an evaluation protocol to assess VLM
effectiveness in delivering walking guidance. Comparative experiments
demonstrate that our space-aware instruction-tuned model outperforms
state-of-the-art algorithms. We have fully open-sourced the SAIT dataset and
SA-Bench, along with the related code, at
https://github.com/byungokhan/Space-awareVLM",http://arxiv.org/abs/2502.07183v2,Recommendation System,"vlms, space, aware, guide, robots"
Tab2Visual: Overcoming Limited Data in Tabular Data Classification Using Deep Learning with Visual Representations,"This research addresses the challenge of limited data in tabular data
classification, particularly prevalent in domains with constraints like
healthcare. We propose Tab2Visual, a novel approach that transforms
heterogeneous tabular data into visual representations, enabling the
application of powerful deep learning models. Tab2Visual effectively addresses
data scarcity by incorporating novel image augmentation techniques and
facilitating transfer learning. We extensively evaluate the proposed approach
on diverse tabular datasets, comparing its performance against a wide range of
machine learning algorithms, including classical methods, tree-based ensembles,
and state-of-the-art deep learning models specifically designed for tabular
data. We also perform an in-depth analysis of factors influencing Tab2Visual's
performance. Our experimental results demonstrate that Tab2Visual outperforms
other methods in classification problems with limited tabular data.",http://arxiv.org/abs/2502.07181v1,Computer Vision,"data, tabular, learning, addresses, limited"
Improved YOLOv7 model for insulator defect detection,"Insulators are crucial insulation components and structural supports in power
grids, playing a vital role in the transmission lines. Due to temperature
fluctuations, internal stress, or damage from hail, insulators are prone to
injury. Automatic detection of damaged insulators faces challenges such as
diverse types, small defect targets, and complex backgrounds and shapes. Most
research for detecting insulator defects has focused on a single defect type or
a specific material. However, the insulators in the grid's transmission lines
have different colors and materials. Various insulator defects coexist, and the
existing methods have difficulty meeting the practical application
requirements. Current methods suffer from low detection accuracy and mAP0.5
cannot meet application requirements. This paper proposes an improved YOLOv7
model for multi-type insulator defect detection. First, our model replaces the
SPPCSPC module with the RFB module to enhance the network's feature extraction
capability. Second, a CA mechanism is introduced into the head part to enhance
the network's feature representation ability and to improve detection accuracy.
Third, a WIoU loss function is employed to address the low-quality samples
hindering model generalization during training, thereby improving the model's
overall performance. The experimental results indicate that the proposed model
exhibits enhancements across various performance metrics. Specifically, there
is a 1.6% advancement in mAP_0.5, a corresponding 1.6% enhancement in
mAP_0.5:0.95, a 1.3% elevation in precision, and a 1% increase in recall.
Moreover, the model achieves parameter reduction by 3.2 million, leading to a
decrease of 2.5 GFLOPS in computational cost. Notably, there is also an
improvement of 2.81 milliseconds in single-image detection speed.",http://arxiv.org/abs/2502.07179v1,Reinforcement Learning,"model, detection, insulators, defect, insulator"
MatrixKAN: Parallelized Kolmogorov-Arnold Network,"Kolmogorov-Arnold Networks (KAN) are a new class of neural network
architecture representing a promising alternative to the Multilayer Perceptron
(MLP), demonstrating improved expressiveness and interpretability. However,
KANs suffer from slow training and inference speeds relative to MLPs due in
part to the recursive nature of the underlying B-spline calculations. This
issue is particularly apparent with respect to KANs utilizing high-degree
B-splines, as the number of required non-parallelizable recursions is
proportional to B-spline degree. We solve this issue by proposing MatrixKAN, a
novel optimization that parallelizes B-spline calculations with matrix
representation and operations, thus significantly improving effective
computation time for models utilizing high-degree B-splines. In this paper, we
demonstrate the superior scaling of MatrixKAN's computation time relative to
B-spline degree. Further, our experiments demonstrate speedups of approximately
40x relative to KAN, with significant additional speedup potential for larger
datasets or higher spline degrees.",http://arxiv.org/abs/2502.07176v1,Recommendation System,"b, spline, degree, relative, kan"
Foreign-Object Detection in High-Voltage Transmission Line Based on Improved YOLOv8m,"The safe operation of high-voltage transmission lines ensures the power
grid's security. Various foreign objects attached to the transmission lines,
such as balloons, kites and nesting birds, can significantly affect the safe
and stable operation of high-voltage transmission lines. With the advancement
of computer vision technology, periodic automatic inspection of foreign objects
is efficient and necessary. Existing detection methods have low accuracy
because foreign objects at-tached to the transmission lines are complex,
including occlusions, diverse object types, significant scale variations, and
complex backgrounds. In response to the practical needs of the Yunnan Branch of
China Southern Power Grid Co., Ltd., this paper proposes an improved
YOLOv8m-based model for detecting foreign objects on transmission lines.
Experiments are conducted on a dataset collected from Yunnan Power Grid. The
proposed model enhances the original YOLOv8m by in-corporating a Global
Attention Module (GAM) into the backbone to focus on occluded foreign objects,
replacing the SPPF module with the SPPCSPC module to augment the model's
multiscale feature extraction capability, and introducing the Focal-EIoU loss
function to address the issue of high- and low-quality sample imbalances. These
improvements accelerate model convergence and enhance detection accuracy. The
experimental results demonstrate that our proposed model achieves a 2.7%
increase in mAP_0.5, a 4% increase in mAP_0.5:0.95, and a 6% increase in
recall.",http://arxiv.org/abs/2502.07175v1,Computer Vision,"transmission, lines, foreign, objects, model"
Advancing Precision Oncology Through Modeling of Longitudinal and Multimodal Data,"Cancer evolves continuously over time through a complex interplay of genetic,
epigenetic, microenvironmental, and phenotypic changes. This dynamic behavior
drives uncontrolled cell growth, metastasis, immune evasion, and therapy
resistance, posing challenges for effective monitoring and treatment. However,
today's data-driven research in oncology has primarily focused on
cross-sectional analysis using data from a single modality, limiting the
ability to fully characterize and interpret the disease's dynamic
heterogeneity. Advances in multiscale data collection and computational methods
now enable the discovery of longitudinal multimodal biomarkers for precision
oncology. Longitudinal data reveal patterns of disease progression and
treatment response that are not evident from single-timepoint data, enabling
timely abnormality detection and dynamic treatment adaptation. Multimodal data
integration offers complementary information from diverse sources for more
precise risk assessment and targeting of cancer therapy. In this review, we
survey methods of longitudinal and multimodal modeling, highlighting their
synergy in providing multifaceted insights for personalized care tailored to
the unique characteristics of a patient's cancer. We summarize the current
challenges and future directions of longitudinal multimodal analysis in
advancing precision oncology.",http://arxiv.org/abs/2502.07836v1,Recommendation System,"data, longitudinal, multimodal, cancer, dynamic"
SemiHMER: Semi-supervised Handwritten Mathematical Expression Recognition using pseudo-labels,"In recent years, deep learning with Convolutional Neural Networks (CNNs) has
achieved remarkable results in the field of HMER (Handwritten Mathematical
Expression Recognition). However, it remains challenging to improve performance
with limited labeled training data. This paper presents, for the first time, a
simple yet effective semi-supervised HMER framework by introducing dual-branch
semi-supervised learning. Specifically, we simplify the conventional deep
co-training from consistency regularization to cross-supervised learning, where
the prediction of one branch is used as a pseudo-label to supervise the other
branch directly end-to-end. Considering that the learning of the two branches
tends to converge in the later stages of model optimization, we also
incorporate a weak-to-strong strategy by applying different levels of
augmentation to each branch, which behaves like expanding the training data and
improving the quality of network training. Meanwhile, We propose a novel
module, Global Dynamic Counting Module(GDCM), to enhance the performance of the
HMER decoder, which alleviates recognition inaccuracies in long-distance
formula recognition and the occurrence of repeated characters. We release our
code at https://github.com/chenkehua/SemiHMER.",http://arxiv.org/abs/2502.07172v1,Recommendation System,"learning, training, branch, hmer, recognition"
Enhancing Robustness Of Digital Shadow For CO2 Storage Monitoring With Augmented Rock Physics Modeling,"To meet climate targets, the IPCC underscores the necessity of technologies
capable of removing gigatonnes of CO2 annually, with Geological Carbon Storage
(GCS) playing a central role. GCS involves capturing CO2 and injecting it into
deep geological formations for long-term storage, requiring precise monitoring
to ensure containment and prevent leakage. Time-lapse seismic imaging is
essential for tracking CO2 migration but often struggles to capture the
complexities of multi-phase subsurface flow. Digital Shadows (DS), leveraging
machine learning-driven data assimilation techniques such as nonlinear Bayesian
filtering and generative AI, provide a more detailed, uncertainty-aware
monitoring approach. By incorporating uncertainties in reservoir properties, DS
frameworks improve CO2 migration forecasts, reducing risks in GCS operations.
However, data assimilation depends on assumptions regarding reservoir
properties, rock physics models, and initial conditions, which, if inaccurate,
can compromise prediction reliability. This study demonstrates that augmenting
forecast ensembles with diverse rock physics models mitigates the impact of
incorrect assumptions and improves predictive accuracy, particularly in
differentiating uniform versus patchy saturation models.",http://arxiv.org/abs/2502.07171v1,Recommendation System,"gcs, models, geological, storage, monitoring"
Advancing Geological Carbon Storage Monitoring With 3d Digital Shadow Technology,"Geological Carbon Storage (GCS) is a key technology for achieving global
climate goals by capturing and storing CO2 in deep geological formations. Its
effectiveness and safety rely on accurate monitoring of subsurface CO2
migration using advanced time-lapse seismic imaging. A Digital Shadow framework
integrates field data, including seismic and borehole measurements, to track
CO2 saturation over time. Machine learning-assisted data assimilation
techniques, such as generative AI and nonlinear ensemble Bayesian filtering,
update a digital model of the CO2 plume while incorporating uncertainties in
reservoir properties. Compared to 2D approaches, 3D monitoring enhances the
spatial accuracy of GCS assessments, capturing the full extent of CO2
migration. This study extends the uncertainty-aware 2D Digital Shadow framework
by incorporating 3D seismic imaging and reservoir modeling, improving
decision-making and risk mitigation in CO2 storage projects.",http://arxiv.org/abs/2502.07169v1,Recommendation System,"seismic, digital, geological, storage, gcs"
Bayesian Optimization for Building Social-Influence-Free Consensus,"We introduce Social Bayesian Optimization (SBO), a vote-efficient algorithm
for consensus-building in collective decision-making. In contrast to
single-agent scenarios, collective decision-making encompasses group dynamics
that may distort agents' preference feedback, thereby impeding their capacity
to achieve a social-influence-free consensus -- the most preferable decision
based on the aggregated agent utilities. We demonstrate that under mild
rationality axioms, reaching social-influence-free consensus using noisy
feedback alone is impossible. To address this, SBO employs a dual voting
system: cheap but noisy public votes (e.g., show of hands in a meeting), and
more accurate, though expensive, private votes (e.g., one-to-one interview). We
model social influence using an unknown social graph and leverage the dual
voting system to efficiently learn this graph. Our theoretical findigns show
that social graph estimation converges faster than the black-box estimation of
agents' utilities, allowing us to reduce reliance on costly private votes early
in the process. This enables efficient consensus-building primarily through
noisy public votes, which are debiased based on the estimated social graph to
infer social-influence-free feedback. We validate the efficacy of SBO across
multiple real-world applications, including thermal comfort, team building,
travel negotiation, and energy trading collaboration.",http://arxiv.org/abs/2502.07166v1,Recommendation System,"social, consensus, influence, votes, graph"
Bridging LLM-Generated Code and Requirements: Reverse Generation technique and SBC Metric for Developer Insights,"The rise of Large Language Models (LLMs) in software engineering,
particularly in code generation, has garnered significant attention. However,
assessing the quality of AI-generated code remains a challenge due to the
inherent complexity of programming tasks and the lack of robust evaluation
metrics that align well with human judgment. Traditional token-based metrics
such as BLEU and ROUGE, while commonly used in natural language processing,
exhibit weak correlations with human assessments in code intelligence and
verification tasks. Furthermore, these metrics are primarily research focused
and are not designed for seamless integration into the software development
lifecycle, limiting their practical utility for developers seeking to improve
code quality and security.
  AI-assisted coding has been shown to be more beneficial for senior
developers, as they possess the expertise to critically evaluate the generated
code for correctness, completeness, and compliance. In contrast, junior
developers may struggle to identify hallucinations, missing functionality, or
incorrect logic in AI-generated code. To bridge this gap, This paper introduces
a novel scoring mechanism called the SBC score, which is based on a reverse
generation technique that leverages the natural language generation
capabilities of LLMs. Unlike direct code analysis, our approach reconstructs
system requirements from AI-generated code and compares them with the original
specifications to quantify accuracy. The SBC score combines semantic
similarity, BLEU, and completeness analysis, providing actionable insights to
developers by highlighting missing features and hallucinations. Our code and
datasets are available on GitHub",http://arxiv.org/abs/2502.07835v1,Natural Language Processing,"code, ai, generated, developers, language"
"Don't Just Demo, Teach Me the Principles: A Principle-Based Multi-Agent Prompting Strategy for Text Classification","We present PRINCIPLE-BASED PROMPTING, a simple but effective multi-agent
prompting strategy for text classification. It first asks multiple LLM agents
to independently generate candidate principles based on analysis of
demonstration samples with or without labels, consolidates them into final
principles via a finalizer agent, and then sends them to a classifier agent to
perform downstream classification tasks. Extensive experiments on binary and
multi-class classification datasets with different sizes of LLMs show that our
approach not only achieves substantial performance gains (1.55% - 19.37%) over
zero-shot prompting on macro-F1 score but also outperforms other strong
baselines (CoT and stepback prompting). Principles generated by our approach
help LLMs perform better on classification tasks than human crafted principles
on two private datasets. Our multi-agent PRINCIPLE-BASED PROMPTING approach
also shows on-par or better performance compared to demonstration-based
few-shot prompting approaches, yet with substantially lower inference costs.
Ablation studies show that label information and the multi-agent cooperative
LLM framework play an important role in generating high-quality principles to
facilitate downstream classification tasks.",http://arxiv.org/abs/2502.07165v1,Recommendation System,"prompting, agent, classification, principles, based"
Does Training on Synthetic Data Make Models Less Robust?,"An increasingly common practice is to train large language models (LLMs)
using synthetic data. Often this synthetic data is produced by the same or
similar LLMs as those it is being used to train. This raises the question of
whether the synthetic data might in fact exacerbate certain ""blindspots"" by
reinforcing heuristics that the LLM already encodes. In this paper, we conduct
simulated experiments on the natural language inference (NLI) task with
Llama-2-7B-hf models. We use MultiNLI as the general task and HANS, a targeted
evaluation set designed to measure the presence of specific heuristic
strategies for NLI, as our ""blindspot"" task. Our goal is to determine whether
performance disparities between the general and blind spot tasks emerge. Our
results indicate that synthetic data does not reinforce blindspots in the way
we expected. Specifically, we see that, while fine-tuning with synthetic data
doesn't necessarily reduce the use of the heuristic, it also does not make it
worse as we hypothesized.",http://arxiv.org/abs/2502.07164v1,Natural Language Processing,"synthetic, data, task, train, language"
A Survey on Mamba Architecture for Vision Applications,"Transformers have become foundational for visual tasks such as object
detection, semantic segmentation, and video understanding, but their quadratic
complexity in attention mechanisms presents scalability challenges. To address
these limitations, the Mamba architecture utilizes state-space models (SSMs)
for linear scalability, efficient processing, and improved contextual
awareness. This paper investigates Mamba architecture for visual domain
applications and its recent advancements, including Vision Mamba (ViM) and
VideoMamba, which introduce bidirectional scanning, selective scanning
mechanisms, and spatiotemporal processing to enhance image and video
understanding. Architectural innovations like position embeddings, cross-scan
modules, and hierarchical designs further optimize the Mamba framework for
global and local feature extraction. These advancements position Mamba as a
promising architecture in computer vision research and applications.",http://arxiv.org/abs/2502.07161v1,Computer Vision,"mamba, architecture, visual, video, understanding"
HDCompression: Hybrid-Diffusion Image Compression for Ultra-Low Bitrates,"Image compression under ultra-low bitrates remains challenging for both
conventional learned image compression (LIC) and generative vector-quantized
(VQ) modeling. Conventional LIC suffers from severe artifacts due to heavy
quantization, while generative VQ modeling gives poor fidelity due to the
mismatch between learned generative priors and specific inputs. In this work,
we propose Hybrid-Diffusion Image Compression (HDCompression), a dual-stream
framework that utilizes both generative VQ-modeling and diffusion models, as
well as conventional LIC, to achieve both high fidelity and high perceptual
quality. Different from previous hybrid methods that directly use pre-trained
LIC models to generate low-quality fidelity-preserving information from heavily
quantized latent, we use diffusion models to extract high-quality complimentary
fidelity information from the ground-truth input, which can enhance the system
performance in several aspects: improving indices map prediction, enhancing the
fidelity-preserving output of the LIC stream, and refining conditioned image
reconstruction with VQ-latent correction. In addition, our diffusion model is
based on a dense representative vector (DRV), which is lightweight with very
simple sampling schedulers. Extensive experiments demonstrate that our
HDCompression outperforms the previous conventional LIC, generative
VQ-modeling, and hybrid frameworks in both quantitative metrics and qualitative
visualization, providing balanced robust compression performance at ultra-low
bitrates.",http://arxiv.org/abs/2502.07160v1,Reinforcement Learning,"lic, generative, vq, fidelity, image"
Early Risk Prediction of Pediatric Cardiac Arrest from Electronic Health Records via Multimodal Fused Transformer,"Early prediction of pediatric cardiac arrest (CA) is critical for timely
intervention in high-risk intensive care settings. We introduce PedCA-FT, a
novel transformer-based framework that fuses tabular view of EHR with the
derived textual view of EHR to fully unleash the interactions of
high-dimensional risk factors and their dynamics. By employing dedicated
transformer modules for each modality view, PedCA-FT captures complex temporal
and contextual patterns to produce robust CA risk estimates. Evaluated on a
curated pediatric cohort from the CHOA-CICU database, our approach outperforms
ten other artificial intelligence models across five key performance metrics
and identifies clinically meaningful risk factors. These findings underscore
the potential of multimodal fusion techniques to enhance early CA detection and
improve patient care.",http://arxiv.org/abs/2502.07158v1,Recommendation System,"risk, view, early, pediatric, high"
MEMHD: Memory-Efficient Multi-Centroid Hyperdimensional Computing for Fully-Utilized In-Memory Computing Architectures,"The implementation of Hyperdimensional Computing (HDC) on In-Memory Computing
(IMC) architectures faces significant challenges due to the mismatch between
highdimensional vectors and IMC array sizes, leading to inefficient memory
utilization and increased computation cycles. This paper presents MEMHD, a
Memory-Efficient Multi-centroid HDC framework designed to address these
challenges. MEMHD introduces a clustering-based initialization method and
quantization aware iterative learning for multi-centroid associative memory.
Through these approaches and its overall architecture, MEMHD achieves a
significant reduction in memory requirements while maintaining or improving
classification accuracy. Our approach achieves full utilization of IMC arrays
and enables one-shot (or few-shot) associative search. Experimental results
demonstrate that MEMHD outperforms state-of-the-art binary HDC models,
achieving up to 13.69% higher accuracy with the same memory usage, or 13.25x
more memory efficiency at the same accuracy level. Moreover, MEMHD reduces
computation cycles by up to 80x and array usage by up to 71x compared to
baseline IMC mapping methods when mapped to 128x128 IMC arrays, while
significantly improving energy and computation cycle efficiency.",http://arxiv.org/abs/2502.07834v1,Recommendation System,"memory, imc, memhd, hdc, computation"
Explaining 3D Computed Tomography Classifiers with Counterfactuals,"Counterfactual explanations in medical imaging are critical for understanding
the predictions made by deep learning models. We extend the Latent Shift
counterfactual generation method from 2D applications to 3D computed tomography
(CT) scans. We address the challenges associated with 3D data, such as limited
training samples and high memory demands, by implementing a slice-based
approach. This method leverages a 2D encoder trained on CT slices, which are
subsequently combined to maintain 3D context. We demonstrate this technique on
two models for clinical phenotype prediction and lung segmentation. Our
approach is both memory-efficient and effective for generating interpretable
counterfactuals in high-resolution 3D medical imaging.",http://arxiv.org/abs/2502.07156v1,Reinforcement Learning,"counterfactual, medical, imaging, models, method"
Rethinking Fine-Tuning when Scaling Test-Time Compute: Limiting Confidence Improves Mathematical Reasoning,"Recent progress in large language models (LLMs) highlights the power of
scaling test-time compute to achieve strong performance on complex tasks, such
as mathematical reasoning and code generation. This raises a critical question:
how should model training be modified to optimize performance under a
subsequent test-time compute strategy and budget? To explore this, we focus on
pass@N, a simple test-time strategy that searches for a correct answer in $N$
independent samples. We show, surprisingly, that training with cross-entropy
(CE) loss can be ${\it misaligned}$ with pass@N in that pass@N accuracy ${\it
decreases}$ with longer training. We explain the origins of this misalignment
in terms of model overconfidence induced by CE, and experimentally verify our
prediction of overconfidence as an impediment to scaling test-time compute via
pass@N. Furthermore we suggest a principled, modified training loss that is
better aligned to pass@N by limiting model confidence and rescuing pass@N test
performance. Our algorithm demonstrates improved mathematical reasoning on MATH
and MiniF2F benchmarks under several scenarios: (1) providing answers to math
questions; and (2) proving theorems by searching over proof trees of varying
shapes. Overall our work underscores the importance of co-designing two
traditionally separate phases of LLM development: training-time protocols and
test-time search and reasoning strategies.",http://arxiv.org/abs/2502.07154v1,Recommendation System,"test, time, training, compute, performance"
Feature Importance Depends on Properties of the Data: Towards Choosing the Correct Explanations for Your Data and Decision Trees based Models,"In order to ensure the reliability of the explanations of machine learning
models, it is crucial to establish their advantages and limits and in which
case each of these methods outperform. However, the current understanding of
when and how each method of explanation can be used is insufficient. To fill
this gap, we perform a comprehensive empirical evaluation by synthesizing
multiple datasets with the desired properties. Our main objective is to assess
the quality of feature importance estimates provided by local explanation
methods, which are used to explain predictions made by decision tree-based
models. By analyzing the results obtained from synthetic datasets as well as
publicly available binary classification datasets, we observe notable
disparities in the magnitude and sign of the feature importance estimates
generated by these methods. Moreover, we find that these estimates are
sensitive to specific properties present in the data. Although some model
hyper-parameters do not significantly influence feature importance assignment,
it is important to recognize that each method of explanation has limitations in
specific contexts. Our assessment highlights these limitations and provides
valuable insight into the suitability and reliability of different explanatory
methods in various scenarios.",http://arxiv.org/abs/2502.07153v1,Recommendation System,"methods, explanation, datasets, feature, importance"
Conditional Distribution Quantization in Machine Learning,"Conditional expectation \mathbb{E}(Y \mid X) often fails to capture the
complexity of multimodal conditional distributions \mathcal{L}(Y \mid X). To
address this, we propose using n-point conditional quantizations--functional
mappings of X that are learnable via gradient descent--to approximate
\mathcal{L}(Y \mid X). This approach adapts Competitive Learning Vector
Quantization (CLVQ), tailored for conditional distributions. It goes beyond
single-valued predictions by providing multiple representative points that
better reflect multimodal structures. It enables the approximation of the true
conditional law in the Wasserstein distance. The resulting framework is
theoretically grounded and useful for uncertainty quantification and multimodal
data generation tasks. For example, in computer vision inpainting tasks,
multiple plausible reconstructions may exist for the same partially observed
input image X. We demonstrate the effectiveness of our approach through
experiments on synthetic and real-world datasets.",http://arxiv.org/abs/2502.07151v1,Computer Vision,"conditional, x, multimodal, distributions, approach"
SHARP: Accelerating Language Model Inference by SHaring Adjacent layers with Recovery Parameters,"While Large language models (LLMs) have advanced natural language processing
tasks, their growing computational and memory demands make deployment on
resource-constrained devices like mobile phones increasingly challenging. In
this paper, we propose SHARP (SHaring Adjacent Layers with Recovery
Parameters), a novel approach to accelerate LLM inference by sharing parameters
across adjacent layers, thus reducing memory load overhead, while introducing
low-rank recovery parameters to maintain performance. Inspired by observations
that consecutive layers have similar outputs, SHARP employs a two-stage
recovery process: Single Layer Warmup (SLW), and Supervised Fine-Tuning (SFT).
The SLW stage aligns the outputs of the shared layers using L_2 loss, providing
a good initialization for the following SFT stage to further restore the model
performance. Extensive experiments demonstrate that SHARP can recover the
model's perplexity on various in-distribution tasks using no more than 50k
fine-tuning data while reducing the number of stored MLP parameters by 38% to
65%. We also conduct several ablation studies of SHARP and show that replacing
layers towards the later parts of the model yields better performance
retention, and that different recovery parameterizations perform similarly when
parameter counts are matched. Furthermore, SHARP saves 42.8% in model storage
and reduces the total inference time by 42.2% compared to the original
Llama2-7b model on mobile devices. Our results highlight SHARP as an efficient
solution for reducing inference costs in deploying LLMs without the need for
pretraining-scale resources.",http://arxiv.org/abs/2502.07832v1,Natural Language Processing,"sharp, layers, model, recovery, parameters"
Mesh2SSM++: A Probabilistic Framework for Unsupervised Learning of Statistical Shape Model of Anatomies from Surface Meshes,"Anatomy evaluation is crucial for understanding the physiological state,
diagnosing abnormalities, and guiding medical interventions. Statistical shape
modeling (SSM) is vital in this process. By enabling the extraction of
quantitative morphological shape descriptors from MRI and CT scans, SSM
provides comprehensive descriptions of anatomical variations within a
population. However, the effectiveness of SSM in anatomy evaluation hinges on
the quality and robustness of the shape models. While deep learning techniques
show promise in addressing these challenges by learning complex nonlinear
representations of shapes, existing models still have limitations and often
require pre-established shape models for training. To overcome these issues, we
propose Mesh2SSM++, a novel approach that learns to estimate correspondences
from meshes in an unsupervised manner. This method leverages unsupervised,
permutation-invariant representation learning to estimate how to deform a
template point cloud into subject-specific meshes, forming a
correspondence-based shape model. Additionally, our probabilistic formulation
allows learning a population-specific template, reducing potential biases
associated with template selection. A key feature of Mesh2SSM++ is its ability
to quantify aleatoric uncertainty, which captures inherent data variability and
is essential for ensuring reliable model predictions and robust decision-making
in clinical tasks, especially under challenging imaging conditions. Through
extensive validation across diverse anatomies, evaluation metrics, and
downstream tasks, we demonstrate that Mesh2SSM++ outperforms existing methods.
Its ability to operate directly on meshes, combined with computational
efficiency and interpretability through its probabilistic framework, makes it
an attractive alternative to traditional and deep learning-based SSM
approaches.",http://arxiv.org/abs/2502.07145v1,Recommendation System,"shape, learning, ssm, evaluation, models"
Small steps no more: Global convergence of stochastic gradient bandits for arbitrary learning rates,"We provide a new understanding of the stochastic gradient bandit algorithm by
showing that it converges to a globally optimal policy almost surely using
\emph{any} constant learning rate. This result demonstrates that the stochastic
gradient algorithm continues to balance exploration and exploitation
appropriately even in scenarios where standard smoothness and noise control
assumptions break down. The proofs are based on novel findings about action
sampling rates and the relationship between cumulative progress and noise, and
extend the current understanding of how simple stochastic gradient methods
behave in bandit settings.",http://arxiv.org/abs/2502.07141v1,Recommendation System,"stochastic, gradient, understanding, bandit, algorithm"
Captured by Captions: On Memorization and its Mitigation in CLIP Models,"Multi-modal models, such as CLIP, have demonstrated strong performance in
aligning visual and textual representations, excelling in tasks like image
retrieval and zero-shot classification. Despite this success, the mechanisms by
which these models utilize training data, particularly the role of
memorization, remain unclear. In uni-modal models, both supervised and
self-supervised, memorization has been shown to be essential for
generalization. However, it is not well understood how these findings would
apply to CLIP, which incorporates elements from both supervised learning via
captions that provide a supervisory signal similar to labels, and from
self-supervised learning via the contrastive objective. To bridge this gap in
understanding, we propose a formal definition of memorization in CLIP (CLIPMem)
and use it to quantify memorization in CLIP models. Our results indicate that
CLIP's memorization behavior falls between the supervised and self-supervised
paradigms, with ""mis-captioned"" samples exhibiting highest levels of
memorization. Additionally, we find that the text encoder contributes more to
memorization than the image encoder, suggesting that mitigation strategies
should focus on the text domain. Building on these insights, we propose
multiple strategies to reduce memorization while at the same time improving
utility--something that had not been shown before for traditional learning
paradigms where reducing memorization typically results in utility decrease.",http://arxiv.org/abs/2502.07830v1,Recommendation System,"memorization, supervised, clip, models, self"
Few-Shot Multi-Human Neural Rendering Using Geometry Constraints,"We present a method for recovering the shape and radiance of a scene
consisting of multiple people given solely a few images. Multi-human scenes are
complex due to additional occlusion and clutter. For single-human settings,
existing approaches using implicit neural representations have achieved
impressive results that deliver accurate geometry and appearance. However, it
remains challenging to extend these methods for estimating multiple humans from
sparse views. We propose a neural implicit reconstruction method that addresses
the inherent challenges of this task through the following contributions:
First, we propose to use geometry constraints by exploiting pre-computed meshes
using a human body model (SMPL). Specifically, we regularize the signed
distances using the SMPL mesh and leverage bounding boxes for improved
rendering. Second, we propose a ray regularization scheme to minimize rendering
inconsistencies, and a saturation regularization for robust optimization in
variable illumination. Extensive experiments on both real and synthetic
datasets demonstrate the benefits of our approach and show state-of-the-art
performance against existing neural reconstruction methods.",http://arxiv.org/abs/2502.07140v1,Recommendation System,"human, neural, propose, method, multiple"
Language-TPP: Integrating Temporal Point Processes with Language Models for Event Analysis,"Temporal Point Processes (TPPs) have been widely used for event sequence
modeling, but they often struggle to incorporate rich textual event
descriptions effectively. Conversely, while Large Language Models (LLMs) have
been shown remarkable capabilities in processing textual data, they lack
mechanisms for handling temporal dynamics. To bridge this gap, we introduce
Language-TPP, a unified framework that integrates TPPs with LLMs for enhanced
event sequence modeling. Language-TPP introduces a novel temporal encoding
mechanism that converts continuous time intervals into specialized byte-tokens,
enabling seamless integration with standard LLM architectures. This approach
allows Language-TPP to achieve state-of-the-art performance across multiple TPP
tasks, including event time prediction, type prediction, and intensity
estimation, on five datasets. Additionally, we demonstrate that incorporating
temporal information significantly improves the quality of generated event
descriptions.",http://arxiv.org/abs/2502.07139v1,Recommendation System,"event, temporal, language, tpp, tpps"
Towards a Robust Framework for Multimodal Hate Detection: A Study on Video vs. Image-based Content,"Social media platforms enable the propagation of hateful content across
different modalities such as textual, auditory, and visual, necessitating
effective detection methods. While recent approaches have shown promise in
handling individual modalities, their effectiveness across different modality
combinations remains unexplored. This paper presents a systematic analysis of
fusion-based approaches for multimodal hate detection, focusing on their
performance across video and image-based content. Our comprehensive evaluation
reveals significant modality-specific limitations: while simple embedding
fusion achieves state-of-the-art performance on video content (HateMM dataset)
with a 9.9% points F1-score improvement, it struggles with complex image-text
relationships in memes (Hateful Memes dataset). Through detailed ablation
studies and error analysis, we demonstrate how current fusion approaches fail
to capture nuanced cross-modal interactions, particularly in cases involving
benign confounders. Our findings provide crucial insights for developing more
robust hate detection systems and highlight the need for modality-specific
architectural considerations. The code is available at
https://github.com/gak97/Video-vs-Meme-Hate.",http://arxiv.org/abs/2502.07138v1,Recommendation System,"content, detection, approaches, modality, fusion"
One-Shot Learning for k-SAT,"Consider a $k$-SAT formula $\Phi$ where every variable appears at most $d$
times, and let $\sigma$ be a satisfying assignment of $\Phi$ sampled
proportionally to $e^{\beta m(\sigma)}$ where $m(\sigma)$ is the number of
variables set to true and $\beta$ is a real parameter. Given $\Phi$ and
$\sigma$, can we learn the value of $\beta$ efficiently?
  This problem falls into a recent line of works about single-sample
(""one-shot"") learning of Markov random fields. The $k$-SAT setting we consider
here was recently studied by Galanis, Kandiros, and Kalavasis (SODA'24) where
they showed that single-sample learning is possible when roughly $d\leq
2^{k/6.45}$ and impossible when $d\geq (k+1) 2^{k-1}$. Crucially, for their
impossibility results they used the existence of unsatisfiable instances which,
aside from the gap in $d$, left open the question of whether the feasibility
threshold for one-shot learning is dictated by the satisfiability threshold of
$k$-SAT formulas of bounded degree.
  Our main contribution is to answer this question negatively. We show that
one-shot learning for $k$-SAT is infeasible well below the satisfiability
threshold; in fact, we obtain impossibility results for degrees $d$ as low as
$k^2$ when $\beta$ is sufficiently large, and bootstrap this to small values of
$\beta$ when $d$ scales exponentially with $k$, via a probabilistic
construction. On the positive side, we simplify the analysis of the learning
algorithm and obtain significantly stronger bounds on $d$ in terms of $\beta$.
In particular, for the uniform case $\beta\rightarrow 0$ that has been studied
extensively in the sampling literature, our analysis shows that learning is
possible under the condition $d\lesssim 2^{k/2}$. This is nearly optimal (up to
constant factors) in the sense that it is known that sampling a
uniformly-distributed satisfying assignment is NP-hard for $d\gtrsim 2^{k/2}$.",http://arxiv.org/abs/2502.07135v1,Reinforcement Learning,"learning, shot, threshold, consider, satisfying"
Interactive Data Harmonization with LLM Agents,"Data harmonization is an essential task that entails integrating datasets
from diverse sources. Despite years of research in this area, it remains a
time-consuming and challenging task due to schema mismatches, varying
terminologies, and differences in data collection methodologies. This paper
presents the case for agentic data harmonization as a means to both empower
experts to harmonize their data and to streamline the process. We introduce
Harmonia, a system that combines LLM-based reasoning, an interactive user
interface, and a library of data harmonization primitives to automate the
synthesis of data harmonization pipelines. We demonstrate Harmonia in a
clinical data harmonization scenario, where it helps to interactively create
reusable pipelines that map datasets to a standard format. Finally, we discuss
challenges and open problems, and suggest research directions for advancing our
vision.",http://arxiv.org/abs/2502.07132v1,Recommendation System,"data, harmonization, task, datasets, research"
Unconstrained Body Recognition at Altitude and Range: Comparing Four Approaches,"This study presents an investigation of four distinct approaches to long-term
person identification using body shape. Unlike short-term re-identification
systems that rely on temporary features (e.g., clothing), we focus on learning
persistent body shape characteristics that remain stable over time. We
introduce a body identification model based on a Vision Transformer (ViT) (Body
Identification from Diverse Datasets, BIDDS) and on a Swin-ViT model
(Swin-BIDDS). We also expand on previous approaches based on the Linguistic and
Non-linguistic Core ResNet Identity Models (LCRIM and NLCRIM), but with
improved training. All models are trained on a large and diverse dataset of
over 1.9 million images of approximately 5k identities across 9 databases.
Performance was evaluated on standard re-identification benchmark datasets
(MARS, MSMT17, Outdoor Gait, DeepChange) and on an unconstrained dataset that
includes images at a distance (from close-range to 1000m), at altitude (from an
unmanned aerial vehicle, UAV), and with clothing change. A comparative analysis
across these models provides insights into how different backbone architectures
and input image sizes impact long-term body identification performance across
real-world conditions.",http://arxiv.org/abs/2502.07130v1,Recommendation System,"identification, body, term, models, approaches"
Fourier-enhanced Neural Networks For Systems Biology Applications,"In the field of systems biology, differential equations are commonly used to
model biological systems, but solving them for large-scale and complex systems
can be computationally expensive. Recently, the integration of machine learning
and mathematical modeling has offered new opportunities for scientific
discoveries in biology and health. The emerging physics-informed neural network
(PINN) has been proposed as a solution to this problem. However, PINN can be
computationally expensive and unreliable for complex biological systems. To
address these issues, we propose the Fourier-enhanced Neural Networks for
systems biology (SB-FNN). SB-FNN uses an embedded Fourier neural network with
an adaptive activation function and a cyclic penalty function to optimize the
prediction of biological dynamics, particularly for biological systems that
exhibit oscillatory patterns. Experimental results demonstrate that SB-FNN
achieves better performance and is more efficient than PINN for handling
complex biological models. Experimental results on cellular and population
models demonstrate that SB-FNN outperforms PINN in both accuracy and
efficiency, making it a promising alternative approach for handling complex
biological models. The proposed method achieved better performance on six
biological models and is expected to replace PINN as the most advanced method
in systems biology.",http://arxiv.org/abs/2502.07129v1,Recommendation System,"systems, biological, pinn, biology, complex"
Cardiverse: Harnessing LLMs for Novel Card Game Prototyping,"The prototyping of computer games, particularly card games, requires
extensive human effort in creative ideation and gameplay evaluation. Recent
advances in Large Language Models (LLMs) offer opportunities to automate and
streamline these processes. However, it remains challenging for LLMs to design
novel game mechanics beyond existing databases, generate consistent gameplay
environments, and develop scalable gameplay AI for large-scale evaluations.
This paper addresses these challenges by introducing a comprehensive automated
card game prototyping framework. The approach highlights a graph-based indexing
method for generating novel game designs, an LLM-driven system for consistent
game code generation validated by gameplay records, and a gameplay AI
constructing method that uses an ensemble of LLM-generated action-value
functions optimized through self-play. These contributions aim to accelerate
card game prototyping, reduce human labor, and lower barriers to entry for game
developers.",http://arxiv.org/abs/2502.07128v1,Recommendation System,"game, gameplay, prototyping, card, games"
Is Long Range Sequential Modeling Necessary For Colorectal Tumor Segmentation?,"Segmentation of colorectal cancer (CRC) tumors in 3D medical imaging is both
complex and clinically critical, providing vital support for effective
radiation therapy planning and survival outcome assessment. Recently, 3D
volumetric segmentation architectures incorporating long-range sequence
modeling mechanisms, such as Transformers and Mamba, have gained attention for
their capacity to achieve high accuracy in 3D medical image segmentation. In
this work, we evaluate the effectiveness of these global token modeling
techniques by pitting them against our proposed MambaOutUNet within the context
of our newly introduced colorectal tumor segmentation dataset (CTS-204). Our
findings suggest that robust local token interactions can outperform long-range
modeling techniques in cases where the region of interest is small and
anatomically complex, proposing a potential shift in 3D tumor segmentation
research.",http://arxiv.org/abs/2502.07120v1,Recommendation System,"segmentation, modeling, colorectal, medical, complex"
SAFE: Self-Supervised Anomaly Detection Framework for Intrusion Detection,"The proliferation of IoT devices has significantly increased network
vulnerabilities, creating an urgent need for effective Intrusion Detection
Systems (IDS). Machine Learning-based IDS (ML-IDS) offer advanced detection
capabilities but rely on labeled attack data, which limits their ability to
identify unknown threats. Self-Supervised Learning (SSL) presents a promising
solution by using only normal data to detect patterns and anomalies. This paper
introduces SAFE, a novel framework that transforms tabular network intrusion
data into an image-like format, enabling Masked Autoencoders (MAEs) to learn
robust representations of network behavior. The features extracted by the MAEs
are then incorporated into a lightweight novelty detector, enhancing the
effectiveness of anomaly detection. Experimental results demonstrate that SAFE
outperforms the state-of-the-art anomaly detection method, Scale Learning-based
Deep Anomaly Detection method (SLAD), by up to 26.2% and surpasses the
state-of-the-art SSL-based network intrusion detection approach, Anomal-E, by
up to 23.5% in F1-score.",http://arxiv.org/abs/2502.07119v1,Recommendation System,"detection, network, intrusion, ids, learning"
Choroidal image analysis for OCT image sequences with applications in systemic health,"The choroid, a highly vascular layer behind the retina, is an extension of
the central nervous system and has parallels with the renal cortex, with blood
flow far exceeding that of the brain and kidney. Thus, there has been growing
interest of choroidal blood flow reflecting physiological status of systemic
disease. Optical coherence tomography (OCT) enables high-resolution imaging of
the choroid, but conventional analysis methods remain manual or semi-automatic,
limiting reproducibility, standardisation and clinical utility. In this thesis,
I develop several new methods to analyse the choroid in OCT image sequences,
with each successive method improving on its predecessors. I first develop two
semi-automatic approaches for choroid region (Gaussian Process Edge Tracing,
GPET) and vessel (Multi-scale Median Cut Quantisation, MMCQ) analysis, which
improve on manual approaches but remain user-dependent. To address this, I
introduce DeepGPET, a deep learning-based region segmentation method which
improves on execution time, reproducibility, and end-user accessibility, but
lacks choroid vessel analysis and automatic feature measurement. Improving on
this, I developed Choroidalyzer, a deep learning-based pipeline to segment the
choroidal space and vessels and generate fully automatic, clinically meaningful
and reproducible choroidal features. I provide rigorous evaluation of these
four approaches and consider their potential clinical value in three
applications into systemic health: OCTANE, assessing choroidal changes in renal
transplant recipients and donors; PREVENT, exploring choroidal associations
with Alzheimer's risk factors at mid-life; D-RISCii, assessing choroidal
variation and feasibility of OCT in critical care. In short, this thesis
contributes many open-source tools for standardised choroidal measurement and
highlights the choroid's potential as a biomarker in systemic health.",http://arxiv.org/abs/2502.07117v1,Reinforcement Learning,"choroidal, choroid, automatic, systemic, oct"
Online Scheduling for LLM Inference with KV Cache Constraints,"Large Language Model (LLM) inference, where a trained model generates text
one word at a time in response to user prompts, is a computationally intensive
process requiring efficient scheduling to optimize latency and resource
utilization. A key challenge in LLM inference is the management of the
Key-Value (KV) cache, which reduces redundant computations but introduces
memory constraints. In this work, we model LLM inference with KV cache
constraints theoretically and propose novel batching and scheduling algorithms
that minimize inference latency while effectively managing the KV cache's
memory.
  We analyze both semi-online and fully online scheduling models, and our
results are threefold. First, we provide a polynomial-time algorithm that
achieves exact optimality in terms of average latency in the semi-online prompt
arrival model. Second, in the fully online case with a stochastic prompt
arrival, we introduce an efficient online scheduling algorithm with constant
regret. Third, we prove that no algorithm (deterministic or randomized) can
achieve a constant competitive ratio in fully online adversarial settings. Our
empirical evaluations on a public LLM inference dataset, using the Llama-70B
model on A100 GPUs, show that our approach significantly outperforms benchmark
algorithms used currently in practice, achieving lower latency while reducing
energy consumption. Overall, our results offer a path toward more sustainable
and cost-effective LLM deployment.",http://arxiv.org/abs/2502.07115v1,Natural Language Processing,"online, model, llm, inference, scheduling"
Online Covariance Matrix Estimation in Sketched Newton Methods,"Given the ubiquity of streaming data, online algorithms have been widely used
for parameter estimation, with second-order methods particularly standing out
for their efficiency and robustness. In this paper, we study an online sketched
Newton method that leverages a randomized sketching technique to perform an
approximate Newton step in each iteration, thereby eliminating the
computational bottleneck of second-order methods. While existing studies have
established the asymptotic normality of sketched Newton methods, a consistent
estimator of the limiting covariance matrix remains an open problem. We propose
a fully online covariance matrix estimator that is constructed entirely from
the Newton iterates and requires no matrix factorization. Compared to
covariance estimators for first-order online methods, our estimator for
second-order methods is batch-free. We establish the consistency and
convergence rate of our estimator, and coupled with asymptotic normality
results, we can then perform online statistical inference for the model
parameters based on sketched Newton methods. We also discuss the extension of
our estimator to constrained problems, and demonstrate its superior performance
on regression problems as well as benchmark problems in the CUTEst set.",http://arxiv.org/abs/2502.07114v1,Recommendation System,"methods, online, newton, estimator, order"
Likelihood-Free Estimation for Spatiotemporal Hawkes processes with missing data and application to predictive policing,"With the growing use of AI technology, many police departments use
forecasting software to predict probable crime hotspots and allocate patrolling
resources effectively for crime prevention. The clustered nature of crime data
makes self-exciting Hawkes processes a popular modeling choice. However, one
significant challenge in fitting such models is the inherent missingness in
crime data due to non-reporting, which can bias the estimated parameters of the
predictive model, leading to inaccurate downstream hotspot forecasts, often
resulting in over or under-policing in various communities, especially the
vulnerable ones. Our work introduces a Wasserstein Generative Adversarial
Networks (WGAN) driven likelihood-free approach to account for unreported
crimes in Spatiotemporal Hawkes models. We demonstrate through empirical
analysis how this methodology improves the accuracy of parametric estimation in
the presence of data missingness, leading to more reliable and efficient
policing strategies.",http://arxiv.org/abs/2502.07111v1,Reinforcement Learning,"crime, data, use, hawkes, models"
Game of Coding With an Unknown Adversary,"Motivated by emerging decentralized applications, the \emph{game of coding}
framework has been recently introduced to address scenarios where the
adversary's control over coded symbols surpasses the fundamental limits of
traditional coding theory. Still, the reward mechanism available in
decentralized systems, motivates the adversary to act rationally. While the
decoder, as the data collector (DC), has an acceptance and rejection mechanism,
followed by an estimation module, the adversary aims to maximize its utility,
as an increasing function of (1) the chance of acceptance (to increase the
reward), and (2) estimation error. On the other hand, the decoder also adjusts
its acceptance rule to maximize its own utility, as (1) an increasing function
of the chance of acceptance (to keep the system functional), (2) decreasing
function of the estimation error. Prior works within this framework rely on the
assumption that the game is complete, that is, both the DC and the adversary
are fully aware of each other's utility functions. However, in practice, the
decoder is often unaware of the utility of the adversary. To address this
limitation, we develop an algorithm enabling the DC to commit to a strategy
that achieves within the vicinity of the equilibrium, without knowledge of the
adversary's utility function. Our approach builds on an observation that at the
equilibrium, the relationship between the probability of acceptance and the
mean squared error (MSE) follows a predetermined curve independent of the
specific utility functions of the players. By exploiting this invariant
relationship, the DC can iteratively refine its strategy based on observable
parameters, converging to a near-optimal solution. We provide theoretical
guarantees on sample complexity and accuracy of the proposed scheme.",http://arxiv.org/abs/2502.07109v1,Recommendation System,"adversary, utility, acceptance, dc, function"
A Framework for Supervised and Unsupervised Segmentation and Classification of Materials Microstructure Images,"Microstructure of materials is often characterized through image analysis to
understand processing-structure-properties linkages. We propose a largely
automated framework that integrates unsupervised and supervised learning
methods to classify micrographs according to microstructure phase/class and,
for multiphase microstructures, segments them into different homogeneous
regions. With the advance of manufacturing and imaging techniques, the
ultra-high resolution of imaging that reveals the complexity of microstructures
and the rapidly increasing quantity of images (i.e., micrographs) enables and
necessitates a more powerful and automated framework to extract materials
characteristics and knowledge. The framework we propose can be used to
gradually build a database of microstructure classes relevant to a particular
process or group of materials, which can help in analyzing and
discovering/identifying new materials. The framework has three steps: (1)
segmentation of multiphase micrographs through a recently developed score-based
method so that different microstructure homogeneous regions can be identified
in an unsupervised manner; (2) {identification and classification of}
homogeneous regions of micrographs through an uncertainty-aware supervised
classification network trained using the segmented micrographs from Step $1$
with their identified labels verified via the built-in uncertainty
quantification and minimal human inspection; (3) supervised segmentation (more
powerful than the segmentation in Step $1$) of multiphase microstructures
through a segmentation network trained with micrographs and the results from
Steps $1$-$2$ using a form of data augmentation. This framework can iteratively
characterize/segment new homogeneous or multiphase materials while expanding
the database to enhance performance. The framework is demonstrated on various
sets of materials and texture images.",http://arxiv.org/abs/2502.07107v1,Recommendation System,"materials, framework, micrographs, microstructure, multiphase"
Lotus: Creating Short Videos From Long Videos With Abstractive and Extractive Summarization,"Short-form videos are popular on platforms like TikTok and Instagram as they
quickly capture viewers' attention. Many creators repurpose their long-form
videos to produce short-form videos, but creators report that planning,
extracting, and arranging clips from long-form videos is challenging.
Currently, creators make extractive short-form videos composed of existing
long-form video clips or abstractive short-form videos by adding newly recorded
narration to visuals. While extractive videos maintain the original connection
between audio and visuals, abstractive videos offer flexibility in selecting
content to be included in a shorter time. We present Lotus, a system that
combines both approaches to balance preserving the original content with
flexibility over the content. Lotus first creates an abstractive short-form
video by generating both a short-form script and its corresponding speech, then
matching long-form video clips to the generated narration. Creators can then
add extractive clips with an automated method or Lotus's editing interface.
Lotus's interface can be used to further refine the short-form video. We
compare short-form videos generated by Lotus with those using an extractive
baseline method. In our user study, we compare creating short-form videos using
Lotus to participants' existing practice.",http://arxiv.org/abs/2502.07096v1,Recommendation System,"form, videos, short, lotus, creators"
Generative Distribution Prediction: A Unified Approach to Multimodal Learning,"Accurate prediction with multimodal data-encompassing tabular, textual, and
visual inputs or outputs-is fundamental to advancing analytics in diverse
application domains. Traditional approaches often struggle to integrate
heterogeneous data types while maintaining high predictive accuracy. We
introduce Generative Distribution Prediction (GDP), a novel framework that
leverages multimodal synthetic data generation-such as conditional diffusion
models-to enhance predictive performance across structured and unstructured
modalities. GDP is model-agnostic, compatible with any high-fidelity generative
model, and supports transfer learning for domain adaptation. We establish a
rigorous theoretical foundation for GDP, providing statistical guarantees on
its predictive accuracy when using diffusion models as the generative backbone.
By estimating the data-generating distribution and adapting to various loss
functions for risk minimization, GDP enables accurate point predictions across
multimodal settings. We empirically validate GDP on four supervised learning
tasks-tabular data prediction, question answering, image captioning, and
adaptive quantile regression-demonstrating its versatility and effectiveness
across diverse domains.",http://arxiv.org/abs/2502.07090v1,Recommendation System,"data, gdp, prediction, multimodal, predictive"
Evaluating the Systematic Reasoning Abilities of Large Language Models through Graph Coloring,"Contemporary large language models are powerful problem-solving tools, but
they exhibit weaknesses in their reasoning abilities which ongoing research
seeks to mitigate. We investigate graph coloring as a means of evaluating an
LLM's capacities for systematic step-by-step reasoning and possibility space
exploration, as well as effects of semantic problem framing. We test Claude 3.5
Sonnet, Llama 3.1 405B, Gemini 1.5 Pro, GPT-4o, o1-mini, and DeepSeek-R1 on a
dataset of $k$-coloring problems with $2 \leq k \leq 4$ and vertex count $4
\leq n \leq 8$, using partial algorithmic solvers to further categorize
problems by difficulty. In addition to substantial but varying framing effects,
we find that all models except o1-mini and R1 exhibit $>60\%$ error rates on
difficult problem types in all frames ($>15\%$ for o1-mini and $>10\%$ for R1),
and no model achieves perfect accuracy even in the simple domain of 2-coloring
4-vertex graphs. Our results highlight both the considerable recent progress in
LLM systematic reasoning and the limits of its reliability, especially in
relation to increasing computational costs. We expect that more complex graph
coloring problems, and procedural generation of arbitrary-complexity reasoning
problems more broadly, offer further untapped potential for LLM benchmarking.",http://arxiv.org/abs/2502.07087v1,Recommendation System,"reasoning, problems, problem, coloring, llm"
Fast Clustering of Categorical Big Data,"The K-Modes algorithm, developed for clustering categorical data, is of high
algorithmic simplicity but suffers from unreliable performances in clustering
quality and clustering efficiency, both heavily influenced by the choice of
initial cluster centers. In this paper, we investigate Bisecting K-Modes
(BK-Modes), a successive bisecting process to find clusters, in examining how
good the cluster centers out of the bisecting process will be when used as
initial centers for the K-Modes. The BK-Modes works by splitting a dataset into
multiple clusters iteratively with one cluster being chosen and bisected into
two clusters in each iteration. We use the sum of distances of data to their
cluster centers as the selection metric to choose a cluster to be bisected in
each iteration. This iterative process stops when K clusters are produced. The
centers of these K clusters are then used as the initial cluster centers for
the K-Modes. Experimental studies of the BK-Modes were carried out and were
compared against the K-Modes with multiple sets of initial cluster centers as
well as the best of the existing methods we found so far in our survey.
Experimental results indicated good performances of BK-Modes both in the
clustering quality and efficiency for large datasets.",http://arxiv.org/abs/2502.07081v1,Recommendation System,"modes, k, cluster, centers, clusters"
IRepair: An Intent-Aware Approach to Repair Data-Driven Errors in Large Language Models,"Not a day goes by without hearing about the impressive feats of large
language models (LLMs), and equally, not a day passes without hearing about
their challenges. LLMs are notoriously vulnerable to biases in their dataset,
leading to issues such as toxicity. While domain-adaptive training has been
employed to mitigate these issues, these techniques often address all model
parameters indiscriminately during the repair process, resulting in poor repair
quality and reduced model versatility. In this paper, we introduce a novel
dynamic slicing-based intent-aware LLM repair strategy, IRepair. This approach
selectively targets the most error-prone sections of the model for repair.
Specifically, we propose dynamically slicing the model's most sensitive layers
that require immediate attention, concentrating repair efforts on those areas.
This method enables more effective repairs with potentially less impact on the
model's overall performance by altering a smaller portion of the model. We
evaluated our technique on three models from the GPT2 and GPT-Neo families,
with parameters ranging from 800M to 1.6B, in a toxicity mitigation setup. Our
results show that IRepair repairs errors 43.6% more effectively while causing
46% less disruption to general performance compared to the closest baseline,
direct preference optimization. Our empirical analysis also reveals that errors
are more concentrated in a smaller section of the model, with the top 20% of
layers exhibiting 773% more error density than the remaining 80\%. This
highlights the need for selective repair. Additionally, we demonstrate that a
dynamic selection approach is essential for addressing errors dispersed
throughout the model, ensuring a robust and efficient repair.",http://arxiv.org/abs/2502.07072v2,Reinforcement Learning,"model, repair, errors, day, hearing"
Contextual Thompson Sampling via Generation of Missing Data,"We introduce a framework for Thompson sampling contextual bandit algorithms,
in which the algorithm's ability to quantify uncertainty and make decisions
depends on the quality of a generative model that is learned offline. Instead
of viewing uncertainty in the environment as arising from unobservable latent
parameters, our algorithm treats uncertainty as stemming from missing, but
potentially observable, future outcomes. If these future outcomes were all
observed, one could simply make decisions using an ""oracle"" policy fit on the
complete dataset. Inspired by this conceptualization, at each decision-time,
our algorithm uses a generative model to probabilistically impute missing
future outcomes, fits a policy using the imputed complete dataset, and uses
that policy to select the next action. We formally show that this algorithm is
a generative formulation of Thompson Sampling and prove a state-of-the-art
regret bound for it. Notably, our regret bound i) depends on the probabilistic
generative model only through the quality of its offline prediction loss, and
ii) applies to any method of fitting the ""oracle"" policy, which easily allows
one to adapt Thompson sampling to decision-making settings with fairness and/or
resource constraints.",http://arxiv.org/abs/2502.07064v1,Recommendation System,"algorithm, generative, policy, thompson, sampling"
"Federated Continual Learning: Concepts, Challenges, and Solutions","Federated Continual Learning (FCL) has emerged as a robust solution for
collaborative model training in dynamic environments, where data samples are
continuously generated and distributed across multiple devices. This survey
provides a comprehensive review of FCL, focusing on key challenges such as
heterogeneity, model stability, communication overhead, and privacy
preservation. We explore various forms of heterogeneity and their impact on
model performance. Solutions to non-IID data, resource-constrained platforms,
and personalized learning are reviewed in an effort to show the complexities of
handling heterogeneous data distributions. Next, we review techniques for
ensuring model stability and avoiding catastrophic forgetting, which are
critical in non-stationary environments. Privacy-preserving techniques are
another aspect of FCL that have been reviewed in this work. This survey has
integrated insights from federated learning and continual learning to present
strategies for improving the efficacy and scalability of FCL systems, making it
applicable to a wide range of real-world scenarios.",http://arxiv.org/abs/2502.07059v1,Recommendation System,"learning, fcl, model, data, federated"
Autonomous Deep Agent,"This technical brief introduces Deep Agent, an advanced autonomous AI system
designed to manage complex multi-phase tasks through a novel hierarchical task
management architecture. The system's foundation is built on our Hierarchical
Task DAG (HTDAG) framework, which dynamically decomposes high-level objectives
into manageable sub-tasks while rigorously maintaining dependencies and
execution coherence. Deep Agent advances beyond traditional agent systems
through three key innovations: First, it implements a recursive two-stage
planner-executor architecture that enables continuous task refinement and
adaptation as circumstances change. Second, it features an Autonomous API &
Tool Creation (AATC) system that automatically generates reusable components
from UI interactions, substantially reducing operational costs for similar
tasks. Third, it incorporates Prompt Tweaking Engine and Autonomous Prompt
Feedback Learning components that optimize Large Language Model prompts for
specific scenarios, enhancing both inference accuracy and operational
stability. These components are integrated to form a service infrastructure
that manages user contexts, handles complex task dependencies, and orchestrates
end-to-end agentic workflow execution. Through this sophisticated architecture,
Deep Agent establishes a novel paradigm in self-governing AI systems,
demonstrating robust capability to independently handle intricate, multi-step
tasks while maintaining consistent efficiency and reliability through
continuous self-optimization.",http://arxiv.org/abs/2502.07056v1,Reinforcement Learning,"agent, tasks, task, deep, autonomous"
Large Language Models in Software Security: A Survey of Vulnerability Detection Techniques and Insights,"Large Language Models (LLMs) are emerging as transformative tools for
software vulnerability detection, addressing critical challenges in the
security domain. Traditional methods, such as static and dynamic analysis,
often falter due to inefficiencies, high false positive rates, and the growing
complexity of modern software systems. By leveraging their ability to analyze
code structures, identify patterns, and generate repair sugges- tions, LLMs,
exemplified by models like GPT, BERT, and CodeBERT, present a novel and
scalable approach to mitigating vulnerabilities. This paper provides a detailed
survey of LLMs in vulnerability detection. It examines key aspects, including
model architectures, application methods, target languages, fine-tuning
strategies, datasets, and evaluation metrics. We also analyze the scope of
current research problems, highlighting the strengths and weaknesses of
existing approaches. Further, we address challenges such as cross-language
vulnerability detection, multimodal data integration, and repository-level
analysis. Based on these findings, we propose solutions for issues like dataset
scalability, model interpretability, and applications in low-resource
scenarios. Our contributions are threefold: (1) a systematic review of how LLMs
are applied in vulnerability detection; (2) an analysis of shared patterns and
differences across studies, with a unified framework for understanding the
field; and (3) a summary of key challenges and future research directions. This
work provides valuable insights for advancing LLM-based vulnerability
detection. We also maintain and regularly update latest selected paper on
https://github.com/OwenSanzas/LLM-For-Vulnerability-Detection",http://arxiv.org/abs/2502.07049v1,Recommendation System,"vulnerability, detection, llms, challenges, analysis"
SnipGen: A Mining Repository Framework for Evaluating LLMs for Code,"Language Models (LLMs), such as transformer-based neural networks trained on
billions of parameters, have become increasingly prevalent in software
engineering (SE). These models, trained on extensive datasets that include code
repositories, exhibit remarkable capabilities for SE tasks. However, evaluating
their effectiveness poses significant challenges, primarily due to the
potential overlap between the datasets used for training and those employed for
evaluation. To address this issue, we introduce SnipGen, a comprehensive
repository mining framework designed to leverage prompt engineering across
various downstream tasks for code generation. SnipGen aims to mitigate data
contamination by generating robust testbeds and crafting tailored data points
to assist researchers and practitioners in evaluating LLMs for code-related
tasks. In our exploratory study, SnipGen mined approximately 227K data points
from 338K recent code changes in GitHub commits, focusing on method-level
granularity. SnipGen features a collection of prompt templates that can be
combined to create a Chain-of-Thought-like sequence of prompts, enabling a
nuanced assessment of LLMs' code generation quality. By providing the mining
tool, the methodology, and the dataset, SnipGen empowers researchers and
practitioners to rigorously evaluate and interpret LLMs' performance in
software engineering contexts.",http://arxiv.org/abs/2502.07046v1,Recommendation System,"code, snipgen, llms, engineering, tasks"
Scalable and Ethical Insider Threat Detection through Data Synthesis and Analysis by LLMs,"Insider threats wield an outsized influence on organizations,
disproportionate to their small numbers. This is due to the internal access
insiders have to systems, information, and infrastructure. %One example of this
influence is where anonymous respondents submit web-based job search site
reviews, an insider threat risk to organizations. Signals for such risks may be
found in anonymous submissions to public web-based job search site reviews.
This research studies the potential for large language models (LLMs) to analyze
and detect insider threat sentiment within job site reviews. Addressing ethical
data collection concerns, this research utilizes synthetic data generation
using LLMs alongside existing job review datasets. A comparative analysis of
sentiment scores generated by LLMs is benchmarked against expert human scoring.
Findings reveal that LLMs demonstrate alignment with human evaluations in most
cases, thus effectively identifying nuanced indicators of threat sentiment. The
performance is lower on human-generated data than synthetic data, suggesting
areas for improvement in evaluating real-world data. Text diversity analysis
found differences between human-generated and LLM-generated datasets, with
synthetic data exhibiting somewhat lower diversity. Overall, the results
demonstrate the applicability of LLMs to insider threat detection, and a
scalable solution for insider sentiment testing by overcoming ethical and
logistical barriers tied to data acquisition.",http://arxiv.org/abs/2502.07045v1,Natural Language Processing,"data, insider, llms, job, threat"
Boosting of Classification Models with Human-in-the-Loop Computational Visual Knowledge Discovery,"High-risk artificial intelligence and machine learning classification tasks,
such as healthcare diagnosis, require accurate and interpretable prediction
models. However, classifier algorithms typically sacrifice individual
case-accuracy for overall model accuracy, limiting analysis of class overlap
areas regardless of task significance. The Adaptive Boosting meta-algorithm,
which won the 2003 G\""odel Prize, analytically assigns higher weights to
misclassified cases to reclassify. However, it relies on weaker base
classifiers that are iteratively strengthened, limiting improvements from base
classifiers. Combining visual and computational approaches enables selecting
stronger base classifiers before boosting. This paper proposes moving boosting
methodology from focusing on only misclassified cases to all cases in the class
overlap areas using Computational and Interactive Visual Learning (CIVL) with a
Human-in-the-Loop. It builds classifiers in lossless visualizations integrating
human domain expertise and visual insights. A Divide and Classify process
splits cases to simple and complex, classifying these individually through
computational analysis and data visualization with lossless visualization
spaces of Parallel Coordinates or other General Line Coordinates. After finding
pure and overlap class areas simple cases in pure areas are classified,
generating interpretable sub-models like decision rules in Propositional and
First-order Logics. Only multidimensional cases in the overlap areas are
losslessly visualized simplifying end-user cognitive tasks to identify
difficult case patterns, including engineering features to form new
classifiable patterns. Demonstration shows a perfectly accurate and losslessly
interpretable model of the Iris dataset, and simulated data shows generalized
benefits to accuracy and interpretability of models, increasing end-user
confidence in discovered models.",http://arxiv.org/abs/2502.07039v1,Recommendation System,"cases, areas, models, overlap, classifiers"
Automated Consistency Analysis of LLMs,"Generative AI (Gen AI) with large language models (LLMs) are being widely
adopted across the industry, academia and government. Cybersecurity is one of
the key sectors where LLMs can be and/or are already being used. There are a
number of problems that inhibit the adoption of trustworthy Gen AI and LLMs in
cybersecurity and such other critical areas. One of the key challenge to the
trustworthiness and reliability of LLMs is: how consistent an LLM is in its
responses?
  In this paper, we have analyzed and developed a formal definition of
consistency of responses of LLMs. We have formally defined what is consistency
of responses and then develop a framework for consistency evaluation. The paper
proposes two approaches to validate consistency: self-validation, and
validation across multiple LLMs. We have carried out extensive experiments for
several LLMs such as GPT4oMini, GPT3.5, Gemini, Cohere, and Llama3, on a
security benchmark consisting of several cybersecurity questions: informational
and situational. Our experiments corroborate the fact that even though these
LLMs are being considered and/or already being used for several cybersecurity
tasks today, they are often inconsistent in their responses, and thus are
untrustworthy and unreliable for cybersecurity.",http://arxiv.org/abs/2502.07036v1,Recommendation System,"llms, cybersecurity, responses, consistency, ai"
PrismAvatar: Real-time animated 3D neural head avatars on edge devices,"We present PrismAvatar: a 3D head avatar model which is designed specifically
to enable real-time animation and rendering on resource-constrained edge
devices, while still enjoying the benefits of neural volumetric rendering at
training time. By integrating a rigged prism lattice with a 3D morphable head
model, we use a hybrid rendering model to simultaneously reconstruct a
mesh-based head and a deformable NeRF model for regions not represented by the
3DMM. We then distill the deformable NeRF into a rigged mesh and neural
textures, which can be animated and rendered efficiently within the constraints
of the traditional triangle rendering pipeline. In addition to running at 60
fps with low memory usage on mobile devices, we find that our trained models
have comparable quality to state-of-the-art 3D avatar models on desktop
devices.",http://arxiv.org/abs/2502.07030v1,Recommendation System,"model, rendering, head, devices, avatar"
Leveraging Allophony in Self-Supervised Speech Models for Atypical Pronunciation Assessment,"Allophony refers to the variation in the phonetic realization of a phoneme
based on its phonetic environment. Modeling allophones is crucial for atypical
pronunciation assessment, which involves distinguishing atypical from typical
pronunciations. However, recent phoneme classifier-based approaches often
simplify this by treating various realizations as a single phoneme, bypassing
the complexity of modeling allophonic variation. Motivated by the acoustic
modeling capabilities of frozen self-supervised speech model (S3M) features, we
propose MixGoP, a novel approach that leverages Gaussian mixture models to
model phoneme distributions with multiple subclusters. Our experiments show
that MixGoP achieves state-of-the-art performance across four out of five
datasets, including dysarthric and non-native speech. Our analysis further
suggests that S3M features capture allophonic variation more effectively than
MFCCs and Mel spectrograms, highlighting the benefits of integrating MixGoP
with S3M features.",http://arxiv.org/abs/2502.07029v1,Recommendation System,"phoneme, variation, modeling, m, features"
Machine Learning for Everyone: Simplifying Healthcare Analytics with BigQuery ML,"Machine learning (ML) is transforming healthcare by enabling predictive
analytics, personalized treatments, and improved patient outcomes. However,
traditional ML workflows require specialized skills, infrastructure, and
resources, limiting accessibility for many healthcare professionals. This paper
explores how Google Cloud's BigQuery ML simplifies the development and
deployment of ML models using SQL, reducing technical barriers. Through a case
study on diabetes prediction using the Diabetes Health Indicators Dataset, we
evaluate three predictive models: Logistic Regression, Boosted Tree, and Deep
Neural Network (DNN). Our results demonstrate that the Boosted Tree model
achieves the highest performance, making it highly effective for diabetes
prediction. This study highlights BigQuery ML's role in democratizing machine
learning by providing a scalable, efficient, and accessible solution for
healthcare analytics.",http://arxiv.org/abs/2502.07026v1,Recommendation System,"ml, healthcare, diabetes, machine, learning"
Detecting Neurodegenerative Diseases using Frame-Level Handwriting Embeddings,"In this study, we explored the use of spectrograms to represent handwriting
signals for assessing neurodegenerative diseases, including 42 healthy controls
(CTL), 35 subjects with Parkinson's Disease (PD), 21 with Alzheimer's Disease
(AD), and 15 with Parkinson's Disease Mimics (PDM). We applied CNN and
CNN-BLSTM models for binary classification using both multi-channel fixed-size
and frame-based spectrograms. Our results showed that handwriting tasks and
spectrogram channel combinations significantly impacted classification
performance. The highest F1-score (89.8%) was achieved for AD vs. CTL, while PD
vs. CTL reached 74.5%, and PD vs. PDM scored 77.97%. CNN consistently
outperformed CNN-BLSTM. Different sliding window lengths were tested for
constructing frame-based spectrograms. A 1-second window worked best for AD,
longer windows improved PD classification, and window length had little effect
on PD vs. PDM.",http://arxiv.org/abs/2502.07025v1,Recommendation System,"pd, cnn, spectrograms, ctl, disease"
AIMS.au: A Dataset for the Analysis of Modern Slavery Countermeasures in Corporate Statements,"Despite over a decade of legislative efforts to address modern slavery in the
supply chains of large corporations, the effectiveness of government oversight
remains hampered by the challenge of scrutinizing thousands of statements
annually. While Large Language Models (LLMs) can be considered a well
established solution for the automatic analysis and summarization of documents,
recognizing concrete modern slavery countermeasures taken by companies and
differentiating those from vague claims remains a challenging task. To help
evaluate and fine-tune LLMs for the assessment of corporate statements, we
introduce a dataset composed of 5,731 modern slavery statements taken from the
Australian Modern Slavery Register and annotated at the sentence level. This
paper details the construction steps for the dataset that include the careful
design of annotation specifications, the selection and preprocessing of
statements, and the creation of high-quality annotation subsets for effective
model evaluations. To demonstrate our dataset's utility, we propose a machine
learning methodology for the detection of sentences relevant to mandatory
reporting requirements set by the Australian Modern Slavery Act. We then follow
this methodology to benchmark modern language models under zero-shot and
supervised learning settings.",http://arxiv.org/abs/2502.07022v1,Recommendation System,"modern, slavery, statements, dataset, large"
Federated Sinkhorn,"In this work we investigate the potential of solving the discrete Optimal
Transport (OT) problem with entropy regularization in a federated learning
setting. Recall that the celebrated Sinkhorn algorithm transforms the classical
OT linear program into strongly convex constrained optimization, facilitating
first order methods for otherwise intractably large problems. A common
contemporary setting that remains an open problem as far as the application of
Sinkhorn is the presence of data spread across clients with distributed
inter-communication, either due to clients whose privacy is a concern, or
simply by necessity of processing and memory hardware limitations. In this work
we investigate various natural procedures, which we refer to as Federated
Sinkhorn, that handle distributed environments where data is partitioned across
multiple clients. We formulate the problem as minimizing the transport cost
with an entropy regularization term, subject to marginal constraints, where
block components of the source and target distribution vectors are locally
known to clients corresponding to each block. We consider both synchronous and
asynchronous variants as well as all-to-all and server-client communication
topology protocols. Each procedure allows clients to compute local operations
on their data partition while periodically exchanging information with others.
We provide theoretical guarantees on convergence for the different variants
under different possible conditions. We empirically demonstrate the algorithms
performance on synthetic datasets and a real-world financial risk assessment
application. The investigation highlights the subtle tradeoffs associated with
computation and communication time in different settings and how they depend on
problem size and sparsity.",http://arxiv.org/abs/2502.07021v1,Recommendation System,"clients, problem, sinkhorn, data, communication"
Preference Alignment on Diffusion Model: A Comprehensive Survey for Image Generation and Editing,"The integration of preference alignment with diffusion models (DMs) has
emerged as a transformative approach to enhance image generation and editing
capabilities. Although integrating diffusion models with preference alignment
strategies poses significant challenges for novices at this intersection,
comprehensive and systematic reviews of this subject are still notably lacking.
To bridge this gap, this paper extensively surveys preference alignment with
diffusion models in image generation and editing. First, we systematically
review cutting-edge optimization techniques such as reinforcement learning with
human feedback (RLHF), direct preference optimization (DPO), and others,
highlighting their pivotal role in aligning preferences with DMs. Then, we
thoroughly explore the applications of aligning preferences with DMs in
autonomous driving, medical imaging, robotics, and more. Finally, we
comprehensively discuss the challenges of preference alignment with DMs. To our
knowledge, this is the first survey centered on preference alignment with DMs,
providing insights to drive future innovation in this dynamic area.",http://arxiv.org/abs/2502.07829v1,Reinforcement Learning,"preference, alignment, dms, diffusion, models"
Finding Words Associated with DIF: Predicting Differential Item Functioning using LLMs and Explainable AI,"We fine-tuned and compared several encoder-based Transformer large language
models (LLM) to predict differential item functioning (DIF) from the item text.
We then applied explainable artificial intelligence (XAI) methods to these
models to identify specific words associated with DIF. The data included 42,180
items designed for English language arts and mathematics summative state
assessments among students in grades 3 to 11. Prediction $R^2$ ranged from .04
to .32 among eight focal and reference group pairs. Our findings suggest that
many words associated with DIF reflect minor sub-domains included in the test
blueprint by design, rather than construct-irrelevant item content that should
be removed from assessments. This may explain why qualitative reviews of DIF
items often yield confusing or inconclusive results. Our approach can be used
to screen words associated with DIF during the item-writing process for
immediate revision, or help review traditional DIF analysis results by
highlighting key words in the text. Extensions of this research can enhance the
fairness of assessment programs, especially those that lack resources to build
high-quality items, and among smaller subpopulations where we do not have
sufficient sample sizes for traditional DIF analyses.",http://arxiv.org/abs/2502.07017v1,Natural Language Processing,"dif, item, words, associated, items"
Confidence Intervals for Evaluation of Data Mining,"In data mining, when binary prediction rules are used to predict a binary
outcome, many performance measures are used in a vast array of literature for
the purposes of evaluation and comparison. Some examples include classification
accuracy, precision, recall, F measures, and Jaccard index. Typically, these
performance measures are only approximately estimated from a finite dataset,
which may lead to findings that are not statistically significant. In order to
properly quantify such statistical uncertainty, it is important to provide
confidence intervals associated with these estimated performance measures. We
consider statistical inference about general performance measures used in data
mining, with both individual and joint confidence intervals. These confidence
intervals are based on asymptotic normal approximations and can be computed
fast, without needs to do bootstrap resampling. We study the finite sample
coverage probabilities for these confidence intervals and also propose a
`blurring correction' on the variance to improve the finite sample performance.
This 'blurring correction' generalizes the plus-four method from binomial
proportion to general performance measures used in data mining. Our framework
allows multiple performance measures of multiple classification rules to be
inferred simultaneously for comparisons.",http://arxiv.org/abs/2502.07016v1,Recommendation System,"performance, measures, confidence, intervals, data"
DROP: Poison Dilution via Knowledge Distillation for Federated Learning,"Federated Learning is vulnerable to adversarial manipulation, where malicious
clients can inject poisoned updates to influence the global model's behavior.
While existing defense mechanisms have made notable progress, they fail to
protect against adversaries that aim to induce targeted backdoors under
different learning and attack configurations. To address this limitation, we
introduce DROP (Distillation-based Reduction Of Poisoning), a novel defense
mechanism that combines clustering and activity-tracking techniques with
extraction of benign behavior from clients via knowledge distillation to tackle
stealthy adversaries that manipulate low data poisoning rates and diverse
malicious client ratios within the federation. Through extensive
experimentation, our approach demonstrates superior robustness compared to
existing defenses across a wide range of learning configurations. Finally, we
evaluate existing defenses and our method under the challenging setting of
non-IID client data distribution and highlight the challenges of designing a
resilient FL defense in this setting.",http://arxiv.org/abs/2502.07011v1,Recommendation System,"learning, existing, defense, malicious, clients"
Early Operative Difficulty Assessment in Laparoscopic Cholecystectomy via Snapshot-Centric Video Analysis,"Purpose: Laparoscopic cholecystectomy (LC) operative difficulty (LCOD) is
highly variable and influences outcomes. Despite extensive LC studies in
surgical workflow analysis, limited efforts explore LCOD using intraoperative
video data. Early recog- nition of LCOD could allow prompt review by expert
surgeons, enhance operating room (OR) planning, and improve surgical outcomes.
  Methods: We propose the clinical task of early LCOD assessment using limited
video observations. We design SurgPrOD, a deep learning model to assess LCOD by
analyzing features from global and local temporal resolutions (snapshots) of
the observed LC video. Also, we propose a novel snapshot-centric attention
(SCA) module, acting across snapshots, to enhance LCOD prediction. We introduce
the CholeScore dataset, featuring video-level LCOD labels to validate our
method.
  Results: We evaluate SurgPrOD on 3 LCOD assessment scales in the CholeScore
dataset. On our new metric assessing early and stable correct predictions,
SurgPrOD surpasses baselines by at least 0.22 points. SurgPrOD improves over
baselines by at least 9 and 5 percentage points in F1 score and top1-accuracy,
respectively, demonstrating its effectiveness in correct predictions.
  Conclusion: We propose a new task for early LCOD assessment and a novel
model, SurgPrOD analyzing surgical video from global and local perspectives.
Our results on the CholeScore dataset establishes a new benchmark to study LCOD
using intraoperative video data.",http://arxiv.org/abs/2502.07008v1,Recommendation System,"lcod, video, surgprod, early, lc"
Grounding Creativity in Physics: A Brief Survey of Physical Priors in AIGC,"Recent advancements in AI-generated content have significantly improved the
realism of 3D and 4D generation. However, most existing methods prioritize
appearance consistency while neglecting underlying physical principles, leading
to artifacts such as unrealistic deformations, unstable dynamics, and
implausible objects interactions. Incorporating physics priors into generative
models has become a crucial research direction to enhance structural integrity
and motion realism. This survey provides a review of physics-aware generative
methods, systematically analyzing how physical constraints are integrated into
3D and 4D generation. First, we examine recent works in incorporating physical
priors into static and dynamic 3D generation, categorizing methods based on
representation types, including vision-based, NeRF-based, and Gaussian
Splatting-based approaches. Second, we explore emerging techniques in 4D
generation, focusing on methods that model temporal dynamics with physical
simulations. Finally, we conduct a comparative analysis of major methods,
highlighting their strengths, limitations, and suitability for different
materials and motion dynamics. By presenting an in-depth analysis of
physics-grounded AIGC, this survey aims to bridge the gap between generative
models and physical realism, providing insights that inspire future research in
physically consistent content generation.",http://arxiv.org/abs/2502.07007v1,Recommendation System,"generation, methods, physical, based, realism"
Some things to know about achieving artificial general intelligence,"Current and foreseeable GenAI models are not capable of achieving artificial
general intelligence because they are burdened with anthropogenic debt. They
depend heavily on human input to provide well-structured problems,
architecture, and training data. They cast every problem as a language pattern
learning problem and are thus not capable of the kind of autonomy needed to
achieve artificial general intelligence. Current models succeed at their tasks
because people solve most of the problems to which these models are directed,
leaving only simple computations for the model to perform, such as gradient
descent. Another barrier is the need to recognize that there are multiple kinds
of problems, some of which cannot be solved by available computational methods
(for example, ""insight problems""). Current methods for evaluating models
(benchmarks and tests) are not adequate to identify the generality of the
solutions, because it is impossible to infer the means by which a problem was
solved from the fact of its solution. A test could be passed, for example, by a
test-specific or a test-general method. It is a logical fallacy (affirming the
consequent) to infer a method of solution from the observation of success.",http://arxiv.org/abs/2502.07828v1,Recommendation System,"models, problems, current, general, problem"
Geometry-aware RL for Manipulation of Varying Shapes and Deformable Objects,"Manipulating objects with varying geometries and deformable objects is a
major challenge in robotics. Tasks such as insertion with different objects or
cloth hanging require precise control and effective modelling of complex
dynamics. In this work, we frame this problem through the lens of a
heterogeneous graph that comprises smaller sub-graphs, such as actuators and
objects, accompanied by different edge types describing their interactions.
This graph representation serves as a unified structure for both rigid and
deformable objects tasks, and can be extended further to tasks comprising
multiple actuators. To evaluate this setup, we present a novel and challenging
reinforcement learning benchmark, including rigid insertion of diverse objects,
as well as rope and cloth manipulation with multiple end-effectors. These tasks
present a large search space, as both the initial and target configurations are
uniformly sampled in 3D space. To address this issue, we propose a novel
graph-based policy model, dubbed Heterogeneous Equivariant Policy (HEPi),
utilizing $SE(3)$
  equivariant message passing networks as the main backbone to exploit the
geometric symmetry. In addition, by modeling explicit heterogeneity, HEPi can
outperform Transformer-based and non-heterogeneous equivariant policies in
terms of average returns, sample efficiency, and generalization to unseen
objects.",http://arxiv.org/abs/2502.07005v2,Reinforcement Learning,"objects, tasks, heterogeneous, graph, equivariant"
AstroLoc: Robust Space to Ground Image Localizer,"Astronauts take thousands of photos of Earth per day from the International
Space Station, which, once localized on Earth's surface, are used for a
multitude of tasks, ranging from climate change research to disaster
management. The localization process, which has been performed manually for
decades, has recently been approached through image retrieval solutions: given
an astronaut photo, find its most similar match among a large database of
geo-tagged satellite images, in a task called Astronaut Photography
Localization (APL). Yet, existing APL approaches are trained only using
satellite images, without taking advantage of the millions open-source
astronaut photos. In this work we present the first APL pipeline capable of
leveraging astronaut photos for training. We first produce full localization
information for 300,000 manually weakly labeled astronaut photos through an
automated pipeline, and then use these images to train a model, called
AstroLoc. AstroLoc learns a robust representation of Earth's surface features
through two losses: astronaut photos paired with their matching satellite
counterparts in a pairwise loss, and a second loss on clusters of satellite
imagery weighted by their relevance to astronaut photography via unsupervised
mining. We find that AstroLoc achieves a staggering 35% average improvement in
recall@1 over previous SOTA, pushing the limits of existing datasets with a
recall@100 consistently over 99%. Finally, we note that AstroLoc, without any
fine-tuning, provides excellent results for related tasks like the
lost-in-space satellite problem and historical space imagery localization.",http://arxiv.org/abs/2502.07003v1,Reinforcement Learning,"astronaut, photos, satellite, localization, astroloc"
Implicit Language Models are RNNs: Balancing Parallelization and Expressivity,"State-space models (SSMs) and transformers dominate the language modeling
landscape. However, they are constrained to a lower computational complexity
than classical recurrent neural networks (RNNs), limiting their expressivity.
In contrast, RNNs lack parallelization during training, raising fundamental
questions about the trade off between parallelization and expressivity. We
propose implicit SSMs, which iterate a transformation until convergence to a
fixed point. Theoretically, we show that implicit SSMs implement the non-linear
state-transitions of RNNs. Empirically, we find that only approximate
fixed-point convergence suffices, enabling the design of a scalable training
curriculum that largely retains parallelization, with full convergence required
only for a small subset of tokens. Our approach demonstrates superior
state-tracking capabilities on regular languages, surpassing transformers and
SSMs. We further scale implicit SSMs to natural language reasoning tasks and
pretraining of large-scale language models up to 1.3B parameters on 207B tokens
- representing, to our knowledge, the largest implicit model trained to date.
Notably, our implicit models outperform their explicit counterparts on standard
benchmarks.",http://arxiv.org/abs/2502.07827v1,Natural Language Processing,"ssms, implicit, state, models, language"
From Image to Video: An Empirical Study of Diffusion Representations,"Diffusion models have revolutionized generative modeling, enabling
unprecedented realism in image and video synthesis. This success has sparked
interest in leveraging their representations for visual understanding tasks.
While recent works have explored this potential for image generation, the
visual understanding capabilities of video diffusion models remain largely
uncharted. To address this gap, we systematically compare the same model
architecture trained for video versus image generation, analyzing the
performance of their latent representations on various downstream tasks
including image classification, action recognition, depth estimation, and
tracking. Results show that video diffusion models consistently outperform
their image counterparts, though we find a striking range in the extent of this
superiority. We further analyze features extracted from different layers and
with varying noise levels, as well as the effect of model size and training
budget on representation and generation quality. This work marks the first
direct comparison of video and image diffusion objectives for visual
understanding, offering insights into the role of temporal information in
representation learning.",http://arxiv.org/abs/2502.07001v1,Computer Vision,"image, video, diffusion, models, visual"
Outsourced diffusion sampling: Efficient posterior inference in latent spaces of generative models,"Any well-behaved generative model over a variable $\mathbf{x}$ can be
expressed as a deterministic transformation of an exogenous ('outsourced')
Gaussian noise variable $\mathbf{z}$: $\mathbf{x}=f_\theta(\mathbf{z})$. In
such a model (e.g., a VAE, GAN, or continuous-time flow-based model), sampling
of the target variable $\mathbf{x} \sim p_\theta(\mathbf{x})$ is
straightforward, but sampling from a posterior distribution of the form
$p(\mathbf{x}\mid\mathbf{y}) \propto
p_\theta(\mathbf{x})r(\mathbf{x},\mathbf{y})$, where $r$ is a constraint
function depending on an auxiliary variable $\mathbf{y}$, is generally
intractable. We propose to amortize the cost of sampling from such posterior
distributions with diffusion models that sample a distribution in the noise
space ($\mathbf{z}$). These diffusion samplers are trained by reinforcement
learning algorithms to enforce that the transformed samples
$f_\theta(\mathbf{z})$ are distributed according to the posterior in the data
space ($\mathbf{x}$). For many models and constraints of interest, the
posterior in the noise space is smoother than the posterior in the data space,
making it more amenable to such amortized inference. Our method enables
conditional sampling under unconditional GAN, (H)VAE, and flow-based priors,
comparing favorably both with current amortized and non-amortized inference
methods. We demonstrate the proposed outsourced diffusion sampling in several
experiments with large pretrained prior models: conditional image generation,
reinforcement learning with human feedback, and protein structure generation.",http://arxiv.org/abs/2502.06999v1,Reinforcement Learning,"sampling, posterior, variable, space, model"
Conditional diffusion model with spatial attention and latent embedding for medical image segmentation,"Diffusion models have been used extensively for high quality image and video
generation tasks. In this paper, we propose a novel conditional diffusion model
with spatial attention and latent embedding (cDAL) for medical image
segmentation. In cDAL, a convolutional neural network (CNN) based discriminator
is used at every time-step of the diffusion process to distinguish between the
generated labels and the real ones. A spatial attention map is computed based
on the features learned by the discriminator to help cDAL generate more
accurate segmentation of discriminative regions in an input image.
Additionally, we incorporated a random latent embedding into each layer of our
model to significantly reduce the number of training and sampling time-steps,
thereby making it much faster than other diffusion models for image
segmentation. We applied cDAL on 3 publicly available medical image
segmentation datasets (MoNuSeg, Chest X-ray and Hippocampus) and observed
significant qualitative and quantitative improvements with higher Dice scores
and mIoU over the state-of-the-art algorithms. The source code is publicly
available at https://github.com/Hejrati/cDAL/.",http://arxiv.org/abs/2502.06997v1,Computer Vision,"image, diffusion, cdal, segmentation, models"
Epistemic Uncertainty in Conformal Scores: A Unified Approach,"Conformal prediction methods create prediction bands with distribution-free
guarantees but do not explicitly capture epistemic uncertainty, which can lead
to overconfident predictions in data-sparse regions. Although recent conformal
scores have been developed to address this limitation, they are typically
designed for specific tasks, such as regression or quantile regression.
Moreover, they rely on particular modeling choices for epistemic uncertainty,
restricting their applicability. We introduce $\texttt{EPICSCORE}$, a
model-agnostic approach that enhances any conformal score by explicitly
integrating epistemic uncertainty. Leveraging Bayesian techniques such as
Gaussian Processes, Monte Carlo Dropout, or Bayesian Additive Regression Trees,
$\texttt{EPICSCORE}$ adaptively expands predictive intervals in regions with
limited data while maintaining compact intervals where data is abundant. As
with any conformal method, it preserves finite-sample marginal coverage.
Additionally, it also achieves asymptotic conditional coverage. Experiments
demonstrate its good performance compared to existing methods. Designed for
compatibility with any Bayesian model, but equipped with distribution-free
guarantees, $\texttt{EPICSCORE}$ provides a general-purpose framework for
uncertainty quantification in prediction problems.",http://arxiv.org/abs/2502.06995v1,Recommendation System,"conformal, uncertainty, prediction, epistemic, data"
SyncMind: Measuring Agent Out-of-Sync Recovery in Collaborative Software Engineering,"Software engineering (SE) is increasingly collaborative, with developers
working together on shared complex codebases. Effective collaboration in shared
environments requires participants -- whether humans or AI agents -- to stay on
the same page as their environment evolves. When a collaborator's understanding
diverges from the current state -- what we term the out-of-sync challenge --
the collaborator's actions may fail, leading to integration issues. In this
work, we introduce SyncMind, a framework that systematically defines the
out-of-sync problem faced by large language model (LLM) agents in collaborative
software engineering (CSE). Based on SyncMind, we create SyncBench, a benchmark
featuring 24,332 instances of agent out-of-sync scenarios in real-world CSE
derived from 21 popular GitHub repositories with executable verification tests.
Experiments on SyncBench uncover critical insights into existing LLM agents'
capabilities and limitations. Besides substantial performance gaps among agents
(from Llama-3.1 agent <= 3.33% to Claude-3.5-Sonnet >= 28.18%), their
consistently low collaboration willingness (<= 4.86%) suggests fundamental
limitations of existing LLM in CSE. However, when collaboration occurs, it
positively correlates with out-of-sync recovery success. Minimal performance
differences in agents' resource-aware out-of-sync recoveries further reveal
their significant lack of resource awareness and adaptability, shedding light
on future resource-efficient collaborative systems. Code and data are openly
available on our project website: https://xhguo7.github.io/SyncMind/.",http://arxiv.org/abs/2502.06994v1,Recommendation System,"agents, sync, collaborative, collaboration, llm"
Universal Vessel Segmentation for Multi-Modality Retinal Images,"We identify two major limitations in the existing studies on retinal vessel
segmentation: (1) Most existing works are restricted to one modality, i.e, the
Color Fundus (CF). However, multi-modality retinal images are used every day in
the study of retina and retinal diseases, and the study of vessel segmentation
on the other modalities is scarce; (2) Even though a small amount of works
extended their experiments to limited new modalities such as the Multi-Color
Scanning Laser Ophthalmoscopy (MC), these works still require finetuning a
separate model for the new modality. And the finetuning will require extra
training data, which is difficult to acquire. In this work, we present a
foundational universal vessel segmentation model (UVSM) for multi-modality
retinal images. Not only do we perform the study on a much wider range of
modalities, but also we propose a universal model to segment the vessels in all
these commonly-used modalities. Despite being much more versatile comparing
with existing methods, our universal model still demonstrates comparable
performance with the state-of-the- art finetuned methods. To the best of our
knowledge, this is the first work that achieves cross-modality retinal vessel
segmentation and also the first work to study retinal vessel segmentation in
some novel modalities.",http://arxiv.org/abs/2502.06987v1,Recommendation System,"retinal, vessel, segmentation, modality, modalities"
Machine Learning Fleet Efficiency: Analyzing and Optimizing Large-Scale Google TPU Systems with ML Productivity Goodput,"Recent years have seen the emergence of machine learning (ML) workloads
deployed in warehouse-scale computing (WSC) settings, also known as ML fleets.
As the computational demands placed on ML fleets have increased due to the rise
of large models and growing demand for ML applications, it has become
increasingly critical to measure and improve the efficiency of such systems.
However, there is not yet an established methodology to characterize ML fleet
performance and identify potential performance optimizations accordingly. This
paper presents a large-scale analysis of an ML fleet based on Google's TPUs,
introducing a framework to capture fleet-wide efficiency, systematically
evaluate performance characteristics, and identify optimization strategies for
the fleet. We begin by defining an ML fleet, outlining its components, and
analyzing an example Google ML fleet in production comprising thousands of
accelerators running diverse workloads. Our study reveals several critical
insights: first, ML fleets extend beyond the hardware layer, with model, data,
framework, compiler, and scheduling layers significantly impacting performance;
second, the heterogeneous nature of ML fleets poses challenges in
characterizing individual workload performance; and third, traditional
utilization-based metrics prove insufficient for ML fleet characterization. To
address these challenges, we present the ""ML Productivity Goodput"" (MPG) metric
to measure ML fleet efficiency. We show how to leverage this metric to
characterize the fleet across the ML system stack. We also present methods to
identify and optimize performance bottlenecks using MPG, providing strategies
for managing warehouse-scale ML systems in general. Lastly, we demonstrate
quantitative evaluations from applying these methods to a real ML fleet for
internal-facing Google TPU workloads, where we observed tangible improvements.",http://arxiv.org/abs/2502.06982v1,Recommendation System,"ml, fleet, performance, fleets, workloads"
Dual Conic Proxy for Semidefinite Relaxation of AC Optimal Power Flow,"The nonlinear, non-convex AC Optimal Power Flow (AC-OPF) problem is
fundamental for power systems operations. The intrinsic complexity of AC-OPF
has fueled a growing interest in the development of optimization proxies for
the problem, i.e., machine learning models that predict high-quality,
close-to-optimal solutions. More recently, dual conic proxy architectures have
been proposed, which combine machine learning and convex relaxations of AC-OPF,
to provide valid certificates of optimality using learning-based methods.
Building on this methodology, this paper proposes, for the first time, a dual
conic proxy architecture for the semidefinite (SDP) relaxation of AC-OPF
problems. Although the SDP relaxation is stronger than the second-order cone
relaxation considered in previous work, its practical use has been hindered by
its computational cost. The proposed method combines a neural network with a
differentiable dual completion strategy that leverages the structure of the
dual SDP problem. This approach guarantees dual feasibility, and therefore
valid dual bounds, while providing orders of magnitude of speedups compared to
interior-point algorithms. The paper also leverages self-supervised learning,
which alleviates the need for time-consuming data generation and allows to
train the proposed models efficiently. Numerical experiments are presented on
several power grid benchmarks with up to 500 buses. The results demonstrate
that the proposed SDP-based proxies can outperform weaker conic relaxations,
while providing several orders of magnitude speedups compared to a
state-of-the-art interior-point SDP solver.",http://arxiv.org/abs/2502.06978v1,Recommendation System,"dual, ac, sdp, opf, learning"
Who is Helping Whom? Analyzing Inter-dependencies to Evaluate Cooperation in Human-AI Teaming,"The long-standing research challenges of Human-AI Teaming(HAT) and Zero-shot
Cooperation(ZSC) have been tackled by applying multi-agent reinforcement
learning(MARL) to train an agent by optimizing the environment reward function
and evaluating their performance through task performance metrics such as task
reward. However, such evaluation focuses only on task completion, while being
agnostic to `how' the two agents work with each other. Specifically, we are
interested in understanding the cooperation arising within the team when
trained agents are paired with humans. To formally address this problem, we
propose the concept of interdependence to measure how much agents rely on each
other's actions to achieve the shared goal, as a key metric for evaluating
cooperation in human-agent teams. Towards this, we ground this concept through
a symbolic formalism and define evaluation metrics that allow us to assess the
degree of reliance between the agents' actions. We pair state-of-the-art agents
trained through MARL for HAT, with learned human models for the the popular
Overcooked domain, and evaluate the team performance for these human-agent
teams. Our results demonstrate that trained agents are not able to induce
cooperative behavior, reporting very low levels of interdependence across all
the teams. We also report that teaming performance of a team is not necessarily
correlated with the task reward.",http://arxiv.org/abs/2502.06976v1,Reinforcement Learning,"agents, human, agent, performance, task"
Position: Episodic Memory is the Missing Piece for Long-Term LLM Agents,"As Large Language Models (LLMs) evolve from text-completion tools into fully
fledged agents operating in dynamic environments, they must address the
challenge of continually learning and retaining long-term knowledge. Many
biological systems solve these challenges with episodic memory, which supports
single-shot learning of instance-specific contexts. Inspired by this, we
present an episodic memory framework for LLM agents, centered around five key
properties of episodic memory that underlie adaptive and context-sensitive
behavior. With various research efforts already partially covering these
properties, this position paper argues that now is the right time for an
explicit, integrated focus on episodic memory to catalyze the development of
long-term agents. To this end, we outline a roadmap that unites several
research directions under the goal to support all five properties of episodic
memory for more efficient long-term LLM agents.",http://arxiv.org/abs/2502.06975v1,Recommendation System,"episodic, memory, agents, long, term"
Indoor Light and Heat Estimation from a Single Panorama,"This paper presents a novel application for directly estimating indoor light
and heat maps from captured indoor-outdoor High Dynamic Range (HDR) panoramas.
In our image-based rendering method, the indoor panorama is used to estimate
the 3D room layout, while the corresponding outdoor panorama serves as an
environment map to infer spatially-varying light and material properties. We
establish a connection between indoor light transport and heat transport and
implement transient heat simulation to generate indoor heat panoramas. The
sensitivity analysis of various thermal parameters is conducted, and the
resulting heat maps are compared with the images captured by the thermal camera
in real-world scenarios. This digital application enables automatic indoor
light and heat estimation without manual inputs and cumbersome field
measurements.",http://arxiv.org/abs/2502.06973v1,Recommendation System,"indoor, heat, light, application, maps"
User-Preference Meets Pareto-Optimality: Multi-Objective Bayesian Optimization with Local Gradient Search,"Incorporating user preferences into multi-objective Bayesian optimization
(MOBO) allows for personalization of the optimization procedure. Preferences
are often abstracted in the form of an unknown utility function, estimated
through pairwise comparisons of potential outcomes. However, utility-driven
MOBO methods can yield solutions that are dominated by nearby solutions, as
non-dominance is not enforced. Additionally, classical MOBO commonly relies on
estimating the entire Pareto-front to identify the Pareto-optimal solutions,
which can be expensive and ignore user preferences. Here, we present a new
method, termed preference-utility-balanced MOBO (PUB-MOBO), that allows users
to disambiguate between near-Pareto candidate solutions. PUB-MOBO combines
utility-based MOBO with local multi-gradient descent to refine user-preferred
solutions to be near-Pareto-optimal. To this end, we propose a novel
preference-dominated utility function that concurrently preserves
user-preferences and dominance amongst candidate solutions. A key advantage of
PUB-MOBO is that the local search is restricted to a (small) region of the
Pareto-front directed by user preferences, alleviating the need to estimate the
entire Pareto-front. PUB-MOBO is tested on three synthetic benchmark problems:
DTLZ1, DTLZ2 and DH1, as well as on three real-world problems: Vehicle Safety,
Conceptual Marine Design, and Car Side Impact. PUB-MOBO consistently
outperforms state-of-the-art competitors in terms of proximity to the
Pareto-front and utility regret across all the problems.",http://arxiv.org/abs/2502.06971v1,Reinforcement Learning,"mobo, pareto, utility, solutions, user"
Model Diffusion for Certifiable Few-shot Transfer Learning,"In modern large-scale deep learning, a prevalent and effective workflow for
solving low-data problems is adapting powerful pre-trained foundation models
(FMs) to new tasks via parameter-efficient fine-tuning (PEFT). However, while
empirically effective, the resulting solutions lack generalisation guarantees
to certify their accuracy - which may be required for ethical or legal reasons
prior to deployment in high-importance applications. In this paper we develop a
novel transfer learning approach that is designed to facilitate non-vacuous
learning theoretic generalisation guarantees for downstream tasks, even in the
low-shot regime. Specifically, we first use upstream tasks to train a
distribution over PEFT parameters. We then learn the downstream task by a
sample-and-evaluate procedure -- sampling plausible PEFTs from the trained
diffusion model and selecting the one with the highest likelihood on the
downstream data. Crucially, this confines our model hypothesis to a finite set
of PEFT samples. In contrast to learning in the typical continuous hypothesis
spaces of neural network weights, this facilitates tighter risk certificates.
We instantiate our bound and show non-trivial generalization guarantees
compared to existing learning approaches which lead to vacuous bounds in the
low-shot regime.",http://arxiv.org/abs/2502.06970v1,Recommendation System,"learning, low, tasks, peft, guarantees"
Task Offloading in Vehicular Edge Computing using Deep Reinforcement Learning: A Survey,"The increasing demand for Intelligent Transportation Systems (ITS) has
introduced significant challenges in managing the complex,
computation-intensive tasks generated by modern vehicles while offloading tasks
to external computing infrastructures such as edge computing (EC), nearby
vehicular , and UAVs has become influential solution to these challenges.
However, traditional computational offloading strategies often struggle to
adapt to the dynamic and heterogeneous nature of vehicular environments. In
this study, we explored the potential of Reinforcement Learning (RL) and Deep
Reinforcement Learning (DRL) frameworks to optimize computational offloading
through adaptive, real-time decision-making, and we have thoroughly
investigated the Markov Decision Process (MDP) approaches on the existing
literature. The paper focuses on key aspects such as standardized learning
models, optimized reward structures, and collaborative multi-agent systems,
aiming to advance the understanding and application of DRL in vehicular
networks. Our findings offer insights into enhancing the efficiency,
scalability, and robustness of ITS, setting the stage for future innovations in
this rapidly evolving field.",http://arxiv.org/abs/2502.06963v1,Reinforcement Learning,"offloading, vehicular, learning, systems, challenges"
GAS: Generative Avatar Synthesis from a Single Image,"We introduce a generalizable and unified framework to synthesize
view-consistent and temporally coherent avatars from a single image, addressing
the challenging problem of single-image avatar generation. While recent methods
employ diffusion models conditioned on human templates like depth or normal
maps, they often struggle to preserve appearance information due to the
discrepancy between sparse driving signals and the actual human subject,
resulting in multi-view and temporal inconsistencies. Our approach bridges this
gap by combining the reconstruction power of regression-based 3D human
reconstruction with the generative capabilities of a diffusion model. The dense
driving signal from the initial reconstructed human provides comprehensive
conditioning, ensuring high-quality synthesis faithful to the reference
appearance and structure. Additionally, we propose a unified framework that
enables the generalization learned from novel pose synthesis on in-the-wild
videos to naturally transfer to novel view synthesis. Our video-based diffusion
model enhances disentangled synthesis with high-quality view-consistent
renderings for novel views and realistic non-rigid deformations in novel pose
animation. Results demonstrate the superior generalization ability of our
method across in-domain and out-of-domain in-the-wild datasets. Project page:
https://humansensinglab.github.io/GAS/",http://arxiv.org/abs/2502.06957v1,Recommendation System,"view, human, synthesis, novel, diffusion"
Generalizable automated ischaemic stroke lesion segmentation with vision transformers,"Ischaemic stroke, a leading cause of death and disability, critically relies
on neuroimaging for characterising the anatomical pattern of injury.
Diffusion-weighted imaging (DWI) provides the highest expressivity in ischemic
stroke but poses substantial challenges for automated lesion segmentation:
susceptibility artefacts, morphological heterogeneity, age-related
comorbidities, time-dependent signal dynamics, instrumental variability, and
limited labelled data. Current U-Net-based models therefore underperform, a
problem accentuated by inadequate evaluation metrics that focus on mean
performance, neglecting anatomical, subpopulation, and acquisition-dependent
variability. Here, we present a high-performance DWI lesion segmentation tool
addressing these challenges through optimized vision transformer-based
architectures, integration of 3563 annotated lesions from multi-site data, and
algorithmic enhancements, achieving state-of-the-art results. We further
propose a novel evaluative framework assessing model fidelity, equity (across
demographics and lesion subtypes), anatomical precision, and robustness to
instrumental variability, promoting clinical and research utility. This work
advances stroke imaging by reconciling model expressivity with domain-specific
challenges and redefining performance benchmarks to prioritize equity and
generalizability, critical for personalized medicine and mechanistic research.",http://arxiv.org/abs/2502.06939v1,Recommendation System,"stroke, anatomical, challenges, lesion, variability"
EVEv2: Improved Baselines for Encoder-Free Vision-Language Models,"Existing encoder-free vision-language models (VLMs) are rapidly narrowing the
performance gap with their encoder-based counterparts, highlighting the
promising potential for unified multimodal systems with structural simplicity
and efficient deployment. We systematically clarify the performance gap between
VLMs using pre-trained vision encoders, discrete tokenizers, and minimalist
visual layers from scratch, deeply excavating the under-examined
characteristics of encoder-free VLMs. We develop efficient strategies for
encoder-free VLMs that rival mainstream encoder-based ones. After an in-depth
investigation, we launch EVEv2.0, a new and improved family of encoder-free
VLMs. We show that: (i) Properly decomposing and hierarchically associating
vision and language within a unified model reduces interference between
modalities. (ii) A well-designed training strategy enables effective
optimization for encoder-free VLMs. Through extensive evaluation, our EVEv2.0
represents a thorough study for developing a decoder-only architecture across
modalities, demonstrating superior data efficiency and strong vision-reasoning
capability. Code is publicly available at: https://github.com/baaivision/EVE.",http://arxiv.org/abs/2502.06788v1,Recommendation System,"encoder, vlms, free, vision, language"
Visual Agentic AI for Spatial Reasoning with a Dynamic API,"Visual reasoning -- the ability to interpret the visual world -- is crucial
for embodied agents that operate within three-dimensional scenes. Progress in
AI has led to vision and language models capable of answering questions from
images. However, their performance declines when tasked with 3D spatial
reasoning. To tackle the complexity of such reasoning problems, we introduce an
agentic program synthesis approach where LLM agents collaboratively generate a
Pythonic API with new functions to solve common subproblems. Our method
overcomes limitations of prior approaches that rely on a static, human-defined
API, allowing it to handle a wider range of queries. To assess AI capabilities
for 3D understanding, we introduce a new benchmark of queries involving
multiple steps of grounding and inference. We show that our method outperforms
prior zero-shot models for visual reasoning in 3D and empirically validate the
effectiveness of our agentic framework for 3D spatial reasoning tasks. Project
website: https://glab-caltech.github.io/vadar/",http://arxiv.org/abs/2502.06787v1,Recommendation System,"reasoning, visual, agents, ai, models"
Matryoshka Quantization,"Quantizing model weights is critical for reducing the communication and
inference costs of large models. However, quantizing models -- especially to
low precisions like int4 or int2 -- requires a trade-off in model quality;
int2, in particular, is known to severely degrade model quality. Consequently,
practitioners are often forced to maintain multiple models with different
quantization levels or serve a single model that best satisfies the
quality-latency trade-off. On the other hand, integer data types, such as int8,
inherently possess a nested (Matryoshka) structure where smaller bit-width
integers, like int4 or int2, are nested within the most significant bits. This
paper proposes Matryoshka Quantization (MatQuant), a novel multi-scale
quantization technique that addresses the challenge of needing multiple
quantized models. It allows training and maintaining just one model, which can
then be served at different precision levels. Furthermore, due to the
co-training and co-distillation regularization provided by MatQuant, the int2
precision models extracted by MatQuant can be up to $10\%$ more accurate than
standard int2 quantization (using techniques like QAT or OmniQuant). This
represents significant progress in model quantization, demonstrated by the fact
that, with the same recipe, an int2 FFN-quantized Gemma-2 9B model is more
accurate than an int8 FFN-quantized Gemma-2 2B model.",http://arxiv.org/abs/2502.06786v1,Recommendation System,"model, models, quantization, like, quality"
DeepCrossAttention: Supercharging Transformer Residual Connections,"Transformer networks have achieved remarkable success across diverse domains,
leveraging a variety of architectural innovations, including residual
connections. However, traditional residual connections, which simply sum the
outputs of previous layers, can dilute crucial information. This work
introduces DeepCrossAttention (DCA), an approach that enhances residual
learning in transformers. DCA employs learnable, input-dependent weights to
dynamically combine layer outputs, enabling the model to selectively focus on
the most relevant information in any of the previous layers. Furthermore, DCA
incorporates depth-wise cross-attention, allowing for richer interactions
between layers at different depths. Our language modeling experiments show that
DCA achieves improved perplexity for a given training time. Moreover, DCA
obtains the same model quality up to 3x faster while adding a negligible number
of parameters. Theoretical analysis confirms that DCA provides an improved
trade-off between accuracy and model size when the ratio of collective layer
ranks to the ambient dimension falls below a critical threshold.",http://arxiv.org/abs/2502.06785v1,Reinforcement Learning,"dca, residual, layers, model, connections"
RelGNN: Composite Message Passing for Relational Deep Learning,"Predictive tasks on relational databases are critical in real-world
applications spanning e-commerce, healthcare, and social media. To address
these tasks effectively, Relational Deep Learning (RDL) encodes relational data
as graphs, enabling Graph Neural Networks (GNNs) to exploit relational
structures for improved predictions. However, existing heterogeneous GNNs often
overlook the intrinsic structural properties of relational databases, leading
to modeling inefficiencies. Here we introduce RelGNN, a novel GNN framework
specifically designed to capture the unique characteristics of relational
databases. At the core of our approach is the introduction of atomic routes,
which are sequences of nodes forming high-order tripartite structures. Building
upon these atomic routes, RelGNN designs new composite message passing
mechanisms between heterogeneous nodes, allowing direct single-hop interactions
between them. This approach avoids redundant aggregations and mitigates
information entanglement, ultimately leading to more efficient and accurate
predictive modeling. RelGNN is evaluated on 30 diverse real-world tasks from
RelBench (Fey et al., 2024), and consistently achieves state-of-the-art
accuracy with up to 25% improvement.",http://arxiv.org/abs/2502.06784v1,Reinforcement Learning,"relational, tasks, databases, relgnn, predictive"
Lumina-Video: Efficient and Flexible Video Generation with Multi-scale Next-DiT,"Recent advancements have established Diffusion Transformers (DiTs) as a
dominant framework in generative modeling. Building on this success,
Lumina-Next achieves exceptional performance in the generation of
photorealistic images with Next-DiT. However, its potential for video
generation remains largely untapped, with significant challenges in modeling
the spatiotemporal complexity inherent to video data. To address this, we
introduce Lumina-Video, a framework that leverages the strengths of Next-DiT
while introducing tailored solutions for video synthesis. Lumina-Video
incorporates a Multi-scale Next-DiT architecture, which jointly learns multiple
patchifications to enhance both efficiency and flexibility. By incorporating
the motion score as an explicit condition, Lumina-Video also enables direct
control of generated videos' dynamic degree. Combined with a progressive
training scheme with increasingly higher resolution and FPS, and a multi-source
training scheme with mixed natural and synthetic data, Lumina-Video achieves
remarkable aesthetic quality and motion smoothness at high training and
inference efficiency. We additionally propose Lumina-V2A, a video-to-audio
model based on Next-DiT, to create synchronized sounds for generated videos.
Codes are released at https://www.github.com/Alpha-VLLM/Lumina-Video.",http://arxiv.org/abs/2502.06782v2,Recommendation System,"video, lumina, dit, training, framework"
Exploring the Limit of Outcome Reward for Learning Mathematical Reasoning,"Reasoning abilities, especially those for solving complex math problems, are
crucial components of general intelligence. Recent advances by proprietary
companies, such as o-series models of OpenAI, have made remarkable progress on
reasoning tasks. However, the complete technical details remain unrevealed, and
the techniques that are believed certainly to be adopted are only reinforcement
learning (RL) and the long chain of thoughts. This paper proposes a new RL
framework, termed OREAL, to pursue the performance limit that can be achieved
through \textbf{O}utcome \textbf{RE}w\textbf{A}rd-based reinforcement
\textbf{L}earning for mathematical reasoning tasks, where only binary outcome
rewards are easily accessible. We theoretically prove that behavior cloning on
positive trajectories from best-of-N (BoN) sampling is sufficient to learn the
KL-regularized optimal policy in binary feedback environments. This formulation
further implies that the rewards of negative samples should be reshaped to
ensure the gradient consistency between positive and negative samples. To
alleviate the long-existing difficulties brought by sparse rewards in RL, which
are even exacerbated by the partial correctness of the long chain of thought
for reasoning tasks, we further apply a token-level reward model to sample
important tokens in reasoning trajectories for learning. With OREAL, for the
first time, a 7B model can obtain 94.0 pass@1 accuracy on MATH-500 through RL,
being on par with 32B models. OREAL-32B also surpasses previous 32B models
trained by distillation with 95.0 pass@1 accuracy on MATH-500. Our
investigation also indicates the importance of initial policy models and
training queries for RL. Code, models, and data will be released to benefit
future research\footnote{https://github.com/InternLM/OREAL}.",http://arxiv.org/abs/2502.06781v1,Reinforcement Learning,"reasoning, models, rl, tasks, long"
KARST: Multi-Kernel Kronecker Adaptation with Re-Scaling Transmission for Visual Classification,"Fine-tuning pre-trained vision models for specific tasks is a common practice
in computer vision. However, this process becomes more expensive as models grow
larger. Recently, parameter-efficient fine-tuning (PEFT) methods have emerged
as a popular solution to improve training efficiency and reduce storage needs
by tuning additional low-rank modules within pre-trained backbones. Despite
their advantages, they struggle with limited representation capabilities and
misalignment with pre-trained intermediate features. To address these issues,
we introduce an innovative Multi-Kernel Kronecker Adaptation with Re-Scaling
Transmission (KARST) for various recognition tasks. Specifically, its
multi-kernel design extends Kronecker projections horizontally and separates
adaptation matrices into multiple complementary spaces, reducing parameter
dependency and creating more compact subspaces. Besides, it incorporates extra
learnable re-scaling factors to better align with pre-trained feature
distributions, allowing for more flexible and balanced feature aggregation.
Extensive experiments validate that our KARST outperforms other PEFT
counterparts with a negligible inference cost due to its re-parameterization
characteristics. Code is publicly available at:
https://github.com/Lucenova/KARST.",http://arxiv.org/abs/2502.06779v1,Computer Vision,"pre, trained, tuning, fine, vision"
Learning an Optimal Assortment Policy under Observational Data,"We study the fundamental problem of offline assortment optimization under the
Multinomial Logit (MNL) model, where sellers must determine the optimal subset
of the products to offer based solely on historical customer choice data. While
most existing approaches to learning-based assortment optimization focus on the
online learning of the optimal assortment through repeated interactions with
customers, such exploration can be costly or even impractical in many
real-world settings. In this paper, we consider the offline learning paradigm
and investigate the minimal data requirements for efficient offline assortment
optimization. To this end, we introduce Pessimistic Rank-Breaking (PRB), an
algorithm that combines rank-breaking with pessimistic estimation. We prove
that PRB is nearly minimax optimal by establishing the tight suboptimality
upper bound and a nearly matching lower bound. This further shows that ""optimal
item coverage"" - where each item in the optimal assortment appears sufficiently
often in the historical data - is both sufficient and necessary for efficient
offline learning. This significantly relaxes the previous requirement of
observing the complete optimal assortment in the data. Our results provide
fundamental insights into the data requirements for offline assortment
optimization under the MNL model.",http://arxiv.org/abs/2502.06777v1,Recommendation System,"assortment, optimal, offline, data, optimization"
Towards Internet-Scale Training For Agents,"The predominant approach for training web navigation agents gathers human
demonstrations for a set of popular websites and hand-written tasks, but it is
becoming clear that human data are an inefficient resource. We develop a
pipeline to facilitate Internet-scale training for agents without laborious
human annotations. In the first stage, an LLM generates tasks for 150k diverse
websites. In the next stage, LLM agents complete tasks and produce
trajectories. In the final stage, an LLM reviews the trajectories and judges
their success. Language models are competitive with human annotators, detecting
and filtering out harmful content with an accuracy of 97%, generating feasible
tasks with an 89% rate, and judging successful trajectories with an 82.6%
accuracy. Scaling the pipeline, agents based on Llama 3.1 70B solve 16.7% of
tasks for 150k sites. Training on the data generated by our pipeline is
competitive with training on human demonstrations. In data-limited settings
derived from Mind2Web and WebLINX, we improve Step Accuracy by up to +89.5% and
+122.1% respectively for agents trained on mixtures of data from our pipeline,
and human data. When training agents with all available human data from these
benchmarks, agents fail to generalize to diverse real sites, and adding our
data improves their generalization by +149.0% for WebLINX and +156.3% for
Mind2Web. Code will be available at: data-for-agents.github.io.",http://arxiv.org/abs/2502.06776v1,Reinforcement Learning,"agents, human, data, training, tasks"
Enhancing Performance of Explainable AI Models with Constrained Concept Refinement,"The trade-off between accuracy and interpretability has long been a challenge
in machine learning (ML). This tension is particularly significant for emerging
interpretable-by-design methods, which aim to redesign ML algorithms for
trustworthy interpretability but often sacrifice accuracy in the process. In
this paper, we address this gap by investigating the impact of deviations in
concept representations-an essential component of interpretable models-on
prediction performance and propose a novel framework to mitigate these effects.
The framework builds on the principle of optimizing concept embeddings under
constraints that preserve interpretability. Using a generative model as a
test-bed, we rigorously prove that our algorithm achieves zero loss while
progressively enhancing the interpretability of the resulting model.
Additionally, we evaluate the practical performance of our proposed framework
in generating explainable predictions for image classification tasks across
various benchmarks. Compared to existing explainable methods, our approach not
only improves prediction accuracy while preserving model interpretability
across various large-scale benchmarks but also achieves this with significantly
lower computational cost.",http://arxiv.org/abs/2502.06775v1,Recommendation System,"interpretability, accuracy, framework, model, ml"
ENFORCE: Exact Nonlinear Constrained Learning with Adaptive-depth Neural Projection,"Ensuring neural networks adhere to domain-specific constraints is crucial for
addressing safety and ethical concerns while also enhancing prediction
accuracy. Despite the nonlinear nature of most real-world tasks, existing
methods are predominantly limited to affine or convex constraints. We introduce
ENFORCE, a neural network architecture that guarantees predictions to satisfy
nonlinear constraints exactly. ENFORCE is trained with standard unconstrained
gradient-based optimizers (e.g., Adam) and leverages autodifferentiation and
local neural projections to enforce any $\mathcal{C}^1$ constraint to arbitrary
tolerance $\epsilon$. We build an adaptive-depth neural projection (AdaNP)
module that dynamically adjusts its complexity to suit the specific problem and
the required tolerance levels. ENFORCE guarantees satisfaction of equality
constraints that are nonlinear in both inputs and outputs of the neural network
with minimal (and adjustable) computational cost.",http://arxiv.org/abs/2502.06774v2,Recommendation System,"neural, constraints, enforce, nonlinear, specific"
On the Emergence of Thinking in LLMs I: Searching for the Right Intuition,"Recent AI advancements, such as OpenAI's new models, are transforming LLMs
into LRMs (Large Reasoning Models) that perform reasoning during inference,
taking extra time and compute for higher-quality outputs. We aim to uncover the
algorithmic framework for training LRMs. Methods like self-consistency, PRM,
and AlphaZero suggest reasoning as guided search. We ask: what is the simplest,
most scalable way to enable search in LLMs?
  We propose a post-training framework called Reinforcement Learning via
Self-Play (RLSP). RLSP involves three steps: (1) supervised fine-tuning with
human or synthetic demonstrations of the reasoning process, (2) using an
exploration reward signal to encourage diverse and efficient reasoning
behaviors, and (3) RL training with an outcome verifier to ensure correctness
while preventing reward hacking. Our key innovation is to decouple exploration
and correctness signals during PPO training, carefully balancing them to
improve performance and efficiency.
  Empirical studies in the math domain show that RLSP improves reasoning. On
the Llama-3.1-8B-Instruct model, RLSP can boost performance by 23% in MATH-500
test set; On AIME 2024 math problems, Qwen2.5-32B-Instruct improved by 10% due
to RLSP. However, a more important finding of this work is that the models
trained using RLSP, even with the simplest exploration reward that encourages
the model to take more intermediate steps, showed several emergent behaviors
such as backtracking, exploration of ideas, and verification. These findings
demonstrate that RLSP framework might be enough to enable emergence of complex
reasoning abilities in LLMs when scaled. Lastly, we propose a theory as to why
RLSP search strategy is more suitable for LLMs inspired by a remarkable result
that says CoT provably increases computational power of LLMs, which grows as
the number of steps in CoT \cite{li2024chain,merrill2023expresssive}.",http://arxiv.org/abs/2502.06773v1,Reinforcement Learning,"rlsp, reasoning, llms, training, exploration"
Neighborhood-Order Learning Graph Attention Network for Fake News Detection,"Fake news detection is a significant challenge in the digital age, which has
become increasingly important with the proliferation of social media and online
communication networks. Graph Neural Networks (GNN)-based methods have shown
high potential in analyzing graph-structured data for this problem. However, a
major limitation in conventional GNN architectures is their inability to
effectively utilize information from neighbors beyond the network's layer
depth, which can reduce the model's accuracy and effectiveness. In this paper,
we propose a novel model called Neighborhood-Order Learning Graph Attention
Network (NOL-GAT) for fake news detection. This model allows each node in each
layer to independently learn its optimal neighborhood order. By doing so, the
model can purposefully and efficiently extract critical information from
distant neighbors. The NOL-GAT architecture consists of two main components: a
Hop Network that determines the optimal neighborhood order and an Embedding
Network that updates node embeddings using these optimal neighborhoods. To
evaluate the model's performance, experiments are conducted on various fake
news datasets. Results demonstrate that NOL-GAT significantly outperforms
baseline models in metrics such as accuracy and F1-score, particularly in
scenarios with limited labeled data. Features such as mitigating the
over-squashing problem, improving information flow, and reducing computational
complexity further highlight the advantages of the proposed model.",http://arxiv.org/abs/2502.06927v1,Recommendation System,"model, network, fake, news, graph"
Unsupervised Particle Tracking with Neuromorphic Computing,"We study the application of a neural network architecture for identifying
charged particle trajectories via unsupervised learning of delays and synaptic
weights using a spike-time-dependent plasticity rule. In the considered model,
the neurons receive time-encoded information on the position of particle hits
in a tracking detector for a particle collider, modeled according to the
geometry of the Compact Muon Solenoid Phase II detector. We show how a spiking
neural network is capable of successfully identifying in a completely
unsupervised way the signal left by charged particles in the presence of
conspicuous noise from accidental or combinatorial hits. These results open the
way to applications of neuromorphic computing to particle tracking, motivating
further studies into its potential for real-time, low-power particle tracking
in future high-energy physics experiments.",http://arxiv.org/abs/2502.06771v1,Recommendation System,"particle, time, tracking, neural, network"
"Train for the Worst, Plan for the Best: Understanding Token Ordering in Masked Diffusions","In recent years, masked diffusion models (MDMs) have emerged as a promising
alternative approach for generative modeling over discrete domains. Compared to
autoregressive models (ARMs), MDMs trade off complexity at training time with
flexibility at inference time. At training time, they must learn to solve an
exponentially large number of infilling problems, but at inference time, they
can decode tokens in essentially arbitrary order. In this work, we closely
examine these two competing effects. On the training front, we theoretically
and empirically demonstrate that MDMs indeed train on computationally
intractable subproblems compared to their autoregressive counterparts. On the
inference front, we show that a suitable strategy for adaptively choosing the
token decoding order significantly enhances the capabilities of MDMs, allowing
them to sidestep hard subproblems. On logic puzzles like Sudoku, we show that
adaptive inference can boost solving accuracy in pretrained MDMs from $<7$% to
$\approx 90$%, even outperforming ARMs with $7\times$ as many parameters and
that were explicitly trained via teacher forcing to learn the right order of
decoding.",http://arxiv.org/abs/2502.06768v1,Reinforcement Learning,"mdms, time, inference, training, order"
Are all models wrong? Fundamental limits in distribution-free empirical model falsification,"In statistics and machine learning, when we train a fitted model on available
data, we typically want to ensure that we are searching within a model class
that contains at least one accurate model -- that is, we would like to ensure
an upper bound on the model class risk (the lowest possible risk that can be
attained by any model in the class). However, it is also of interest to
establish lower bounds on the model class risk, for instance so that we can
determine whether our fitted model is at least approximately optimal within the
class, or, so that we can decide whether the model class is unsuitable for the
particular task at hand. Particularly in the setting of interpolation learning
where machine learning models are trained to reach zero error on the training
data, we might ask if, at the very least, a positive lower bound on the model
class risk is possible -- or are we unable to detect that ""all models are
wrong""? In this work, we answer these questions in a distribution-free setting
by establishing a model-agnostic, fundamental hardness result for the problem
of constructing a lower bound on the best test error achievable over a model
class, and examine its implications on specific model classes such as
tree-based methods and linear regression.",http://arxiv.org/abs/2502.06765v1,Recommendation System,"model, class, risk, learning, bound"
History-Guided Video Diffusion,"Classifier-free guidance (CFG) is a key technique for improving conditional
generation in diffusion models, enabling more accurate control while enhancing
sample quality. It is natural to extend this technique to video diffusion,
which generates video conditioned on a variable number of context frames,
collectively referred to as history. However, we find two key challenges to
guiding with variable-length history: architectures that only support
fixed-size conditioning, and the empirical observation that CFG-style history
dropout performs poorly. To address this, we propose the Diffusion Forcing
Transformer (DFoT), a video diffusion architecture and theoretically grounded
training objective that jointly enable conditioning on a flexible number of
history frames. We then introduce History Guidance, a family of guidance
methods uniquely enabled by DFoT. We show that its simplest form, vanilla
history guidance, already significantly improves video generation quality and
temporal consistency. A more advanced method, history guidance across time and
frequency further enhances motion dynamics, enables compositional
generalization to out-of-distribution history, and can stably roll out
extremely long videos. Website: https://boyuan.space/history-guidance",http://arxiv.org/abs/2502.06764v1,Recommendation System,"history, guidance, diffusion, video, cfg"
"When, Where and Why to Average Weights?","Averaging checkpoints along the training trajectory is a simple yet powerful
approach to improve the generalization performance of Machine Learning models
and reduce training time. Motivated by these potential gains, and in an effort
to fairly and thoroughly benchmark this technique, we present an extensive
evaluation of averaging techniques in modern Deep Learning, which we perform
using AlgoPerf \citep{dahl_benchmarking_2023}, a large-scale benchmark for
optimization algorithms. We investigate whether weight averaging can reduce
training time, improve generalization, and replace learning rate decay, as
suggested by recent literature. Our evaluation across seven architectures and
datasets reveals that averaging significantly accelerates training and yields
considerable efficiency gains, at the price of a minimal implementation and
memory cost, while mildly improving generalization across all considered
workloads. Finally, we explore the relationship between averaging and learning
rate annealing and show how to optimally combine the two to achieve the best
performances.",http://arxiv.org/abs/2502.06761v1,Recommendation System,"averaging, training, learning, generalization, improve"
Rationalization Models for Text-to-SQL,"We introduce a framework for generating Chain-of-Thought (CoT) rationales to
enhance text-to-SQL model fine-tuning. These rationales consist of intermediate
SQL statements and explanations, serving as incremental steps toward
constructing the final SQL query. The process begins with manually annotating a
small set of examples, which are then used to prompt a large language model in
an iterative, dynamic few-shot knowledge distillation procedure from a teacher
model. A rationalization model is subsequently trained on the validated
decomposed queries, enabling extensive synthetic CoT annotations for
text-to-SQL datasets. To evaluate the approach, we fine-tune small language
models with and without these rationales on the BIRD dataset. Results indicate
that step-by-step query generation improves execution accuracy, especially for
moderately and highly complex queries, while also enhancing explainability.",http://arxiv.org/abs/2502.06759v1,Reinforcement Learning,"sql, model, rationales, cot, text"
SAMRefiner: Taming Segment Anything Model for Universal Mask Refinement,"In this paper, we explore a principal way to enhance the quality of widely
pre-existing coarse masks, enabling them to serve as reliable training data for
segmentation models to reduce the annotation cost. In contrast to prior
refinement techniques that are tailored to specific models or tasks in a
close-world manner, we propose SAMRefiner, a universal and efficient approach
by adapting SAM to the mask refinement task. The core technique of our model is
the noise-tolerant prompting scheme. Specifically, we introduce a multi-prompt
excavation strategy to mine diverse input prompts for SAM (i.e.,
distance-guided points, context-aware elastic bounding boxes, and
Gaussian-style masks) from initial coarse masks. These prompts can collaborate
with each other to mitigate the effect of defects in coarse masks. In
particular, considering the difficulty of SAM to handle the multi-object case
in semantic segmentation, we introduce a split-then-merge (STM) pipeline.
Additionally, we extend our method to SAMRefiner++ by introducing an additional
IoU adaption step to further boost the performance of the generic SAMRefiner on
the target dataset. This step is self-boosted and requires no additional
annotation. The proposed framework is versatile and can flexibly cooperate with
existing segmentation methods. We evaluate our mask framework on a wide range
of benchmarks under different settings, demonstrating better accuracy and
efficiency. SAMRefiner holds significant potential to expedite the evolution of
refinement tools. Our code is available at
https://github.com/linyq2117/SAMRefiner.",http://arxiv.org/abs/2502.06756v1,Reinforcement Learning,"masks, coarse, segmentation, refinement, samrefiner"
Sparse Autoencoders for Scientifically Rigorous Interpretation of Vision Models,"To truly understand vision models, we must not only interpret their learned
features but also validate these interpretations through controlled
experiments. Current approaches either provide interpretable features without
the ability to test their causal influence, or enable model editing without
interpretable controls. We present a unified framework using sparse
autoencoders (SAEs) that bridges this gap, allowing us to discover
human-interpretable visual features and precisely manipulate them to test
hypotheses about model behavior. By applying our method to state-of-the-art
vision models, we reveal key differences in the semantic abstractions learned
by models with different pre-training objectives. We then demonstrate the
practical usage of our framework through controlled interventions across
multiple vision tasks. We show that SAEs can reliably identify and manipulate
interpretable visual features without model re-training, providing a powerful
tool for understanding and controlling vision model behavior. We provide code,
demos and models on our project website: https://osu-nlp-group.github.io/SAE-V.",http://arxiv.org/abs/2502.06755v1,Recommendation System,"vision, models, features, interpretable, model"
Case for a unified surrogate modelling framework in the age of AI,"Surrogate models are widely used in natural sciences, engineering, and
machine learning to approximate complex systems and reduce computational costs.
However, the current landscape lacks standardisation across key stages of the
pipeline, including data collection, sampling design, model class selection,
evaluation metrics, and downstream task performance analysis. This
fragmentation limits reproducibility, reliability, and cross-domain
applicability. The issue has only been exacerbated by the AI revolution and a
new suite of surrogate model classes that it offers. In this position paper, we
argue for the urgent need for a unified framework to guide the development and
evaluation of surrogate models. We outline essential steps for constructing a
comprehensive pipeline and discuss alternative perspectives, such as the
benefits of domain-specific frameworks. By advocating for a standardised
approach, this paper seeks to improve the reliability of surrogate modelling,
foster cross-disciplinary knowledge transfer, and, as a result, accelerate
scientific progress.",http://arxiv.org/abs/2502.06753v1,Recommendation System,"surrogate, models, pipeline, model, evaluation"
What makes a good feedforward computational graph?,"As implied by the plethora of literature on graph rewiring, the choice of
computational graph employed by a neural network can make a significant impact
on its downstream performance. Certain effects related to the computational
graph, such as under-reaching and over-squashing, may even render the model
incapable of learning certain functions. Most of these effects have only been
thoroughly studied in the domain of undirected graphs; however, recent years
have seen a significant rise in interest in feedforward computational graphs:
directed graphs without any back edges. In this paper, we study the desirable
properties of a feedforward computational graph, discovering two important
complementary measures: fidelity and mixing time, and evaluating a few popular
choices of graphs through the lens of these measures. Our study is backed by
both theoretical analyses of the metrics' asymptotic behaviour for various
graphs, as well as correlating these metrics to the performance of trained
neural network models using the corresponding graphs.",http://arxiv.org/abs/2502.06751v1,Recommendation System,"graphs, graph, computational, neural, network"
Accelerating Data Processing and Benchmarking of AI Models for Pathology,"Advances in foundation modeling have reshaped computational pathology.
However, the increasing number of available models and lack of standardized
benchmarks make it increasingly complex to assess their strengths, limitations,
and potential for further development. To address these challenges, we
introduce a new suite of software tools for whole-slide image processing,
foundation model benchmarking, and curated publicly available tasks. We
anticipate that these resources will promote transparency, reproducibility, and
continued progress in the field.",http://arxiv.org/abs/2502.06750v1,Recommendation System,"foundation, available, advances, modeling, reshaped"
Occam's model: Selecting simpler representations for better transferability estimation,"Fine-tuning models that have been pre-trained on large datasets has become a
cornerstone of modern machine learning workflows. With the widespread
availability of online model repositories, such as Hugging Face, it is now
easier than ever to fine-tune pre-trained models for specific tasks. This
raises a critical question: which pre-trained model is most suitable for a
given task? This problem is called transferability estimation. In this work, we
introduce two novel and effective metrics for estimating the transferability of
pre-trained models. Our approach is grounded in viewing transferability as a
measure of how easily a pre-trained model's representations can be trained to
separate target classes, providing a unique perspective on transferability
estimation. We rigorously evaluate the proposed metrics against
state-of-the-art alternatives across diverse problem settings, demonstrating
their robustness and practical utility. Additionally, we present theoretical
insights that explain our metrics' efficacy and adaptability to various
scenarios. We experimentally show that our metrics increase Kendall's Tau by up
to 32% compared to the state-of-the-art baselines.",http://arxiv.org/abs/2502.06925v1,Recommendation System,"trained, pre, transferability, metrics, models"
Incentivizing Desirable Effort Profiles in Strategic Classification: The Role of Causality and Uncertainty,"We study strategic classification in binary decision-making settings where
agents can modify their features in order to improve their classification
outcomes. Importantly, our work considers the causal structure across different
features, acknowledging that effort in a given feature may affect other
features. The main goal of our work is to understand \emph{when and how much
agent effort is invested towards desirable features}, and how this is
influenced by the deployed classifier, the causal structure of the agent's
features, their ability to modify them, and the information available to the
agent about the classifier and the feature causal graph.
  In the complete information case, when agents know the classifier and the
causal structure of the problem, we derive conditions ensuring that rational
agents focus on features favored by the principal. We show that designing
classifiers to induce desirable behavior is generally non-convex, though
tractable in special cases. We also extend our analysis to settings where
agents have incomplete information about the classifier or the causal graph.
While optimal effort selection is again a non-convex problem under general
uncertainty, we highlight special cases of partial uncertainty where this
selection problem becomes tractable. Our results indicate that uncertainty
drives agents to favor features with higher expected importance and lower
variance, potentially misaligning with principal preferences. Finally,
numerical experiments based on a cardiovascular disease risk study illustrate
how to incentivize desirable modifications under uncertainty.",http://arxiv.org/abs/2502.06749v1,Recommendation System,"features, agents, causal, classifier, uncertainty"
Wandering around: A bioinspired approach to visual attention through object motion sensitivity,"Active vision enables dynamic visual perception, offering an alternative to
static feedforward architectures in computer vision, which rely on large
datasets and high computational resources. Biological selective attention
mechanisms allow agents to focus on salient Regions of Interest (ROIs),
reducing computational demand while maintaining real-time responsiveness.
Event-based cameras, inspired by the mammalian retina, enhance this capability
by capturing asynchronous scene changes enabling efficient low-latency
processing. To distinguish moving objects while the event-based camera is in
motion the agent requires an object motion segmentation mechanism to accurately
detect targets and center them in the visual field (fovea). Integrating
event-based sensors with neuromorphic algorithms represents a paradigm shift,
using Spiking Neural Networks to parallelize computation and adapt to dynamic
environments. This work presents a Spiking Convolutional Neural Network
bioinspired attention system for selective attention through object motion
sensitivity. The system generates events via fixational eye movements using a
Dynamic Vision Sensor integrated into the Speck neuromorphic hardware, mounted
on a Pan-Tilt unit, to identify the ROI and saccade toward it. The system,
characterized using ideal gratings and benchmarked against the Event Camera
Motion Segmentation Dataset, reaches a mean IoU of 82.2% and a mean SSIM of 96%
in multi-object motion segmentation. The detection of salient objects reaches
88.8% accuracy in office scenarios and 89.8% in low-light conditions on the
Event-Assisted Low-Light Video Object Segmentation Dataset. A real-time
demonstrator shows the system's 0.12 s response to dynamic scenes. Its
learning-free design ensures robustness across perceptual scenes, making it a
reliable foundation for real-time robotic applications serving as a basis for
more complex architectures.",http://arxiv.org/abs/2502.06747v1,Computer Vision,"event, motion, dynamic, object, segmentation"
Deep Learning in Automated Power Line Inspection: A Review,"In recent years, power line maintenance has seen a paradigm shift by moving
towards computer vision-powered automated inspection. The utilization of an
extensive collection of videos and images has become essential for maintaining
the reliability, safety, and sustainability of electricity transmission. A
significant focus on applying deep learning techniques for enhancing power line
inspection processes has been observed in recent research. A comprehensive
review of existing studies has been conducted in this paper, to aid researchers
and industries in developing improved deep learning-based systems for analyzing
power line data. The conventional steps of data analysis in power line
inspections have been examined, and the body of current research has been
systematically categorized into two main areas: the detection of components and
the diagnosis of faults. A detailed summary of the diverse methods and
techniques employed in these areas has been encapsulated, providing insights
into their functionality and use cases. Special attention has been given to the
exploration of deep learning-based methodologies for the analysis of power line
inspection data, with an exposition of their fundamental principles and
practical applications. Moreover, a vision for future research directions has
been outlined, highlighting the need for advancements such as edge-cloud
collaboration, and multi-modal analysis among others. Thus, this paper serves
as a comprehensive resource for researchers delving into deep learning for
power line analysis, illuminating the extent of current knowledge and the
potential areas for future investigation.",http://arxiv.org/abs/2502.07826v1,Computer Vision,"power, line, deep, learning, analysis"
Gradient Multi-Normalization for Stateless and Scalable LLM Training,"Training large language models (LLMs) typically relies on adaptive optimizers
like Adam (Kingma & Ba, 2015) which store additional state information to
accelerate convergence but incur significant memory overhead. Recent efforts,
such as SWAN (Ma et al., 2024) address this by eliminating the need for
optimizer states while achieving performance comparable to Adam via a
multi-step preprocessing procedure applied to instantaneous gradients.
Motivated by the success of SWAN, we introduce a novel framework for designing
stateless optimizers that normalizes stochastic gradients according to multiple
norms. To achieve this, we propose a simple alternating scheme to enforce the
normalization of gradients w.r.t these norms. We show that our procedure can
produce, up to an arbitrary precision, a fixed-point of the problem, and that
SWAN is a particular instance of our approach with carefully chosen norms,
providing a deeper understanding of its design. However, SWAN's computationally
expensive whitening/orthogonalization step limit its practicality for large
LMs. Using our principled perspective, we develop of a more efficient,
scalable, and practical stateless optimizer. Our algorithm relaxes the
properties of SWAN, significantly reducing its computational cost while
retaining its memory efficiency, making it applicable to training large-scale
models. Experiments on pre-training LLaMA models with up to 1 billion
parameters demonstrate a 3X speedup over Adam with significantly reduced memory
requirements, outperforming other memory-efficient baselines.",http://arxiv.org/abs/2502.06742v1,Natural Language Processing,"swan, memory, training, large, models"
ViSIR: Vision Transformer Single Image Reconstruction Method for Earth System Models,"Purpose: Earth system models (ESMs) integrate the interactions of the
atmosphere, ocean, land, ice, and biosphere to estimate the state of regional
and global climate under a wide variety of conditions. The ESMs are highly
complex, and thus, deep neural network architectures are used to model the
complexity and store the down-sampled data. In this paper, we propose the
Vision Transformer Sinusoidal Representation Networks (ViSIR) to improve the
single image SR (SR) reconstruction task for the ESM data.
  Methods: ViSIR combines the SR capability of Vision Transformers (ViT) with
the high-frequency detail preservation of the Sinusoidal Representation Network
(SIREN) to address the spectral bias observed in SR tasks.
  Results: The ViSIR outperforms ViT by 4.1 dB, SIREN by 7.5 dB, and
SR-Generative Adversarial (SR-GANs) by 7.1dB PSNR on average for three
different measurements.
  Conclusion: The proposed ViSIR is evaluated and compared with
state-of-the-art methods. The results show that the proposed algorithm is
outperforming other methods in terms of Mean Square Error(MSE),
Peak-Signal-to-Noise-Ratio(PSNR), and Structural Similarity Index
Measure(SSIM).",http://arxiv.org/abs/2502.06741v2,Recommendation System,"sr, visir, methods, esms, state"
A note on the physical interpretation of neural PDE's,"We highlight a formal and substantial analogy between Machine Learning (ML)
algorithms and discrete dynamical systems (DDS) in relaxation form. The analogy
offers a transparent interpretation of the weights in terms of physical
information-propagation processes and identifies the model function of the
forward ML step with the local attractor of the corresponding discrete
dynamics. Besides improving the explainability of current ML applications, this
analogy may also facilitate the development of a new class ML algorithms with a
reduced number of weights.",http://arxiv.org/abs/2502.06739v1,Recommendation System,"ml, analogy, algorithms, discrete, weights"
Resurrecting saturated LLM benchmarks with adversarial encoding,"Recent work showed that small changes in benchmark questions can reduce LLMs'
reasoning and recall. We explore two such changes: pairing questions and adding
more answer options, on three benchmarks: WMDP-bio, GPQA, and MMLU variants. We
find that for more capable models, these predictably reduce performance,
essentially heightening the performance ceiling of a benchmark and unsaturating
it again. We suggest this approach can resurrect old benchmarks.",http://arxiv.org/abs/2502.06738v1,Recommendation System,"changes, benchmark, questions, reduce, benchmarks"
VersaPRM: Multi-Domain Process Reward Model via Synthetic Reasoning Data,"Process Reward Models (PRMs) have proven effective at enhancing mathematical
reasoning for Large Language Models (LLMs) by leveraging increased
inference-time computation. However, they are predominantly trained on
mathematical data and their generalizability to non-mathematical domains has
not been rigorously studied. In response, this work first shows that current
PRMs have poor performance in other domains. To address this limitation, we
introduce VersaPRM, a multi-domain PRM trained on synthetic reasoning data
generated using our novel data generation and annotation method. VersaPRM
achieves consistent performance gains across diverse domains. For instance, in
the MMLU-Pro category of Law, VersaPRM via weighted majority voting, achieves a
7.9% performance gain over the majority voting baseline -- surpassing
Qwen2.5-Math-PRM's gain of 1.3%. We further contribute to the community by
open-sourcing all data, code and models for VersaPRM.",http://arxiv.org/abs/2502.06737v1,Reinforcement Learning,"data, versaprm, models, mathematical, domains"
Low-power Spike-based Wearable Analytics on RRAM Crossbars,"This work introduces a spike-based wearable analytics system utilizing
Spiking Neural Networks (SNNs) deployed on an In-memory Computing engine based
on RRAM crossbars, which are known for their compactness and energy-efficiency.
Given the hardware constraints and noise characteristics of the underlying RRAM
crossbars, we propose online adaptation of pre-trained SNNs in real-time using
Direct Feedback Alignment (DFA) against traditional backpropagation (BP).
Direct Feedback Alignment (DFA) learning, that allows layer-parallel gradient
computations, acts as a fast, energy & area-efficient method for online
adaptation of SNNs on RRAM crossbars, unleashing better algorithmic performance
against those adapted using BP. Through extensive simulations using our
in-house hardware evaluation engine called DFA_Sim, we find that DFA achieves
upto 64.1% lower energy consumption, 10.1% lower area overhead, and a 2.1x
reduction in latency compared to BP, while delivering upto 7.55% higher
inference accuracy on human activity recognition (HAR) tasks.",http://arxiv.org/abs/2502.06736v1,Recommendation System,"snns, rram, crossbars, energy, dfa"
Enhancing Pneumonia Diagnosis and Severity Assessment through Deep Learning: A Comprehensive Approach Integrating CNN Classification and Infection Segmentation,"Lung disease poses a substantial global health challenge, with pneumonia
being a prevalent concern. This research focuses on leveraging deep learning
techniques to detect and assess pneumonia, addressing two interconnected
objectives. Initially, Convolutional Neural Network (CNN) models are introduced
for pneumonia classification, emphasizing the necessity of comprehensive
diagnostic assessments considering COVID-19. Subsequently, the study advocates
for the utilization of deep learning-based segmentation to determine the
severity of infection. This dual-pronged approach offers valuable insights for
medical professionals, facilitating a more nuanced understanding and effective
treatment of pneumonia. Integrating deep learning aims to elevate the accuracy
and efficiency of pneumonia detection, thereby contributing to enhanced
healthcare outcomes on a global scale.",http://arxiv.org/abs/2502.06735v1,Recommendation System,"pneumonia, deep, learning, global, lung"
Señorita-2M: A High-Quality Instruction-based Dataset for General Video Editing by Video Specialists,"Recent advancements in video generation have spurred the development of video
editing techniques, which can be divided into inversion-based and end-to-end
methods. However, current video editing methods still suffer from several
challenges. Inversion-based methods, though training-free and flexible, are
time-consuming during inference, struggle with fine-grained editing
instructions, and produce artifacts and jitter. On the other hand, end-to-end
methods, which rely on edited video pairs for training, offer faster inference
speeds but often produce poor editing results due to a lack of high-quality
training video pairs. In this paper, to close the gap in end-to-end methods, we
introduce Se\~norita-2M, a high-quality video editing dataset. Se\~norita-2M
consists of approximately 2 millions of video editing pairs. It is built by
crafting four high-quality, specialized video editing models, each crafted and
trained by our team to achieve state-of-the-art editing results. We also
propose a filtering pipeline to eliminate poorly edited video pairs.
Furthermore, we explore common video editing architectures to identify the most
effective structure based on current pre-trained generative model. Extensive
experiments show that our dataset can help to yield remarkably high-quality
video editing results. More details are available at
https://senorita.github.io.",http://arxiv.org/abs/2502.06734v1,Recommendation System,"video, editing, end, methods, pairs"
Dynamic Loss-Based Sample Reweighting for Improved Large Language Model Pretraining,"Pretraining large language models (LLMs) on vast and heterogeneous datasets
is crucial for achieving state-of-the-art performance across diverse downstream
tasks. However, current training paradigms treat all samples equally,
overlooking the importance or relevance of individual samples throughout the
training process. Existing reweighting strategies, which primarily focus on
group-level data importance, fail to leverage fine-grained instance-level
information and do not adapt dynamically to individual sample importance as
training progresses. In this paper, we introduce novel algorithms for dynamic,
instance-level data reweighting aimed at improving both the efficiency and
effectiveness of LLM pretraining. Our methods adjust the weight of each
training sample based on its loss value in an online fashion, allowing the
model to dynamically focus on more informative or important samples at the
current training stage. In particular, our framework allows us to
systematically devise reweighting strategies deprioritizing redundant or
uninformative data, which we find tend to work best. Furthermore, we develop a
new theoretical framework for analyzing the impact of loss-based reweighting on
the convergence of gradient-based optimization, providing the first formal
characterization of how these strategies affect convergence bounds. We
empirically validate our approach across a spectrum of tasks, from pretraining
7B and 1.4B parameter LLMs to smaller-scale language models and linear
regression problems, demonstrating that our loss-based reweighting approach can
lead to faster convergence and significantly improved performance.",http://arxiv.org/abs/2502.06733v1,Recommendation System,"training, reweighting, based, pretraining, samples"
FlexDeMo: Decoupled Momentum Optimization for Fully and Hybrid Sharded Training,"Training large neural network models requires extensive computational
resources, often distributed across several nodes and accelerators. Recent
findings suggest that it may be sufficient to only exchange the fast moving
components of the gradients, while accumulating momentum locally (Decoupled
Momentum, or DeMo). However, when considering larger models that do not fit on
a single accelerate, the exchange of gradient information and the integration
of DeMo needs to be reconsidered. Here, we propose employing a hybrid strategy,
FlexDeMo, whereby nodes fully synchronize locally between different GPUs and
inter-node communication is improved through only using the fast-moving
components. This effectively combines previous hybrid sharding strategies with
the advantages of decoupled momentum. Our experimental results show that
FlexDeMo is on par with AdamW in terms of validation loss, demonstrating its
viability.",http://arxiv.org/abs/2502.06728v1,Recommendation System,"momentum, models, nodes, exchange, fast"
Application of Artificial Intelligence (AI) in Civil Engineering,"Hard computing generally deals with precise data, which provides ideal
solutions to problems. However, in the civil engineering field, amongst other
disciplines, that is not always the case as real-world systems are continuously
changing. Here lies the need to explore soft computing methods and artificial
intelligence to solve civil engineering shortcomings. The integration of
advanced computational models, including Artificial Neural Networks (ANNs),
Fuzzy Logic, Genetic Algorithms (GAs), and Probabilistic Reasoning, has
revolutionized the domain of civil engineering. These models have significantly
advanced diverse sub-fields by offering innovative solutions and improved
analysis capabilities. Sub-fields such as: slope stability analysis, bearing
capacity, water quality and treatment, transportation systems, air quality,
structural materials, etc. ANNs predict non-linearities and provide accurate
estimates. Fuzzy logic uses an efficient decision-making process to provide a
more precise assessment of systems. Lastly, while GAs optimizes models (based
on evolutionary processes) for better outcomes, probabilistic reasoning lowers
their statistical uncertainties.",http://arxiv.org/abs/2502.06727v1,Recommendation System,"civil, engineering, systems, models, computing"
Gaussian Approximation and Multiplier Bootstrap for Stochastic Gradient Descent,"In this paper, we establish non-asymptotic convergence rates in the central
limit theorem for Polyak-Ruppert-averaged iterates of stochastic gradient
descent (SGD). Our analysis builds on the result of the Gaussian approximation
for nonlinear statistics of independent random variables of Shao and Zhang
(2022). Using this result, we prove the non-asymptotic validity of the
multiplier bootstrap for constructing the confidence sets for the optimal
solution of an optimization problem. In particular, our approach avoids the
need to approximate the limiting covariance of Polyak-Ruppert SGD iterates,
which allows us to derive approximation rates in convex distance of order up to
$1/\sqrt{n}$.",http://arxiv.org/abs/2502.06719v1,Recommendation System,"non, asymptotic, rates, polyak, ruppert"
Learning Musical Representations for Music Performance Question Answering,"Music performances are representative scenarios for audio-visual modeling.
Unlike common scenarios with sparse audio, music performances continuously
involve dense audio signals throughout. While existing multimodal learning
methods on the audio-video QA demonstrate impressive capabilities in general
scenarios, they are incapable of dealing with fundamental problems within the
music performances: they underexplore the interaction between the multimodal
signals in performance and fail to consider the distinctive characteristics of
instruments and music. Therefore, existing methods tend to answer questions
regarding musical performances inaccurately. To bridge the above research gaps,
(i) given the intricate multimodal interconnectivity inherent to music data,
our primary backbone is designed to incorporate multimodal interactions within
the context of music; (ii) to enable the model to learn music characteristics,
we annotate and release rhythmic and music sources in the current music
datasets; (iii) for time-aware audio-visual modeling, we align the model's
music predictions with the temporal dimension. Our experiments show
state-of-the-art effects on the Music AVQA datasets. Our code is available at
https://github.com/xid32/Amuse.",http://arxiv.org/abs/2502.06710v1,Recommendation System,"music, audio, performances, multimodal, scenarios"
TEMSET-24K: Densely Annotated Dataset for Indexing Multipart Endoscopic Videos using Surgical Timeline Segmentation,"Indexing endoscopic surgical videos is vital in surgical data science,
forming the basis for systematic retrospective analysis and clinical
performance evaluation. Despite its significance, current video analytics rely
on manual indexing, a time-consuming process. Advances in computer vision,
particularly deep learning, offer automation potential, yet progress is limited
by the lack of publicly available, densely annotated surgical datasets. To
address this, we present TEMSET-24K, an open-source dataset comprising 24,306
trans-anal endoscopic microsurgery (TEMS) video micro-clips. Each clip is
meticulously annotated by clinical experts using a novel hierarchical labeling
taxonomy encompassing phase, task, and action triplets, capturing intricate
surgical workflows. To validate this dataset, we benchmarked deep learning
models, including transformer-based architectures. Our in silico evaluation
demonstrates high accuracy (up to 0.99) and F1 scores (up to 0.99) for key
phases like Setup and Suturing. The STALNet model, tested with ConvNeXt, ViT,
and SWIN V2 encoders, consistently segmented well-represented phases.
TEMSET-24K provides a critical benchmark, propelling state-of-the-art solutions
in surgical data science.",http://arxiv.org/abs/2502.06708v1,Computer Vision,"surgical, indexing, endoscopic, data, science"
XAMBA: Enabling Efficient State Space Models on Resource-Constrained Neural Processing Units,"State-Space Models (SSMs) have emerged as efficient alternatives to
transformers for sequential data tasks, offering linear or near-linear
scalability with sequence length, making them ideal for long-sequence
applications in NLP, vision, and edge AI, including real-time transcription,
translation, and contextual search. These applications require lightweight,
high-performance models for deployment on resource-constrained devices like
laptops and PCs. Designing specialized accelerators for every emerging neural
network is costly and impractical; instead, optimizing models for existing NPUs
in AI PCs provides a scalable solution. To this end, we propose XAMBA, the
first framework to enable and optimize SSMs on commercial off-the-shelf (COTS)
state-of-the-art (SOTA) NPUs. XAMBA follows a three-step methodology: (1)
enabling SSMs on NPUs, (2) optimizing performance to meet KPI requirements, and
(3) trading accuracy for additional performance gains. After enabling SSMs on
NPUs, XAMBA mitigates key bottlenecks using CumBA and ReduBA, replacing
sequential CumSum and ReduceSum operations with matrix-based computations,
significantly improving execution speed and memory efficiency. Additionally,
ActiBA enhances performance by approximating expensive activation functions
(e.g., Swish, Softplus) using piecewise linear mappings, reducing latency with
minimal accuracy loss. Evaluations on an Intel Core Ultra Series 2 AI PC show
that XAMBA achieves up to 2.6X speed-up over the baseline. Our implementation
is available at https://github.com/arghadippurdue/XAMBA.",http://arxiv.org/abs/2502.06924v1,Natural Language Processing,"ssms, performance, npus, xamba, models"
RSAttAE: An Information-Aware Attention-based Autoencoder Recommender System,"Recommender systems play a crucial role in modern life, including information
retrieval, the pharmaceutical industry, retail, and entertainment. The
entertainment sector, in particular, attracts significant attention and
generates substantial profits. This work proposes a new method for predicting
unknown user-movie ratings to enhance customer satisfaction. To achieve this,
we utilize the MovieLens 100K dataset. Our approach introduces an
attention-based autoencoder to create meaningful representations and the
XGBoost method for rating predictions. The results demonstrate that our
proposal outperforms most of the existing state-of-the-art methods.
Availability: github.com/ComputationIASBS/RecommSys",http://arxiv.org/abs/2502.06705v1,Recommendation System,"entertainment, attention, method, recommender, systems"
Do Attention Heads Compete or Cooperate during Counting?,"We present an in-depth mechanistic interpretability analysis of training
small transformers on an elementary task, counting, which is a crucial
deductive step in many algorithms. In particular, we investigate the
collaboration/competition among the attention heads: we ask whether the
attention heads behave as a pseudo-ensemble, all solving the same subtask, or
they perform different subtasks, meaning that they can only solve the original
task in conjunction. Our work presents evidence that on the semantics of the
counting task, attention heads behave as a pseudo-ensemble, but their outputs
need to be aggregated in a non-uniform manner in order to create an encoding
that conforms to the syntax. Our source code will be available upon
publication.",http://arxiv.org/abs/2502.06923v1,Recommendation System,"task, attention, heads, counting, behave"
FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups,"Deep learning models frequently exploit spurious features in training data to
achieve low training error, often resulting in poor generalization when faced
with shifted testing distributions. To address this issue, various methods from
imbalanced learning, representation learning, and classifier recalibration have
been proposed to enhance the robustness of deep neural networks against
spurious correlations. In this paper, we observe that models trained with
empirical risk minimization tend to generalize well for examples from the
majority groups while memorizing instances from minority groups. Building on
recent findings that show memorization can be localized to a limited number of
neurons, we apply example-tied dropout as a method we term FairDropout, aimed
at redirecting this memorization to specific neurons that we subsequently drop
out during inference. We empirically evaluate FairDropout using the
subpopulation benchmark suite encompassing vision, language, and healthcare
tasks, demonstrating that it significantly reduces reliance on spurious
correlations, and outperforms state-of-the-art methods.",http://arxiv.org/abs/2502.06695v1,Recommendation System,"learning, spurious, deep, models, training"
"Recent Advances, Applications and Open Challenges in Machine Learning for Health: Reflections from Research Roundtables at ML4H 2024 Symposium","The fourth Machine Learning for Health (ML4H) symposium was held in person on
December 15th and 16th, 2024, in the traditional, ancestral, and unceded
territories of the Musqueam, Squamish, and Tsleil-Waututh Nations in Vancouver,
British Columbia, Canada. The symposium included research roundtable sessions
to foster discussions between participants and senior researchers on timely and
relevant topics for the ML4H community. The organization of the research
roundtables at the conference involved 13 senior and 27 junior chairs across 13
tables. Each roundtable session included an invited senior chair (with
substantial experience in the field), junior chairs (responsible for
facilitating the discussion), and attendees from diverse backgrounds with an
interest in the session's topic.",http://arxiv.org/abs/2502.06693v1,Recommendation System,"senior, symposium, included, research, roundtable"
Multi-label Scandinavian Language Identification (SLIDE),"Identifying closely related languages at sentence level is difficult, in
particular because it is often impossible to assign a sentence to a single
language. In this paper, we focus on multi-label sentence-level Scandinavian
language identification (LID) for Danish, Norwegian Bokm\r{a}l, Norwegian
Nynorsk, and Swedish. We present the Scandinavian Language Identification and
Evaluation, SLIDE, a manually curated multi-label evaluation dataset and a
suite of LID models with varying speed-accuracy tradeoffs. We demonstrate that
the ability to identify multiple languages simultaneously is necessary for any
accurate LID method, and present a novel approach to training such multi-label
LID models.",http://arxiv.org/abs/2502.06692v1,Natural Language Processing,"lid, sentence, language, multi, label"
Synthetic Audio Helps for Cognitive State Tasks,"The NLP community has broadly focused on text-only approaches of cognitive
state tasks, but audio can provide vital missing cues through prosody. We posit
that text-to-speech models learn to track aspects of cognitive state in order
to produce naturalistic audio, and that the signal audio models implicitly
identify is orthogonal to the information that language models exploit. We
present Synthetic Audio Data fine-tuning (SAD), a framework where we show that
7 tasks related to cognitive state modeling benefit from multimodal training on
both text and zero-shot synthetic audio data from an off-the-shelf TTS system.
We show an improvement over the text-only modality when adding synthetic audio
data to text-only corpora. Furthermore, on tasks and corpora that do contain
gold audio, we show our SAD framework achieves competitive performance with
text and synthetic audio compared to text and gold audio.",http://arxiv.org/abs/2502.06922v1,Natural Language Processing,"audio, text, synthetic, cognitive, state"
Neumann eigenmaps for landmark embedding,"We present Neumann eigenmaps (NeuMaps), a novel approach for enhancing the
standard diffusion map embedding using landmarks, i.e distinguished samples
within the dataset. By interpreting these landmarks as a subgraph of the larger
data graph, NeuMaps are obtained via the eigendecomposition of a renormalized
Neumann Laplacian. We show that NeuMaps offer two key advantages: (1) they
provide a computationally efficient embedding that accurately recovers the
diffusion distance associated with the reflecting random walk on the subgraph,
and (2) they naturally incorporate the Nystr\""om extension within the diffusion
map framework through the discrete Neumann boundary condition. Through examples
in digit classification and molecular dynamics, we demonstrate that NeuMaps not
only improve upon existing landmark-based embedding methods but also enhance
the stability of diffusion map embeddings to the removal of highly significant
points.",http://arxiv.org/abs/2502.06689v1,Computer Vision,"neumaps, diffusion, neumann, map, embedding"
"No Trick, No Treat: Pursuits and Challenges Towards Simulation-free Training of Neural Samplers","We consider the sampling problem, where the aim is to draw samples from a
distribution whose density is known only up to a normalization constant. Recent
breakthroughs in generative modeling to approximate a high-dimensional data
distribution have sparked significant interest in developing neural
network-based methods for this challenging problem. However, neural samplers
typically incur heavy computational overhead due to simulating trajectories
during training. This motivates the pursuit of simulation-free training
procedures of neural samplers. In this work, we propose an elegant modification
to previous methods, which allows simulation-free training with the help of a
time-dependent normalizing flow. However, it ultimately suffers from severe
mode collapse. On closer inspection, we find that nearly all successful neural
samplers rely on Langevin preconditioning to avoid mode collapsing. We
systematically analyze several popular methods with various objective functions
and demonstrate that, in the absence of Langevin preconditioning, most of them
fail to adequately cover even a simple target. Finally, we draw attention to a
strong baseline by combining the state-of-the-art MCMC method, Parallel
Tempering (PT), with an additional generative model to shed light on future
explorations of neural samplers.",http://arxiv.org/abs/2502.06685v1,Recommendation System,"neural, samplers, methods, training, problem"
EquiTabPFN: A Target-Permutation Equivariant Prior Fitted Networks,"Recent foundational models for tabular data, such as TabPFN, have
demonstrated remarkable effectiveness in adapting to new tasks through
in-context learning. However, these models overlook a crucial equivariance
property: the arbitrary ordering of target dimensions should not influence
model predictions. In this study, we identify this oversight as a source of
incompressible error, termed the equivariance gap, which introduces instability
in predictions. To mitigate these issues, we propose a novel model designed to
preserve equivariance across output dimensions. Our experimental results
indicate that our proposed model not only addresses these pitfalls effectively
but also achieves competitive benchmark performance.",http://arxiv.org/abs/2502.06684v1,Recommendation System,"equivariance, model, models, dimensions, predictions"
Transfer Your Perspective: Controllable 3D Generation from Any Viewpoint in a Driving Scene,"Self-driving cars relying solely on ego-centric perception face limitations
in sensing, often failing to detect occluded, faraway objects. Collaborative
autonomous driving (CAV) seems like a promising direction, but collecting data
for development is non-trivial. It requires placing multiple sensor-equipped
agents in a real-world driving scene, simultaneously! As such, existing
datasets are limited in locations and agents. We introduce a novel surrogate to
the rescue, which is to generate realistic perception from different viewpoints
in a driving scene, conditioned on a real-world sample - the ego-car's sensory
data. This surrogate has huge potential: it could potentially turn any ego-car
dataset into a collaborative driving one to scale up the development of CAV. We
present the very first solution, using a combination of simulated collaborative
data and real ego-car data. Our method, Transfer Your Perspective (TYP), learns
a conditioned diffusion model whose output samples are not only realistic but
also consistent in both semantics and layouts with the given ego-car data.
Empirical results demonstrate TYP's effectiveness in aiding in a CAV setting.
In particular, TYP enables us to (pre-)train collaborative perception
algorithms like early and late fusion with little or no real-world
collaborative data, greatly facilitating downstream CAV applications.",http://arxiv.org/abs/2502.06682v1,Recommendation System,"data, driving, ego, collaborative, cav"
CHIRLA: Comprehensive High-resolution Identification and Re-identification for Large-scale Analysis,"Person re-identification (Re-ID) is a key challenge in computer vision,
requiring the matching of individuals across different cameras, locations, and
time periods. While most research focuses on short-term scenarios with minimal
appearance changes, real-world applications demand robust Re-ID systems capable
of handling long-term scenarios, where persons' appearances can change
significantly due to variations in clothing and physical characteristics. In
this paper, we present CHIRLA, Comprehensive High-resolution Identification and
Re-identification for Large-scale Analysis, a novel dataset specifically
designed for long-term person Re-ID. CHIRLA consists of recordings from
strategically placed cameras over a seven-month period, capturing significant
variations in both temporal and appearance attributes, including controlled
changes in participants' clothing and physical features. The dataset includes
22 individuals, four connected indoor environments, and seven cameras. We
collected more than five hours of video that we semi-automatically labeled to
generate around one million bounding boxes with identity annotations. By
introducing this comprehensive benchmark, we aim to facilitate the development
and evaluation of Re-ID algorithms that can reliably perform in challenging,
long-term real-world scenarios.",http://arxiv.org/abs/2502.06681v1,Computer Vision,"id, term, identification, cameras, scenarios"
Quantile Multi-Armed Bandits with 1-bit Feedback,"In this paper, we study a variant of best-arm identification involving
elements of risk sensitivity and communication constraints. Specifically, the
goal of the learner is to identify the arm with the highest quantile reward,
while the communication from an agent (who observes rewards) and the learner
(who chooses actions) is restricted to only one bit of feedback per arm pull.
We propose an algorithm that utilizes noisy binary search as a subroutine,
allowing the learner to estimate quantile rewards through 1-bit feedback. We
derive an instance-dependent upper bound on the sample complexity of our
algorithm and provide an algorithm-independent lower bound for specific
instances, with the two matching to within logarithmic factors under mild
conditions, or even to within constant factors in certain low error probability
scaling regimes. The lower bound is applicable even in the absence of
communication constraints, and thus we conclude that restricting to 1-bit
feedback has a minimal impact on the scaling of the sample complexity.",http://arxiv.org/abs/2502.06678v1,Recommendation System,"arm, communication, learner, bit, feedback"
GraNNite: Enabling High-Performance Execution of Graph Neural Networks on Resource-Constrained Neural Processing Units,"Graph Neural Networks (GNNs) are vital for learning from graph-structured
data, enabling applications in network analysis, recommendation systems, and
speech analytics. Deploying them on edge devices like client PCs and laptops
enhances real-time processing, privacy, and cloud independence. GNNs aid
Retrieval-Augmented Generation (RAG) for Large Language Models (LLMs) and
enable event-based vision tasks. However, irregular memory access, sparsity,
and dynamic structures cause high latency and energy overhead on
resource-constrained devices. While modern edge processors integrate CPUs,
GPUs, and NPUs, NPUs designed for data-parallel tasks struggle with irregular
GNN computations. We introduce GraNNite, the first hardware-aware framework
optimizing GNN execution on commercial-off-the-shelf (COTS) SOTA DNN
accelerators via a structured three-step methodology: (1) enabling NPU
execution, (2) optimizing performance, and (3) trading accuracy for efficiency
gains. Step 1 employs GraphSplit for workload distribution and StaGr for static
aggregation, while GrAd and NodePad handle dynamic graphs. Step 2 boosts
performance using EffOp for control-heavy tasks and GraSp for sparsity
exploitation. Graph Convolution optimizations PreG, SymG, and CacheG reduce
redundancy and memory transfers. Step 3 balances quality versus efficiency,
where QuantGr applies INT8 quantization, and GrAx1, GrAx2, and GrAx3 accelerate
attention, broadcast-add, and SAGE-max aggregation. On Intel Core Ultra AI PCs,
GraNNite achieves 2.6X to 7.6X speedups over default NPU mappings and up to
8.6X energy gains over CPUs and GPUs, delivering 10.8X and 6.7X higher
performance than CPUs and GPUs, respectively, across GNN models.",http://arxiv.org/abs/2502.06921v1,Recommendation System,"step, graph, tasks, cpus, gpus"
RAILS: Risk-Aware Iterated Local Search for Joint SLA Decomposition and Service Provider Management in Multi-Domain Networks,"The emergence of the fifth generation (5G) technology has transformed mobile
networks into multi-service environments, necessitating efficient network
slicing to meet diverse Service Level Agreements (SLAs). SLA decomposition
across multiple network domains, each potentially managed by different service
providers, poses a significant challenge due to limited visibility into
real-time underlying domain conditions. This paper introduces Risk-Aware
Iterated Local Search (RAILS), a novel risk model-driven meta-heuristic
framework designed to jointly address SLA decomposition and service provider
selection in multi-domain networks. By integrating online risk modeling with
iterated local search principles, RAILS effectively navigates the complex
optimization landscape, utilizing historical feedback from domain controllers.
We formulate the joint problem as a Mixed-Integer Nonlinear Programming (MINLP)
problem and prove its NP-hardness. Extensive simulations demonstrate that RAILS
achieves near-optimal performance, offering an efficient, real-time solution
for adaptive SLA management in modern multi-domain networks.",http://arxiv.org/abs/2502.06674v1,Recommendation System,"service, domain, networks, multi, sla"
Covariates-Adjusted Mixed-Membership Estimation: A Novel Network Model with Optimal Guarantees,"This paper addresses the problem of mixed-membership estimation in networks,
where the goal is to efficiently estimate the latent mixed-membership structure
from the observed network. Recognizing the widespread availability and valuable
information carried by node covariates, we propose a novel network model that
incorporates both community information, as represented by the Degree-Corrected
Mixed Membership (DCMM) model, and node covariate similarities to determine
connections.
  We investigate the regularized maximum likelihood estimation (MLE) for this
model and demonstrate that our approach achieves optimal estimation accuracy
for both the similarity matrix and the mixed-membership, in terms of both the
Frobenius norm and the entrywise loss. Since directly analyzing the original
convex optimization problem is intractable, we employ nonconvex optimization to
facilitate the analysis. A key contribution of our work is identifying a
crucial assumption that bridges the gap between convex and nonconvex solutions,
enabling the transfer of statistical guarantees from the nonconvex approach to
its convex counterpart. Importantly, our analysis extends beyond the MLE loss
and the mean squared error (MSE) used in matrix completion problems,
generalizing to all the convex loss functions. Consequently, our analysis
techniques extend to a broader set of applications, including ranking problems
based on pairwise comparisons.
  Finally, simulation experiments validate our theoretical findings, and
real-world data analyses confirm the practical relevance of our model.",http://arxiv.org/abs/2502.06671v1,Reinforcement Learning,"mixed, membership, model, convex, estimation"
Boosting Self-Efficacy and Performance of Large Language Models via Verbal Efficacy Stimulations,"Significant improvements have been observed in the zero-shot capabilities of
the Large Language Models (LLMs). Due to their high sensitivity to input,
research has increasingly focused on enhancing LLMs' performance via direct and
simple prompt engineering rather than intricate domain adaptation. Studies
suggest that LLMs exhibit emotional intelligence, and both positive and
negative emotions can potentially enhance task performances. However, prior
interaction prompts have predominantly concentrated on a single stimulus type,
neglecting to compare different stimulus effects, examine the influence of
varying task difficulties, or explore underlying mechanisms. This paper,
inspired by the positive correlation between self-efficacy and task performance
within the social cognitive theory, introduces Verbal Efficacy Stimulations
(VES). Our VES comprises three types of verbal prompts: encouraging,
provocative, and critical, addressing six aspects such as helpfulness and
competence. And we further categorize task difficulty, aiming to extensively
investigate how distinct VES influence the self-efficacy and task achievements
of language models at varied levels of difficulty. The experimental results
show that the three types of VES improve the performance of LLMs on most tasks,
and the most effective VES varies for different models. In extensive
experiments, we have obtained some findings consistent with psychological
theories, providing novel insights for future research.",http://arxiv.org/abs/2502.06669v1,Recommendation System,"task, ves, llms, models, performance"
Automatic Evaluation of Healthcare LLMs Beyond Question-Answering,"Current Large Language Models (LLMs) benchmarks are often based on open-ended
or close-ended QA evaluations, avoiding the requirement of human labor.
Close-ended measurements evaluate the factuality of responses but lack
expressiveness. Open-ended capture the model's capacity to produce discourse
responses but are harder to assess for correctness. These two approaches are
commonly used, either independently or together, though their relationship
remains poorly understood. This work is focused on the healthcare domain, where
both factuality and discourse matter greatly. It introduces a comprehensive,
multi-axis suite for healthcare LLM evaluation, exploring correlations between
open and close benchmarks and metrics. Findings include blind spots and
overlaps in current methodologies. As an updated sanity check, we release a new
medical benchmark--CareQA--, with both open and closed variants. Finally, we
propose a novel metric for open-ended evaluations --Relaxed Perplexity-- to
mitigate the identified limitations.",http://arxiv.org/abs/2502.06666v1,Recommendation System,"open, ended, close, current, benchmarks"
Evaluation of Deep Audio Representations for Hearables,"Effectively steering hearable devices requires understanding the acoustic
environment around the user. In the computational analysis of sound scenes,
foundation models have emerged as the state of the art to produce
high-performance, robust, multi-purpose audio representations. We introduce and
release Deep Evaluation of Audio Representations (DEAR), the first dataset and
benchmark to evaluate the efficacy of foundation models in capturing essential
acoustic properties for hearables. The dataset includes 1,158 audio tracks,
each 30 seconds long, created by spatially mixing proprietary monologues with
commercial, high-quality recordings of everyday acoustic scenes. Our benchmark
encompasses eight tasks that assess the general context, speech sources, and
technical acoustic properties of the audio scenes. Through our evaluation of
four general-purpose audio representation models, we demonstrate that the BEATs
model significantly surpasses its counterparts. This superiority underscores
the advantage of models trained on diverse audio collections, confirming their
applicability to a wide array of auditory tasks, including encoding the
environment properties necessary for hearable steering. The DEAR dataset and
associated code are available at https://dear-dataset.github.io.",http://arxiv.org/abs/2502.06664v1,Recommendation System,"audio, acoustic, models, scenes, dataset"
EfficientLLM: Scalable Pruning-Aware Pretraining for Architecture-Agnostic Edge Language Models,"Modern large language models (LLMs) driven by scaling laws, achieve
intelligence emergency in large model sizes. Recently, the increasing concerns
about cloud costs, latency, and privacy make it an urgent requirement to
develop compact edge language models. Distinguished from direct pretraining
that bounded by the scaling law, this work proposes the pruning-aware
pretraining, focusing on retaining performance of much larger optimized models.
It features following characteristics: 1) Data-scalable: we introduce minimal
parameter groups in LLM and continuously optimize structural pruning, extending
post-training pruning methods like LLM-Pruner and SparseGPT into the
pretraining phase. 2) Architecture-agnostic: the LLM architecture is
auto-designed using saliency-driven pruning, which is the first time to exceed
SoTA human-designed LLMs in modern pretraining. We reveal that it achieves
top-quality edge language models, termed EfficientLLM, by scaling up LLM
compression and extending its boundary. EfficientLLM significantly outperforms
SoTA baselines with $100M \sim 1B$ parameters, such as MobileLLM, SmolLM,
Qwen2.5-0.5B, OLMo-1B, Llama3.2-1B in common sense benchmarks. As the first
attempt, EfficientLLM bridges the performance gap between traditional LLM
compression and direct pretraining methods, and we will fully open source at
https://github.com/Xingrun-Xing2/EfficientLLM.",http://arxiv.org/abs/2502.06663v2,Recommendation System,"pretraining, llm, models, pruning, language"
iLOCO: Distribution-Free Inference for Feature Interactions,"Feature importance measures are widely studied and are essential for
understanding model behavior, guiding feature selection, and enhancing
interpretability. However, many machine learning fitted models involve complex,
higher-order interactions between features. Existing feature importance metrics
fail to capture these higher-order effects while existing interaction metrics
often suffer from limited applicability or excessive computation; no methods
exist to conduct statistical inference for feature interactions. To bridge this
gap, we first propose a new model-agnostic metric, interaction
Leave-One-Covariate-Out iLOCO, for measuring the importance of higher-order
feature interactions. Next, we leverage recent advances in LOCO inference to
develop distribution-free and assumption-light confidence intervals for our
iLOCO metric. To address computational challenges, we also introduce an
ensemble learning method for calculating the iLOCO metric and confidence
intervals that we show is both computationally and statistically efficient. We
validate our iLOCO metric and our confidence intervals on both synthetic and
real data sets, showing that our approach outperforms existing methods and
provides the first inferential approach to detecting feature interactions.",http://arxiv.org/abs/2502.06661v1,Recommendation System,"feature, interactions, metric, iloco, importance"
Generating Samples to Question Trained Models,"There is a growing need for investigating how machine learning models
operate. With this work, we aim to understand trained machine learning models
by questioning their data preferences. We propose a mathematical framework that
allows us to probe trained models and identify their preferred samples in
various scenarios including prediction-risky, parameter-sensitive, or
model-contrastive samples. To showcase our framework, we pose these queries to
a range of models trained on a range of classification and regression tasks,
and receive answers in the form of generated data.",http://arxiv.org/abs/2502.06658v1,Recommendation System,"models, trained, machine, learning, data"
A Frontier AI Risk Management Framework: Bridging the Gap Between Current AI Practices and Established Risk Management,"The recent development of powerful AI systems has highlighted the need for
robust risk management frameworks in the AI industry. Although companies have
begun to implement safety frameworks, current approaches often lack the
systematic rigor found in other high-risk industries. This paper presents a
comprehensive risk management framework for the development of frontier AI that
bridges this gap by integrating established risk management principles with
emerging AI-specific practices. The framework consists of four key components:
(1) risk identification (through literature review, open-ended red-teaming, and
risk modeling), (2) risk analysis and evaluation using quantitative metrics and
clearly defined thresholds, (3) risk treatment through mitigation measures such
as containment, deployment controls, and assurance processes, and (4) risk
governance establishing clear organizational structures and accountability.
Drawing from best practices in mature industries such as aviation or nuclear
power, while accounting for AI's unique challenges, this framework provides AI
developers with actionable guidelines for implementing robust risk management.
The paper details how each component should be implemented throughout the
life-cycle of the AI system - from planning through deployment - and emphasizes
the importance and feasibility of conducting risk management work prior to the
final training run to minimize the burden associated with it.",http://arxiv.org/abs/2502.06656v1,Recommendation System,"risk, ai, management, framework, development"
Unbiased Evaluation of Large Language Models from a Causal Perspective,"Benchmark contamination has become a significant concern in the LLM
evaluation community. Previous Agents-as-an-Evaluator address this issue by
involving agents in the generation of questions. Despite their success, the
biases in Agents-as-an-Evaluator methods remain largely unexplored. In this
paper, we present a theoretical formulation of evaluation bias, providing
valuable insights into designing unbiased evaluation protocols. Furthermore, we
identify two type of bias in Agents-as-an-Evaluator through carefully designed
probing tasks on a minimal Agents-as-an-Evaluator setup. To address these
issues, we propose the Unbiased Evaluator, an evaluation protocol that delivers
a more comprehensive, unbiased, and interpretable assessment of LLMs.Extensive
experiments reveal significant room for improvement in current LLMs.
Additionally, we demonstrate that the Unbiased Evaluator not only offers strong
evidence of benchmark contamination but also provides interpretable evaluation
results.",http://arxiv.org/abs/2502.06655v1,Recommendation System,"evaluator, evaluation, agents, unbiased, benchmark"
Prototype Contrastive Consistency Learning for Semi-Supervised Medical Image Segmentation,"Medical image segmentation is a crucial task in medical image analysis, but
it can be very challenging especially when there are less labeled data but with
large unlabeled data. Contrastive learning has proven to be effective for
medical image segmentation in semi-supervised learning by constructing
contrastive samples from partial pixels. However, although previous contrastive
learning methods can mine semantic information from partial pixels within
images, they ignore the whole context information of unlabeled images, which is
very important to precise segmentation. In order to solve this problem, we
propose a novel prototype contrastive learning method called Prototype
Contrastive Consistency Segmentation (PCCS) for semi-supervised medical image
segmentation. The core idea is to enforce the prototypes of the same semantic
class to be closer and push the prototypes in different semantic classes far
away from each other. Specifically, we construct a signed distance map and an
uncertainty map from unlabeled images. The signed distance map is used to
construct prototypes for contrastive learning, and then we estimate the
prototype uncertainty from the uncertainty map as trade-off among prototypes.
In order to obtain better prototypes, based on the student-teacher
architecture, a new mechanism named prototype updating prototype is designed to
assist in updating the prototypes for contrastive learning. In addition, we
propose an uncertainty-consistency loss to mine more reliable information from
unlabeled data. Extensive experiments on medical image segmentation demonstrate
that PCCS achieves better segmentation performance than the state-of-the-art
methods. The code is available at https://github.com/comphsh/PCCS.",http://arxiv.org/abs/2502.06650v1,Recommendation System,"segmentation, contrastive, learning, prototypes, medical"
Estimation of Food Intake Quantity Using Inertial Signals from Smartwatches,"Accurate monitoring of eating behavior is crucial for managing obesity and
eating disorders such as bulimia nervosa. At the same time, existing methods
rely on multiple and/or specialized sensors, greatly harming adherence and
ultimately, the quality and continuity of data. This paper introduces a novel
approach for estimating the weight of a bite, from a commercial smartwatch. Our
publicly-available dataset contains smartwatch inertial data from ten
participants, with manually annotated start and end times of each bite along
with their corresponding weights from a smart scale, under semi-controlled
conditions. The proposed method combines extracted behavioral features such as
the time required to load the utensil with food, with statistical features of
inertial signals, that serve as input to a Support Vector Regression model to
estimate bite weights. Under a leave-one-subject-out cross-validation scheme,
our approach achieves a mean absolute error (MAE) of 3.99 grams per bite. To
contextualize this performance, we introduce the improvement metric, that
measures the relative MAE difference compared to a baseline model. Our method
demonstrates a 17.41% improvement, while the adapted state-of-the art method
shows a -28.89% performance against that same baseline. The results presented
in this work establish the feasibility of extracting meaningful bite weight
estimates from commercial smartwatch inertial sensors alone, laying the
groundwork for future accessible, non-invasive dietary monitoring systems.",http://arxiv.org/abs/2502.06649v1,Recommendation System,"bite, smartwatch, inertial, method, monitoring"
The 2021 Tokyo Olympics Multilingual News Article Dataset,"In this paper, we introduce a dataset of multilingual news articles covering
the 2021 Tokyo Olympics. A total of 10,940 news articles were gathered from
1,918 different publishers, covering 1,350 sub-events of the 2021 Olympics, and
published between July 1, 2021, and August 14, 2021. These articles are written
in nine languages from different language families and in different scripts. To
create the dataset, the raw news articles were first retrieved via a service
that collects and analyzes news articles. Then, the articles were grouped using
an online clustering algorithm, with each group containing articles reporting
on the same sub-event. Finally, the groups were manually annotated and
evaluated. The development of this dataset aims to provide a resource for
evaluating the performance of multilingual news clustering algorithms, for
which limited datasets are available. It can also be used to analyze the
dynamics and events of the 2021 Tokyo Olympics from different perspectives. The
dataset is available in CSV format and can be accessed from the CLARIN.SI
repository.",http://arxiv.org/abs/2502.06648v1,Recommendation System,"articles, news, dataset, different, olympics"
Koopman-Equivariant Gaussian Processes,"Credible forecasting and representation learning of dynamical systems are of
ever-increasing importance for reliable decision-making. To that end, we
propose a family of Gaussian processes (GP) for dynamical systems with linear
time-invariant responses, which are nonlinear only in initial conditions. This
linearity allows us to tractably quantify forecasting and representational
uncertainty, simultaneously alleviating the challenge of computing the
distribution of trajectories from a GP-based dynamical system and enabling a
new probabilistic treatment of learning Koopman operator representations. Using
a trajectory-based equivariance -- which we refer to as \textit{Koopman
equivariance} -- we obtain a GP model with enhanced generalization
capabilities. To allow for large-scale regression, we equip our framework with
variational inference based on suitable inducing points. Experiments
demonstrate on-par and often better forecasting performance compared to
kernel-based methods for learning dynamical systems.",http://arxiv.org/abs/2502.06645v1,Recommendation System,"dynamical, based, forecasting, learning, systems"
MoETuner: Optimized Mixture of Expert Serving with Balanced Expert Placement and Token Routing,"Mixture-of-Experts (MoE) model architecture has emerged as a promising
solution for scaling transformer models efficiently, offering sparse activation
that reduces computational costs while increasing model capacity. However, as
MoE models scale, they need to be distributed across GPU devices, thus face
critical performance bottlenecks due to their large memory footprint. Expert
parallelism distributes experts across GPUs, however, faces key challenges
including an unbalanced token routing and expert activation, resulting in
communication tail latency and processing inefficiencies. While existing
solutions address some of these issues, they fail to resolve the dual
challenges of load imbalance and communication skew. The imbalance in token
processing load across experts causes uneven processing times on different
GPUs, while communication skew between GPUs leads to unbalanced inter-GPU data
transfers. These factors degrade the performance of MoE models by increasing
tail latency and reducing overall throughput. To address these limitations, we
propose an Integer Linear Programming (ILP) formulation to optimize expert
placement by jointly considering token load, communication, and computation
costs. We exploit the property that there is a token routing dependency across
layers, where tokens routed to a specific expert in one layer are likely to be
routed to a limited set of experts in the subsequent layer. Our solution,
MoETuner, offers an optimal expert-to-GPU assignment that minimizes inter-GPU
token routing costs and balances token processing across devices, thereby
reducing tail latency and end-to-end execution time. Experimental results
demonstrate 9.3% and 17.5% of end-to-end speedups for single-node and
multi-node inference respectively, showcasing the potential of our ILP-based
optimization for offering expert parallel solutions for next-generation MoEs.",http://arxiv.org/abs/2502.06643v1,Recommendation System,"expert, token, experts, gpu, communication"
Steel-LLM:From Scratch to Open Source -- A Personal Journey in Building a Chinese-Centric LLM,"Steel-LLM is a Chinese-centric language model developed from scratch with the
goal of creating a high-quality, open-source model despite limited
computational resources. Launched in March 2024, the project aimed to train a
1-billion-parameter model on a large-scale dataset, prioritizing transparency
and the sharing of practical insights to assist others in the community. The
training process primarily focused on Chinese data, with a small proportion of
English data included, addressing gaps in existing open-source LLMs by
providing a more detailed and practical account of the model-building journey.
Steel-LLM has demonstrated competitive performance on benchmarks such as CEVAL
and CMMLU, outperforming early models from larger institutions. This paper
provides a comprehensive summary of the project's key contributions, including
data collection, model design, training methodologies, and the challenges
encountered along the way, offering a valuable resource for researchers and
practitioners looking to develop their own LLMs. The model checkpoints and
training script are available at https://github.com/zhanshijinwat/Steel-LLM.",http://arxiv.org/abs/2502.06635v1,Recommendation System,"model, training, data, steel, llm"
Automatic Annotation Augmentation Boosts Translation between Molecules and Natural Language,"Recent advancements in AI for biological research focus on integrating
molecular data with natural language to accelerate drug discovery. However, the
scarcity of high-quality annotations limits progress in this area. This paper
introduces LA$^3$, a Language-based Automatic Annotation Augmentation framework
that leverages large language models to augment existing datasets, thereby
improving AI training. We demonstrate the effectiveness of LA$^3$ by creating
an enhanced dataset, LaChEBI-20, where we systematically rewrite the
annotations of molecules from an established dataset. These rewritten
annotations preserve essential molecular information while providing more
varied sentence structures and vocabulary. Using LaChEBI-20, we train LaMolT5
based on a benchmark architecture to learn the mapping between molecular
representations and augmented annotations.
  Experimental results on text-based *de novo* molecule generation and molecule
captioning demonstrate that LaMolT5 outperforms state-of-the-art models.
Notably, incorporating LA$^3$ leads to improvements of up to 301% over the
benchmark architecture. Furthermore, we validate the effectiveness of LA$^3$
notable applications in *image*, *text* and *graph* tasks, affirming its
versatility and utility.",http://arxiv.org/abs/2502.06634v1,Natural Language Processing,"annotations, molecular, language, based, ai"
Combining Large Language Models with Static Analyzers for Code Review Generation,"Code review is a crucial but often complex, subjective, and time-consuming
activity in software development. Over the past decades, significant efforts
have been made to automate this process. Early approaches focused on
knowledge-based systems (KBS) that apply rule-based mechanisms to detect code
issues, providing precise feedback but struggling with complex,
context-dependent cases. More recent work has shifted toward fine-tuning
pre-trained language models for code review, enabling broader issue coverage
but often at the expense of precision. In this paper, we propose a hybrid
approach that combines the strengths of KBS and learning-based systems (LBS) to
generate high-quality, comprehensive code reviews. Our method integrates
knowledge at three distinct stages of the language model pipeline: during data
preparation (Data-Augmented Training, DAT), at inference (Retrieval-Augmented
Generation, RAG), and after inference (Naive Concatenation of Outputs, NCO). We
empirically evaluate our combination strategies against standalone KBS and LBS
fine-tuned on a real-world dataset. Our results show that these hybrid
strategies enhance the relevance, completeness, and overall quality of review
comments, effectively bridging the gap between rule-based tools and deep
learning models.",http://arxiv.org/abs/2502.06633v1,Recommendation System,"code, based, review, kbs, complex"
Few-Shot Classification and Anatomical Localization of Tissues in SPECT Imaging,"Accurate classification and anatomical localization are essential for
effective medical diagnostics and research, which may be efficiently performed
using deep learning techniques. However, availability of limited labeled data
poses a significant challenge. To address this, we adapted Prototypical
Networks and the Propagation-Reconstruction Network (PRNet) for few-shot
classification and localization, respectively, in Single Photon Emission
Computed Tomography (SPECT) images. For the proof of concept we used a
2D-sliced image cropped around heart. The Prototypical Network, with a
pre-trained ResNet-18 backbone, classified ventricles, myocardium, and liver
tissues with 96.67% training and 93.33% validation accuracy. PRNet, adapted for
2D imaging with an encoder-decoder architecture and skip connections, achieved
a training loss of 1.395, accurately reconstructing patches and capturing
spatial relationships. These results highlight the potential of Prototypical
Networks for tissue classification with limited labeled data and PRNet for
anatomical landmark localization, paving the way for improved performance in
deep learning frameworks.",http://arxiv.org/abs/2502.06632v1,Recommendation System,"classification, localization, prototypical, prnet, anatomical"
Conformal Predictions for Human Action Recognition with Vision-Language Models,"Human-In-The-Loop (HITL) frameworks are integral to many real-world computer
vision systems, enabling human operators to make informed decisions with AI
assistance. Conformal Predictions (CP), which provide label sets with rigorous
guarantees on ground truth inclusion probabilities, have recently gained
traction as a valuable tool in HITL settings. One key application area is video
surveillance, closely associated with Human Action Recognition (HAR). This
study explores the application of CP on top of state-of-the-art HAR methods
that utilize extensively pre-trained Vision-Language Models (VLMs). Our
findings reveal that CP can significantly reduce the average number of
candidate classes without modifying the underlying VLM. However, these
reductions often result in distributions with long tails. To address this, we
introduce a method based on tuning the temperature parameter of the VLMs to
minimize these tails without requiring additional calibration data. Our code is
made available on GitHub at the address https://github.com/tbary/CP4VLM.",http://arxiv.org/abs/2502.06631v1,Computer Vision,"human, cp, hitl, vision, application"
Direct Estimation of Pediatric Heart Rate Variability from BOLD-fMRI: A Machine Learning Approach Using Dynamic Connectivity,"In many pediatric fMRI studies, cardiac signals are often missing or of poor
quality. A tool to extract Heart Rate Variation (HRV) waveforms directly from
fMRI data, without the need for peripheral recording devices, would be highly
beneficial. We developed a machine learning framework to accurately reconstruct
HRV for pediatric applications. A hybrid model combining one-dimensional
Convolutional Neural Networks (1D-CNN) and Gated Recurrent Units (GRU) analyzed
BOLD signals from 628 ROIs, integrating past and future data. The model
achieved an 8% improvement in HRV accuracy, as evidenced by enhanced
performance metrics. This approach eliminates the need for peripheral
photoplethysmography devices, reduces costs, and simplifies procedures in
pediatric fMRI. Additionally, it improves the robustness of pediatric fMRI
studies, which are more sensitive to physiological and developmental variations
than those in adults.",http://arxiv.org/abs/2502.06920v1,Recommendation System,"pediatric, fmri, hrv, studies, signals"
Unleashing the Potential of Pre-Trained Diffusion Models for Generalizable Person Re-Identification,"Domain-generalizable re-identification (DG Re-ID) aims to train a model on
one or more source domains and evaluate its performance on unseen target
domains, a task that has attracted growing attention due to its practical
relevance. While numerous methods have been proposed, most rely on
discriminative or contrastive learning frameworks to learn generalizable
feature representations. However, these approaches often fail to mitigate
shortcut learning, leading to suboptimal performance. In this work, we propose
a novel method called diffusion model-assisted representation learning with a
correlation-aware conditioning scheme (DCAC) to enhance DG Re-ID. Our method
integrates a discriminative and contrastive Re-ID model with a pre-trained
diffusion model through a correlation-aware conditioning scheme. By
incorporating ID classification probabilities generated from the Re-ID model
with a set of learnable ID-wise prompts, the conditioning scheme injects dark
knowledge that captures ID correlations to guide the diffusion process.
Simultaneously, feedback from the diffusion model is back-propagated through
the conditioning scheme to the Re-ID model, effectively improving the
generalization capability of Re-ID features. Extensive experiments on both
single-source and multi-source DG Re-ID tasks demonstrate that our method
achieves state-of-the-art performance. Comprehensive ablation studies further
validate the effectiveness of the proposed approach, providing insights into
its robustness. Codes will be available at https://github.com/RikoLi/DCAC.",http://arxiv.org/abs/2502.06619v2,Reinforcement Learning,"id, model, diffusion, conditioning, scheme"
Multi-Scale Feature Fusion with Image-Driven Spatial Integration for Left Atrium Segmentation from Cardiac MRI Images,"Accurate segmentation of the left atrium (LA) from late gadolinium-enhanced
magnetic resonance imaging plays a vital role in visualizing diseased atrial
structures, enabling the diagnosis and management of cardiovascular diseases.
It is particularly essential for planning treatment with ablation therapy, a
key intervention for atrial fibrillation (AF). However, manual segmentation is
time-intensive and prone to inter-observer variability, underscoring the need
for automated solutions. Class-agnostic foundation models like DINOv2 have
demonstrated remarkable feature extraction capabilities in vision tasks.
However, their lack of domain specificity and task-specific adaptation can
reduce spatial resolution during feature extraction, impacting the capture of
fine anatomical detail in medical imaging. To address this limitation, we
propose a segmentation framework that integrates DINOv2 as an encoder with a
UNet-style decoder, incorporating multi-scale feature fusion and input image
integration to enhance segmentation accuracy. The learnable weighting mechanism
dynamically prioritizes hierarchical features from different encoder blocks of
the foundation model, optimizing feature selection for task relevance.
Additionally, the input image is reintroduced during the decoding stage to
preserve high-resolution spatial details, addressing limitations of
downsampling in the encoder. We validate our approach on the LAScarQS 2022
dataset and demonstrate improved performance with a 92.3% Dice and 84.1% IoU
score for giant architecture compared to the nnUNet baseline model. These
findings emphasize the efficacy of our approach in advancing the field of
automated left atrium segmentation from cardiac MRI.",http://arxiv.org/abs/2502.06615v1,Recommendation System,"segmentation, feature, encoder, left, atrium"
TripoSG: High-Fidelity 3D Shape Synthesis using Large-Scale Rectified Flow Models,"Recent advancements in diffusion techniques have propelled image and video
generation to unprece- dented levels of quality, significantly accelerating the
deployment and application of generative AI. However, 3D shape generation
technology has so far lagged behind, constrained by limitations in 3D data
scale, complexity of 3D data process- ing, and insufficient exploration of
advanced tech- niques in the 3D domain. Current approaches to 3D shape
generation face substantial challenges in terms of output quality,
generalization capa- bility, and alignment with input conditions. We present
TripoSG, a new streamlined shape diffu- sion paradigm capable of generating
high-fidelity 3D meshes with precise correspondence to input images.
Specifically, we propose: 1) A large-scale rectified flow transformer for 3D
shape generation, achieving state-of-the-art fidelity through training on
extensive, high-quality data. 2) A hybrid supervised training strategy
combining SDF, normal, and eikonal losses for 3D VAE, achieving high- quality
3D reconstruction performance. 3) A data processing pipeline to generate 2
million high- quality 3D samples, highlighting the crucial rules for data
quality and quantity in training 3D gen- erative models. Through comprehensive
experi- ments, we have validated the effectiveness of each component in our new
framework. The seamless integration of these parts has enabled TripoSG to
achieve state-of-the-art performance in 3D shape generation. The resulting 3D
shapes exhibit en- hanced detail due to high-resolution capabilities and
demonstrate exceptional fidelity to input im- ages. Moreover, TripoSG
demonstrates improved versatility in generating 3D models from diverse image
styles and contents, showcasing strong gen- eralization capabilities. To foster
progress and innovation in the field of 3D generation, we will make our model
publicly available.",http://arxiv.org/abs/2502.06608v1,Recommendation System,"generation, quality, shape, data, input"
Select before Act: Spatially Decoupled Action Repetition for Continuous Control,"Reinforcement Learning (RL) has achieved remarkable success in various
continuous control tasks, such as robot manipulation and locomotion. Different
to mainstream RL which makes decisions at individual steps, recent studies have
incorporated action repetition into RL, achieving enhanced action persistence
with improved sample efficiency and superior performance. However, existing
methods treat all action dimensions as a whole during repetition, ignoring
variations among them. This constraint leads to inflexibility in decisions,
which reduces policy agility with inferior effectiveness. In this work, we
propose a novel repetition framework called SDAR, which implements Spatially
Decoupled Action Repetition through performing closed-loop act-or-repeat
selection for each action dimension individually. SDAR achieves more flexible
repetition strategies, leading to an improved balance between action
persistence and diversity. Compared to existing repetition frameworks, SDAR is
more sample efficient with higher policy performance and reduced action
fluctuation. Experiments are conducted on various continuous control scenarios,
demonstrating the effectiveness of spatially decoupled repetition design
proposed in this work.",http://arxiv.org/abs/2502.06919v1,Reinforcement Learning,"action, repetition, rl, sdar, continuous"
Illegal Waste Detection in Remote Sensing Images: A Case Study,"Environmental crime currently represents the third largest criminal activity
worldwide while threatening ecosystems as well as human health. Among the
crimes related to this activity, improper waste management can nowadays be
countered more easily thanks to the increasing availability and decreasing cost
of Very-High-Resolution Remote Sensing images, which enable semi-automatic
territory scanning in search of illegal landfills. This paper proposes a
pipeline, developed in collaboration with professionals from a local
environmental agency, for detecting candidate illegal dumping sites leveraging
a classifier of Remote Sensing images. To identify the best configuration for
such classifier, an extensive set of experiments was conducted and the impact
of diverse image characteristics and training settings was thoroughly analyzed.
The local environmental agency was then involved in an experimental exercise
where outputs from the developed classifier were integrated in the experts'
everyday work, resulting in time savings with respect to manual
photo-interpretation. The classifier was eventually run with valuable results
on a location outside of the training area, highlighting potential for
cross-border applicability of the proposed pipeline.",http://arxiv.org/abs/2502.06607v1,Recommendation System,"classifier, environmental, activity, remote, sensing"
"MaterialFusion: High-Quality, Zero-Shot, and Controllable Material Transfer with Diffusion Models","Manipulating the material appearance of objects in images is critical for
applications like augmented reality, virtual prototyping, and digital content
creation. We present MaterialFusion, a novel framework for high-quality
material transfer that allows users to adjust the degree of material
application, achieving an optimal balance between new material properties and
the object's original features. MaterialFusion seamlessly integrates the
modified object into the scene by maintaining background consistency and
mitigating boundary artifacts. To thoroughly evaluate our approach, we have
compiled a dataset of real-world material transfer examples and conducted
complex comparative analyses. Through comprehensive quantitative evaluations
and user studies, we demonstrate that MaterialFusion significantly outperforms
existing methods in terms of quality, user control, and background
preservation. Code is available at
https://github.com/ControlGenAI/MaterialFusion.",http://arxiv.org/abs/2502.06606v2,Reinforcement Learning,"material, materialfusion, quality, transfer, object"
Amortized In-Context Bayesian Posterior Estimation,"Bayesian inference provides a natural way of incorporating prior beliefs and
assigning a probability measure to the space of hypotheses. Current solutions
rely on iterative routines like Markov Chain Monte Carlo (MCMC) sampling and
Variational Inference (VI), which need to be re-run whenever new observations
are available. Amortization, through conditional estimation, is a viable
strategy to alleviate such difficulties and has been the guiding principle
behind simulation-based inference, neural processes and in-context methods
using pre-trained models. In this work, we conduct a thorough comparative
analysis of amortized in-context Bayesian posterior estimation methods from the
lens of different optimization objectives and architectural choices. Such
methods train an amortized estimator to perform posterior parameter inference
by conditioning on a set of data examples passed as context to a sequence model
such as a transformer. In contrast to language models, we leverage permutation
invariant architectures as the true posterior is invariant to the ordering of
context examples. Our empirical study includes generalization to
out-of-distribution tasks, cases where the assumed underlying model is
misspecified, and transfer from simulated to real problems. Subsequently, it
highlights the superiority of the reverse KL estimator for predictive problems,
especially when combined with the transformer architecture and normalizing
flows.",http://arxiv.org/abs/2502.06601v1,Recommendation System,"inference, context, methods, posterior, bayesian"
Evaluation of Multilingual Image Captioning: How far can we get with CLIP models?,"The evaluation of image captions, looking at both linguistic fluency and
semantic correspondence to visual contents, has witnessed a significant effort.
Still, despite advancements such as the CLIPScore metric, multilingual
captioning evaluation has remained relatively unexplored. This work presents
several strategies, and extensive experiments, related to evaluating CLIPScore
variants in multilingual settings. To address the lack of multilingual test
data, we consider two different strategies: (1) using quality aware
machine-translated datasets with human judgements, and (2) re-purposing
multilingual datasets that target semantic inference and reasoning. Our results
highlight the potential of finetuned multilingual models to generalize across
languages and to handle complex linguistic challenges. Tests with
machine-translated data show that multilingual CLIPScore models can maintain a
high correlation with human judgements across different languages, and
additional tests with natively multilingual and multicultural data further
attest to the high-quality assessments.",http://arxiv.org/abs/2502.06600v1,Recommendation System,"multilingual, clipscore, data, evaluation, linguistic"
Continual Release Moment Estimation with Differential Privacy,"We propose Joint Moment Estimation (JME), a method for continually and
privately estimating both the first and second moments of data with reduced
noise compared to naive approaches. JME uses the matrix mechanism and a joint
sensitivity analysis to allow the second moment estimation with no additional
privacy cost, thereby improving accuracy while maintaining privacy. We
demonstrate JME's effectiveness in two applications: estimating the running
mean and covariance matrix for Gaussian density estimation, and model training
with DP-Adam on CIFAR-10.",http://arxiv.org/abs/2502.06597v1,Recommendation System,"estimation, jme, joint, moment, estimating"
A Large-scale AI-generated Image Inpainting Benchmark,"Recent advances in generative models enable highly realistic image
manipulations, creating an urgent need for robust forgery detection methods.
Current datasets for training and evaluating these methods are limited in scale
and diversity. To address this, we propose a methodology for creating
high-quality inpainting datasets and apply it to create DiQuID, comprising over
95,000 inpainted images generated from 78,000 original images sourced from
MS-COCO, RAISE, and OpenImages. Our methodology consists of three components:
(1) Semantically Aligned Object Replacement (SAOR) that identifies suitable
objects through instance segmentation and generates contextually appropriate
prompts, (2) Multiple Model Image Inpainting (MMII) that employs various
state-of-the-art inpainting pipelines primarily based on diffusion models to
create diverse manipulations, and (3) Uncertainty-Guided Deceptiveness
Assessment (UGDA) that evaluates image realism through comparative analysis
with originals. The resulting dataset surpasses existing ones in diversity,
aesthetic quality, and technical quality. We provide comprehensive benchmarking
results using state-of-the-art forgery detection methods, demonstrating the
dataset's effectiveness in evaluating and improving detection algorithms.
Through a human study with 42 participants on 1,000 images, we show that while
humans struggle with images classified as deceiving by our methodology, models
trained on our dataset maintain high performance on these challenging cases.
Code and dataset are available at https://github.com/mever-team/DiQuID.",http://arxiv.org/abs/2502.06593v1,Recommendation System,"images, dataset, models, image, detection"
Diffeomorphic Temporal Alignment Nets for Time-series Joint Alignment and Averaging,"In time-series analysis, nonlinear temporal misalignment remains a pivotal
challenge that forestalls even simple averaging. Since its introduction, the
Diffeomorphic Temporal Alignment Net (DTAN), which we first introduced (Weber
et al., 2019) and further developed in (Weber & Freifeld, 2023), has proven
itself as an effective solution for this problem (these conference papers are
earlier partial versions of the current manuscript). DTAN predicts and applies
diffeomorphic transformations in an input-dependent manner, thus facilitating
the joint alignment (JA) and averaging of time-series ensembles in an
unsupervised or a weakly-supervised manner. The inherent challenges of the
weakly/unsupervised setting, particularly the risk of trivial solutions through
excessive signal distortion, are mitigated using either one of two distinct
strategies: 1) a regularization term for warps; 2) using the Inverse
Consistency Averaging Error (ICAE). The latter is a novel, regularization-free
approach which also facilitates the JA of variable-length signals. We also
further extend our framework to incorporate multi-task learning (MT-DTAN),
enabling simultaneous time-series alignment and classification. Additionally,
we conduct a comprehensive evaluation of different backbone architectures,
demonstrating their efficacy in time-series alignment tasks. Finally, we
showcase the utility of our approach in enabling Principal Component Analysis
(PCA) for misaligned time-series data. Extensive experiments across 128 UCR
datasets validate the superiority of our approach over contemporary averaging
methods, including both traditional and learning-based approaches, marking a
significant advancement in the field of time-series analysis.",http://arxiv.org/abs/2502.06591v1,Recommendation System,"time, series, averaging, alignment, analysis"
Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training,"Due to the scarcity of agent-oriented pre-training data, LLM-based autonomous
agents typically rely on complex prompting or extensive fine-tuning, which
often fails to introduce new capabilities while preserving strong
generalizability. We introduce Hephaestus-Forge, the first large-scale
pre-training corpus designed to enhance the fundamental capabilities of LLM
agents in API function calling, intrinsic reasoning and planning, and adapting
to environmental feedback. Hephaestus-Forge comprises 103B agent-specific data
encompassing 76,537 APIs, including both tool documentation to introduce
knowledge of API functions and function calling trajectories to strengthen
intrinsic reasoning. To explore effective training protocols, we investigate
scaling laws to identify the optimal recipe in data mixing ratios. By continual
pre-training on Hephaestus-Forge, Hephaestus outperforms small- to medium-scale
open-source LLMs and rivals commercial LLMs on three agent benchmarks,
demonstrating the effectiveness of our pre-training corpus in enhancing
fundamental agentic capabilities and generalization of LLMs to new tasks or
environments.",http://arxiv.org/abs/2502.06589v1,Reinforcement Learning,"training, pre, hephaestus, agent, data"
evclust: Python library for evidential clustering,"A recent developing trend in clustering is the advancement of algorithms that
not only identify clusters within data, but also express and capture the
uncertainty of cluster membership. Evidential clustering addresses this by
using the Dempster-Shafer theory of belief functions, a framework designed to
manage and represent uncertainty. This approach results in a credal partition,
a structured set of mass functions that quantify the uncertain assignment of
each object to potential groups. The Python framework evclust, presented in
this paper, offers a suite of efficient evidence clustering algorithms as well
as tools for visualizing, evaluating and analyzing credal partitions.",http://arxiv.org/abs/2502.06587v1,Natural Language Processing,"clustering, algorithms, uncertainty, functions, framework"
Deep Reinforcement Learning based Triggering Function for Early Classifiers of Time Series,"Early Classification of Time Series (ECTS) has been recognized as an
important problem in many areas where decisions have to be taken as soon as
possible, before the full data availability, while time pressure increases.
Numerous ECTS approaches have been proposed, based on different triggering
functions, each taking into account various pieces of information related to
the incoming time series and/or the output of a classifier. Although their
performances have been empirically compared in the literature, no studies have
been carried out on the optimality of these triggering functions that involve
``man-tailored'' decision rules. Based on the same information, could there be
better triggering functions? This paper presents one way to investigate this
question by showing first how to translate ECTS problems into Reinforcement
Learning (RL) ones, where the very same information is used in the state space.
A thorough comparison of the performance obtained by ``handmade'' approaches
and their ``RL-based'' counterparts has been carried out. A second question
investigated in this paper is whether a different combination of information,
defining the state space in RL systems, can achieve even better performance.
Experiments show that the system we describe, called \textsc{Alert},
significantly outperforms its state-of-the-art competitors on a large number of
datasets.",http://arxiv.org/abs/2502.06584v1,Reinforcement Learning,"information, time, ects, based, triggering"
Adaptive Perception for Unified Visual Multi-modal Object Tracking,"Recently, many multi-modal trackers prioritize RGB as the dominant modality,
treating other modalities as auxiliary, and fine-tuning separately various
multi-modal tasks. This imbalance in modality dependence limits the ability of
methods to dynamically utilize complementary information from each modality in
complex scenarios, making it challenging to fully perceive the advantages of
multi-modal. As a result, a unified parameter model often underperforms in
various multi-modal tracking tasks. To address this issue, we propose APTrack,
a novel unified tracker designed for multi-modal adaptive perception. Unlike
previous methods, APTrack explores a unified representation through an equal
modeling strategy. This strategy allows the model to dynamically adapt to
various modalities and tasks without requiring additional fine-tuning between
different tasks. Moreover, our tracker integrates an adaptive modality
interaction (AMI) module that efficiently bridges cross-modality interactions
by generating learnable tokens. Experiments conducted on five diverse
multi-modal datasets (RGBT234, LasHeR, VisEvent, DepthTrack, and VOT-RGBD2022)
demonstrate that APTrack not only surpasses existing state-of-the-art unified
multi-modal trackers but also outperforms trackers designed for specific
multi-modal tasks.",http://arxiv.org/abs/2502.06583v1,Recommendation System,"multi, modal, modality, tasks, unified"
A Survey on Video Analytics in Cloud-Edge-Terminal Collaborative Systems,"The explosive growth of video data has driven the development of distributed
video analytics in cloud-edge-terminal collaborative (CETC) systems, enabling
efficient video processing, real-time inference, and privacy-preserving
analysis. Among multiple advantages, CETC systems can distribute video
processing tasks and enable adaptive analytics across cloud, edge, and terminal
devices, leading to breakthroughs in video surveillance, autonomous driving,
and smart cities. In this survey, we first analyze fundamental architectural
components, including hierarchical, distributed, and hybrid frameworks,
alongside edge computing platforms and resource management mechanisms. Building
upon these foundations, edge-centric approaches emphasize on-device processing,
edge-assisted offloading, and edge intelligence, while cloud-centric methods
leverage powerful computational capabilities for complex video understanding
and model training. Our investigation also covers hybrid video analytics
incorporating adaptive task offloading and resource-aware scheduling techniques
that optimize performance across the entire system. Beyond conventional
approaches, recent advances in large language models and multimodal integration
reveal both opportunities and challenges in platform scalability, data
protection, and system reliability. Future directions also encompass
explainable systems, efficient processing mechanisms, and advanced video
analytics, offering valuable insights for researchers and practitioners in this
dynamic field.",http://arxiv.org/abs/2502.06581v2,Recommendation System,"video, edge, analytics, processing, cloud"
The Minimal Search Space for Conditional Causal Bandits,"Causal knowledge can be used to support decision-making problems. This has
been recognized in the causal bandits literature, where a causal (multi-armed)
bandit is characterized by a causal graphical model and a target variable. The
arms are then interventions on the causal model, and rewards are samples of the
target variable. Causal bandits were originally studied with a focus on hard
interventions. We focus instead on cases where the arms are conditional
interventions, which more accurately model many real-world decision-making
problems by allowing the value of the intervened variable to be chosen based on
the observed values of other variables. This paper presents a graphical
characterization of the minimal set of nodes guaranteed to contain the optimal
conditional intervention, which maximizes the expected reward. We then propose
an efficient algorithm with a time complexity of $O(|V| + |E|)$ to identify
this minimal set of nodes. We prove that the graphical characterization and the
proposed algorithm are correct. Finally, we empirically demonstrate that our
algorithm significantly prunes the search space and substantially accelerates
convergence rates when integrated into standard multi-armed bandit algorithms.",http://arxiv.org/abs/2502.06577v1,Reinforcement Learning,"causal, graphical, model, variable, interventions"
Predictive Red Teaming: Breaking Policies Without Breaking Robots,"Visuomotor policies trained via imitation learning are capable of performing
challenging manipulation tasks, but are often extremely brittle to lighting,
visual distractors, and object locations. These vulnerabilities can depend
unpredictably on the specifics of training, and are challenging to expose
without time-consuming and expensive hardware evaluations. We propose the
problem of predictive red teaming: discovering vulnerabilities of a policy with
respect to environmental factors, and predicting the corresponding performance
degradation without hardware evaluations in off-nominal scenarios. In order to
achieve this, we develop RoboART: an automated red teaming (ART) pipeline that
(1) modifies nominal observations using generative image editing to vary
different environmental factors, and (2) predicts performance under each
variation using a policy-specific anomaly detector executed on edited
observations. Experiments across 500+ hardware trials in twelve off-nominal
conditions for visuomotor diffusion policies demonstrate that RoboART predicts
performance degradation with high accuracy (less than 0.19 average difference
between predicted and real success rates). We also demonstrate how predictive
red teaming enables targeted data collection: fine-tuning with data collected
under conditions predicted to be adverse boosts baseline performance by 2-7x.",http://arxiv.org/abs/2502.06575v1,Reinforcement Learning,"performance, hardware, red, teaming, nominal"
On the Impact of the Utility in Semivalue-based Data Valuation,"Semivalue-based data valuation in machine learning (ML) quantifies the
contribution of individual data points to a downstream ML task by leveraging
principles from cooperative game theory and the notion of utility. While this
framework has been used in practice for assessing data quality, our experiments
reveal inconsistent valuation outcomes across different utilities, albeit all
related to ML performance. Beyond raising concerns about the reliability of
data valuation, this inconsistency is challenging to interpret, as it stems
from the complex interaction of the utility with data points and semivalue
weights, which has barely been studied in prior work. In this paper, we take a
first step toward clarifying the utility impact on semivalue-based data
valuation. Specifically, we provide geometric interpretations of this impact
for a broad family of classification utilities, which includes the accuracy and
the arithmetic mean. We introduce the notion of spatial signatures: given a
semivalue, data points can be embedded into a two-dimensional space, and
utility functions map to the dual of this space. This geometric perspective
separates the influence of the dataset and semivalue from that of the utility,
providing a theoretical explanation for the experimentally observed sensitivity
of valuation outcomes to the utility choice.",http://arxiv.org/abs/2502.06574v1,Recommendation System,"data, utility, semivalue, valuation, ml"
LawGPT: Knowledge-Guided Data Generation and Its Application to Legal LLM,"Large language models (LLMs), both proprietary and open-source, have
demonstrated remarkable capabilities across various natural language processing
tasks. However, they face significant limitations in legal reasoning tasks.
Proprietary models introduce data privacy risks and high inference costs, while
open-source models underperform due to insufficient legal domain training data.
To address these limitations, we study data generation for legal reasoning to
improve the legal reasoning performance of open-source LLMs with the help of
proprietary LLMs. This is challenging due to the lack of legal knowledge in
proprietary LLMs and the difficulty in verifying the generated data. We propose
KgDG, a knowledge-guided data generation framework for legal reasoning. Our
framework enables leveraging legal knowledge to enhance generation diversity
and introduces a refinement and verification process to ensure the quality of
generated data. Moreover, we expand the generated dataset to further enhance
the LLM reasoning capabilities. Using KgDG, we create a synthetic legal
reasoning dataset containing 50K high-quality examples. Our trained model
LawGPT outperforms existing legal-specific LLMs and achieves performance
comparable to proprietary LLMs, demonstrating the effectiveness of KgDG and
LawGPT. Our code and resources is publicly available at
https://anonymous.4open.science/r/KgDG-45F5 .",http://arxiv.org/abs/2502.06572v1,Natural Language Processing,"legal, llms, reasoning, data, proprietary"
Membership Inference Risks in Quantized Models: A Theoretical and Empirical Study,"Quantizing machine learning models has demonstrated its effectiveness in
lowering memory and inference costs while maintaining performance levels
comparable to the original models. In this work, we investigate the impact of
quantization procedures on the privacy of data-driven models, specifically
focusing on their vulnerability to membership inference attacks. We derive an
asymptotic theoretical analysis of Membership Inference Security (MIS),
characterizing the privacy implications of quantized algorithm weights against
the most powerful (and possibly unknown) attacks. Building on these theoretical
insights, we propose a novel methodology to empirically assess and rank the
privacy levels of various quantization procedures. Using synthetic datasets, we
demonstrate the effectiveness of our approach in assessing the MIS of different
quantizers. Furthermore, we explore the trade-off between privacy and
performance using real-world data and models in the context of molecular
modeling.",http://arxiv.org/abs/2502.06567v1,Recommendation System,"models, privacy, inference, effectiveness, performance"
Leveraging GPT-4o Efficiency for Detecting Rework Anomaly in Business Processes,"This paper investigates the effectiveness of GPT-4o-2024-08-06, one of the
Large Language Models (LLM) from OpenAI, in detecting business process
anomalies, with a focus on rework anomalies. In our study, we developed a
GPT-4o-based tool capable of transforming event logs into a structured format
and identifying reworked activities within business event logs. The analysis
was performed on a synthetic dataset designed to contain rework anomalies but
free of loops. To evaluate the anomaly detection capabilities of GPT
4o-2024-08-06, we used three prompting techniques: zero-shot, one-shot, and
few-shot. These techniques were tested on different anomaly distributions,
namely normal, uniform, and exponential, to identify the most effective
approach for each case. The results demonstrate the strong performance of
GPT-4o-2024-08-06. On our dataset, the model achieved 96.14% accuracy with
one-shot prompting for the normal distribution, 97.94% accuracy with few-shot
prompting for the uniform distribution, and 74.21% accuracy with few-shot
prompting for the exponential distribution. These results highlight the model's
potential as a reliable tool for detecting rework anomalies in event logs and
how anomaly distribution and prompting strategy influence the model's
performance.",http://arxiv.org/abs/2502.06918v1,Natural Language Processing,"shot, prompting, anomalies, distribution, rework"
Robust Scatter Matrix Estimation for Elliptical Distributions in Polynomial Time,"We study the problem of computationally efficient robust estimation of
scatter matrices of elliptical distributions under the strong contamination
model. We design polynomial time algorithms that achieve dimension-independent
error in Frobenius norm.
  Our first result is a sequence of efficient algorithms that approaches nearly
optimal error. Specifically, under a mild assumption on the eigenvalues of the
scatter matrix $\Sigma$, for every $t \in \mathbb{N}$, we design an estimator
that, given $n = d^{O(t)}$ samples, in time $n^{O(t)}$ finds $\hat{\Sigma}$
such that $ \Vert{\Sigma^{-1/2}\, ({\hat{\Sigma} - \Sigma})\,
\Sigma^{-1/2}}\Vert_{\text{F}} \le O(t \cdot \varepsilon^{1-\frac{1}{t}})$,
where $\varepsilon$ is the fraction of corruption. We do not require any
assumptions on the moments of the distribution, while all previously known
computationally efficient algorithms for robust covariance/scatter estimation
with dimension-independent error rely on strong assumptions on the moments,
such as sub-Gaussianity or (certifiable) hypercontractivity.
  Furthermore, under a stronger assumption on the eigenvalues of $\Sigma$
(that, in particular, is satisfied by all matrices with constant condition
number),
  we provide a fast (sub-quadratic in the input size) algorithm that, given
nearly optimal number of samples $n = \tilde{O}(d^2/\varepsilon)$, in time
$\tilde{O}({nd^2 poly(1/\varepsilon)})$ finds $\hat{\Sigma}$ such that
$\Vert\hat{\Sigma} - \Sigma\Vert_{\text{F}} \le O(\Vert{\Sigma}\Vert \cdot
\sqrt{\varepsilon})$.
  Our approach is based on robust covariance estimation of the spatial sign
(the projection onto the sphere of radius $\sqrt{d}$) of elliptical
distributions.",http://arxiv.org/abs/2502.06564v1,Recommendation System,"efficient, robust, estimation, scatter, time"
Can We Trust AI Benchmarks? An Interdisciplinary Review of Current Issues in AI Evaluation,"Quantitative Artificial Intelligence (AI) Benchmarks have emerged as
fundamental tools for evaluating the performance, capability, and safety of AI
models and systems. Currently, they shape the direction of AI development and
are playing an increasingly prominent role in regulatory frameworks. As their
influence grows, however, so too does concerns about how and with what effects
they evaluate highly sensitive topics such as capabilities, including
high-impact capabilities, safety and systemic risks. This paper presents an
interdisciplinary meta-review of about 100 studies that discuss shortcomings in
quantitative benchmarking practices, published in the last 10 years. It brings
together many fine-grained issues in the design and application of benchmarks
(such as biases in dataset creation, inadequate documentation, data
contamination, and failures to distinguish signal from noise) with broader
sociotechnical issues (such as an over-focus on evaluating text-based AI models
according to one-time testing logic that fails to account for how AI models are
increasingly multimodal and interact with humans and other technical systems).
Our review also highlights a series of systemic flaws in current benchmarking
practices, such as misaligned incentives, construct validity issues, unknown
unknowns, and problems with the gaming of benchmark results. Furthermore, it
underscores how benchmark practices are fundamentally shaped by cultural,
commercial and competitive dynamics that often prioritise state-of-the-art
performance at the expense of broader societal concerns. By providing an
overview of risks associated with existing benchmarking procedures, we
problematise disproportionate trust placed in benchmarks and contribute to
ongoing efforts to improve the accountability and relevance of quantitative AI
benchmarks within the complexities of real-world scenarios.",http://arxiv.org/abs/2502.06559v1,Recommendation System,"ai, benchmarks, quantitative, models, benchmarking"
Is API Access to LLMs Useful for Generating Private Synthetic Tabular Data?,"Differentially private (DP) synthetic data is a versatile tool for enabling
the analysis of private data. Recent advancements in large language models
(LLMs) have inspired a number of algorithm techniques for improving DP
synthetic data generation. One family of approaches uses DP finetuning on the
foundation model weights; however, the model weights for state-of-the-art
models may not be public. In this work we propose two DP synthetic tabular data
algorithms that only require API access to the foundation model. We adapt the
Private Evolution algorithm (Lin et al., 2023; Xie et al., 2024) -- which was
designed for image and text data -- to the tabular data domain. In our
extension of Private Evolution, we define a query workload-based distance
measure, which may be of independent interest. We propose a family of
algorithms that use one-shot API access to LLMs, rather than adaptive queries
to the LLM. Our findings reveal that API-access to powerful LLMs does not
always improve the quality of DP synthetic data compared to established
baselines that operate without such access. We provide insights into the
underlying reasons and propose improvements to LLMs that could make them more
effective for this application.",http://arxiv.org/abs/2502.06555v1,Recommendation System,"data, dp, private, synthetic, llms"
Diffusion Models for Computational Neuroimaging: A Survey,"Computational neuroimaging involves analyzing brain images or signals to
provide mechanistic insights and predictive tools for human cognition and
behavior. While diffusion models have shown stability and high-quality
generation in natural images, there is increasing interest in adapting them to
analyze brain data for various neurological tasks such as data enhancement,
disease diagnosis and brain decoding. This survey provides an overview of
recent efforts to integrate diffusion models into computational neuroimaging.
We begin by introducing the common neuroimaging data modalities, follow with
the diffusion formulations and conditioning mechanisms. Then we discuss how the
variations of the denoising starting point, condition input and generation
target of diffusion models are developed and enhance specific neuroimaging
tasks. For a comprehensive overview of the ongoing research, we provide a
publicly available repository at https://github.com/JoeZhao527/dm4neuro.",http://arxiv.org/abs/2502.06552v1,Recommendation System,"neuroimaging, diffusion, brain, models, data"
Data Augmentation and Regularization for Learning Group Equivariance,"In many machine learning tasks, known symmetries can be used as an inductive
bias to improve model performance. In this paper, we consider learning group
equivariance through training with data augmentation. We summarize results from
a previous paper of our own, and extend the results to show that equivariance
of the trained model can be achieved through training on augmented data in
tandem with regularization.",http://arxiv.org/abs/2502.06547v1,Recommendation System,"learning, model, paper, equivariance, training"
Krum Federated Chain (KFC): Using blockchain to defend against adversarial attacks in Federated Learning,"Federated Learning presents a nascent approach to machine learning, enabling
collaborative model training across decentralized devices while safeguarding
data privacy. However, its distributed nature renders it susceptible to
adversarial attacks. Integrating blockchain technology with Federated Learning
offers a promising avenue to enhance security and integrity. In this paper, we
tackle the potential of blockchain in defending Federated Learning against
adversarial attacks. First, we test Proof of Federated Learning, a well known
consensus mechanism designed ad-hoc to federated contexts, as a defense
mechanism demonstrating its efficacy against Byzantine and backdoor attacks
when at least one miner remains uncompromised. Second, we propose Krum
Federated Chain, a novel defense strategy combining Krum and Proof of Federated
Learning, valid to defend against any configuration of Byzantine or backdoor
attacks, even when all miners are compromised. Our experiments conducted on
image classification datasets validate the effectiveness of our proposed
approaches.",http://arxiv.org/abs/2502.06917v1,Recommendation System,"federated, learning, attacks, adversarial, blockchain"
Dimension-free Regret for Learning Asymmetric Linear Dynamical Systems,"Previously, methods for learning marginally stable linear dynamical systems
either required the transition matrix to be symmetric or incurred regret bounds
that scale polynomially with the system's hidden dimension. In this work, we
introduce a novel method that overcomes this trade-off, achieving
dimension-free regret despite the presence of asymmetric matrices and marginal
stability. Our method combines spectral filtering with linear predictors and
employs Chebyshev polynomials in the complex plane to construct a novel
spectral filtering basis. This construction guarantees sublinear regret in an
online learning framework, without relying on any statistical or generative
assumptions. Specifically, we prove that as long as the transition matrix has
eigenvalues with complex component bounded by $1/\mathrm{poly} \log T$, then
our method achieves regret $\tilde{O}(T^{9/10})$ when compared to the best
linear dynamical predictor in hindsight.",http://arxiv.org/abs/2502.06545v1,Recommendation System,"regret, linear, method, learning, dynamical"
Sequence Transferability and Task Order Selection in Continual Learning,"In continual learning, understanding the properties of task sequences and
their relationships to model performance is important for developing advanced
algorithms with better accuracy. However, efforts in this direction remain
underdeveloped despite encouraging progress in methodology development. In this
work, we investigate the impacts of sequence transferability on continual
learning and propose two novel measures that capture the total transferability
of a task sequence, either in the forward or backward direction. Based on the
empirical properties of these measures, we then develop a new method for the
task order selection problem in continual learning. Our method can be shown to
offer a better performance than the conventional strategy of random task
selection.",http://arxiv.org/abs/2502.06544v1,Recommendation System,"task, continual, learning, properties, performance"
Unsupervised Learning for Feature Extraction and Temporal Alignment of 3D+t Point Clouds of Zebrafish Embryos,"Zebrafish are widely used in biomedical research and developmental stages of
their embryos often need to be synchronized for further analysis. We present an
unsupervised approach to extract descriptive features from 3D+t point clouds of
zebrafish embryos and subsequently use those features to temporally align
corresponding developmental stages. An autoencoder architecture is proposed to
learn a descriptive representation of the point clouds and we designed a deep
regression network for their temporal alignment. We achieve a high alignment
accuracy with an average mismatch of only 3.83 minutes over an experimental
duration of 5.3 hours. As a fully-unsupervised approach, there is no manual
labeling effort required and unlike manual analyses the method easily scales.
Besides, the alignment without human annotation of the data also avoids any
influence caused by subjective bias.",http://arxiv.org/abs/2502.06543v1,Recommendation System,"alignment, zebrafish, developmental, stages, embryos"
Sample-efficient Learning of Concepts with Theoretical Guarantees: from Data to Concepts without Interventions,"Machine learning is a vital part of many real-world systems, but several
concerns remain about the lack of interpretability, explainability and
robustness of black-box AI systems. Concept-based models (CBM) address some of
these challenges by learning interpretable concepts from high-dimensional data,
e.g. images, which are used to predict labels. An important issue in CBMs is
concept leakage, i.e., spurious information in the learned concepts, which
effectively leads to learning ""wrong"" concepts. Current mitigating strategies
are heuristic, have strong assumptions, e.g., they assume that the concepts are
statistically independent of each other, or require substantial human
interaction in terms of both interventions and labels provided by annotators.
In this paper, we describe a framework that provides theoretical guarantees on
the correctness of the learned concepts and on the number of required labels,
without requiring any interventions. Our framework leverages causal
representation learning (CRL) to learn high-level causal variables from
low-level data, and learns to align these variables with interpretable
concepts. We propose a linear and a non-parametric estimator for this mapping,
providing a finite-sample high probability result in the linear case and an
asymptotic consistency result for the non-parametric estimator. We implement
our framework with state-of-the-art CRL methods, and show its efficacy in
learning the correct concepts in synthetic and image benchmarks.",http://arxiv.org/abs/2502.06536v1,Recommendation System,"concepts, learning, high, labels, framework"
Ignore the KL Penalty! Boosting Exploration on Critical Tokens to Enhance RL Fine-Tuning,"The ability to achieve long-term goals is a key challenge in the current
development of large language models (LLMs). To address this, pre-trained LLMs
can be fine-tuned with reinforcement learning (RL) to explore solutions that
optimize a given goal. However, exploration with LLMs is difficult, as a
balance has to be struck between discovering new solutions and staying close
enough to the pre-trained model, so as not to degrade basic capabilities. This
is typically controlled with a Kullback-Leibler (KL) penalty. In this paper, we
investigate the exploration dynamics of a small language model on a simple
arithmetic task. We show how varying degrees of pre-training influence
exploration and demonstrate the importance of ""critical tokens"" which have a
dramatic impact on the final outcome. Consequently, we introduce a simple
modification to the KL penalty that favors exploration on critical tokens,
increasing the efficiency of the RL fine-tuning stage.",http://arxiv.org/abs/2502.06533v1,Reinforcement Learning,"exploration, llms, pre, language, trained"
CustomVideoX: 3D Reference Attention Driven Dynamic Adaptation for Zero-Shot Customized Video Diffusion Transformers,"Customized generation has achieved significant progress in image synthesis,
yet personalized video generation remains challenging due to temporal
inconsistencies and quality degradation. In this paper, we introduce
CustomVideoX, an innovative framework leveraging the video diffusion
transformer for personalized video generation from a reference image.
CustomVideoX capitalizes on pre-trained video networks by exclusively training
the LoRA parameters to extract reference features, ensuring both efficiency and
adaptability. To facilitate seamless interaction between the reference image
and video content, we propose 3D Reference Attention, which enables direct and
simultaneous engagement of reference image features with all video frames
across spatial and temporal dimensions. To mitigate the excessive influence of
reference image features and textual guidance on generated video content during
inference, we implement the Time-Aware Reference Attention Bias (TAB) strategy,
dynamically modulating reference bias over different time steps. Additionally,
we introduce the Entity Region-Aware Enhancement (ERAE) module, aligning highly
activated regions of key entity tokens with reference feature injection by
adjusting attention bias. To thoroughly evaluate personalized video generation,
we establish a new benchmark, VideoBench, comprising over 50 objects and 100
prompts for extensive assessment. Experimental results show that CustomVideoX
significantly outperforms existing methods in terms of video consistency and
quality.",http://arxiv.org/abs/2502.06527v1,Reinforcement Learning,"video, reference, image, generation, personalized"
Properties of Wasserstein Gradient Flows for the Sliced-Wasserstein Distance,"In this paper, we investigate the properties of the Sliced Wasserstein
Distance (SW) when employed as an objective functional. The SW metric has
gained significant interest in the optimal transport and machine learning
literature, due to its ability to capture intricate geometric properties of
probability distributions while remaining computationally tractable, making it
a valuable tool for various applications, including generative modeling and
domain adaptation. Our study aims to provide a rigorous analysis of the
critical points arising from the optimization of the SW objective. By computing
explicit perturbations, we establish that stable critical points of SW cannot
concentrate on segments. This stability analysis is crucial for understanding
the behaviour of optimization algorithms for models trained using the SW
objective. Furthermore, we investigate the properties of the SW objective,
shedding light on the existence and convergence behavior of critical points. We
illustrate our theoretical results through numerical experiments.",http://arxiv.org/abs/2502.06525v1,Recommendation System,"sw, objective, properties, critical, points"
Pre-Trained Video Generative Models as World Simulators,"Video generative models pre-trained on large-scale internet datasets have
achieved remarkable success, excelling at producing realistic synthetic videos.
However, they often generate clips based on static prompts (e.g., text or
images), limiting their ability to model interactive and dynamic scenarios. In
this paper, we propose Dynamic World Simulation (DWS), a novel approach to
transform pre-trained video generative models into controllable world
simulators capable of executing specified action trajectories. To achieve
precise alignment between conditioned actions and generated visual changes, we
introduce a lightweight, universal action-conditioned module that seamlessly
integrates into any existing model. Instead of focusing on complex visual
details, we demonstrate that consistent dynamic transition modeling is the key
to building powerful world simulators. Building upon this insight, we further
introduce a motion-reinforced loss that enhances action controllability by
compelling the model to capture dynamic changes more effectively. Experiments
demonstrate that DWS can be versatilely applied to both diffusion and
autoregressive transformer models, achieving significant improvements in
generating action-controllable, dynamically consistent videos across games and
robotics domains. Moreover, to facilitate the applications of the learned world
simulator in downstream tasks such as model-based reinforcement learning, we
propose prioritized imagination to improve sample efficiency, demonstrating
competitive performance compared with state-of-the-art methods.",http://arxiv.org/abs/2502.07825v1,Reinforcement Learning,"model, dynamic, world, action, models"
Tighter Value-Function Approximations for POMDPs,"Solving partially observable Markov decision processes (POMDPs) typically
requires reasoning about the values of exponentially many state beliefs.
Towards practical performance, state-of-the-art solvers use value bounds to
guide this reasoning. However, sound upper value bounds are often
computationally expensive to compute, and there is a tradeoff between the
tightness of such bounds and their computational cost. This paper introduces
new and provably tighter upper value bounds than the commonly used fast
informed bound. Our empirical evaluation shows that, despite their additional
computational overhead, the new upper bounds accelerate state-of-the-art POMDP
solvers on a wide range of benchmarks.",http://arxiv.org/abs/2502.06523v1,Recommendation System,"bounds, state, value, upper, reasoning"
"SIREN: Semantic, Initialization-Free Registration of Multi-Robot Gaussian Splatting Maps","We present SIREN for registration of multi-robot Gaussian Splatting (GSplat)
maps, with zero access to camera poses, images, and inter-map transforms for
initialization or fusion of local submaps. To realize these capabilities, SIREN
harnesses the versatility and robustness of semantics in three critical ways to
derive a rigorous registration pipeline for multi-robot GSplat maps. First,
SIREN utilizes semantics to identify feature-rich regions of the local maps
where the registration problem is better posed, eliminating the need for any
initialization which is generally required in prior work. Second, SIREN
identifies candidate correspondences between Gaussians in the local maps using
robust semantic features, constituting the foundation for robust geometric
optimization, coarsely aligning 3D Gaussian primitives extracted from the local
maps. Third, this key step enables subsequent photometric refinement of the
transformation between the submaps, where SIREN leverages novel-view synthesis
in GSplat maps along with a semantics-based image filter to compute a
high-accuracy non-rigid transformation for the generation of a high-fidelity
fused map. We demonstrate the superior performance of SIREN compared to
competing baselines across a range of real-world datasets, and in particular,
across the most widely-used robot hardware platforms, including a manipulator,
drone, and quadruped. In our experiments, SIREN achieves about 90x smaller
rotation errors, 300x smaller translation errors, and 44x smaller scale errors
in the most challenging scenes, where competing methods struggle. We will
release the code and provide a link to the project page after the review
process.",http://arxiv.org/abs/2502.06519v1,Reinforcement Learning,"siren, maps, local, registration, robot"
Boost-and-Skip: A Simple Guidance-Free Diffusion for Minority Generation,"Minority samples are underrepresented instances located in low-density
regions of a data manifold, and are valuable in many generative AI
applications, such as data augmentation, creative content generation, etc.
Unfortunately, existing diffusion-based minority generators often rely on
computationally expensive guidance dedicated for minority generation. To
address this, here we present a simple yet powerful guidance-free approach
called Boost-and-Skip for generating minority samples using diffusion models.
The key advantage of our framework requires only two minimal changes to
standard generative processes: (i) variance-boosted initialization and (ii)
timestep skipping. We highlight that these seemingly-trivial modifications are
supported by solid theoretical and empirical evidence, thereby effectively
promoting emergence of underrepresented minority features. Our comprehensive
experiments demonstrate that Boost-and-Skip greatly enhances the capability of
generating minority samples, even rivaling guidance-based state-of-the-art
approaches while requiring significantly fewer computations.",http://arxiv.org/abs/2502.06516v1,Recommendation System,"minority, samples, guidance, underrepresented, data"
Learning Clustering-based Prototypes for Compositional Zero-shot Learning,"Learning primitive (i.e., attribute and object) concepts from seen
compositions is the primary challenge of Compositional Zero-Shot Learning
(CZSL). Existing CZSL solutions typically rely on oversimplified data
assumptions, e.g., modeling each primitive with a single centroid primitive
representation, ignoring the natural diversities of the attribute (resp.
object) when coupled with different objects (resp. attribute). In this work, we
develop ClusPro, a robust clustering-based prototype mining framework for CZSL
that defines the conceptual boundaries of primitives through a set of
diversified prototypes. Specifically, ClusPro conducts within-primitive
clustering on the embedding space for automatically discovering and dynamically
updating prototypes. These representative prototypes are subsequently used to
repaint a well-structured and independent primitive embedding space, ensuring
intra-primitive separation and inter-primitive decorrelation through
prototype-based contrastive learning and decorrelation learning. Moreover,
ClusPro efficiently performs prototype clustering in a non-parametric fashion
without the introduction of additional learnable parameters or computational
budget during testing. Experiments on three benchmarks demonstrate ClusPro
outperforms various top-leading CZSL solutions under both closed-world and
open-world settings.",http://arxiv.org/abs/2502.06501v1,Recommendation System,"primitive, learning, czsl, cluspro, attribute"
Decision Boundary Optimization-Informed Domain Adaptation,"Maximum Mean Discrepancy (MMD) is widely used in a number of domain
adaptation (DA) methods and shows its effectiveness in aligning data
distributions across domains. However, in previous DA research, MMD-based DA
methods focus mostly on distribution alignment, and ignore to optimize the
decision boundary for classification-aware DA, thereby falling short in
reducing the DA upper error bound. In this paper, we propose a strengthened MMD
measurement, namely, Decision Boundary optimization-informed MMD (DB-MMD),
which enables MMD to carefully take into account the decision boundaries,
thereby simultaneously optimizing the distribution alignment and cross-domain
classifier within a hybrid framework, and leading to a theoretical bound guided
DA. We further seamlessly embed the proposed DB-MMD measurement into several
popular DA methods, e.g., MEDA, DGA-DA, to demonstrate its effectiveness w.r.t
different experimental settings. We carry out comprehensive experiments using 8
standard DA datasets. The experimental results show that the DB-MMD enforced DA
methods improve their baseline models using plain vanilla MMD, with a margin
that can be as high as 9.5.",http://arxiv.org/abs/2502.06498v1,Recommendation System,"da, mmd, methods, decision, db"
GuideLLM: Exploring LLM-Guided Conversation with Applications in Autobiography Interviewing,"Although Large Language Models (LLMs) succeed in human-guided conversations
such as instruction following and question answering, the potential of
LLM-guided conversations-where LLMs direct the discourse and steer the
conversation's objectives-remains under-explored. In this study, we first
characterize LLM-guided conversation into three fundamental components: (i)
Goal Navigation; (ii) Context Management; (iii) Empathetic Engagement, and
propose GuideLLM as an installation. We then implement an interviewing
environment for the evaluation of LLM-guided conversation. Specifically,
various topics are involved in this environment for comprehensive interviewing
evaluation, resulting in around 1.4k turns of utterances, 184k tokens, and over
200 events mentioned during the interviewing for each chatbot evaluation. We
compare GuideLLM with 6 state-of-the-art LLMs such as GPT-4o and
Llama-3-70b-Instruct, from the perspective of interviewing quality, and
autobiography generation quality. For automatic evaluation, we derive user
proxies from multiple autobiographies and employ LLM-as-a-judge to score LLM
behaviors. We further conduct a human-involved experiment by employing 45 human
participants to chat with GuideLLM and baselines. We then collect human
feedback, preferences, and ratings regarding the qualities of conversation and
autobiography. Experimental results indicate that GuideLLM significantly
outperforms baseline LLMs in automatic evaluation and achieves consistent
leading performances in human ratings.",http://arxiv.org/abs/2502.06494v1,Natural Language Processing,"human, llm, evaluation, llms, guided"
Model-Based Offline Reinforcement Learning with Reliability-Guaranteed Sequence Modeling,"Model-based offline reinforcement learning (MORL) aims to learn a policy by
exploiting a dynamics model derived from an existing dataset. Applying
conservative quantification to the dynamics model, most existing works on MORL
generate trajectories that approximate the real data distribution to facilitate
policy learning by using current information (e.g., the state and action at
time step $t$). However, these works neglect the impact of historical
information on environmental dynamics, leading to the generation of unreliable
trajectories that may not align with the real data distribution. In this paper,
we propose a new MORL algorithm \textbf{R}eliability-guaranteed
\textbf{T}ransformer (RT), which can eliminate unreliable trajectories by
calculating the cumulative reliability of the generated trajectory (i.e., using
a weighted variational distance away from the real data). Moreover, by sampling
candidate actions with high rewards, RT can efficiently generate high-return
trajectories from the existing offline data. We theoretically prove the
performance guarantees of RT in policy learning, and empirically demonstrate
its effectiveness against state-of-the-art model-based methods on several
benchmark tasks.",http://arxiv.org/abs/2502.06491v1,Reinforcement Learning,"model, trajectories, data, learning, morl"
Recent Advances in Discrete Speech Tokens: A Review,"The rapid advancement of speech generation technologies in the era of large
language models (LLMs) has established discrete speech tokens as a foundational
paradigm for speech representation. These tokens, characterized by their
discrete, compact, and concise nature, are not only advantageous for efficient
transmission and storage, but also inherently compatible with the language
modeling framework, enabling seamless integration of speech into text-dominated
LLM architectures. Current research categorizes discrete speech tokens into two
principal classes: acoustic tokens and semantic tokens, each of which has
evolved into a rich research domain characterized by unique design philosophies
and methodological approaches. This survey systematically synthesizes the
existing taxonomy and recent innovations in discrete speech tokenization,
conducts a critical examination of the strengths and limitations of each
paradigm, and presents systematic experimental comparisons across token types.
Furthermore, we identify persistent challenges in the field and propose
potential research directions, aiming to offer actionable insights to inspire
future advancements in the development and application of discrete speech
tokens.",http://arxiv.org/abs/2502.06490v1,Recommendation System,"speech, tokens, discrete, research, language"
Biomechanical Reconstruction with Confidence Intervals from Multiview Markerless Motion Capture,"Advances in multiview markerless motion capture (MMMC) promise high-quality
movement analysis for clinical practice and research. While prior validation
studies show MMMC performs well on average, they do not provide what is needed
in clinical practice or for large-scale utilization of MMMC -- confidence
intervals over specific kinematic estimates from a specific individual analyzed
using a possibly unique camera configuration. We extend our previous work using
an implicit representation of trajectories optimized end-to-end through a
differentiable biomechanical model to learn the posterior probability
distribution over pose given all the detected keypoints. This posterior
probability is learned through a variational approximation and estimates
confidence intervals for individual joints at each moment in a trial, showing
confidence intervals generally within 10-15 mm of spatial error for virtual
marker locations, consistent with our prior validation studies. Confidence
intervals over joint angles are typically only a few degrees and widen for more
distal joints. The posterior also models the correlation structure over joint
angles, such as correlations between hip and pelvis angles. The confidence
intervals estimated through this method allow us to identify times and trials
where kinematic uncertainty is high.",http://arxiv.org/abs/2502.06486v1,Recommendation System,"confidence, intervals, mmmc, posterior, angles"
WyckoffDiff - A Generative Diffusion Model for Crystal Symmetry,"Crystalline materials often exhibit a high level of symmetry. However, most
generative models do not account for symmetry, but rather model each atom
without any constraints on its position or element. We propose a generative
model, Wyckoff Diffusion (WyckoffDiff), which generates symmetry-based
descriptions of crystals. This is enabled by considering a crystal structure
representation that encodes all symmetry, and we design a novel neural network
architecture which enables using this representation inside a discrete
generative model framework. In addition to respecting symmetry by construction,
the discrete nature of our model enables fast generation. We additionally
present a new metric, Fr\'echet Wrenformer Distance, which captures the
symmetry aspects of the materials generated, and we benchmark WyckoffDiff
against recently proposed generative models for crystal generation.",http://arxiv.org/abs/2502.06485v1,Recommendation System,"symmetry, generative, model, materials, models"
Logarithmic Regret of Exploration in Average Reward Markov Decision Processes,"In average reward Markov decision processes, state-of-the-art algorithms for
regret minimization follow a well-established framework: They are model-based,
optimistic and episodic. First, they maintain a confidence region from which
optimistic policies are computed using a well-known subroutine called Extended
Value Iteration (EVI). Second, these policies are used over time windows called
episodes, each ended by the Doubling Trick (DT) rule or a variant thereof. In
this work, without modifying EVI, we show that there is a significant advantage
in replacing (DT) by another simple rule, that we call the Vanishing
Multiplicative (VM) rule. When managing episodes with (VM), the algorithm's
regret is, both in theory and in practice, as good if not better than with
(DT), while the one-shot behavior is greatly improved. More specifically, the
management of bad episodes (when sub-optimal policies are being used) is much
better under (VM) than (DT) by making the regret of exploration logarithmic
rather than linear. These results are made possible by a new in-depth
understanding of the contrasting behaviors of confidence regions during good
and bad episodes.",http://arxiv.org/abs/2502.06480v1,Recommendation System,"episodes, dt, regret, policies, rule"
Image Intrinsic Scale Assessment: Bridging the Gap Between Quality and Resolution,"Image Quality Assessment (IQA) measures and predicts perceived image quality
by human observers. Although recent studies have highlighted the critical
influence that variations in the scale of an image have on its perceived
quality, this relationship has not been systematically quantified. To bridge
this gap, we introduce the Image Intrinsic Scale (IIS), defined as the largest
scale where an image exhibits its highest perceived quality. We also present
the Image Intrinsic Scale Assessment (IISA) task, which involves subjectively
measuring and predicting the IIS based on human judgments. We develop a
subjective annotation methodology and create the IISA-DB dataset, comprising
785 image-IIS pairs annotated by experts in a rigorously controlled
crowdsourcing study. Furthermore, we propose WIISA (Weak-labeling for Image
Intrinsic Scale Assessment), a strategy that leverages how the IIS of an image
varies with downscaling to generate weak labels. Experiments show that applying
WIISA during the training of several IQA methods adapted for IISA consistently
improves the performance compared to using only ground-truth labels. We will
release the code, dataset, and pre-trained models upon acceptance.",http://arxiv.org/abs/2502.06476v1,Recommendation System,"image, scale, quality, iis, assessment"
UniMoD: Efficient Unified Multimodal Transformers with Mixture-of-Depths,"Unified multimodal transformers, which handle both generation and
understanding tasks within a shared parameter space, have received increasing
attention in recent research. Although various unified transformers have been
proposed, training these models is costly due to redundant tokens and heavy
attention computation. In the past, studies on large language models have
demonstrated that token pruning methods, such as Mixture of Depths (MoD), can
significantly improve computational efficiency. MoD employs a router to select
the most important ones for processing within a transformer layer. However,
directly applying MoD-based token pruning to unified transformers will result
in suboptimal performance because different tasks exhibit varying levels of
token redundancy. In our work, we analyze the unified transformers by (1)
examining attention weight patterns, (2) evaluating the layer importance and
token redundancy, and (3) analyzing task interactions. Our findings reveal that
token redundancy is primarily influenced by different tasks and layers.
Building on these findings, we introduce UniMoD, a task-aware token pruning
method that employs a separate router for each task to determine which tokens
should be pruned. We apply our method to Show-o and Emu3, reducing training
FLOPs by approximately 15% in Show-o and 40% in Emu3, while maintaining or
improving performance on several benchmarks. Code will be released at
https://github.com/showlab/UniMoD.",http://arxiv.org/abs/2502.06474v1,Reinforcement Learning,"token, unified, transformers, tasks, attention"
KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment,"Maintaining comprehensive and up-to-date knowledge graphs (KGs) is critical
for modern AI systems, but manual curation struggles to scale with the rapid
growth of scientific literature. This paper presents KARMA, a novel framework
employing multi-agent large language models (LLMs) to automate KG enrichment
through structured analysis of unstructured text. Our approach employs nine
collaborative agents, spanning entity discovery, relation extraction, schema
alignment, and conflict resolution that iteratively parse documents, verify
extracted knowledge, and integrate it into existing graph structures while
adhering to domain-specific schema. Experiments on 1,200 PubMed articles from
three different domains demonstrate the effectiveness of KARMA in knowledge
graph enrichment, with the identification of up to 38,230 new entities while
achieving 83.1\% LLM-verified correctness and reducing conflict edges by 18.6\%
through multi-layer assessments.",http://arxiv.org/abs/2502.06472v1,Recommendation System,"knowledge, karma, multi, enrichment, schema"
"A Survey of Theory of Mind in Large Language Models: Evaluations, Representations, and Safety Risks","Theory of Mind (ToM), the ability to attribute mental states to others and
predict their behaviour, is fundamental to social intelligence. In this paper,
we survey studies evaluating behavioural and representational ToM in Large
Language Models (LLMs), identify important safety risks from advanced LLM ToM
capabilities, and suggest several research directions for effective evaluation
and mitigation of these risks.",http://arxiv.org/abs/2502.06470v1,Recommendation System,"tom, risks, theory, mind, ability"
Group-CLIP Uncertainty Modeling for Group Re-Identification,"Group Re-Identification (Group ReID) aims matching groups of pedestrians
across non-overlapping cameras. Unlike single-person ReID, Group ReID focuses
more on the changes in group structure, emphasizing the number of members and
their spatial arrangement. However, most methods rely on certainty-based
models, which consider only the specific group structures in the group images,
often failing to match unseen group configurations. To this end, we propose a
novel Group-CLIP UncertaintyModeling (GCUM) approach that adapts group text
descriptions to undetermined accommodate member and layout variations.
Specifically, we design a Member Variant Simulation (MVS)module that simulates
member exclusions using a Bernoulli distribution and a Group Layout Adaptation
(GLA) module that generates uncertain group text descriptions with
identity-specific tokens. In addition, we design a Group
RelationshipConstruction Encoder (GRCE) that uses group features to refine
individual features, and employ cross-modal contrastive loss to obtain
generalizable knowledge from group text descriptions. It is worth noting that
we are the first to employ CLIP to GroupReID, and extensive experiments show
that GCUM significantly outperforms state-of-the-art Group ReID methods.",http://arxiv.org/abs/2502.06460v1,Reinforcement Learning,"group, reid, text, descriptions, member"
MATH-Perturb: Benchmarking LLMs' Math Reasoning Abilities against Hard Perturbations,"Large language models have demonstrated impressive performance on challenging
mathematical reasoning tasks, which has triggered the discussion of whether the
performance is achieved by true reasoning capability or memorization. To
investigate this question, prior work has constructed mathematical benchmarks
when questions undergo simple perturbations -- modifications that still
preserve the underlying reasoning patterns of the solutions. However, no work
has explored hard perturbations, which fundamentally change the nature of the
problem so that the original solution steps do not apply. To bridge the gap, we
construct MATH-P-Simple and MATH-P-Hard via simple perturbation and hard
perturbation, respectively. Each consists of 279 perturbed math problems
derived from level-5 (hardest) problems in the MATH dataset (Hendrycksmath et.
al., 2021). We observe significant performance drops on MATH-P-Hard across
various models, including o1-mini (-16.49%) and gemini-2.0-flash-thinking
(-12.9%). We also raise concerns about a novel form of memorization where
models blindly apply learned problem-solving skills without assessing their
applicability to modified contexts. This issue is amplified when using original
problems for in-context learning. We call for research efforts to address this
challenge, which is critical for developing more robust and reliable reasoning
models.",http://arxiv.org/abs/2502.06453v1,Natural Language Processing,"math, models, reasoning, hard, performance"
SparseFocus: Learning-based One-shot Autofocus for Microscopy with Sparse Content,"Autofocus is necessary for high-throughput and real-time scanning in
microscopic imaging. Traditional methods rely on complex hardware or iterative
hill-climbing algorithms. Recent learning-based approaches have demonstrated
remarkable efficacy in a one-shot setting, avoiding hardware modifications or
iterative mechanical lens adjustments. However, in this paper, we highlight a
significant challenge that the richness of image content can significantly
affect autofocus performance. When the image content is sparse, previous
autofocus methods, whether traditional climbing-hill or learning-based, tend to
fail. To tackle this, we propose a content-importance-based solution, named
SparseFocus, featuring a novel two-stage pipeline. The first stage measures the
importance of regions within the image, while the second stage calculates the
defocus distance from selected important regions. To validate our approach and
benefit the research community, we collect a large-scale dataset comprising
millions of labelled defocused images, encompassing both dense, sparse and
extremely sparse scenarios. Experimental results show that SparseFocus
surpasses existing methods, effectively handling all levels of content
sparsity. Moreover, we integrate SparseFocus into our Whole Slide Imaging (WSI)
system that performs well in real-world applications. The code and dataset will
be made available upon the publication of this paper.",http://arxiv.org/abs/2502.06452v1,Recommendation System,"content, autofocus, methods, based, image"
Benchmarking Vision-Language Models on Optical Character Recognition in Dynamic Video Environments,"This paper introduces an open-source benchmark for evaluating Vision-Language
Models (VLMs) on Optical Character Recognition (OCR) tasks in dynamic video
environments. We present a curated dataset containing 1,477 manually annotated
frames spanning diverse domains, including code editors, news broadcasts,
YouTube videos, and advertisements. Three state of the art VLMs - Claude-3,
Gemini-1.5, and GPT-4o are benchmarked against traditional OCR systems such as
EasyOCR and RapidOCR. Evaluation metrics include Word Error Rate (WER),
Character Error Rate (CER), and Accuracy. Our results highlight the strengths
and limitations of VLMs in video-based OCR tasks, demonstrating their potential
to outperform conventional OCR models in many scenarios. However, challenges
such as hallucinations, content security policies, and sensitivity to occluded
or stylized text remain. The dataset and benchmarking framework are publicly
available to foster further research.",http://arxiv.org/abs/2502.06445v1,Computer Vision,"ocr, vlms, models, character, tasks"
Low-dimensional Functions are Efficiently Learnable under Randomly Biased Distributions,"The problem of learning single index and multi index models has gained
significant interest as a fundamental task in high-dimensional statistics. Many
recent works have analysed gradient-based methods, particularly in the setting
of isotropic data distributions, often in the context of neural network
training. Such studies have uncovered precise characterisations of algorithmic
sample complexity in terms of certain analytic properties of the target
function, such as the leap, information, and generative exponents. These
properties establish a quantitative separation between low and high complexity
learning tasks. In this work, we show that high complexity cases are rare.
Specifically, we prove that introducing a small random perturbation to the data
distribution--via a random shift in the first moment--renders any Gaussian
single index model as easy to learn as a linear function. We further extend
this result to a class of multi index models, namely sparse Boolean functions,
also known as Juntas.",http://arxiv.org/abs/2502.06443v1,Recommendation System,"index, high, complexity, learning, single"
SIGMA: Sheaf-Informed Geometric Multi-Agent Pathfinding,"The Multi-Agent Path Finding (MAPF) problem aims to determine the shortest
and collision-free paths for multiple agents in a known, potentially
obstacle-ridden environment. It is the core challenge for robotic deployments
in large-scale logistics and transportation. Decentralized learning-based
approaches have shown great potential for addressing the MAPF problems,
offering more reactive and scalable solutions. However, existing learning-based
MAPF methods usually rely on agents making decisions based on a limited field
of view (FOV), resulting in short-sighted policies and inefficient cooperation
in complex scenarios. There, a critical challenge is to achieve consensus on
potential movements between agents based on limited observations and
communications. To tackle this challenge, we introduce a new framework that
applies sheaf theory to decentralized deep reinforcement learning, enabling
agents to learn geometric cross-dependencies between each other through local
consensus and utilize them for tightly cooperative decision-making. In
particular, sheaf theory provides a mathematical proof of conditions for
achieving global consensus through local observation. Inspired by this, we
incorporate a neural network to approximately model the consensus in latent
space based on sheaf theory and train it through self-supervised learning.
During the task, in addition to normal features for MAPF as in previous works,
each agent distributedly reasons about a learned consensus feature, leading to
efficient cooperation on pathfinding and collision avoidance. As a result, our
proposed method demonstrates significant improvements over state-of-the-art
learning-based MAPF planners, especially in relatively large and complex
scenarios, demonstrating its superiority over baselines in various simulations
and real-world robot experiments.",http://arxiv.org/abs/2502.06440v1,Reinforcement Learning,"based, mapf, learning, consensus, agents"
Testing software for non-discrimination: an updated and extended audit in the Italian car insurance domain,"Context. As software systems become more integrated into society's
infrastructure, the responsibility of software professionals to ensure
compliance with various non-functional requirements increases. These
requirements include security, safety, privacy, and, increasingly,
non-discrimination.
  Motivation. Fairness in pricing algorithms grants equitable access to basic
services without discriminating on the basis of protected attributes.
  Method. We replicate a previous empirical study that used black box testing
to audit pricing algorithms used by Italian car insurance companies, accessible
through a popular online system. With respect to the previous study, we
enlarged the number of tests and the number of demographic variables under
analysis.
  Results. Our work confirms and extends previous findings, highlighting the
problematic permanence of discrimination across time: demographic variables
significantly impact pricing to this day, with birthplace remaining the main
discriminatory factor against individuals not born in Italian cities. We also
found that driver profiles can determine the number of quotes available to the
user, denying equal opportunities to all.
  Conclusion. The study underscores the importance of testing for
non-discrimination in software systems that affect people's everyday lives.
Performing algorithmic audits over time makes it possible to evaluate the
evolution of such algorithms. It also demonstrates the role that empirical
software engineering can play in making software systems more accountable.",http://arxiv.org/abs/2502.06439v1,Recommendation System,"software, systems, non, discrimination, pricing"
FEMBA: Efficient and Scalable EEG Analysis with a Bidirectional Mamba Foundation Model,"Accurate and efficient electroencephalography (EEG) analysis is essential for
detecting seizures and artifacts in long-term monitoring, with applications
spanning hospital diagnostics to wearable health devices. Robust EEG analytics
have the potential to greatly improve patient care. However, traditional deep
learning models, especially Transformer-based architectures, are hindered by
their quadratic time and memory complexity, making them less suitable for
resource-constrained environments. To address these challenges, we present
FEMBA (Foundational EEG Mamba + Bidirectional Architecture), a novel
self-supervised framework that establishes new efficiency benchmarks for EEG
analysis through bidirectional state-space modeling. Unlike Transformer-based
models, which incur quadratic time and memory complexity, FEMBA scales linearly
with sequence length, enabling more scalable and efficient processing of
extended EEG recordings. Trained on over 21,000 hours of unlabeled EEG and
fine-tuned on three downstream tasks, FEMBA achieves competitive performance in
comparison with transformer models, with significantly lower computational
cost. Specifically, it reaches 81.82% balanced accuracy (0.8921 AUROC) on TUAB
and 0.949 AUROC on TUAR, while a tiny 7.8M-parameter variant demonstrates
viability for resource-constrained devices. These results pave the way for
scalable, general-purpose EEG analytics in both clinical and highlight FEMBA as
a promising candidate for wearable applications.",http://arxiv.org/abs/2502.06438v1,Recommendation System,"eeg, femba, models, transformer, efficient"
Rethinking Large-scale Dataset Compression: Shifting Focus From Labels to Images,"Dataset distillation and dataset pruning are two prominent techniques for
compressing datasets to improve computational and storage efficiency. Despite
their overlapping objectives, these approaches are rarely compared directly.
Even within each field, the evaluation protocols are inconsistent across
various methods, which complicates fair comparisons and hinders
reproducibility. Considering these limitations, we introduce in this paper a
benchmark that equitably evaluates methodologies across both distillation and
pruning literatures. Notably, our benchmark reveals that in the mainstream
dataset distillation setting for large-scale datasets, which heavily rely on
soft labels from pre-trained models, even randomly selected subsets can achieve
surprisingly competitive performance. This finding suggests that an
overemphasis on soft labels may be diverting attention from the intrinsic value
of the image data, while also imposing additional burdens in terms of
generation, storage, and application. To address these issues, we propose a new
framework for dataset compression, termed Prune, Combine, and Augment (PCA),
which focuses on leveraging image data exclusively, relies solely on hard
labels for evaluation, and achieves state-of-the-art performance in this setup.
By shifting the emphasis back to the images, our benchmark and PCA framework
pave the way for more balanced and accessible techniques in dataset compression
research. Our code is available at:
https://github.com/ArmandXiao/Rethinking-Dataset-Compression",http://arxiv.org/abs/2502.06434v1,Recommendation System,"dataset, distillation, benchmark, labels, pruning"
Prompt-SID: Learning Structural Representation Prompt via Latent Diffusion for Single-Image Denoising,"Many studies have concentrated on constructing supervised models utilizing
paired datasets for image denoising, which proves to be expensive and
time-consuming. Current self-supervised and unsupervised approaches typically
rely on blind-spot networks or sub-image pairs sampling, resulting in pixel
information loss and destruction of detailed structural information, thereby
significantly constraining the efficacy of such methods. In this paper, we
introduce Prompt-SID, a prompt-learning-based single image denoising framework
that emphasizes preserving of structural details. This approach is trained in a
self-supervised manner using downsampled image pairs. It captures
original-scale image information through structural encoding and integrates
this prompt into the denoiser. To achieve this, we propose a structural
representation generation model based on the latent diffusion process and
design a structural attention module within the transformer-based denoiser
architecture to decode the prompt. Additionally, we introduce a scale replay
training mechanism, which effectively mitigates the scale gap from images of
different resolutions. We conduct comprehensive experiments on synthetic,
real-world, and fluorescence imaging datasets, showcasing the remarkable
effectiveness of Prompt-SID.",http://arxiv.org/abs/2502.06432v1,Recommendation System,"image, structural, prompt, supervised, information"
FCVSR: A Frequency-aware Method for Compressed Video Super-Resolution,"Compressed video super-resolution (SR) aims to generate high-resolution (HR)
videos from the corresponding low-resolution (LR) compressed videos. Recently,
some compressed video SR methods attempt to exploit the spatio-temporal
information in the frequency domain, showing great promise in super-resolution
performance. However, these methods do not differentiate various frequency
subbands spatially or capture the temporal frequency dynamics, potentially
leading to suboptimal results. In this paper, we propose a deep frequency-based
compressed video SR model (FCVSR) consisting of a motion-guided adaptive
alignment (MGAA) network and a multi-frequency feature refinement (MFFR)
module. Additionally, a frequency-aware contrastive loss is proposed for
training FCVSR, in order to reconstruct finer spatial details. The proposed
model has been evaluated on three public compressed video super-resolution
datasets, with results demonstrating its effectiveness when compared to
existing works in terms of super-resolution performance (up to a 0.14dB gain in
PSNR over the second-best model) and complexity.",http://arxiv.org/abs/2502.06431v1,Recommendation System,"resolution, frequency, compressed, video, super"
Hyper Compressed Fine-Tuning of Large Foundation Models with Quantum Inspired Adapters,"Fine-tuning pre-trained large foundation models for specific tasks has become
increasingly challenging due to the computational and storage demands
associated with full parameter updates. Parameter-Efficient Fine-Tuning (PEFT)
methods address this issue by updating only a small subset of model parameters
using adapter modules. In this work, we propose \emph{Quantum-Inspired
Adapters}, a PEFT approach inspired by Hamming-weight preserving quantum
circuits from quantum machine learning literature. These models can be both
expressive and parameter-efficient by operating in a combinatorially large
space while simultaneously preserving orthogonality in weight parameters. We
test our proposed adapters by adapting large language models and large vision
transformers on benchmark datasets. Our method can achieve 99.2\% of the
performance of existing fine-tuning methods such LoRA with a 44x parameter
compression on language understanding datasets like GLUE and VTAB. Compared to
existing orthogonal fine-tuning methods such as OFT or BOFT, we achieve 98\%
relative performance with 25x fewer parameters. This demonstrates competitive
performance paired with a significant reduction in trainable parameters.
Through ablation studies, we determine that combining multiple Hamming-weight
orders with orthogonality and matrix compounding are essential for performant
fine-tuning. Our findings suggest that Quantum-Inspired Adapters offer a
promising direction for efficient adaptation of language and vision models in
resource-constrained environments.",http://arxiv.org/abs/2502.06916v1,Recommendation System,"fine, tuning, large, models, parameter"
CoS: Chain-of-Shot Prompting for Long Video Understanding,"Multi-modal Large Language Models (MLLMs) struggle with long videos due to
the need for excessive visual tokens. These tokens exceed massively the context
length of MLLMs, resulting in filled by redundant task-irrelevant shots. How to
select shots is an unsolved critical problem: sparse sampling risks missing key
details, while exhaustive sampling overwhelms the model with irrelevant
content, leading to video misunderstanding. To solve this problem, we propose
Chain-of-Shot prompting (CoS). The key idea is to frame shot selection as
test-time visual prompt optimisation, choosing shots adaptive to video
understanding semantic task by optimising shots-task alignment. CoS has two key
parts: (1) a binary video summary mechanism that performs pseudo temporal
grounding, discovering a binary coding to identify task-relevant shots, and (2)
a video co-reasoning module that deploys the binary coding to pair (learning to
align) task-relevant positive shots with irrelevant negative shots. It embeds
the optimised shot selections into the original video, facilitating a focus on
relevant context to optimize long video understanding. Experiments across three
baselines and five datasets demonstrate the effectiveness and adaptability of
CoS. Code given in https://lwpyh.github.io/CoS.",http://arxiv.org/abs/2502.06428v2,Recommendation System,"shots, video, task, irrelevant, key"
Hybrid State-Space and GRU-based Graph Tokenization Mamba for Hyperspectral Image Classification,"Hyperspectral image (HSI) classification plays a pivotal role in domains such
as environmental monitoring, agriculture, and urban planning. However, it faces
significant challenges due to the high-dimensional nature of the data and the
complex spectral-spatial relationships inherent in HSI. Traditional methods,
including conventional machine learning and convolutional neural networks
(CNNs), often struggle to effectively capture these intricate spectral-spatial
features and global contextual information. Transformer-based models, while
powerful in capturing long-range dependencies, often demand substantial
computational resources, posing challenges in scenarios where labeled datasets
are limited, as is commonly seen in HSI applications. To overcome these
challenges, this work proposes GraphMamba, a hybrid model that combines
spectral-spatial token generation, graph-based token prioritization, and
cross-attention mechanisms. The model introduces a novel hybridization of
state-space modeling and Gated Recurrent Units (GRU), capturing both linear and
nonlinear spatial-spectral dynamics. GraphMamba enhances the ability to model
complex spatial-spectral relationships while maintaining scalability and
computational efficiency across diverse HSI datasets. Through comprehensive
experiments, we demonstrate that GraphMamba outperforms existing
state-of-the-art models, offering a scalable and robust solution for complex
HSI classification tasks.",http://arxiv.org/abs/2502.06427v1,Recommendation System,"hsi, spectral, spatial, challenges, complex"
Generating Privacy-Preserving Personalized Advice with Zero-Knowledge Proofs and LLMs,"Large language models (LLMs) are increasingly utilized in domains such as
finance, healthcare, and interpersonal relationships to provide advice tailored
to user traits and contexts. However, this personalization often relies on
sensitive data, raising critical privacy concerns and necessitating data
minimization. To address these challenges, we propose a framework that
integrates zero-knowledge proof (ZKP) technology, specifically zkVM, with
LLM-based chatbots. This integration enables privacy-preserving data sharing by
verifying user traits without disclosing sensitive information. Our research
introduces both an architecture and a prompting strategy for this approach.
Through empirical evaluation, we clarify the current constraints and
performance limitations of both zkVM and the proposed prompting strategy,
thereby demonstrating their practical feasibility in real-world scenarios.",http://arxiv.org/abs/2502.06425v1,Natural Language Processing,"data, user, traits, sensitive, privacy"
CS-SHAP: Extending SHAP to Cyclic-Spectral Domain for Better Interpretability of Intelligent Fault Diagnosis,"Neural networks (NNs), with their powerful nonlinear mapping and end-to-end
capabilities, are widely applied in mechanical intelligent fault diagnosis
(IFD). However, as typical black-box models, they pose challenges in
understanding their decision basis and logic, limiting their deployment in
high-reliability scenarios. Hence, various methods have been proposed to
enhance the interpretability of IFD. Among these, post-hoc approaches can
provide explanations without changing model architecture, preserving its
flexibility and scalability. However, existing post-hoc methods often suffer
from limitations in explanation forms. They either require preprocessing that
disrupts the end-to-end nature or overlook fault mechanisms, leading to
suboptimal explanations. To address these issues, we derived the
cyclic-spectral (CS) transform and proposed the CS-SHAP by extending Shapley
additive explanations (SHAP) to the CS domain. CS-SHAP can evaluate
contributions from both carrier and modulation frequencies, aligning more
closely with fault mechanisms and delivering clearer and more accurate
explanations. Three datasets are utilized to validate the superior
interpretability of CS-SHAP, ensuring its correctness, reproducibility, and
practical performance. With open-source code and outstanding interpretability,
CS-SHAP has the potential to be widely adopted and become the post-hoc
interpretability benchmark in IFD, even in other classification tasks. The code
is available on https://github.com/ChenQian0618/CS-SHAP.",http://arxiv.org/abs/2502.06424v1,Recommendation System,"cs, shap, end, interpretability, explanations"
Robust Watermarks Leak: Channel-Aware Feature Extraction Enables Adversarial Watermark Manipulation,"Watermarking plays a key role in the provenance and detection of AI-generated
content. While existing methods prioritize robustness against real-world
distortions (e.g., JPEG compression and noise addition), we reveal a
fundamental tradeoff: such robust watermarks inherently improve the redundancy
of detectable patterns encoded into images, creating exploitable information
leakage. To leverage this, we propose an attack framework that extracts leakage
of watermark patterns through multi-channel feature learning using a
pre-trained vision model. Unlike prior works requiring massive data or detector
access, our method achieves both forgery and detection evasion with a single
watermarked image. Extensive experiments demonstrate that our method achieves a
60\% success rate gain in detection evasion and 51\% improvement in forgery
accuracy compared to state-of-the-art methods while maintaining visual
fidelity. Our work exposes the robustness-stealthiness paradox: current
""robust"" watermarks sacrifice security for distortion resistance, providing
insights for future watermark design.",http://arxiv.org/abs/2502.06418v1,Recommendation System,"detection, methods, robustness, robust, watermarks"
Systematic Outliers in Large Language Models,"Outliers have been widely observed in Large Language Models (LLMs),
significantly impacting model performance and posing challenges for model
compression. Understanding the functionality and formation mechanisms of these
outliers is critically important. Existing works, however, largely focus on
reducing the impact of outliers from an algorithmic perspective, lacking an
in-depth investigation into their causes and roles. In this work, we provide a
detailed analysis of the formation process, underlying causes, and functions of
outliers in LLMs. We define and categorize three types of outliers-activation
outliers, weight outliers, and attention outliers-and analyze their
distributions across different dimensions, uncovering inherent connections
between their occurrences and their ultimate influence on the attention
mechanism. Based on these observations, we hypothesize and explore the
mechanisms by which these outliers arise and function, demonstrating through
theoretical derivations and experiments that they emerge due to the
self-attention mechanism's softmax operation. These outliers act as implicit
context-aware scaling factors within the attention mechanism. As these outliers
stem from systematic influences, we term them systematic outliers. Our study
not only enhances the understanding of Transformer-based LLMs but also shows
that structurally eliminating outliers can accelerate convergence and improve
model compression. The code is avilable at
https://github.com/an-yongqi/systematic-outliers.",http://arxiv.org/abs/2502.06415v1,Recommendation System,"outliers, attention, llms, model, mechanism"
Runtime Tunable Tsetlin Machines for Edge Inference on eFPGAs,"Embedded Field-Programmable Gate Arrays (eFPGAs) allow for the design of
hardware accelerators of edge Machine Learning (ML) applications at a lower
power budget compared with traditional FPGA platforms. However, the limited
eFPGA logic and memory significantly constrain compute capabilities and model
size. As such, ML application deployment on eFPGAs is in direct contrast with
the most recent FPGA approaches developing architecture-specific
implementations and maximizing throughput over resource frugality. This paper
focuses on the opposite side of this trade-off: the proposed eFPGA accelerator
focuses on minimizing resource usage and allowing flexibility for on-field
recalibration over throughput. This allows for runtime changes in model size,
architecture, and input data dimensionality without offline resynthesis. This
is made possible through the use of a bitwise compressed inference architecture
of the Tsetlin Machine (TM) algorithm. TM compute does not require any
multiplication operations, being limited to only bitwise AND, OR, NOT,
summations and additions. Additionally, TM model compression allows the entire
model to fit within the on-chip block RAM of the eFPGA. The paper uses this
accelerator to propose a strategy for runtime model tuning in the field. The
proposed approach uses 2.5x fewer Look-up-Tables (LUTs) and 3.38x fewer
registers than the current most resource-fugal design and achieves up to 129x
energy reduction compared with low-power microcontrollers running the same ML
application.",http://arxiv.org/abs/2502.07823v1,Recommendation System,"model, field, ml, efpga, architecture"
An Automated Machine Learning Framework for Surgical Suturing Action Detection under Class Imbalance,"In laparoscopy surgical training and evaluation, real-time detection of
surgical actions with interpretable outputs is crucial for automated and
real-time instructional feedback and skill development. Such capability would
enable development of machine guided training systems. This paper presents a
rapid deployment approach utilizing automated machine learning methods, based
on surgical action data collected from both experienced and trainee surgeons.
The proposed approach effectively tackles the challenge of highly imbalanced
class distributions, ensuring robust predictions across varying skill levels of
surgeons. Additionally, our method partially incorporates model transparency,
addressing the reliability requirements in medical applications. Compared to
deep learning approaches, traditional machine learning models not only
facilitate efficient rapid deployment but also offer significant advantages in
interpretability. Through experiments, this study demonstrates the potential of
this approach to provide quick, reliable and effective real-time detection in
surgical training environments",http://arxiv.org/abs/2502.06407v1,Recommendation System,"surgical, training, real, time, machine"
The AI off-switch problem as a signalling game: bounded rationality and incomparability,"The off-switch problem is a critical challenge in AI control: if an AI system
resists being switched off, it poses a significant risk. In this paper, we
model the off-switch problem as a signalling game, where a human decision-maker
communicates its preferences about some underlying decision problem to an AI
agent, which then selects actions to maximise the human's utility. We assume
that the human is a bounded rational agent and explore various bounded
rationality mechanisms. Using real machine learning models, we reprove prior
results and demonstrate that a necessary condition for an AI system to refrain
from disabling its off-switch is its uncertainty about the human's utility. We
also analyse how message costs influence optimal strategies and extend the
analysis to scenarios involving incomparability.",http://arxiv.org/abs/2502.06403v2,Recommendation System,"ai, human, switch, problem, system"
PDM-SSD: Single-Stage Three-Dimensional Object Detector With Point Dilation,"Current Point-based detectors can only learn from the provided points, with
limited receptive fields and insufficient global learning capabilities for such
targets. In this paper, we present a novel Point Dilation Mechanism for
single-stage 3D detection (PDM-SSD) that takes advantage of these two
representations. Specifically, we first use a PointNet-style 3D backbone for
efficient feature encoding. Then, a neck with Point Dilation Mechanism (PDM) is
used to expand the feature space, which involves two key steps: point dilation
and feature filling. The former expands points to a certain size grid centered
around the sampled points in Euclidean space. The latter fills the unoccupied
grid with feature for backpropagation using spherical harmonic coefficients and
Gaussian density function in terms of direction and scale. Next, we associate
multiple dilation centers and fuse coefficients to obtain sparse grid features
through height compression. Finally, we design a hybrid detection head for
joint learning, where on one hand, the scene heatmap is predicted to complement
the voting point set for improved detection accuracy, and on the other hand,
the target probability of detected boxes are calibrated through feature fusion.
On the challenging Karlsruhe Institute of Technology and Toyota Technological
Institute (KITTI) dataset, PDM-SSD achieves state-of-the-art results for
multi-class detection among single-modal methods with an inference speed of 68
frames. We also demonstrate the advantages of PDM-SSD in detecting sparse and
incomplete objects through numerous object-level instances. Additionally, PDM
can serve as an auxiliary network to establish a connection between sampling
points and object centers, thereby improving the accuracy of the model without
sacrificing inference speed. Our code will be available at
https://github.com/AlanLiangC/PDM-SSD.git.",http://arxiv.org/abs/2502.07822v1,Computer Vision,"point, pdm, feature, points, dilation"
Habitizing Diffusion Planning for Efficient and Effective Decision Making,"Diffusion models have shown great promise in decision-making, also known as
diffusion planning. However, the slow inference speeds limit their potential
for broader real-world applications. Here, we introduce Habi, a general
framework that transforms powerful but slow diffusion planning models into fast
decision-making models, which mimics the cognitive process in the brain that
costly goal-directed behavior gradually transitions to efficient habitual
behavior with repetitive practice. Even using a laptop CPU, the habitized model
can achieve an average 800+ Hz decision-making frequency (faster than previous
diffusion planners by orders of magnitude) on standard offline reinforcement
learning benchmarks D4RL, while maintaining comparable or even higher
performance compared to its corresponding diffusion planner. Our work proposes
a fresh perspective of leveraging powerful diffusion models for real-world
decision-making tasks. We also provide robust evaluations and analysis,
offering insights from both biological and engineering perspectives for
efficient and effective decision-making.",http://arxiv.org/abs/2502.06401v1,Reinforcement Learning,"diffusion, decision, making, models, planning"
Learning Counterfactual Outcomes Under Rank Preservation,"Counterfactual inference aims to estimate the counterfactual outcome at the
individual level given knowledge of an observed treatment and the factual
outcome, with broad applications in fields such as epidemiology, econometrics,
and management science. Previous methods rely on a known structural causal
model (SCM) or assume the homogeneity of the exogenous variable and strict
monotonicity between the outcome and exogenous variable. In this paper, we
propose a principled approach for identifying and estimating the counterfactual
outcome. We first introduce a simple and intuitive rank preservation assumption
to identify the counterfactual outcome without relying on a known structural
causal model. Building on this, we propose a novel ideal loss for theoretically
unbiased learning of the counterfactual outcome and further develop a
kernel-based estimator for its empirical estimation. Our theoretical analysis
shows that the rank preservation assumption is not stronger than the
homogeneity and strict monotonicity assumptions, and shows that the proposed
ideal loss is convex, and the proposed estimator is unbiased. Extensive
semi-synthetic and real-world experiments are conducted to demonstrate the
effectiveness of the proposed method.",http://arxiv.org/abs/2502.06398v1,Recommendation System,"outcome, counterfactual, proposed, known, structural"
AppVLM: A Lightweight Vision Language Model for Online App Control,"The utilisation of foundation models as smartphone assistants, termed app
agents, is a critical research challenge. These agents aim to execute human
instructions on smartphones by interpreting textual instructions and performing
actions via the device's interface. While promising, current approaches face
significant limitations. Methods that use large proprietary models, such as
GPT-4o, are computationally expensive, while those that use smaller fine-tuned
models often lack adaptability to out-of-distribution tasks. In this work, we
introduce AppVLM, a lightweight Vision-Language Model (VLM). First, we
fine-tune it offline on the AndroidControl dataset. Then, we refine its policy
by collecting data from the AndroidWorld environment and performing further
training iterations. Our results indicate that AppVLM achieves the highest
action prediction accuracy in offline evaluation on the AndroidControl dataset,
compared to all evaluated baselines, and matches GPT-4o in online task
completion success rate in the AndroidWorld environment, while being up to ten
times faster. This makes AppVLM a practical and efficient solution for
real-world deployment.",http://arxiv.org/abs/2502.06395v1,Computer Vision,"models, appvlm, agents, instructions, performing"
TANGLED: Generating 3D Hair Strands from Images with Arbitrary Styles and Viewpoints,"Hairstyles are intricate and culturally significant with various geometries,
textures, and structures. Existing text or image-guided generation methods fail
to handle the richness and complexity of diverse styles. We present TANGLED, a
novel approach for 3D hair strand generation that accommodates diverse image
inputs across styles, viewpoints, and quantities of input views. TANGLED
employs a three-step pipeline. First, our MultiHair Dataset provides 457
diverse hairstyles annotated with 74 attributes, emphasizing complex and
culturally significant styles to improve model generalization. Second, we
propose a diffusion framework conditioned on multi-view linearts that can
capture topological cues (e.g., strand density and parting lines) while
filtering out noise. By leveraging a latent diffusion model with
cross-attention on lineart features, our method achieves flexible and robust 3D
hair generation across diverse input conditions. Third, a parametric
post-processing module enforces braid-specific constraints to maintain
coherence in complex structures. This framework not only advances hairstyle
realism and diversity but also enables culturally inclusive digital avatars and
novel applications like sketch-based 3D strand editing for animation and
augmented reality.",http://arxiv.org/abs/2502.06392v1,Recommendation System,"diverse, culturally, generation, styles, strand"
When Data Manipulation Meets Attack Goals: An In-depth Survey of Attacks for VLMs,"Vision-Language Models (VLMs) have gained considerable prominence in recent
years due to their remarkable capability to effectively integrate and process
both textual and visual information. This integration has significantly
enhanced performance across a diverse spectrum of applications, such as scene
perception and robotics. However, the deployment of VLMs has also given rise to
critical safety and security concerns, necessitating extensive research to
assess the potential vulnerabilities these VLM systems may harbor. In this
work, we present an in-depth survey of the attack strategies tailored for VLMs.
We categorize these attacks based on their underlying objectives - namely
jailbreak, camouflage, and exploitation - while also detailing the various
methodologies employed for data manipulation of VLMs. Meanwhile, we outline
corresponding defense mechanisms that have been proposed to mitigate these
vulnerabilities. By discerning key connections and distinctions among the
diverse types of attacks, we propose a compelling taxonomy for VLM attacks.
Moreover, we summarize the evaluation metrics that comprehensively describe the
characteristics and impact of different attacks on VLMs. Finally, we conclude
with a discussion of promising future research directions that could further
enhance the robustness and safety of VLMs, emphasizing the importance of
ongoing exploration in this critical area of study. To facilitate community
engagement, we maintain an up-to-date project page, accessible at:
https://github.com/AobtDai/VLM_Attack_Paper_List.",http://arxiv.org/abs/2502.06390v2,Computer Vision,"vlms, attacks, diverse, critical, safety"
How Humans Help LLMs: Assessing and Incentivizing Human Preference Annotators,"Human-annotated preference data play an important role in aligning large
language models (LLMs). In this paper, we investigate the questions of
assessing the performance of human annotators and incentivizing them to provide
high-quality annotations. The quality assessment of language/text annotation
faces two challenges: (i) the intrinsic heterogeneity among annotators, which
prevents the classic methods that assume the underlying existence of a true
label; and (ii) the unclear relationship between the annotation quality and the
performance of downstream tasks, which excludes the possibility of inferring
the annotators' behavior based on the model performance trained from the
annotation data. Then we formulate a principal-agent model to characterize the
behaviors of and the interactions between the company and the human annotators.
The model rationalizes a practical mechanism of a bonus scheme to incentivize
annotators which benefits both parties and it underscores the importance of the
joint presence of an assessment system and a proper contract scheme. From a
technical perspective, our analysis extends the existing literature on the
principal-agent model by considering a continuous action space for the agent.
We show the gap between the first-best and the second-best solutions (under the
continuous action space) is of $\Theta(1/\sqrt{n \log n})$ for the binary
contracts and $\Theta(1/n)$ for the linear contracts, where $n$ is the number
of samples used for performance assessment; this contrasts with the known
result of $\exp(-\Theta(n))$ for the binary contracts when the action space is
discrete. Throughout the paper, we use real preference annotation data to
accompany our discussions.",http://arxiv.org/abs/2502.06387v1,Recommendation System,"annotators, performance, annotation, model, human"
Structure-preserving contrastive learning for spatial time series,"Informative representations enhance model performance and generalisability in
downstream tasks. However, learning self-supervised representations for
spatially characterised time series, like traffic interactions, poses
challenges as it requires maintaining fine-grained similarity relations in the
latent space. In this study, we incorporate two structure-preserving
regularisers for the contrastive learning of spatial time series: one
regulariser preserves the topology of similarities between instances, and the
other preserves the graph geometry of similarities across spatial and temporal
dimensions. To balance contrastive learning and structure preservation, we
propose a dynamic mechanism that adaptively weighs the trade-off and stabilises
training. We conduct experiments on multivariate time series classification, as
well as macroscopic and microscopic traffic prediction. For all three tasks,
our approach preserves the structures of similarity relations more effectively
and improves state-of-the-art task performances. The proposed approach can be
applied to an arbitrary encoder and is particularly beneficial for time series
with spatial or geographical features. Furthermore, this study suggests that
higher similarity structure preservation indicates more informative and useful
representations. This may help to understand the contribution of representation
learning in pattern recognition with neural networks. Our code is made openly
accessible with all resulting data at https://github.com/yiru-jiao/spclt.",http://arxiv.org/abs/2502.06380v1,Recommendation System,"learning, time, series, representations, similarity"
Solving Linear-Gaussian Bayesian Inverse Problems with Decoupled Diffusion Sequential Monte Carlo,"A recent line of research has exploited pre-trained generative diffusion
models as priors for solving Bayesian inverse problems. We contribute to this
research direction by designing a sequential Monte Carlo method for
linear-Gaussian inverse problems which builds on ``decoupled diffusion"", where
the generative process is designed such that larger updates to the sample are
possible. The method is asymptotically exact and we demonstrate the
effectiveness of our Decoupled Diffusion Sequential Monte Carlo (DDSMC)
algorithm on both synthetic data and image reconstruction tasks. Further, we
demonstrate how the approach can be extended to discrete data.",http://arxiv.org/abs/2502.06379v1,Recommendation System,"diffusion, research, generative, inverse, problems"
Many-Task Federated Fine-Tuning via Unified Task Vectors,"Federated Learning (FL) traditionally assumes homogeneous client tasks;
however, in real-world scenarios, clients often specialize in diverse tasks,
introducing task heterogeneity. To address this challenge, Many-Task FL
(MaT-FL) has emerged, enabling clients to collaborate effectively despite task
diversity. Existing MaT-FL approaches rely on client grouping or personalized
layers, requiring the server to manage individual models and failing to account
for clients handling multiple tasks. We propose MaTU, a MaT-FL approach that
enables joint learning of task vectors across clients, eliminating the need for
clustering or client-specific weight storage at the server. Our method
introduces a novel aggregation mechanism that determines task similarity based
on the direction of clients task vectors and constructs a unified task vector
encapsulating all tasks. To address task-specific requirements, we augment the
unified task vector with lightweight modulators that facilitate knowledge
transfer among related tasks while disentangling dissimilar ones. Evaluated
across 30 datasets, MaTU achieves superior performance over state-of-the-art
MaT-FL approaches, with results comparable to per-task fine-tuning, while
delivering significant communication savings.",http://arxiv.org/abs/2502.06376v1,Reinforcement Learning,"task, fl, tasks, clients, mat"
Amnesia as a Catalyst for Enhancing Black Box Pixel Attacks in Image Classification and Object Detection,"It is well known that query-based attacks tend to have relatively higher
success rates in adversarial black-box attacks. While research on black-box
attacks is actively being conducted, relatively few studies have focused on
pixel attacks that target only a limited number of pixels. In image
classification, query-based pixel attacks often rely on patches, which heavily
depend on randomness and neglect the fact that scattered pixels are more
suitable for adversarial attacks. Moreover, to the best of our knowledge,
query-based pixel attacks have not been explored in the field of object
detection. To address these issues, we propose a novel pixel-based black-box
attack called Remember and Forget Pixel Attack using Reinforcement
Learning(RFPAR), consisting of two main components: the Remember and Forget
processes. RFPAR mitigates randomness and avoids patch dependency by leveraging
rewards generated through a one-step RL algorithm to perturb pixels. RFPAR
effectively creates perturbed images that minimize the confidence scores while
adhering to limited pixel constraints. Furthermore, we advance our proposed
attack beyond image classification to object detection, where RFPAR reduces the
confidence scores of detected objects to avoid detection. Experiments on the
ImageNet-1K dataset for classification show that RFPAR outperformed
state-of-the-art query-based pixel attacks. For object detection, using the
MSCOCO dataset with YOLOv8 and DDQ, RFPAR demonstrates comparable mAP reduction
to state-of-the-art query-based attack while requiring fewer query. Further
experiments on the Argoverse dataset using YOLOv8 confirm that RFPAR
effectively removed objects on a larger scale dataset. Our code is available at
https://github.com/KAU-QuantumAILab/RFPAR.",http://arxiv.org/abs/2502.07821v1,Reinforcement Learning,"attacks, pixel, query, based, rfpar"
Hyperparameters in Score-Based Membership Inference Attacks,"Membership Inference Attacks (MIAs) have emerged as a valuable framework for
evaluating privacy leakage by machine learning models. Score-based MIAs are
distinguished, in particular, by their ability to exploit the confidence scores
that the model generates for particular inputs. Existing score-based MIAs
implicitly assume that the adversary has access to the target model's
hyperparameters, which can be used to train the shadow models for the attack.
In this work, we demonstrate that the knowledge of target hyperparameters is
not a prerequisite for MIA in the transfer learning setting. Based on this, we
propose a novel approach to select the hyperparameters for training the shadow
models for MIA when the attacker has no prior knowledge about them by matching
the output distributions of target and shadow models. We demonstrate that using
the new approach yields hyperparameters that lead to an attack near
indistinguishable in performance from an attack that uses target
hyperparameters to train the shadow models. Furthermore, we study the empirical
privacy risk of unaccounted use of training data for hyperparameter
optimization (HPO) in differentially private (DP) transfer learning. We find no
statistically significant evidence that performing HPO using training data
would increase vulnerability to MIA.",http://arxiv.org/abs/2502.06374v1,Recommendation System,"models, hyperparameters, target, shadow, mias"
FOCUS - Multi-View Foot Reconstruction From Synthetically Trained Dense Correspondences,"Surface reconstruction from multiple, calibrated images is a challenging task
- often requiring a large number of collected images with significant overlap.
We look at the specific case of human foot reconstruction. As with previous
successful foot reconstruction work, we seek to extract rich per-pixel geometry
cues from multi-view RGB images, and fuse these into a final 3D object. Our
method, FOCUS, tackles this problem with 3 main contributions: (i) SynFoot2, an
extension of an existing synthetic foot dataset to include a new data type:
dense correspondence with the parameterized foot model FIND; (ii) an
uncertainty-aware dense correspondence predictor trained on our synthetic
dataset; (iii) two methods for reconstructing a 3D surface from dense
correspondence predictions: one inspired by Structure-from-Motion, and one
optimization-based using the FIND model. We show that our reconstruction
achieves state-of-the-art reconstruction quality in a few-view setting,
performing comparably to state-of-the-art when many views are available, and
runs substantially faster. We release our synthetic dataset to the research
community. Code is available at: https://github.com/OllieBoyne/FOCUS",http://arxiv.org/abs/2502.06367v1,Reinforcement Learning,"reconstruction, foot, images, synthetic, dataset"
Automatic Identification of Samples in Hip-Hop Music via Multi-Loss Training and an Artificial Dataset,"Sampling, the practice of reusing recorded music or sounds from another
source in a new work, is common in popular music genres like hip-hop and rap.
Numerous services have emerged that allow users to identify connections between
samples and the songs that incorporate them, with the goal of enhancing music
discovery. Designing a system that can perform the same task automatically is
challenging, as samples are commonly altered with audio effects like pitch- and
time-stretching and may only be seconds long. Progress on this task has been
minimal and is further blocked by the limited availability of training data.
Here, we show that a convolutional neural network trained on an artificial
dataset can identify real-world samples in commercial hip-hop music. We extract
vocal, harmonic, and percussive elements from several databases of
non-commercial music recordings using audio source separation, and train the
model to fingerprint a subset of these elements in transformed versions of the
original audio. We optimize the model using a joint classification and metric
learning loss and show that it achieves 13% greater precision on real-world
instances of sampling than a fingerprinting system using acoustic landmarks,
and that it can recognize samples that have been both pitch shifted and time
stretched. We also show that, for half of the commercial music recordings we
tested, our model is capable of locating the position of a sample to within
five seconds.",http://arxiv.org/abs/2502.06364v1,Recommendation System,"music, samples, audio, commercial, model"
"Improved Regret Analysis in Gaussian Process Bandits: Optimality for Noiseless Reward, RKHS norm, and Non-Stationary Variance","We study the Gaussian process (GP) bandit problem, whose goal is to minimize
regret under an unknown reward function lying in some reproducing kernel
Hilbert space (RKHS). The maximum posterior variance analysis is vital in
analyzing near-optimal GP bandit algorithms such as maximum variance reduction
(MVR) and phased elimination (PE). Therefore, we first show the new upper bound
of the maximum posterior variance, which improves the dependence of the noise
variance parameters of the GP. By leveraging this result, we refine the MVR and
PE to obtain (i) a nearly optimal regret upper bound in the noiseless setting
and (ii) regret upper bounds that are optimal with respect to the RKHS norm of
the reward function. Furthermore, as another application of our proposed bound,
we analyze the GP bandit under the time-varying noise variance setting, which
is the kernelized extension of the linear bandit with heteroscedastic noise.
For this problem, we show that MVR and PE-based algorithms achieve noise
variance-dependent regret upper bounds, which matches our regret lower bound.",http://arxiv.org/abs/2502.06363v1,Recommendation System,"variance, regret, gp, bandit, upper"
Analytic Personalized Federated Meta-Learning,"Analytic federated learning (AFL) which updates model weights only once by
using closed-form least-square (LS) solutions can reduce abundant training time
in gradient-free federated learning (FL). The current AFL framework cannot
support deep neural network (DNN) training, which hinders its implementation on
complex machine learning tasks. Meanwhile, it overlooks the heterogeneous data
distribution problem that restricts the single global model from performing
well on each client's task. To overcome the first challenge, we propose an AFL
framework, namely FedACnnL, in which we resort to a novel local analytic
learning method (ACnnL) and model the training of each layer as a distributed
LS problem. For the second challenge, we propose an analytic personalized
federated meta-learning framework, namely pFedACnnL, which is inherited from
FedACnnL. In pFedACnnL, clients with similar data distribution share a common
robust global model for fast adapting it to local tasks in an analytic manner.
FedACnnL is theoretically proven to require significantly shorter training time
than the conventional zeroth-order (i.e. gradient-free) FL frameworks on DNN
training while the reduction ratio is $98\%$ in the experiment. Meanwhile,
pFedACnnL achieves state-of-the-art (SOTA) model performance in most cases of
convex and non-convex settings, compared with the previous SOTA frameworks.",http://arxiv.org/abs/2502.06915v1,Recommendation System,"learning, model, training, analytic, federated"
Towards bandit-based prompt-tuning for in-the-wild foundation agents,"Prompting has emerged as the dominant paradigm for adapting large,
pre-trained transformer-based models to downstream tasks. The Prompting
Decision Transformer (PDT) enables large-scale, multi-task offline
reinforcement learning pre-training by leveraging stochastic trajectory prompts
to identify the target task. However, these prompts are sampled uniformly from
expert demonstrations, overlooking a critical limitation: Not all prompts are
equally informative for differentiating between tasks. To address this, we
propose an inference time bandit-based prompt-tuning framework that explores
and optimizes trajectory prompt selection to enhance task performance. Our
experiments indicate not only clear performance gains due to bandit-based
prompt-tuning, but also better sample complexity, scalability, and prompt space
exploration compared to prompt-tuning baselines.",http://arxiv.org/abs/2502.06358v2,Reinforcement Learning,"prompt, based, task, prompts, tuning"
Fine-tuning Multimodal Transformers on Edge: A Parallel Split Learning Approach,"Multimodal transformers integrate diverse data types like images, audio, and
text, advancing tasks such as audio-visual understanding and image-text
retrieval; yet their high parameterization limits deployment on
resource-constrained edge devices. Split Learning (SL), which partitions models
at a designated cut-layer to offload compute-intensive operations to the
server, offers a promising approach for distributed training of multimodal
transformers, though its application remains underexplored. We present MPSL, a
parallel SL approach for computational efficient fine-tuning of multimodal
transformers in a distributed manner, while eliminating label sharing, client
synchronization, and per-client sub-model management. MPSL employs lightweight
client-side tokenizers and a unified modality-agnostic encoder, allowing
flexible adaptation to task-specific needs. Our evaluation across 7 multimodal
datasets demonstrates that MPSL matches or outperforms Federated Learning,
reduces client-side computations by 250x, and achieves superior scalability in
communication cost with model growth. Through extensive analysis, we highlight
task suitability, trade-offs, and scenarios where MPSL excels, inspiring
further exploration.",http://arxiv.org/abs/2502.06355v1,Recommendation System,"multimodal, mpsl, client, transformers, audio"
Guidance-base Diffusion Models for Improving Photoacoustic Image Quality,"Photoacoustic(PA) imaging is a non-destructive and non-invasive technology
for visualizing minute blood vessel structures in the body using ultrasonic
sensors. In PA imaging, the image quality of a single-shot image is poor, and
it is necessary to improve the image quality by averaging many single-shot
images. Therefore, imaging the entire subject requires high imaging costs. In
our study, we propose a method to improve the quality of PA images using
diffusion models. In our method, we improve the reverse diffusion process using
sensor information of PA imaging and introduce a guidance method using imaging
condition information to generate high-quality images.",http://arxiv.org/abs/2502.06354v1,Recommendation System,"imaging, quality, pa, image, improve"
LANTERN++: Enhanced Relaxed Speculative Decoding with Static Tree Drafting for Visual Auto-regressive Models,"Speculative decoding has been widely used to accelerate autoregressive (AR)
text generation. However, its effectiveness in visual AR models remains limited
due to token selection ambiguity, where multiple tokens receive similarly low
probabilities, reducing acceptance rates. While dynamic tree drafting has been
proposed to improve speculative decoding, we show that it fails to mitigate
token selection ambiguity, resulting in shallow draft trees and suboptimal
acceleration. To address this, we introduce LANTERN++, a novel framework that
integrates static tree drafting with a relaxed acceptance condition, allowing
drafts to be selected independently of low-confidence predictions. This enables
deeper accepted sequences, improving decoding efficiency while preserving image
quality. Extensive experiments on state-of-the-art visual AR models demonstrate
that LANTERN++ significantly accelerates inference, achieving up to
$\mathbf{\times 2.56}$ speedup over standard AR decoding while maintaining high
image quality.",http://arxiv.org/abs/2502.06352v1,Reinforcement Learning,"decoding, ar, speculative, visual, models"
Calibrating LLMs with Information-Theoretic Evidential Deep Learning,"Fine-tuned large language models (LLMs) often exhibit overconfidence,
particularly when trained on small datasets, resulting in poor calibration and
inaccurate uncertainty estimates. Evidential Deep Learning (EDL), an
uncertainty-aware approach, enables uncertainty estimation in a single forward
pass, making it a promising method for calibrating fine-tuned LLMs. However,
despite its computational efficiency, EDL is prone to overfitting, as its
training objective can result in overly concentrated probability distributions.
To mitigate this, we propose regularizing EDL by incorporating an information
bottleneck (IB). Our approach IB-EDL suppresses spurious information in the
evidence generated by the model and encourages truly predictive information to
influence both the predictions and uncertainty estimates. Extensive experiments
across various fine-tuned LLMs and tasks demonstrate that IB-EDL outperforms
both existing EDL and non-EDL approaches. By improving the trustworthiness of
LLMs, IB-EDL facilitates their broader adoption in domains requiring high
levels of confidence calibration. Code is available at
https://github.com/sandylaker/ib-edl.",http://arxiv.org/abs/2502.06351v2,Recommendation System,"edl, llms, uncertainty, ib, fine"
Provably Near-Optimal Federated Ensemble Distillation with Negligible Overhead,"Federated ensemble distillation addresses client heterogeneity by generating
pseudo-labels for an unlabeled server dataset based on client predictions and
training the server model using the pseudo-labeled dataset. The unlabeled
server dataset can either be pre-existing or generated through a data-free
approach. The effectiveness of this approach critically depends on the method
of assigning weights to client predictions when creating pseudo-labels,
especially in highly heterogeneous settings. Inspired by theoretical results
from GANs, we propose a provably near-optimal weighting method that leverages
client discriminators trained with a server-distributed generator and local
datasets. Our experiments on various image classification tasks demonstrate
that the proposed method significantly outperforms baselines. Furthermore, we
show that the additional communication cost, client-side privacy leakage, and
client-side computational overhead introduced by our method are negligible,
both in scenarios with and without a pre-existing server dataset.",http://arxiv.org/abs/2502.06349v1,Recommendation System,"client, server, dataset, method, pseudo"
AiRacleX: Automated Detection of Price Oracle Manipulations via LLM-Driven Knowledge Mining and Prompt Generation,"Decentralized finance (DeFi) applications depend on accurate price oracles to
ensure secure transactions, yet these oracles are highly vulnerable to
manipulation, enabling attackers to exploit smart contract vulnerabilities for
unfair asset valuation and financial gain. Detecting such manipulations
traditionally relies on the manual effort of experienced experts, presenting
significant challenges. In this paper, we propose a novel LLM-driven framework
that automates the detection of price oracle manipulations by leveraging the
complementary strengths of different LLM models (LLMs). Our approach begins
with domain-specific knowledge extraction, where an LLM model synthesizes
precise insights about price oracle vulnerabilities from top-tier academic
papers, eliminating the need for profound expertise from developers or
auditors. This knowledge forms the foundation for a second LLM model to
generate structured, context-aware chain of thought prompts, which guide a
third LLM model in accurately identifying manipulation patterns in smart
contracts. We validate the effectiveness of framework through experiments on 60
known vulnerabilities from 46 real-world DeFi attacks or projects spanning 2021
to 2023. The best performing combination of LLMs (Haiku-Haiku-4o-mini)
identified by AiRacleX demonstrate a 2.58-times improvement in recall (0.667 vs
0.259) compared to the state-of-the-art tool GPTScan, while maintaining
comparable precision. Furthermore, our framework demonstrates the feasibility
of replacing commercial models with open-source alternatives, enhancing privacy
and security for developers.",http://arxiv.org/abs/2502.06348v2,Reinforcement Learning,"llm, price, vulnerabilities, framework, model"
Causal Lifting of Neural Representations: Zero-Shot Generalization for Causal Inferences,"A plethora of real-world scientific investigations is waiting to scale with
the support of trustworthy predictive models that can reduce the need for
costly data annotations. We focus on causal inferences on a target experiment
with unlabeled factual outcomes, retrieved by a predictive model fine-tuned on
a labeled similar experiment. First, we show that factual outcome estimation
via Empirical Risk Minimization (ERM) may fail to yield valid causal inferences
on the target population, even in a randomized controlled experiment and
infinite training samples. Then, we propose to leverage the observed
experimental settings during training to empower generalization to downstream
interventional investigations, ``Causal Lifting'' the predictive model. We
propose Deconfounded Empirical Risk Minimization (DERM), a new simple learning
procedure minimizing the risk over a fictitious target population, preventing
potential confounding effects. We validate our method on both synthetic and
real-world scientific data. Notably, for the first time, we zero-shot
generalize causal inferences on ISTAnt dataset (without annotation) by causal
lifting a predictive model on our experiment variant.",http://arxiv.org/abs/2502.06343v1,Recommendation System,"causal, predictive, experiment, inferences, target"
Facial Analysis Systems and Down Syndrome,"The ethical, social and legal issues surrounding facial analysis technologies
have been widely debated in recent years. Key critics have argued that these
technologies can perpetuate bias and discrimination, particularly against
marginalized groups. We contribute to this field of research by reporting on
the limitations of facial analysis systems with the faces of people with Down
syndrome: this particularly vulnerable group has received very little attention
in the literature so far. This study involved the creation of a specific
dataset of face images. An experimental group with faces of people with Down
syndrome, and a control group with faces of people who are not affected by the
syndrome. Two commercial tools were tested on the dataset, along three tasks:
gender recognition, age prediction and face labelling. The results show an
overall lower accuracy of prediction in the experimental group, and other
specific patterns of performance differences: i) high error rates in gender
recognition in the category of males with Down syndrome; ii) adults with Down
syndrome were more often incorrectly labelled as children; iii) social
stereotypes are propagated in both the control and experimental groups, with
labels related to aesthetics more often associated with women, and labels
related to education level and skills more often associated with men. These
results, although limited in scope, shed new light on the biases that alter
face classification when applied to faces of people with Down syndrome. They
confirm the structural limitation of the technology, which is inherently
dependent on the datasets used to train the models.",http://arxiv.org/abs/2502.06341v1,Recommendation System,"syndrome, faces, people, group, face"
Zero-shot Depth Completion via Test-time Alignment with Affine-invariant Depth Prior,"Depth completion, predicting dense depth maps from sparse depth measurements,
is an ill-posed problem requiring prior knowledge. Recent methods adopt
learning-based approaches to implicitly capture priors, but the priors
primarily fit in-domain data and do not generalize well to out-of-domain
scenarios. To address this, we propose a zero-shot depth completion method
composed of an affine-invariant depth diffusion model and test-time alignment.
We use pre-trained depth diffusion models as depth prior knowledge, which
implicitly understand how to fill in depth for scenes. Our approach aligns the
affine-invariant depth prior with metric-scale sparse measurements, enforcing
them as hard constraints via an optimization loop at test-time. Our zero-shot
depth completion method demonstrates generalization across various domain
datasets, achieving up to a 21\% average performance improvement over the
previous state-of-the-art methods while enhancing spatial understanding by
sharpening scene details. We demonstrate that aligning a monocular
affine-invariant depth prior with sparse metric measurements is a proven
strategy to achieve domain-generalizable depth completion without relying on
extensive training data. Project page:
https://hyoseok1223.github.io/zero-shot-depth-completion/.",http://arxiv.org/abs/2502.06338v1,Recommendation System,"depth, completion, prior, domain, sparse"
Accelerating Outlier-robust Rotation Estimation by Stereographic Projection,"Rotation estimation plays a fundamental role in many computer vision and
robot tasks. However, efficiently estimating rotation in large inputs
containing numerous outliers (i.e., mismatches) and noise is a recognized
challenge. Many robust rotation estimation methods have been designed to
address this challenge. Unfortunately, existing methods are often inapplicable
due to their long computation time and the risk of local optima. In this paper,
we propose an efficient and robust rotation estimation method. Specifically,
our method first investigates geometric constraints involving only the rotation
axis. Then, it uses stereographic projection and spatial voting techniques to
identify the rotation axis and angle. Furthermore, our method efficiently
obtains the optimal rotation estimation and can estimate multiple rotations
simultaneously. To verify the feasibility of our method, we conduct comparative
experiments using both synthetic and real-world data. The results show that,
with GPU assistance, our method can solve large-scale ($10^6$ points) and
severely corrupted (90\% outlier rate) rotation estimation problems within 0.07
seconds, with an angular error of only 0.01 degrees, which is superior to
existing methods in terms of accuracy and efficiency.",http://arxiv.org/abs/2502.06337v1,Computer Vision,"rotation, estimation, method, methods, efficiently"
DefTransNet: A Transformer-based Method for Non-Rigid Point Cloud Registration in the Simulation of Soft Tissue Deformation,"Soft-tissue surgeries, such as tumor resections, are complicated by tissue
deformations that can obscure the accurate location and shape of tissues. By
representing tissue surfaces as point clouds and applying non-rigid point cloud
registration (PCR) methods, surgeons can better understand tissue deformations
before, during, and after surgery. Existing non-rigid PCR methods, such as
feature-based approaches, struggle with robustness against challenges like
noise, outliers, partial data, and large deformations, making accurate point
correspondence difficult. Although learning-based PCR methods, particularly
Transformer-based approaches, have recently shown promise due to their
attention mechanisms for capturing interactions, their robustness remains
limited in challenging scenarios. In this paper, we present DefTransNet, a
novel end-to-end Transformer-based architecture for non-rigid PCR. DefTransNet
is designed to address the key challenges of deformable registration, including
large deformations, outliers, noise, and partial data, by inputting source and
target point clouds and outputting displacement vector fields. The proposed
method incorporates a learnable transformation matrix to enhance robustness to
affine transformations, integrates global and local geometric information, and
captures long-range dependencies among points using Transformers. We validate
our approach on four datasets: ModelNet, SynBench, 4DMatch, and DeformedTissue,
using both synthetic and real-world data to demonstrate the generalization of
our proposed method. Experimental results demonstrate that DefTransNet
outperforms current state-of-the-art registration networks across various
challenging conditions. Our code and data are publicly available.",http://arxiv.org/abs/2502.06336v1,Reinforcement Learning,"tissue, deformations, point, pcr, based"
Microcanonical Langevin Ensembles: Advancing the Sampling of Bayesian Neural Networks,"Despite recent advances, sampling-based inference for Bayesian Neural
Networks (BNNs) remains a significant challenge in probabilistic deep learning.
While sampling-based approaches do not require a variational distribution
assumption, current state-of-the-art samplers still struggle to navigate the
complex and highly multimodal posteriors of BNNs. As a consequence, sampling
still requires considerably longer inference times than non-Bayesian methods
even for small neural networks, despite recent advances in making software
implementations more efficient. Besides the difficulty of finding
high-probability regions, the time until samplers provide sufficient
exploration of these areas remains unpredictable. To tackle these challenges,
we introduce an ensembling approach that leverages strategies from optimization
and a recently proposed sampler called Microcanonical Langevin Monte Carlo
(MCLMC) for efficient, robust and predictable sampling performance. Compared to
approaches based on the state-of-the-art No-U-Turn Sampler, our approach
delivers substantial speedups up to an order of magnitude, while maintaining or
improving predictive performance and uncertainty quantification across diverse
tasks and data modalities. The suggested Microcanonical Langevin Ensembles and
modifications to MCLMC additionally enhance the method's predictability in
resource requirements, facilitating easier parallelization. All in all, the
proposed method offers a promising direction for practical, scalable inference
for BNNs.",http://arxiv.org/abs/2502.06335v1,Recommendation System,"sampling, based, inference, bnns, despite"
Conformal Prediction Regions are Imprecise Highest Density Regions,"Recently, Cella and Martin proved how, under an assumption called consonance,
a credal set (i.e. a closed and convex set of probabilities) can be derived
from the conformal transducer associated with transductive conformal
prediction. We show that the Imprecise Highest Density Region (IHDR) associated
with such a credal set corresponds to the classical Conformal Prediction
Region. In proving this result, we relate the set of probability density/mass
functions (pdf/pmf's) associated with the elements of the credal set to the
imprecise probabilistic concept of a cloud. As a result, we establish new
relationships between Conformal Prediction and Imprecise Probability (IP)
theories. A byproduct of our presentation is the discovery that consonant
plausibility functions are monoid homomorphisms, a new algebraic property of an
IP tool.",http://arxiv.org/abs/2502.06331v1,Recommendation System,"set, conformal, credal, associated, prediction"
Prompt-Driven Continual Graph Learning,"Continual Graph Learning (CGL), which aims to accommodate new tasks over
evolving graph data without forgetting prior knowledge, is garnering
significant research interest. Mainstream solutions adopt the memory
replay-based idea, ie, caching representative data from earlier tasks for
retraining the graph model. However, this strategy struggles with scalability
issues for constantly evolving graphs and raises concerns regarding data
privacy. Inspired by recent advancements in the prompt-based learning paradigm,
this paper introduces a novel prompt-driven continual graph learning
(PROMPTCGL) framework, which learns a separate prompt for each incoming task
and maintains the underlying graph neural network model fixed. In this way,
PROMPTCGL naturally avoids catastrophic forgetting of knowledge from previous
tasks. More specifically, we propose hierarchical prompting to instruct the
model from both feature- and topology-level to fully address the variability of
task graphs in dynamic continual learning. Additionally, we develop a
personalized prompt generator to generate tailored prompts for each graph node
while minimizing the number of prompts needed, leading to constant memory
consumption regardless of the graph scale. Extensive experiments on four
benchmarks show that PROMPTCGL achieves superior performance against existing
CGL approaches while significantly reducing memory consumption. Our code is
available at https://github.com/QiWang98/PromptCGL.",http://arxiv.org/abs/2502.06327v1,Recommendation System,"graph, learning, prompt, continual, tasks"
UniDemoiré: Towards Universal Image Demoiréing with Data Generation and Synthesis,"Image demoir\'eing poses one of the most formidable challenges in image
restoration, primarily due to the unpredictable and anisotropic nature of
moir\'e patterns. Limited by the quantity and diversity of training data,
current methods tend to overfit to a single moir\'e domain, resulting in
performance degradation for new domains and restricting their robustness in
real-world applications. In this paper, we propose a universal image
demoir\'eing solution, UniDemoir\'e, which has superior generalization
capability. Notably, we propose innovative and effective data generation and
synthesis methods that can automatically provide vast high-quality moir\'e
images to train a universal demoir\'eing model. Our extensive experiments
demonstrate the cutting-edge performance and broad potential of our approach
for generalized image demoir\'eing.",http://arxiv.org/abs/2502.06324v1,Recommendation System,"image, data, methods, performance, propose"
A physics-based data-driven model for CO$_2$ gas diffusion electrodes to drive automated laboratories,"The electrochemical reduction of atmospheric CO$_2$ into high-energy
molecules with renewable energy is a promising avenue for energy storage that
can take advantage of existing infrastructure especially in areas where
sustainable alternatives to fossil fuels do not exist. Automated laboratories
are currently being developed and used to optimize the composition and
operating conditions of gas diffusion electrodes (GDEs), the device in which
this reaction takes place. Improving the efficiency of GDEs is crucial for this
technology to become viable. Here we present a modeling framework to
efficiently explore the high-dimensional parameter space of GDE designs in an
active learning context. At the core of the framework is an uncertainty-aware
physics model calibrated with experimental data. The model has the flexibility
to capture various input parameter spaces and any carbon products which can be
modeled with Tafel kinetics. It is interpretable, and a Gaussian process layer
can capture deviations of real data from the function space of the physical
model itself. We deploy the model in a simulated active learning setup with
real electrochemical data gathered by the AdaCarbon automated laboratory and
show that it can be used to efficiently traverse the multi-dimensional
parameter space.",http://arxiv.org/abs/2502.06323v1,Recommendation System,"model, energy, parameter, space, data"
From Pixels to Components: Eigenvector Masking for Visual Representation Learning,"Predicting masked from visible parts of an image is a powerful
self-supervised approach for visual representation learning. However, the
common practice of masking random patches of pixels exhibits certain failure
modes, which can prevent learning meaningful high-level features, as required
for downstream tasks. We propose an alternative masking strategy that operates
on a suitable transformation of the data rather than on the raw pixels.
Specifically, we perform principal component analysis and then randomly mask a
subset of components, which accounts for a fixed ratio of the data variance.
The learning task then amounts to reconstructing the masked components from the
visible ones. Compared to local patches of pixels, the principal components of
images carry more global information. We thus posit that predicting masked from
visible components involves more high-level features, allowing our masking
strategy to extract more useful representations. This is corroborated by our
empirical findings which demonstrate improved image classification performance
for component over pixel masking. Our method thus constitutes a simple and
robust data-driven alternative to traditional masked image modeling approaches.",http://arxiv.org/abs/2502.06314v2,Recommendation System,"masked, masking, components, visible, image"
Analog In-memory Training on General Non-ideal Resistive Elements: The Impact of Response Functions,"As the economic and environmental costs of training and deploying large
vision or language models increase dramatically, analog in-memory computing
(AIMC) emerges as a promising energy-efficient solution. However, the training
perspective, especially its training dynamic, is underexplored. In AIMC
hardware, the trainable weights are represented by the conductance of resistive
elements and updated using consecutive electrical pulses. Among all the
physical properties of resistive elements, the response to the pulses directly
affects the training dynamics. This paper first provides a theoretical
foundation for gradient-based training on AIMC hardware and studies the impact
of response functions. We demonstrate that noisy update and asymmetric response
functions negatively impact Analog SGD by imposing an implicit penalty term on
the objective. To overcome the issue, Tiki-Taka, a residual learning algorithm,
converges exactly to a critical point by optimizing a main array and a residual
array bilevelly. The conclusion is supported by simulations validating our
theoretical insights.",http://arxiv.org/abs/2502.06309v1,Recommendation System,"training, aimc, response, analog, hardware"
Cell Nuclei Detection and Classification in Whole Slide Images with Transformers,"Accurate and efficient cell nuclei detection and classification in
histopathological Whole Slide Images (WSIs) are pivotal for digital pathology
applications. Traditional cell segmentation approaches, while commonly used,
are computationally expensive and require extensive post-processing, limiting
their practicality for high-throughput clinical settings. In this paper, we
propose a paradigm shift from segmentation to detection for extracting cell
information from WSIs, introducing CellNuc-DETR as a more effective solution.
We evaluate the accuracy performance of CellNuc-DETR on the PanNuke dataset and
conduct cross-dataset evaluations on CoNSeP and MoNuSeg to assess robustness
and generalization capabilities. Our results demonstrate state-of-the-art
performance in both cell nuclei detection and classification tasks.
Additionally, we assess the efficiency of CellNuc-DETR on large WSIs, showing
that it not only outperforms current methods in accuracy but also significantly
reduces inference times. Specifically, CellNuc-DETR is twice as fast as the
fastest segmentation-based method, HoVer-NeXt, while achieving substantially
higher accuracy. Moreover, it surpasses CellViT in accuracy and is
approximately ten times more efficient in inference speed on WSIs. These
results establish CellNuc-DETR as a superior approach for cell analysis in
digital pathology, combining high accuracy with computational efficiency.",http://arxiv.org/abs/2502.06307v1,Recommendation System,"cell, cellnuc, detr, accuracy, wsis"
UniZyme: A Unified Protein Cleavage Site Predictor Enhanced with Enzyme Active-Site Knowledge,"Enzyme-catalyzed protein cleavage is essential for many biological functions.
Accurate prediction of cleavage sites can facilitate various applications such
as drug development, enzyme design, and a deeper understanding of biological
mechanisms. However, most existing models are restricted to an individual
enzyme, which neglects shared knowledge of enzymes and fails generalize to
novel enzymes. Thus, we introduce a unified protein cleavage site predictor
named UniZyme, which can generalize across diverse enzymes. To enhance the
enzyme encoding for the protein cleavage site prediction, UniZyme employs a
novel biochemically-informed model architecture along with active-site
knowledge of proteolytic enzymes. Extensive experiments demonstrate that
UniZyme achieves high accuracy in predicting cleavage sites across a range of
proteolytic enzymes, including unseen enzymes. The code is available in
https://anonymous.4open.science/r/UniZyme-4A67.",http://arxiv.org/abs/2502.06914v2,Recommendation System,"enzymes, cleavage, enzyme, protein, site"
Utilizing Novelty-based Evolution Strategies to Train Transformers in Reinforcement Learning,"In this paper, we experiment with novelty-based variants of OpenAI-ES, the
NS-ES and NSR-ES algorithms, and evaluate their effectiveness in training
complex, transformer-based architectures designed for the problem of
reinforcement learning such as Decision Transformers. We also test if we can
accelerate the novelty-based training of these larger models by seeding the
training by a pretrained models. By this, we build on our previous work, where
we tested the ability of evolution strategies - specifically the aforementioned
OpenAI-ES - to train the Decision Transformer architecture. The results were
mixed. NS-ES showed progress, but it would clearly need many more iterations
for it to yield interesting results. NSR-ES, on the other hand, proved quite
capable of being straightforwardly used on larger models, since its performance
appears as similar between the feed-forward model and Decision Transformer, as
it was for the OpenAI-ES in our previous work.",http://arxiv.org/abs/2502.06301v1,Reinforcement Learning,"es, based, openai, training, transformer"
The impact of allocation strategies in subset learning on the expressive power of neural networks,"In traditional machine learning, models are defined by a set of parameters,
which are optimized to perform specific tasks. In neural networks, these
parameters correspond to the synaptic weights. However, in reality, it is often
infeasible to control or update all weights. This challenge is not limited to
artificial networks but extends to biological networks, such as the brain,
where the extent of distributed synaptic weight modification during learning
remains unclear. Motivated by these insights, we theoretically investigate how
different allocations of a fixed number of learnable weights influence the
capacity of neural networks. Using a teacher-student setup, we introduce a
benchmark to quantify the expressivity associated with each allocation. We
establish conditions under which allocations have maximal or minimal expressive
power in linear recurrent neural networks and linear multi-layer feedforward
networks. For suboptimal allocations, we propose heuristic principles to
estimate their expressivity. These principles extend to shallow ReLU networks
as well. Finally, we validate our theoretical findings with empirical
experiments. Our results emphasize the critical role of strategically
distributing learnable weights across the network, showing that a more
widespread allocation generally enhances the network's expressive power.",http://arxiv.org/abs/2502.06300v1,Recommendation System,"networks, weights, neural, allocations, learning"
SeaExam and SeaBench: Benchmarking LLMs with Local Multilingual Questions in Southeast Asia,"This study introduces two novel benchmarks, SeaExam and SeaBench, designed to
evaluate the capabilities of Large Language Models (LLMs) in Southeast Asian
(SEA) application scenarios. Unlike existing multilingual datasets primarily
derived from English translations, these benchmarks are constructed based on
real-world scenarios from SEA regions. SeaExam draws from regional educational
exams to form a comprehensive dataset that encompasses subjects such as local
history and literature. In contrast, SeaBench is crafted around multi-turn,
open-ended tasks that reflect daily interactions within SEA communities. Our
evaluations demonstrate that SeaExam and SeaBench more effectively discern LLM
performance on SEA language tasks compared to their translated benchmarks. This
highlights the importance of using real-world queries to assess the
multilingual capabilities of LLMs.",http://arxiv.org/abs/2502.06298v1,Recommendation System,"sea, benchmarks, seaexam, seabench, capabilities"
DVFS-Aware DNN Inference on GPUs: Latency Modeling and Performance Analysis,"The rapid development of deep neural networks (DNNs) is inherently
accompanied by the problem of high computational costs. To tackle this
challenge, dynamic voltage frequency scaling (DVFS) is emerging as a promising
technology for balancing the latency and energy consumption of DNN inference by
adjusting the computing frequency of processors. However, most existing models
of DNN inference time are based on the CPU-DVFS technique, and directly
applying the CPU-DVFS model to DNN inference on GPUs will lead to significant
errors in optimizing latency and energy consumption. In this paper, we propose
a DVFS-aware latency model to precisely characterize DNN inference time on
GPUs. We first formulate the DNN inference time based on extensive experiment
results for different devices and analyze the impact of fitting parameters.
Then by dividing DNNs into multiple blocks and obtaining the actual inference
time, the proposed model is further verified. Finally, we compare our proposed
model with the CPU-DVFS model in two specific cases. Evaluation results
demonstrate that local inference optimization with our proposed model achieves
a reduction of no less than 66% and 69% in inference time and energy
consumption respectively. In addition, cooperative inference with our proposed
model can improve the partition policy and reduce the energy consumption
compared to the CPU-DVFS model.",http://arxiv.org/abs/2502.06295v1,Recommendation System,"inference, model, dvfs, dnn, time"
Is an Ultra Large Natural Image-Based Foundation Model Superior to a Retina-Specific Model for Detecting Ocular and Systemic Diseases?,"The advent of foundation models (FMs) is transforming medical domain. In
ophthalmology, RETFound, a retina-specific FM pre-trained sequentially on 1.4
million natural images and 1.6 million retinal images, has demonstrated high
adaptability across clinical applications. Conversely, DINOv2, a
general-purpose vision FM pre-trained on 142 million natural images, has shown
promise in non-medical domains. However, its applicability to clinical tasks
remains underexplored. To address this, we conducted head-to-head evaluations
by fine-tuning RETFound and three DINOv2 models (large, base, small) for ocular
disease detection and systemic disease prediction tasks, across eight
standardized open-source ocular datasets, as well as the Moorfields AlzEye and
the UK Biobank datasets. DINOv2-large model outperformed RETFound in detecting
diabetic retinopathy (AUROC=0.850-0.952 vs 0.823-0.944, across three datasets,
all P<=0.007) and multi-class eye diseases (AUROC=0.892 vs. 0.846, P<0.001). In
glaucoma, DINOv2-base model outperformed RETFound (AUROC=0.958 vs 0.940,
P<0.001). Conversely, RETFound achieved superior performance over all DINOv2
models in predicting heart failure, myocardial infarction, and ischaemic stroke
(AUROC=0.732-0.796 vs 0.663-0.771, all P<0.001). These trends persisted even
with 10% of the fine-tuning data. These findings showcase the distinct
scenarios where general-purpose and domain-specific FMs excel, highlighting the
importance of aligning FM selection with task-specific requirements to optimise
clinical performance.",http://arxiv.org/abs/2502.06289v1,Recommendation System,"retfound, models, specific, fm, million"
Enhancing Ground-to-Aerial Image Matching for Visual Misinformation Detection Using Semantic Segmentation,"The recent advancements in generative AI techniques, which have significantly
increased the online dissemination of altered images and videos, have raised
serious concerns about the credibility of digital media available on the
Internet and distributed through information channels and social networks. This
issue particularly affects domains that rely heavily on trustworthy data, such
as journalism, forensic analysis, and Earth observation. To address these
concerns, the ability to geolocate a non-geo-tagged ground-view image without
external information, such as GPS coordinates, has become increasingly
critical. This study tackles the challenge of linking a ground-view image,
potentially exhibiting varying fields of view (FoV), to its corresponding
satellite image without the aid of GPS data. To achieve this, we propose a
novel four-stream Siamese-like architecture, the Quadruple Semantic Align Net
(SAN-QUAD), which extends previous state-of-the-art (SOTA) approaches by
leveraging semantic segmentation applied to both ground and satellite imagery.
Experimental results on a subset of the CVUSA dataset demonstrate significant
improvements of up to 9.8\% over prior methods across various FoV settings.",http://arxiv.org/abs/2502.06288v2,Recommendation System,"ground, view, image, concerns, information"
End-to-End Multi-Microphone Speaker Extraction Using Relative Transfer Functions,"This paper introduces a multi-microphone method for extracting a desired
speaker from a mixture involving multiple speakers and directional noise in a
reverberant environment. In this work, we propose leveraging the instantaneous
relative transfer function (RTF), estimated from a reference utterance recorded
in the same position as the desired source. The effectiveness of the RTF-based
spatial cue is compared with direction of arrival (DOA)-based spatial cue and
the conventional spectral embedding. Experimental results in challenging
acoustic scenarios demonstrate that using spatial cues yields better
performance than the spectral-based cue and that the instantaneous RTF
outperforms the DOA-based spatial cue.",http://arxiv.org/abs/2502.06285v1,Recommendation System,"spatial, cue, rtf, based, desired"
A Simple yet Effective DDG Predictor is An Unsupervised Antibody Optimizer and Explainer,"The proteins that exist today have been optimized over billions of years of
natural evolution, during which nature creates random mutations and selects
them. The discovery of functionally promising mutations is challenged by the
limited evolutionary accessible regions, i.e., only a small region on the
fitness landscape is beneficial. There have been numerous priors used to
constrain protein evolution to regions of landscapes with high-fitness
variants, among which the change in binding free energy (DDG) of protein
complexes upon mutations is one of the most commonly used priors. However, the
huge mutation space poses two challenges: (1) how to improve the efficiency of
DDG prediction for fast mutation screening; and (2) how to explain mutation
preferences and efficiently explore accessible evolutionary regions. To address
these challenges, we propose a lightweight DDG predictor (Light-DDG), which
adopts a structure-aware Transformer as the backbone and enhances it by
knowledge distilled from existing powerful but computationally heavy DDG
predictors. Additionally, we augmented, annotated, and released a large-scale
dataset containing millions of mutation data for pre-training Light-DDG. We
find that such a simple yet effective Light-DDG can serve as a good
unsupervised antibody optimizer and explainer. For the target antibody, we
propose a novel Mutation Explainer to learn mutation preferences, which
accounts for the marginal benefit of each mutation per residue. To further
explore accessible evolutionary regions, we conduct preference-guided antibody
optimization and evaluate antibody candidates quickly using Light-DDG to
identify desirable mutations.",http://arxiv.org/abs/2502.06913v1,Reinforcement Learning,"ddg, mutation, mutations, regions, light"
On the Expressiveness of Rational ReLU Neural Networks With Bounded Depth,"To confirm that the expressive power of ReLU neural networks grows with their
depth, the function $F_n = \max \{0,x_1,\ldots,x_n\}$ has been considered in
the literature. A conjecture by Hertrich, Basu, Di Summa, and Skutella [NeurIPS
2021] states that any ReLU network that exactly represents $F_n$ has at least
$\lceil\log_2 (n+1)\rceil$ hidden layers. The conjecture has recently been
confirmed for networks with integer weights by Haase, Hertrich, and Loho [ICLR
2023].
  We follow up on this line of research and show that, within ReLU networks
whose weights are decimal fractions, $F_n$ can only be represented by networks
with at least $\lceil\log_3 (n+1)\rceil$ hidden layers. Moreover, if all
weights are $N$-ary fractions, then $F_n$ can only be represented by networks
with at least $\Omega( \frac{\ln n}{\ln \ln N})$ layers. These results are a
partial confirmation of the above conjecture for rational ReLU networks, and
provide the first non-constant lower bound on the depth of practically relevant
ReLU networks.",http://arxiv.org/abs/2502.06283v1,Recommendation System,"networks, relu, conjecture, layers, weights"
Jakiro: Boosting Speculative Decoding with Decoupled Multi-Head via MoE,"Speculative decoding (SD) accelerates large language model inference by using
a smaller draft model to predict multiple tokens, which are then verified in
parallel by the larger target model. However, the limited capacity of the draft
model often necessitates tree-based sampling to improve prediction accuracy,
where multiple candidates are generated at each step. We identify a key
limitation in this approach: the candidates at the same step are derived from
the same representation, limiting diversity and reducing overall effectiveness.
To address this, we propose Jakiro, leveraging Mixture of Experts (MoE), where
independent experts generate diverse predictions, effectively decoupling
correlations among candidates. Furthermore, we introduce a hybrid inference
strategy, combining autoregressive decoding for initial tokens with parallel
decoding for subsequent stages, and enhance the latter with contrastive
mechanism in features to improve accuracy. Our method significantly boosts
prediction accuracy and achieves higher inference speedups. Extensive
experiments across diverse models validate the effectiveness and robustness of
our approach, establishing a new SOTA in speculative decoding. Our codes are
available at https://github.com/haiduo/Jakiro.",http://arxiv.org/abs/2502.06282v1,Reinforcement Learning,"decoding, model, inference, accuracy, candidates"
Application of quantum machine learning using quantum kernel algorithms on multiclass neuron M type classification,"The functional characterization of different neuronal types has been a
longstanding and crucial challenge. With the advent of physical quantum
computers, it has become possible to apply quantum machine learning algorithms
to translate theoretical research into practical solutions. Previous studies
have shown the advantages of quantum algorithms on artificially generated
datasets, and initial experiments with small binary classification problems
have yielded comparable outcomes to classical algorithms. However, it is
essential to investigate the potential quantum advantage using real-world data.
To the best of our knowledge, this study is the first to propose the
utilization of quantum systems to classify neuron morphologies, thereby
enhancing our understanding of the performance of automatic multiclass neuron
classification using quantum kernel methods. We examined the influence of
feature engineering on classification accuracy and found that quantum kernel
methods achieved similar performance to classical methods, with certain
advantages observed in various configurations.",http://arxiv.org/abs/2502.06281v1,Recommendation System,"quantum, algorithms, classification, methods, advantages"
IceBerg: Debiased Self-Training for Class-Imbalanced Node Classification,"Graph Neural Networks (GNNs) have achieved great success in dealing with
non-Euclidean graph-structured data and have been widely deployed in many
real-world applications. However, their effectiveness is often jeopardized
under class-imbalanced training sets. Most existing studies have analyzed
class-imbalanced node classification from a supervised learning perspective,
but they do not fully utilize the large number of unlabeled nodes in
semi-supervised scenarios. We claim that the supervised signal is just the tip
of the iceberg and a large number of unlabeled nodes have not yet been
effectively utilized. In this work, we propose IceBerg, a debiased
self-training framework to address the class-imbalanced and few-shot challenges
for GNNs at the same time. Specifically, to figure out the Matthew effect and
label distribution shift in self-training, we propose Double Balancing, which
can largely improve the performance of existing baselines with just a few lines
of code as a simple plug-and-play module. Secondly, to enhance the long-range
propagation capability of GNNs, we disentangle the propagation and
transformation operations of GNNs. Therefore, the weak supervision signals can
propagate more effectively to address the few-shot issue. In summary, we find
that leveraging unlabeled nodes can significantly enhance the performance of
GNNs in class-imbalanced and few-shot scenarios, and even small, surgical
modifications can lead to substantial performance improvements. Systematic
experiments on benchmark datasets show that our method can deliver considerable
performance gain over existing class-imbalanced node classification baselines.
Additionally, due to IceBerg's outstanding ability to leverage unsupervised
signals, it also achieves state-of-the-art results in few-shot node
classification scenarios. The code of IceBerg is available at:
https://github.com/ZhixunLEE/IceBerg.",http://arxiv.org/abs/2502.06280v1,Reinforcement Learning,"gnns, class, imbalanced, iceberg, shot"
DebateBench: A Challenging Long Context Reasoning Benchmark For Large Language Models,"We introduce DebateBench, a novel dataset consisting of an extensive
collection of transcripts and metadata from some of the world's most
prestigious competitive debates. The dataset consists of British Parliamentary
debates from prestigious debating tournaments on diverse topics, annotated with
detailed speech-level scores and house rankings sourced from official
adjudication data. We curate 256 speeches across 32 debates with each debate
being over 1 hour long with each input being an average of 32,000 tokens.
Designed to capture long-context, large-scale reasoning tasks, DebateBench
provides a benchmark for evaluating modern large language models (LLMs) on
their ability to engage in argumentation, deliberation, and alignment with
human experts. To do well on DebateBench, the LLMs must perform in-context
learning to understand the rules and evaluation criteria of the debates, then
analyze 8 seven minute long speeches and reason about the arguments presented
by all speakers to give the final results. Our preliminary evaluation using GPT
o1, GPT-4o, and Claude Haiku, shows that LLMs struggle to perform well on
DebateBench, highlighting the need to develop more sophisticated techniques for
improving their performance.",http://arxiv.org/abs/2502.06279v1,Reinforcement Learning,"debatebench, debates, long, llms, dataset"
HODDI: A Dataset of High-Order Drug-Drug Interactions for Computational Pharmacovigilance,"Drug-side effect research is vital for understanding adverse reactions
arising in complex multi-drug therapies. However, the scarcity of higher-order
datasets that capture the combinatorial effects of multiple drugs severely
limits progress in this field. Existing resources such as TWOSIDES primarily
focus on pairwise interactions. To fill this critical gap, we introduce HODDI,
the first Higher-Order Drug-Drug Interaction Dataset, constructed from U.S.
Food and Drug Administration (FDA) Adverse Event Reporting System (FAERS)
records spanning the past decade, to advance computational pharmacovigilance.
HODDI contains 109,744 records involving 2,506 unique drugs and 4,569 unique
side effects, specifically curated to capture multi-drug interactions and their
collective impact on adverse effects. Comprehensive statistical analyses
demonstrate HODDI's extensive coverage and robust analytical metrics, making it
a valuable resource for studying higher-order drug relationships. Evaluating
HODDI with multiple models, we found that simple Multi-Layer Perceptron (MLP)
can outperform graph models, while hypergraph models demonstrate superior
performance in capturing complex multi-drug interactions, further validating
HODDI's effectiveness. Our findings highlight the inherent value of
higher-order information in drug-side effect prediction and position HODDI as a
benchmark dataset for advancing research in pharmacovigilance, drug safety, and
personalized medicine. The dataset and codes are available at
https://github.com/TIML-Group/HODDI.",http://arxiv.org/abs/2502.06274v1,Recommendation System,"drug, hoddi, multi, higher, order"
Beyond Batch Learning: Global Awareness Enhanced Domain Adaptation,"In domain adaptation (DA), the effectiveness of deep learning-based models is
often constrained by batch learning strategies that fail to fully apprehend the
global statistical and geometric characteristics of data distributions.
Addressing this gap, we introduce 'Global Awareness Enhanced Domain Adaptation'
(GAN-DA), a novel approach that transcends traditional batch-based limitations.
GAN-DA integrates a unique predefined feature representation (PFR) to
facilitate the alignment of cross-domain distributions, thereby achieving a
comprehensive global statistical awareness. This representation is innovatively
expanded to encompass orthogonal and common feature aspects, which enhances the
unification of global manifold structures and refines decision boundaries for
more effective DA. Our extensive experiments, encompassing 27 diverse
cross-domain image classification tasks, demonstrate GAN-DA's remarkable
superiority, outperforming 24 established DA methods by a significant margin.
Furthermore, our in-depth analyses shed light on the decision-making processes,
revealing insights into the adaptability and efficiency of GAN-DA. This
approach not only addresses the limitations of existing DA methodologies but
also sets a new benchmark in the realm of domain adaptation, offering broad
implications for future research and applications in this field.",http://arxiv.org/abs/2502.06272v1,Recommendation System,"da, domain, global, gan, adaptation"
Spectral-factorized Positive-definite Curvature Learning for NN Training,"Many training methods, such as Adam(W) and Shampoo, learn a positive-definite
curvature matrix and apply an inverse root before preconditioning. Recently,
non-diagonal training methods, such as Shampoo, have gained significant
attention; however, they remain computationally inefficient and are limited to
specific types of curvature information due to the costly matrix root
computation via matrix decomposition. To address this, we propose a Riemannian
optimization approach that dynamically adapts spectral-factorized
positive-definite curvature estimates, enabling the efficient application of
arbitrary matrix roots and generic curvature learning. We demonstrate the
efficacy and versatility of our approach in positive-definite matrix
optimization and covariance adaptation for gradient-free optimization, as well
as its efficiency in curvature learning for neural net training.",http://arxiv.org/abs/2502.06268v1,Recommendation System,"curvature, matrix, training, positive, definite"
Low-Rank Compression for IMC Arrays,"In this study, we address the challenge of low-rank model compression in the
context of in-memory computing (IMC) architectures. Traditional pruning
approaches, while effective in model size reduction, necessitate additional
peripheral circuitry to manage complex dataflows and mitigate dislocation
issues, leading to increased area and energy overheads. To circumvent these
drawbacks, we propose leveraging low-rank compression techniques, which, unlike
pruning, streamline the dataflow and seamlessly integrate with IMC
architectures. However, low-rank compression presents its own set of
challenges, namely i) suboptimal IMC array utilization and ii) compromised
accuracy. To address these issues, we introduce a novel approach i) employing
shift and duplicate kernel (SDK) mapping technique, which exploits idle IMC
columns for parallel processing, and ii) group low-rank convolution, which
mitigates the information imbalance in the decomposed matrices. Our
experimental results demonstrate that our proposed method achieves up to 2.5x
speedup or +20.9% accuracy boost over existing pruning techniques.",http://arxiv.org/abs/2502.07820v1,Recommendation System,"low, rank, imc, compression, pruning"
Reducing Variance Caused by Communication in Decentralized Multi-agent Deep Reinforcement Learning,"In decentralized multi-agent deep reinforcement learning (MADRL),
communication can help agents to gain a better understanding of the environment
to better coordinate their behaviors. Nevertheless, communication may involve
uncertainty, which potentially introduces variance to the learning of
decentralized agents. In this paper, we focus on a specific decentralized MADRL
setting with communication and conduct a theoretical analysis to study the
variance that is caused by communication in policy gradients. We propose
modular techniques to reduce the variance in policy gradients during training.
We adopt our modular techniques into two existing algorithms for decentralized
MADRL with communication and evaluate them on multiple tasks in the StarCraft
Multi-Agent Challenge and Traffic Junction domains. The results show that
decentralized MADRL communication methods extended with our proposed techniques
not only achieve high-performing agents but also reduce variance in policy
gradients during training.",http://arxiv.org/abs/2502.06261v1,Reinforcement Learning,"communication, decentralized, madrl, variance, agents"
Emergent Response Planning in LLM,"In this work, we argue that large language models (LLMs), though trained to
predict only the next token, exhibit emergent planning behaviors:
$\textbf{their hidden representations encode future outputs beyond the next
token}$. Through simple probing, we demonstrate that LLM prompt representations
encode global attributes of their entire responses, including
$\textit{structural attributes}$ (response length, reasoning steps),
$\textit{content attributes}$ (character choices in storywriting,
multiple-choice answers at the end of response), and $\textit{behavioral
attributes}$ (answer confidence, factual consistency). In addition to
identifying response planning, we explore how it scales with model size across
tasks and how it evolves during generation. The findings that LLMs plan ahead
for the future in their hidden representations suggests potential applications
for improving transparency and generation control.",http://arxiv.org/abs/2502.06258v1,Natural Language Processing,"representations, response, llms, planning, hidden"
K-ON: Stacking Knowledge On the Head Layer of Large Language Model,"Recent advancements in large language models (LLMs) have significantly
improved various natural language processing (NLP) tasks. Typically, LLMs are
trained to predict the next token, aligning well with many NLP tasks. However,
in knowledge graph (KG) scenarios, entities are the fundamental units and
identifying an entity requires at least several tokens. This leads to a
granularity mismatch between KGs and natural languages. To address this issue,
we propose K-ON, which integrates KG knowledge into the LLM by employing
multiple head layers for next k-step prediction. K-ON can not only generate
entity-level results in one step, but also enables contrastive loss against
entities, which is the most powerful tool in KG representation learning.
Experimental results show that K-ON outperforms state-of-the-art methods that
incorporate text and even the other modalities.",http://arxiv.org/abs/2502.06257v1,Natural Language Processing,"k, kg, language, llms, natural"
Towards Efficient and Intelligent Laser Weeding: Method and Dataset for Weed Stem Detection,"Weed control is a critical challenge in modern agriculture, as weeds compete
with crops for essential nutrient resources, significantly reducing crop yield
and quality. Traditional weed control methods, including chemical and
mechanical approaches, have real-life limitations such as associated
environmental impact and efficiency. An emerging yet effective approach is
laser weeding, which uses a laser beam as the stem cutter. Although there have
been studies that use deep learning in weed recognition, its application in
intelligent laser weeding still requires a comprehensive understanding. Thus,
this study represents the first empirical investigation of weed recognition for
laser weeding. To increase the efficiency of laser beam cut and avoid damaging
the crops of interest, the laser beam shall be directly aimed at the weed root.
Yet, weed stem detection remains an under-explored problem. We integrate the
detection of crop and weed with the localization of weed stem into one
end-to-end system. To train and validate the proposed system in a real-life
scenario, we curate and construct a high-quality weed stem detection dataset
with human annotations. The dataset consists of 7,161 high-resolution pictures
collected in the field with annotations of 11,151 instances of weed.
Experimental results show that the proposed system improves weeding accuracy by
6.7% and reduces energy cost by 32.3% compared to existing weed recognition
systems.",http://arxiv.org/abs/2502.06255v1,Recommendation System,"weed, laser, weeding, stem, beam"
"DGNO: A Novel Physics-aware Neural Operator for Solving Forward and Inverse PDE Problems based on Deep, Generative Probabilistic Modeling","Solving parametric partial differential equations (PDEs) and associated
PDE-based, inverse problems is a central task in engineering and physics, yet
existing neural operator methods struggle with high-dimensional, discontinuous
inputs and require large amounts of {\em labeled} training data. We propose the
Deep Generative Neural Operator (DGNO), a physics-aware framework that
addresses these challenges by leveraging a deep, generative, probabilistic
model in combination with a set of lower-dimensional, latent variables that
simultaneously encode PDE-inputs and PDE-outputs. This formulation can make use
of unlabeled data and significantly improves inverse problem-solving,
particularly for discontinuous or discrete-valued input functions. DGNO
enforces physics constraints without labeled data by incorporating as virtual
observables, weak-form residuals based on compactly supported radial basis
functions (CSRBFs). These relax regularity constraints and eliminate
higher-order derivatives from the objective function. We also introduce
MultiONet, a novel neural operator architecture, which is a more expressive
generalization of the popular DeepONet that significantly enhances the
approximating power of the proposed model. These innovations make DGNO
particularly effective for challenging forward and inverse, PDE-based problems,
such as those involving multi-phase media. Numerical experiments demonstrate
that DGNO achieves higher accuracy across multiple benchmarks while exhibiting
robustness to noise and strong generalization to out-of-distribution cases. Its
adaptability, and the ability to handle sparse, noisy data while providing
probabilistic estimates, make DGNO a powerful tool for scientific and
engineering applications.",http://arxiv.org/abs/2502.06250v1,Recommendation System,"dgno, pde, data, based, inverse"
Conditioning through indifference in quantum mechanics,"We can learn (more) about the state a quantum system is in through
measurements. We look at how to describe the uncertainty about a quantum
system's state conditional on executing such measurements. We show that by
exploiting the interplay between desirability, coherence and indifference, a
general rule for conditioning can be derived. We then apply this rule to
conditioning on measurement outcomes, and show how it generalises to
conditioning on a set of measurement outcomes.",http://arxiv.org/abs/2502.06249v1,Recommendation System,"conditioning, state, quantum, system, measurements"
PiKE: Adaptive Data Mixing for Multi-Task Learning Under Low Gradient Conflicts,"Modern machine learning models are trained on diverse datasets and tasks to
improve generalization. A key challenge in multitask learning is determining
the optimal data mixing and sampling strategy across different data sources.
Prior research in this multi-task learning setting has primarily focused on
mitigating gradient conflicts between tasks. However, we observe that many
real-world multitask learning scenarios-such as multilingual training and
multi-domain learning in large foundation models-exhibit predominantly positive
task interactions with minimal or no gradient conflict. Building on this
insight, we introduce PiKE (Positive gradient interaction-based K-task weights
Estimator), an adaptive data mixing algorithm that dynamically adjusts task
contributions throughout training. PiKE optimizes task sampling to minimize
overall loss, effectively leveraging positive gradient interactions with almost
no additional computational overhead. We establish theoretical convergence
guarantees for PiKE and demonstrate its superiority over static and
non-adaptive mixing strategies. Additionally, we extend PiKE to promote fair
learning across tasks, ensuring balanced progress and preventing task
underrepresentation. Empirical evaluations on large-scale language model
pretraining show that PiKE consistently outperforms existing heuristic and
static mixing strategies, leading to faster convergence and improved downstream
task performance.",http://arxiv.org/abs/2502.06244v1,Recommendation System,"task, learning, pike, mixing, gradient"
Multi-Scale Transformer Architecture for Accurate Medical Image Classification,"This study introduces an AI-driven skin lesion classification algorithm built
on an enhanced Transformer architecture, addressing the challenges of accuracy
and robustness in medical image analysis. By integrating a multi-scale feature
fusion mechanism and refining the self-attention process, the model effectively
extracts both global and local features, enhancing its ability to detect
lesions with ambiguous boundaries and intricate structures. Performance
evaluation on the ISIC 2017 dataset demonstrates that the improved Transformer
surpasses established AI models, including ResNet50, VGG19, ResNext, and Vision
Transformer, across key metrics such as accuracy, AUC, F1-Score, and Precision.
Grad-CAM visualizations further highlight the interpretability of the model,
showcasing strong alignment between the algorithm's focus areas and actual
lesion sites. This research underscores the transformative potential of
advanced AI models in medical imaging, paving the way for more accurate and
reliable diagnostic tools. Future work will explore the scalability of this
approach to broader medical imaging tasks and investigate the integration of
multimodal data to enhance AI-driven diagnostic frameworks for intelligent
healthcare.",http://arxiv.org/abs/2502.06243v1,Reinforcement Learning,"ai, transformer, medical, driven, lesion"
Conditioning and AGM-like belief change in the Desirability-Indifference framework,"We show how the AGM framework for belief change (expansion, revision,
contraction) can be extended to deal with conditioning in the so-called
Desirability-Indifference framework, based on abstract notions of accepting and
rejecting options, as well as on abstract notions of events. This level of
abstraction allows us to deal simultaneously with classical and quantum
probability theory.",http://arxiv.org/abs/2502.06235v1,Recommendation System,"framework, deal, abstract, notions, agm"
Confidence Improves Self-Consistency in LLMs,"Self-consistency decoding enhances LLMs' performance on reasoning tasks by
sampling diverse reasoning paths and selecting the most frequent answer.
However, it is computationally expensive, as sampling many of these (lengthy)
paths is required to increase the chances that the correct answer emerges as
the most frequent one. To address this, we introduce Confidence-Informed
Self-Consistency (CISC). CISC performs a weighted majority vote based on
confidence scores obtained directly from the model. By prioritizing
high-confidence paths, it can identify the correct answer with a significantly
smaller sample size. When tested on nine models and four datasets, CISC
outperforms self-consistency in nearly all configurations, reducing the
required number of reasoning paths by over 40% on average. In addition, we
introduce the notion of within-question confidence evaluation, after showing
that standard evaluation methods are poor predictors of success in
distinguishing correct and incorrect answers to the same question. In fact, the
most calibrated confidence method proved to be the least effective for CISC.
Lastly, beyond these practical implications, our results and analyses show that
LLMs can effectively judge the correctness of their own outputs, contributing
to the ongoing debate on this topic.",http://arxiv.org/abs/2502.06233v1,Recommendation System,"confidence, paths, cisc, self, consistency"
Falsification of Unconfoundedness by Testing Independence of Causal Mechanisms,"A major challenge in estimating treatment effects in observational studies is
the reliance on untestable conditions such as the assumption of no unmeasured
confounding. In this work, we propose an algorithm that can falsify the
assumption of no unmeasured confounding in a setting with observational data
from multiple heterogeneous sources, which we refer to as environments. Our
proposed falsification strategy leverages a key observation that unmeasured
confounding can cause observed causal mechanisms to appear dependent. Building
on this observation, we develop a novel two-stage procedure that detects these
dependencies with high statistical power while controlling false positives. The
algorithm does not require access to randomized data and, in contrast to other
falsification approaches, functions even under transportability violations when
the environment has a direct effect on the outcome of interest. To showcase the
practical relevance of our approach, we show that our method is able to
efficiently detect confounding on both simulated and real-world data.",http://arxiv.org/abs/2502.06231v1,Recommendation System,"confounding, unmeasured, data, observational, assumption"
Unsupervised deep learning for semantic segmentation of multispectral LiDAR forest point clouds,"Point clouds captured with laser scanning systems from forest environments
can be utilized in a wide variety of applications within forestry and plant
ecology, such as the estimation of tree stem attributes, leaf angle
distribution, and above-ground biomass. However, effectively utilizing the data
in such tasks requires the semantic segmentation of the data into wood and
foliage points, also known as leaf-wood separation. The traditional approach to
leaf-wood separation has been geometry- and radiometry-based unsupervised
algorithms, which tend to perform poorly on data captured with airborne laser
scanning (ALS) systems, even with a high point density. While recent machine
and deep learning approaches achieve great results even on sparse point clouds,
they require manually labeled training data, which is often extremely laborious
to produce. Multispectral (MS) information has been demonstrated to have
potential for improving the accuracy of leaf-wood separation, but quantitative
assessment of its effects has been lacking. This study proposes a fully
unsupervised deep learning method, GrowSP-ForMS, which is specifically designed
for leaf-wood separation of high-density MS ALS point clouds and based on the
GrowSP architecture. GrowSP-ForMS achieved a mean accuracy of 84.3% and a mean
intersection over union (mIoU) of 69.6% on our MS test set, outperforming the
unsupervised reference methods by a significant margin. When compared to
supervised deep learning methods, our model performed similarly to the slightly
older PointNet architecture but was outclassed by more recent approaches.
Finally, two ablation studies were conducted, which demonstrated that our
proposed changes increased the test set mIoU of GrowSP-ForMS by 29.4 percentage
points (pp) in comparison to the original GrowSP model and that utilizing MS
data improved the mIoU by 5.6 pp from the monospectral case.",http://arxiv.org/abs/2502.06227v1,Recommendation System,"leaf, data, wood, growsp, point"
FunduSAM: A Specialized Deep Learning Model for Enhanced Optic Disc and Cup Segmentation in Fundus Images,"The Segment Anything Model (SAM) has gained popularity as a versatile image
segmentation method, thanks to its strong generalization capabilities across
various domains. However, when applied to optic disc (OD) and optic cup (OC)
segmentation tasks, SAM encounters challenges due to the complex structures,
low contrast, and blurred boundaries typical of fundus images, leading to
suboptimal performance. To overcome these challenges, we introduce a novel
model, FunduSAM, which incorporates several Adapters into SAM to create a deep
network specifically designed for OD and OC segmentation. The FunduSAM utilizes
Adapter into each transformer block after encoder for parameter fine-tuning
(PEFT). It enhances SAM's feature extraction capabilities by designing a
Convolutional Block Attention Module (CBAM), addressing issues related to
blurred boundaries and low contrast. Given the unique requirements of OD and OC
segmentation, polar transformation is used to convert the original fundus OD
images into a format better suited for training and evaluating FunduSAM. A
joint loss is used to achieve structure preservation between the OD and OC,
while accurate segmentation. Extensive experiments on the REFUGE dataset,
comprising 1,200 fundus images, demonstrate the superior performance of
FunduSAM compared to five mainstream approaches.",http://arxiv.org/abs/2502.06220v1,Computer Vision,"segmentation, od, sam, oc, fundusam"
Fully Exploiting Vision Foundation Model's Profound Prior Knowledge for Generalizable RGB-Depth Driving Scene Parsing,"Recent vision foundation models (VFMs), typically based on Vision Transformer
(ViT), have significantly advanced numerous computer vision tasks. Despite
their success in tasks focused solely on RGB images, the potential of VFMs in
RGB-depth driving scene parsing remains largely under-explored. In this
article, we take one step toward this emerging research area by investigating a
feasible technique to fully exploit VFMs for generalizable RGB-depth driving
scene parsing. Specifically, we explore the inherent characteristics of RGB and
depth data, thereby presenting a Heterogeneous Feature Integration Transformer
(HFIT). This network enables the efficient extraction and integration of
comprehensive heterogeneous features without re-training ViTs. Relative depth
prediction results from VFMs, used as inputs to the HFIT side adapter, overcome
the limitations of the dependence on depth maps. Our proposed HFIT demonstrates
superior performance compared to all other traditional single-modal and
data-fusion scene parsing networks, pre-trained VFMs, and ViT adapters on the
Cityscapes and KITTI Semantics datasets. We believe this novel strategy paves
the way for future innovations in VFM-based data-fusion techniques for driving
scene parsing. Our source code is publicly available at
https://mias.group/HFIT.",http://arxiv.org/abs/2502.06219v1,Computer Vision,"vfms, depth, rgb, scene, parsing"
Examining False Positives under Inference Scaling for Mathematical Reasoning,"Recent advancements in language models have led to significant improvements
in mathematical reasoning across various benchmarks. However, most of these
benchmarks rely on automatic evaluation methods that only compare final answers
using heuristics, without verifying the underlying reasoning steps. This
limitation results in false positive solutions, where models may produce
correct final answers but with flawed deduction paths. In this paper, we
systematically examine the prevalence of false positive solutions in
mathematical problem solving for language models. We analyze the
characteristics and extent of this issue across different open-source models,
datasets of varying difficulty levels, and decoding strategies. Specifically,
we explore how false positives influence the inference time scaling behavior of
language models. Our experimental results reveal that: (1) false positive
solutions persist across different models, datasets, and decoding methods, (2)
sampling-based inference time scaling methods do not alleviate the problem, and
(3) the pass@N evaluation metric is more susceptible to false positives,
suggesting a significantly lower scaling ceiling than what automatic
evaluations indicate. Additionally, we analyze specific instances of false
positives and discuss potential limitations in self-improvement techniques and
synthetic data generation under such conditions.",http://arxiv.org/abs/2502.06217v1,Recommendation System,"models, false, language, methods, positive"
LessLeak-Bench: A First Investigation of Data Leakage in LLMs Across 83 Software Engineering Benchmarks,"Large Language Models (LLMs) are widely utilized in software engineering (SE)
tasks, such as code generation and automated program repair. However, their
reliance on extensive and often undisclosed pre-training datasets raises
significant concerns about data leakage, where the evaluation benchmark data is
unintentionally ``seen'' by LLMs during the model's construction phase. The
data leakage issue could largely undermine the validity of LLM-based research
and evaluations. Despite the increasing use of LLMs in the SE community, there
is no comprehensive study that assesses the extent of data leakage in SE
benchmarks for LLMs yet. To address this gap, this paper presents the first
large-scale analysis of data leakage in 83 SE benchmarks concerning LLMs. Our
results show that in general, data leakage in SE benchmarks is minimal, with
average leakage ratios of only 4.8\%, 2.8\%, and 0.7\% for Python, Java, and
C/C++ benchmarks, respectively. However, some benchmarks exhibit relatively
higher leakage ratios, which raises concerns about their bias in evaluation.
For instance, QuixBugs and BigCloneBench have leakage ratios of 100.0\% and
55.7\%, respectively. Furthermore, we observe that data leakage has a
substantial impact on LLM evaluation. We also identify key causes of high data
leakage, such as the direct inclusion of benchmark data in pre-training
datasets and the use of coding platforms like LeetCode for benchmark
construction. To address the data leakage, we introduce
\textbf{LessLeak-Bench}, a new benchmark that removes leaked samples from the
83 SE benchmarks, enabling more reliable LLM evaluations in future research.
Our study enhances the understanding of data leakage in SE benchmarks and
provides valuable insights for future research involving LLMs in SE.",http://arxiv.org/abs/2502.06215v1,Recommendation System,"leakage, data, se, benchmarks, llms"
Position: Continual Learning Benefits from An Evolving Population over An Unified Model,"Deep neural networks have demonstrated remarkable success in machine
learning; however, they remain fundamentally ill-suited for Continual Learning
(CL). Recent research has increasingly focused on achieving CL without the need
for rehearsal. Among these, parameter isolation-based methods have proven
particularly effective in enhancing CL by optimizing model weights for each
incremental task. Despite their success, they fall short in optimizing
architectures tailored to distinct incremental tasks. To address this
limitation, updating a group of models with different architectures offers a
promising alternative to the traditional CL paradigm that relies on a single
unified model. Building on this insight, this study introduces a novel
Population-based Continual Learning (PCL) framework. PCL extends CL to the
architectural level by maintaining and evolving a population of neural network
architectures, which are continually refined for the current task through NAS.
Importantly, the well-evolved population for the current incremental task is
naturally inherited by the subsequent one, thereby facilitating forward
transfer, a crucial objective in CL. Throughout the CL process, the population
evolves, yielding task-specific architectures that collectively form a robust
CL system. Experimental results demonstrate that PCL outperforms
state-of-the-art rehearsal-free CL methods that employs a unified model,
highlighting its potential as a new paradigm for CL.",http://arxiv.org/abs/2502.06210v1,Recommendation System,"cl, task, architectures, population, learning"
Enhancing Cost Efficiency in Active Learning with Candidate Set Query,"This paper introduces a cost-efficient active learning (AL) framework for
classification, featuring a novel query design called candidate set query.
Unlike traditional AL queries requiring the oracle to examine all possible
classes, our method narrows down the set of candidate classes likely to include
the ground-truth class, significantly reducing the search space and labeling
cost. Moreover, we leverage conformal prediction to dynamically generate small
yet reliable candidate sets, adapting to model enhancement over successive AL
rounds. To this end, we introduce an acquisition function designed to
prioritize data points that offer high information gain at lower cost.
Empirical evaluations on CIFAR-10, CIFAR-100, and ImageNet64x64 demonstrate the
effectiveness and scalability of our framework. Notably, it reduces labeling
cost by 42% on ImageNet64x64.",http://arxiv.org/abs/2502.06209v1,Recommendation System,"cost, al, candidate, framework, query"
Unveiling the Capabilities of Large Language Models in Detecting Offensive Language with Annotation Disagreement,"LLMs are widely used for offensive language detection due to their advanced
capability. However, the challenges posed by human annotation disagreement in
real-world datasets remain underexplored. These disagreement samples are
difficult to detect due to their ambiguous nature. Additionally, the confidence
of LLMs in processing disagreement samples can provide valuable insights into
their alignment with human annotators. To address this gap, we systematically
evaluate the ability of LLMs to detect offensive language with annotation
disagreement. We compare the binary accuracy of multiple LLMs across varying
annotation agreement levels and analyze the relationship between LLM confidence
and annotation agreement. Furthermore, we investigate the impact of
disagreement samples on LLM decision-making during few-shot learning and
instruction fine-tuning. Our findings highlight the challenges posed by
disagreement samples and offer guidance for improving LLM-based offensive
language detection.",http://arxiv.org/abs/2502.06207v1,Natural Language Processing,"disagreement, llms, annotation, samples, offensive"
C-3PO: Compact Plug-and-Play Proxy Optimization to Achieve Human-like Retrieval-Augmented Generation,"Retrieval-augmented generation (RAG) systems face a fundamental challenge in
aligning independently developed retrievers and large language models (LLMs).
Existing approaches typically involve modifying either component or introducing
simple intermediate modules, resulting in practical limitations and sub-optimal
performance. Inspired by human search behavior -- typically involving a
back-and-forth process of proposing search queries and reviewing documents, we
propose C-3PO, a proxy-centric framework that facilitates communication between
retrievers and LLMs through a lightweight multi-agent system. Our framework
implements three specialized agents that collaboratively optimize the entire
RAG pipeline without altering the retriever and LLMs. These agents work
together to assess the need for retrieval, generate effective queries, and
select information suitable for the LLMs. To enable effective multi-agent
coordination, we develop a tree-structured rollout approach for reward credit
assignment in reinforcement learning. Extensive experiments in both in-domain
and out-of-distribution scenarios demonstrate that C-3PO significantly enhances
RAG performance while maintaining plug-and-play flexibility and superior
generalization capabilities.",http://arxiv.org/abs/2502.06205v1,Reinforcement Learning,"llms, rag, retrieval, retrievers, typically"
Comparing Image Segmentation Algorithms,"This paper presents a novel approach for denoising binary images using
simulated annealing (SA), a global optimization technique that addresses the
inherent challenges of non convex energy functions. Binary images are often
corrupted by noise, necessitating effective restoration methods. We propose an
energy function E(x, y) that captures the relationship between the noisy image
y and the desired clean image x. Our algorithm combines simulated annealing
with a localized optimization strategy to efficiently navigate the solution
space, minimizing the energy function while maintaining computational
efficiency. We evaluate the performance of the proposed method against
traditional iterative conditional modes (ICM), employing a binary image with
10% pixel corruption as a test case. Experimental results demonstrate that the
simulated annealing method achieves a significant restoration improvement,
yielding a 99.19% agreement with the original image compared to 96.21% for ICM.
Visual assessments reveal that simulated annealing effectively removes noise
while preserving structural details, making it a promising approach for binary
image denoising. This work contributes to the field of image processing by
highlighting the advantages of incorporating global optimization techniques in
restoration tasks.",http://arxiv.org/abs/2502.06201v1,Recommendation System,"image, binary, simulated, annealing, optimization"
On the query complexity of sampling from non-log-concave distributions,"We study the problem of sampling from a $d$-dimensional distribution with
density $p(x)\propto e^{-f(x)}$, which does not necessarily satisfy good
isoperimetric conditions.
  Specifically, we show that for any $L,M$ satisfying $LM\ge d\ge 5$,
$\epsilon\in \left(0,\frac{1}{32}\right)$, and any algorithm with query
accesses to the value of $f(x)$ and $\nabla f(x)$, there exists an
$L$-log-smooth distribution with second moment at most $M$ such that the
algorithm requires $\left(\frac{LM}{d\epsilon}\right)^{\Omega(d)}$ queries to
compute a sample whose distribution is within $\epsilon$ in total variation
distance to the target distribution. We complement the lower bound with an
algorithm requiring $\left(\frac{LM}{d\epsilon}\right)^{\mathcal O(d)}$
queries, thereby characterizing the tight (up to the constant in the exponent)
query complexity for sampling from the family of non-log-concave distributions.
  Our results are in sharp contrast with the recent work of Huang et al.
(COLT'24), where an algorithm with quasi-polynomial query complexity was
proposed for sampling from a non-log-concave distribution when
$M=\mathtt{poly}(d)$. Their algorithm works under the stronger condition that
all distributions along the trajectory of the Ornstein-Uhlenbeck process,
starting from the target distribution, are $\mathcal O(1)$-log-smooth. We
investigate this condition and prove that it is strictly stronger than
requiring the target distribution to be $\mathcal O(1)$-log-smooth.
Additionally, we study this condition in the context of mixtures of Gaussians.
  Finally, we place our results within the broader theme of ``sampling versus
optimization'', as studied in Ma et al. (PNAS'19). We show that for a wide
range of parameters, sampling is strictly easier than optimization by a
super-exponential factor in the dimension $d$.",http://arxiv.org/abs/2502.06200v2,Recommendation System,"distribution, sampling, algorithm, query, smooth"
Multimodal Task Representation Memory Bank vs. Catastrophic Forgetting in Anomaly Detection,"Unsupervised Continuous Anomaly Detection (UCAD) faces significant challenges
in multi-task representation learning, with existing methods suffering from
incomplete representation and catastrophic forgetting. Unlike supervised
models, unsupervised scenarios lack prior information, making it difficult to
effectively distinguish redundant and complementary multimodal features. To
address this, we propose the Multimodal Task Representation Memory Bank (MTRMB)
method through two key technical innovations: A Key-Prompt-Multimodal Knowledge
(KPMK) mechanism that uses concise key prompts to guide cross-modal feature
interaction between BERT and ViT. Refined Structure-based Contrastive Learning
(RSCL) leveraging Grounding DINO and SAM to generate precise segmentation
masks, pulling features of the same structural region closer while pushing
different structural regions apart. Experiments on MVtec AD and VisA datasets
demonstrate MTRMB's superiority, achieving an average detection accuracy of
0.921 at the lowest forgetting rate, significantly outperforming
state-of-the-art methods. We plan to open source on GitHub.",http://arxiv.org/abs/2502.06194v1,Reinforcement Learning,"representation, multimodal, key, unsupervised, detection"
Can LLMs Replace Human Evaluators? An Empirical Study of LLM-as-a-Judge in Software Engineering,"Recently, large language models (LLMs) have been deployed to tackle various
software engineering (SE) tasks like code generation, significantly advancing
the automation of SE tasks. However, assessing the quality of these
LLM-generated code and text remains challenging. The commonly used Pass@k
metric necessitates extensive unit tests and configured environments, demands a
high labor cost, and is not suitable for evaluating LLM-generated text.
Conventional metrics like BLEU, which measure only lexical rather than semantic
similarity, have also come under scrutiny. In response, a new trend has emerged
to employ LLMs for automated evaluation, known as LLM-as-a-judge. These
LLM-as-a-judge methods are claimed to better mimic human assessment than
conventional metrics without relying on high-quality reference answers.
Nevertheless, their exact human alignment in SE tasks remains unexplored. In
this paper, we empirically explore LLM-as-a-judge methods for evaluating SE
tasks, focusing on their alignment with human judgments. We select seven
LLM-as-a-judge methods that utilize general-purpose LLMs, alongside two LLMs
specifically fine-tuned for evaluation. After generating and manually scoring
LLM responses on three recent SE datasets of code translation, code generation,
and code summarization, we then prompt these methods to evaluate each response.
Finally, we compare the scores generated by these methods with human
evaluation. The results indicate that output-based methods reach the highest
Pearson correlation of 81.32 and 68.51 with human scores in code translation
and generation, achieving near-human evaluation, noticeably outperforming
ChrF++, one of the best conventional metrics, at 34.23 and 64.92. Such
output-based methods prompt LLMs to output judgments directly, and exhibit more
balanced score distributions that resemble human score patterns. Finally, we
provide...",http://arxiv.org/abs/2502.06193v1,Recommendation System,"llm, methods, human, code, llms"
Right Time to Learn:Promoting Generalization via Bio-inspired Spacing Effect in Knowledge Distillation,"Knowledge distillation (KD) is a powerful strategy for training deep neural
networks (DNNs). Although it was originally proposed to train a more compact
``student'' model from a large ``teacher'' model, many recent efforts have
focused on adapting it to promote generalization of the model itself, such as
online KD and self KD. % as an effective way Here, we propose an accessible and
compatible strategy named Spaced KD to improve the effectiveness of both online
KD and self KD, in which the student model distills knowledge from a teacher
model trained with a space interval ahead. This strategy is inspired by a
prominent theory named \emph{spacing effect} in biological learning and memory,
positing that appropriate intervals between learning trials can significantly
enhance learning performance. With both theoretical and empirical analyses, we
demonstrate that the benefits of the proposed Spaced KD stem from convergence
to a flatter loss landscape during stochastic gradient descent (SGD). We
perform extensive experiments to validate the effectiveness of Spaced KD in
improving the learning performance of DNNs (e.g., the performance gain is up to
2.31\% and 3.34\% on Tiny-ImageNet over online KD and self KD, respectively).",http://arxiv.org/abs/2502.06192v1,Recommendation System,"kd, model, learning, strategy, online"
Multi-Level Decoupled Relational Distillation for Heterogeneous Architectures,"Heterogeneous distillation is an effective way to transfer knowledge from
cross-architecture teacher models to student models. However, existing
heterogeneous distillation methods do not take full advantage of the dark
knowledge hidden in the teacher's output, limiting their performance.To this
end, we propose a novel framework named Multi-Level Decoupled Relational
Knowledge Distillation (MLDR-KD) to unleash the potential of relational
distillation in heterogeneous distillation. Concretely, we first introduce
Decoupled Finegrained Relation Alignment (DFRA) in both logit and feature
levels to balance the trade-off between distilled dark knowledge and the
confidence in the correct category of the heterogeneous teacher model. Then,
Multi-Scale Dynamic Fusion (MSDF) module is applied to dynamically fuse the
projected logits of multiscale features at different stages in student model,
further improving performance of our method in feature level. We verify our
method on four architectures (CNNs, Transformers, MLPs and Mambas), two
datasets (CIFAR-100 and Tiny-ImageNet). Compared with the best available
method, our MLDR-KD improves student model performance with gains of up to
4.86% on CIFAR-100 and 2.78% on Tiny-ImageNet datasets respectively, showing
robustness and generality in heterogeneous distillation. Code will be released
soon.",http://arxiv.org/abs/2502.06189v1,Recommendation System,"distillation, heterogeneous, knowledge, teacher, student"
Discourse-Driven Evaluation: Unveiling Factual Inconsistency in Long Document Summarization,"Detecting factual inconsistency for long document summarization remains
challenging, given the complex structure of the source article and long summary
length. In this work, we study factual inconsistency errors and connect them
with a line of discourse analysis. We find that errors are more common in
complex sentences and are associated with several discourse features. We
propose a framework that decomposes long texts into discourse-inspired chunks
and utilizes discourse information to better aggregate sentence-level scores
predicted by natural language inference models. Our approach shows improved
performance on top of different model baselines over several evaluation
benchmarks, covering rich domains of texts, focusing on long document
summarization. This underscores the significance of incorporating discourse
features in developing models for scoring summaries for long document factual
inconsistency.",http://arxiv.org/abs/2502.06185v1,Natural Language Processing,"long, discourse, factual, inconsistency, document"
CANeRV: Content Adaptive Neural Representation for Video Compression,"Recent advances in video compression introduce implicit neural representation
(INR) based methods, which effectively capture global dependencies and
characteristics of entire video sequences. Unlike traditional and deep learning
based approaches, INR-based methods optimize network parameters from a global
perspective, resulting in superior compression potential. However, most current
INR methods utilize a fixed and uniform network architecture across all frames,
limiting their adaptability to dynamic variations within and between video
sequences. This often leads to suboptimal compression outcomes as these methods
struggle to capture the distinct nuances and transitions in video content. To
overcome these challenges, we propose Content Adaptive Neural Representation
for Video Compression (CANeRV), an innovative INR-based video compression
network that adaptively conducts structure optimisation based on the specific
content of each video sequence. To better capture dynamic information across
video sequences, we propose a dynamic sequence-level adjustment (DSA).
Furthermore, to enhance the capture of dynamics between frames within a
sequence, we implement a dynamic frame-level adjustment (DFA). {Finally, to
effectively capture spatial structural information within video frames, thereby
enhancing the detail restoration capabilities of CANeRV, we devise a structure
level hierarchical structural adaptation (HSA).} Experimental results
demonstrate that CANeRV can outperform both H.266/VVC and state-of-the-art
INR-based video compression techniques across diverse video datasets.",http://arxiv.org/abs/2502.06181v1,Recommendation System,"video, compression, based, inr, capture"
"RideKE: Leveraging Low-Resource, User-Generated Twitter Content for Sentiment and Emotion Detection in Kenyan Code-Switched Dataset","Social media has become a crucial open-access platform for individuals to
express opinions and share experiences. However, leveraging low-resource
language data from Twitter is challenging due to scarce, poor-quality content
and the major variations in language use, such as slang and code-switching.
Identifying tweets in these languages can be difficult as Twitter primarily
supports high-resource languages. We analyze Kenyan code-switched data and
evaluate four state-of-the-art (SOTA) transformer-based pretrained models for
sentiment and emotion classification, using supervised and semi-supervised
methods. We detail the methodology behind data collection and annotation, and
the challenges encountered during the data curation phase. Our results show
that XLM-R outperforms other models; for sentiment analysis, XLM-R supervised
model achieves the highest accuracy (69.2\%) and F1 score (66.1\%), XLM-R
semi-supervised (67.2\% accuracy, 64.1\% F1 score). In emotion analysis,
DistilBERT supervised leads in accuracy (59.8\%) and F1 score (31\%), mBERT
semi-supervised (accuracy (59\% and F1 score 26.5\%). AfriBERTa models show the
lowest accuracy and F1 scores. All models tend to predict neutral sentiment,
with Afri-BERT showing the highest bias and unique sensitivity to empathy
emotion. https://github.com/NEtori21/Ride_hailing",http://arxiv.org/abs/2502.06180v1,Reinforcement Learning,"supervised, accuracy, data, models, score"
Bayesian Optimization by Kernel Regression and Density-based Exploration,"Bayesian optimization is highly effective for optimizing
expensive-to-evaluate black-box functions, but it faces significant
computational challenges due to the high computational complexity of Gaussian
processes, which results in a total time complexity that is quartic with
respect to the number of iterations. To address this limitation, we propose the
Bayesian Optimization by Kernel regression and density-based Exploration (BOKE)
algorithm. BOKE uses kernel regression for efficient function approximation,
kernel density for exploration, and the improved kernel regression upper
confidence bound criteria to guide the optimization process, thus reducing
computational costs to quadratic. Our theoretical analysis rigorously
establishes the global convergence of BOKE and ensures its robustness. Through
extensive numerical experiments on both synthetic and real-world optimization
tasks, we demonstrate that BOKE not only performs competitively compared to
Gaussian process-based methods but also exhibits superior computational
efficiency. These results highlight BOKE's effectiveness in
resource-constrained environments, providing a practical approach for
optimization problems in engineering applications.",http://arxiv.org/abs/2502.06178v1,Recommendation System,"optimization, boke, computational, kernel, regression"
Uncertainty-Aware Adaptation of Large Language Models for Protein-Protein Interaction Analysis,"Identification of protein-protein interactions (PPIs) helps derive cellular
mechanistic understanding, particularly in the context of complex conditions
such as neurodegenerative disorders, metabolic syndromes, and cancer. Large
Language Models (LLMs) have demonstrated remarkable potential in predicting
protein structures and interactions via automated mining of vast biomedical
literature; yet their inherent uncertainty remains a key challenge for deriving
reproducible findings, critical for biomedical applications. In this study, we
present an uncertainty-aware adaptation of LLMs for PPI analysis, leveraging
fine-tuned LLaMA-3 and BioMedGPT models. To enhance prediction reliability, we
integrate LoRA ensembles and Bayesian LoRA models for uncertainty
quantification (UQ), ensuring confidence-calibrated insights into protein
behavior. Our approach achieves competitive performance in PPI identification
across diverse disease contexts while addressing model uncertainty, thereby
enhancing trustworthiness and reproducibility in computational biology. These
findings underscore the potential of uncertainty-aware LLM adaptation for
advancing precision medicine and biomedical research.",http://arxiv.org/abs/2502.06173v1,Recommendation System,"uncertainty, protein, models, biomedical, identification"
PLATTER: A Page-Level Handwritten Text Recognition System for Indic Scripts,"In recent years, the field of Handwritten Text Recognition (HTR) has seen the
emergence of various new models, each claiming to perform competitively better
than the other in specific scenarios. However, making a fair comparison of
these models is challenging due to inconsistent choices and diversity in test
sets. Furthermore, recent advancements in HTR often fail to account for the
diverse languages, especially Indic languages, likely due to the scarcity of
relevant labeled datasets. Moreover, much of the previous work has focused
primarily on character-level or word-level recognition, overlooking the crucial
stage of Handwritten Text Detection (HTD) necessary for building a page-level
end-to-end handwritten OCR pipeline. Through our paper, we address these gaps
by making three pivotal contributions. Firstly, we present an end-to-end
framework for Page-Level hAndwriTTen TExt Recognition (PLATTER) by treating it
as a two-stage problem involving word-level HTD followed by HTR. This approach
enables us to identify, assess, and address challenges in each stage
independently. Secondly, we demonstrate the usage of PLATTER to measure the
performance of our language-agnostic HTD model and present a consistent
comparison of six trained HTR models on ten diverse Indic languages thereby
encouraging consistent comparisons. Finally, we also release a Corpus of
Handwritten Indic Scripts (CHIPS), a meticulously curated, page-level Indic
handwritten OCR dataset labeled for both detection and recognition purposes.
Additionally, we release our code and trained models, to encourage further
contributions in this direction.",http://arxiv.org/abs/2502.06172v1,Recommendation System,"handwritten, level, recognition, htr, models"
A Data-Efficient Pan-Tumor Foundation Model for Oncology CT Interpretation,"Artificial intelligence-assisted imaging analysis has made substantial
strides in tumor diagnosis and management. Here we present PASTA, a pan-tumor
CT foundation model that achieves state-of-the-art performance on 45 of 46
representative oncology tasks -- including lesion segmentation, tumor detection
in plain CT, tumor staging, survival prediction, structured report generation,
and cross-modality transfer learning, significantly outperforming the
second-best models on 35 tasks. This remarkable advancement is driven by our
development of PASTA-Gen, an innovative synthetic tumor generation framework
that produces a comprehensive dataset of 30,000 CT scans with pixel-level
annotated lesions and paired structured reports, encompassing malignancies
across ten organs and five benign lesion types. By leveraging this rich,
high-quality synthetic data, we overcome a longstanding bottleneck in the
development of CT foundation models -- specifically, the scarcity of publicly
available, high-quality annotated datasets due to privacy constraints and the
substantial labor required for scaling precise data annotation. Encouragingly,
PASTA demonstrates exceptional data efficiency with promising practical value,
markedly improving performance on various tasks with only a small amount of
real-world data. The open release of both the synthetic dataset and PASTA
foundation model effectively addresses the challenge of data scarcity, thereby
advancing oncological research and clinical translation.",http://arxiv.org/abs/2502.06171v1,Recommendation System,"tumor, data, pasta, ct, foundation"
An Interpretable Implicit-Based Approach for Modeling Local Spatial Effects: A Case Study of Global Gross Primary Productivity,"In Earth sciences, unobserved factors exhibit non-stationary spatial
distributions, causing the relationships between features and targets to
display spatial heterogeneity. In geographic machine learning tasks,
conventional statistical learning methods often struggle to capture spatial
heterogeneity, leading to unsatisfactory prediction accuracy and unreliable
interpretability. While approaches like Geographically Weighted Regression
(GWR) capture local variations, they fall short of uncovering global patterns
and tracking the continuous evolution of spatial heterogeneity. Motivated by
this limitation, we propose a novel perspective - that is, simultaneously
modeling common features across different locations alongside spatial
differences using deep neural networks. The proposed method is a dual-branch
neural network with an encoder-decoder structure. In the encoding stage, the
method aggregates node information in a spatiotemporal conditional graph using
GCN and LSTM, encoding location-specific spatiotemporal heterogeneity as an
implicit conditional vector. Additionally, a self-attention-based encoder is
used to extract location-invariant common features from the data. In the
decoding stage, the approach employs a conditional generation strategy that
predicts response variables and interpretative weights based on data features
under spatiotemporal conditions. The approach is validated by predicting
vegetation gross primary productivity (GPP) using global climate and land cover
data from 2001 to 2020. Trained on 50 million samples and tested on 2.8
million, the proposed model achieves an RMSE of 0.836, outperforming LightGBM
(1.063) and TabNet (0.944). Visualization analyses indicate that our method can
reveal the distribution differences of the dominant factors of GPP across
various times and locations.",http://arxiv.org/abs/2502.06170v1,Recommendation System,"spatial, features, heterogeneity, method, spatiotemporal"
Dynamic Pricing with Adversarially-Censored Demands,"We study an online dynamic pricing problem where the potential demand at each
time period $t=1,2,\ldots, T$ is stochastic and dependent on the price.
However, a perishable inventory is imposed at the beginning of each time $t$,
censoring the potential demand if it exceeds the inventory level. To address
this problem, we introduce a pricing algorithm based on the optimistic
estimates of derivatives. We show that our algorithm achieves
$\tilde{O}(\sqrt{T})$ optimal regret even with adversarial inventory series.
Our findings advance the state-of-the-art in online decision-making problems
with censored feedback, offering a theoretically optimal solution against
adversarial observations.",http://arxiv.org/abs/2502.06168v1,Recommendation System,"inventory, online, pricing, problem, potential"
Universal Approximation of Visual Autoregressive Transformers,"We investigate the fundamental limits of transformer-based foundation models,
extending our analysis to include Visual Autoregressive (VAR) transformers. VAR
represents a big step toward generating images using a novel, scalable,
coarse-to-fine ``next-scale prediction'' framework. These models set a new
quality bar, outperforming all previous methods, including Diffusion
Transformers, while having state-of-the-art performance for image synthesis
tasks. Our primary contributions establish that, for single-head VAR
transformers with a single self-attention layer and single interpolation layer,
the VAR Transformer is universal. From the statistical perspective, we prove
that such simple VAR transformers are universal approximators for any
image-to-image Lipschitz functions. Furthermore, we demonstrate that flow-based
autoregressive transformers inherit similar approximation capabilities. Our
results provide important design principles for effective and computationally
efficient VAR Transformer strategies that can be used to extend their utility
to more sophisticated VAR models in image generation and other related areas.",http://arxiv.org/abs/2502.06167v1,Recommendation System,"var, transformers, image, transformer, models"
Adversarial Transform Particle Filters,"The particle filter (PF) and the ensemble Kalman filter (EnKF) are widely
used for approximate inference in state-space models. From a Bayesian
perspective, these algorithms represent the prior by an ensemble of particles
and update it to the posterior with new observations over time. However, the PF
often suffers from weight degeneracy in high-dimensional settings, whereas the
EnKF relies on linear Gaussian assumptions that can introduce significant
approximation errors. In this paper, we propose the Adversarial Transform
Particle Filter (ATPF), a novel filtering framework that combines the strengths
of the PF and the EnKF through adversarial learning. Specifically, importance
sampling is used to ensure statistical consistency as in the PF, while
adversarially learned transformations, such as neural networks, allow accurate
posterior matching for nonlinear and non-Gaussian systems. In addition, we
incorporate kernel methods to ease optimization and leverage regularization
techniques based on optimal transport for better statistical properties and
numerical stability. We provide theoretical guarantees, including
generalization bounds for both the analysis and forecast steps of ATPF.
Extensive experiments across various nonlinear and non-Gaussian scenarios
demonstrate the effectiveness and practical advantages of our method.",http://arxiv.org/abs/2502.06165v1,Reinforcement Learning,"pf, filter, enkf, gaussian, particle"
Generalized Temporal Tensor Decomposition with Rank-revealing Latent-ODE,"Tensor decomposition is a fundamental tool for analyzing multi-dimensional
data by learning low-rank factors to represent high-order interactions. While
recent works on temporal tensor decomposition have made significant progress by
incorporating continuous timestamps in latent factors, they still struggle with
general tensor data with continuous indexes not only in the temporal mode but
also in other modes, such as spatial coordinates in climate data. Additionally,
the problem of determining the tensor rank remains largely unexplored in
temporal tensor models. To address these limitations, we propose
\underline{G}eneralized temporal tensor decomposition with
\underline{R}ank-r\underline{E}vealing laten\underline{T}-ODE (GRET).
  Our approach encodes continuous spatial indexes as learnable Fourier features
and employs neural ODEs in latent space to learn the temporal trajectories of
factors. To automatically reveal the rank of temporal tensors, we introduce a
rank-revealing Gaussian-Gamma prior over the factor trajectories. We develop an
efficient variational inference scheme with an analytical evidence lower bound,
enabling sampling-free optimization. Through extensive experiments on both
synthetic and real-world datasets, we demonstrate that GRET not only reveals
the underlying ranks of temporal tensors but also significantly outperforms
existing methods in prediction performance and robustness against noise.",http://arxiv.org/abs/2502.06164v1,Reinforcement Learning,"temporal, tensor, rank, decomposition, data"
Scalable k-Means Clustering for Large k via Seeded Approximate Nearest-Neighbor Search,"For very large values of $k$, we consider methods for fast $k$-means
clustering of massive datasets with $10^7\sim10^9$ points in high-dimensions
($d\geq100$). All current practical methods for this problem have runtimes at
least $\Omega(k^2)$. We find that initialization routines are not a bottleneck
for this case. Instead, it is critical to improve the speed of Lloyd's
local-search algorithm, particularly the step that reassigns points to their
closest center. Attempting to improve this step naturally leads us to leverage
approximate nearest-neighbor search methods, although this alone is not enough
to be practical. Instead, we propose a family of problems we call ""Seeded
Approximate Nearest-Neighbor Search"", for which we propose ""Seeded
Search-Graph"" methods as a solution.",http://arxiv.org/abs/2502.06163v1,Recommendation System,"methods, search, points, practical, instead"
Foundation Models for Anomaly Detection: Vision and Challenges,"As data continues to grow in volume and complexity across domains such as
finance, manufacturing, and healthcare, effective anomaly detection is
essential for identifying irregular patterns that may signal critical issues.
Recently, foundation models (FMs) have emerged as a powerful tool for advancing
anomaly detection. They have demonstrated unprecedented capabilities in
enhancing anomaly identification, generating detailed data descriptions, and
providing visual explanations. This survey presents the first comprehensive
review of recent advancements in FM-based anomaly detection. We propose a novel
taxonomy that classifies FMs into three categories based on their roles in
anomaly detection tasks, i.e., as encoders, detectors, or interpreters. We
provide a systematic analysis of state-of-the-art methods and discuss key
challenges in leveraging FMs for improved anomaly detection. We also outline
future research directions in this rapidly evolving field.",http://arxiv.org/abs/2502.06911v1,Recommendation System,"anomaly, detection, fms, data, based"
Efficient-vDiT: Efficient Video Diffusion Transformers With Attention Tile,"Despite the promise of synthesizing high-fidelity videos, Diffusion
Transformers (DiTs) with 3D full attention suffer from expensive inference due
to the complexity of attention computation and numerous sampling steps. For
example, the popular Open-Sora-Plan model consumes more than 9 minutes for
generating a single video of 29 frames. This paper addresses the inefficiency
issue from two aspects: 1) Prune the 3D full attention based on the redundancy
within video data; We identify a prevalent tile-style repetitive pattern in the
3D attention maps for video data, and advocate a new family of sparse 3D
attention that holds a linear complexity w.r.t. the number of video frames. 2)
Shorten the sampling process by adopting existing multi-step consistency
distillation; We split the entire sampling trajectory into several segments and
perform consistency distillation within each one to activate few-step
generation capacities. We further devise a three-stage training pipeline to
conjoin the low-complexity attention and few-step generation capacities.
Notably, with 0.1% pretraining data, we turn the Open-Sora-Plan-1.2 model into
an efficient one that is 7.4x -7.8x faster for 29 and 93 frames 720p video
generation with a marginal performance trade-off in VBench. In addition, we
demonstrate that our approach is amenable to distributed inference, achieving
an additional 3.91x speedup when running on 4 GPUs with sequence parallelism.",http://arxiv.org/abs/2502.06155v1,Computer Vision,"attention, video, complexity, sampling, frames"
Low Tensor-Rank Adaptation of Kolmogorov--Arnold Networks,"Kolmogorov--Arnold networks (KANs) have demonstrated their potential as an
alternative to multi-layer perceptions (MLPs) in various domains, especially
for science-related tasks. However, transfer learning of KANs remains a
relatively unexplored area. In this paper, inspired by Tucker decomposition of
tensors and evidence on the low tensor-rank structure in KAN parameter updates,
we develop low tensor-rank adaptation (LoTRA) for fine-tuning KANs. We study
the expressiveness of LoTRA based on Tucker decomposition approximations.
Furthermore, we provide a theoretical analysis to select the learning rates for
each LoTRA component to enable efficient training. Our analysis also shows that
using identical learning rates across all components leads to inefficient
training, highlighting the need for an adaptive learning rate strategy. Beyond
theoretical insights, we explore the application of LoTRA for efficiently
solving various partial differential equations (PDEs) by fine-tuning KANs.
Additionally, we propose Slim KANs that incorporate the inherent
low-tensor-rank properties of KAN parameter tensors to reduce model size while
maintaining superior performance. Experimental results validate the efficacy of
the proposed learning rate selection strategy and demonstrate the effectiveness
of LoTRA for transfer learning of KANs in solving PDEs. Further evaluations on
Slim KANs for function representation and image classification tasks highlight
the expressiveness of LoTRA and the potential for parameter reduction through
low tensor-rank decomposition.",http://arxiv.org/abs/2502.06153v1,Recommendation System,"kans, learning, lotra, low, tensor"
The Value of Information in Human-AI Decision-making,"Humans and AIs are often paired on decision tasks with the expectation of
achieving complementary performance, where the combination of human and AI
outperforms either one alone. However, how to improve performance of a human-AI
team is often not clear without knowing more about what particular information
and strategies each agent employs. We provide a decision-theoretic framework
for characterizing the value of information -- and consequently, opportunities
for agents to better exploit available information--in AI-assisted decision
workflow. We demonstrate the use of the framework for model selection,
empirical evaluation of human-AI performance, and explanation design. We
propose a novel information-based instance-level explanation technique that
adapts a conventional saliency-based explanation to explain information value
in decision making.",http://arxiv.org/abs/2502.06152v1,Recommendation System,"information, decision, ai, performance, human"
Powerformer: A Transformer with Weighted Causal Attention for Time-series Forecasting,"Transformers have recently shown strong performance in time-series
forecasting, but their all-to-all attention mechanism overlooks the (temporal)
causal and often (temporally) local nature of data. We introduce Powerformer, a
novel Transformer variant that replaces noncausal attention weights with causal
weights that are reweighted according to a smooth heavy-tailed decay. This
simple yet effective modification endows the model with an inductive bias
favoring temporally local dependencies, while still allowing sufficient
flexibility to learn the unique correlation structure of each dataset. Our
empirical results demonstrate that Powerformer not only achieves
state-of-the-art accuracy on public time-series benchmarks, but also that it
offers improved interpretability of attention patterns. Our analyses show that
the model's locality bias is amplified during training, demonstrating an
interplay between time-series data and power-law-based attention. These
findings highlight the importance of domain-specific modifications to the
Transformer architecture for time-series forecasting, and they establish
Powerformer as a strong, efficient, and principled baseline for future research
and real-world applications.",http://arxiv.org/abs/2502.06151v1,Reinforcement Learning,"time, series, attention, powerformer, strong"
Guided Exploration for Efficient Relational Model Learning,"Efficient exploration is critical for learning relational models in
large-scale environments with complex, long-horizon tasks. Random exploration
methods often collect redundant or irrelevant data, limiting their ability to
learn accurate relational models of the environment. Goal-literal babbling
(GLIB) improves upon random exploration by setting and planning to novel goals,
but its reliance on random actions and random novel goal selection limits its
scalability to larger domains. In this work, we identify the principles
underlying efficient exploration in relational domains: (1) operator
initialization with demonstrations that cover the distinct lifted effects
necessary for planning and (2) refining preconditions to collect maximally
informative transitions by selecting informative goal-action pairs and
executing plans to them. To demonstrate these principles, we introduce
Baking-Large, a challenging domain with extensive state-action spaces and
long-horizon tasks. We evaluate methods using oracle-driven demonstrations for
operator initialization and precondition-targeting guidance to efficiently
gather critical transitions. Experiments show that both the oracle
demonstrations and precondition-targeting oracle guidance significantly improve
sample efficiency and generalization, paving the way for future methods to use
these principles to efficiently learn accurate relational models in complex
domains.",http://arxiv.org/abs/2502.06146v1,Recommendation System,"exploration, relational, random, models, methods"
Enhancing kidney transplantation through multi-agent kidney exchange programs: A comprehensive review and optimization models,"This paper presents a comprehensive review of the last two decades of
research on Kidney Exchange Programs (KEPs), systematically categorizing and
classifying key contributions to provide readers with a structured
understanding of advancements in the field. The review highlights the evolution
of KEP methodologies and lays the foundation for our contribution. We propose
three mathematical models aimed at improving both the quantity and quality of
kidney transplants. Model 1 maximizes the number of transplants by focusing on
compatibility based on blood type and PRA, without additional constraints.
Model 2 introduces a minimum Human Leukocyte Antigen (HLA) compatibility
threshold to enhance transplant quality, though this leads to fewer matches.
Model 3 extends the problem to a Multi-Agent Kidney Exchange Program (MKEP),
pooling incompatible donor-recipient pairs across multiple agents, resulting in
a higher number of successful transplants while ensuring fairness across
agents. Sensitivity analyses demonstrate trade-offs between transplant quantity
and quality, with Model 3 striking the optimal balance by leveraging
multi-agent collaboration to improve both the number and quality of
transplants. These findings underscore the potential benefits of more
integrated kidney exchange systems.",http://arxiv.org/abs/2502.07819v1,Recommendation System,"kidney, quality, transplants, model, exchange"
Animate Anyone 2: High-Fidelity Character Image Animation with Environment Affordance,"Recent character image animation methods based on diffusion models, such as
Animate Anyone, have made significant progress in generating consistent and
generalizable character animations. However, these approaches fail to produce
reasonable associations between characters and their environments. To address
this limitation, we introduce Animate Anyone 2, aiming to animate characters
with environment affordance. Beyond extracting motion signals from source
video, we additionally capture environmental representations as conditional
inputs. The environment is formulated as the region with the exclusion of
characters and our model generates characters to populate these regions while
maintaining coherence with the environmental context. We propose a
shape-agnostic mask strategy that more effectively characterizes the
relationship between character and environment. Furthermore, to enhance the
fidelity of object interactions, we leverage an object guider to extract
features of interacting objects and employ spatial blending for feature
injection. We also introduce a pose modulation strategy that enables the model
to handle more diverse motion patterns. Experimental results demonstrate the
superior performance of the proposed method.",http://arxiv.org/abs/2502.06145v1,Reinforcement Learning,"characters, character, animate, environment, introduce"
Linear Bandits with Partially Observable Features,"We introduce a novel linear bandit problem with partially observable
features, resulting in partial reward information and spurious estimates.
Without proper address for latent part, regret possibly grows linearly in
decision horizon $T$, as their influence on rewards are unknown. To tackle
this, we propose a novel analysis to handle the latent features and an
algorithm that achieves sublinear regret. The core of our algorithm involves
(i) augmenting basis vectors orthogonal to the observed feature space, and (ii)
introducing an efficient doubly robust estimator. Our approach achieves a
regret bound of $\tilde{O}(\sqrt{(d + d_h)T})$, where $d$ is the dimension of
observed features, and $d_h$ is the unknown dimension of the subspace of the
unobserved features. Notably, our algorithm requires no prior knowledge of the
unobserved feature space, which may expand as more features become hidden.
Numerical experiments confirm that our algorithm outperforms both
non-contextual multi-armed bandits and linear bandit algorithms depending
solely on observed features.",http://arxiv.org/abs/2502.06142v1,Recommendation System,"features, algorithm, regret, observed, novel"
Enhanced Hybrid Deep Learning Approach for Botnet Attacks Detection in IoT Environment,"Cyberattacks in an Internet of Things (IoT) environment can have significant
impacts because of the interconnected nature of devices and systems. An
attacker uses a network of compromised IoT devices in a botnet attack to carry
out various harmful activities. Detecting botnet attacks poses several
challenges because of the intricate and evolving nature of these threats.
Botnet attacks erode trust in IoT devices and systems, undermining confidence
in their security, reliability, and integrity. Deep learning techniques have
significantly enhanced the detection of botnet attacks due to their ability to
analyze and learn from complex patterns in data. This research proposed the
stacking of Deep convolutional neural networks, Bi-Directional Long Short-Term
Memory (Bi-LSTM), Bi-Directional Gated Recurrent Unit (Bi-GRU), and Recurrent
Neural Networks (RNN) for botnet attacks detection. The UNSW-NB15 dataset is
utilized for botnet attacks detection. According to experimental results, the
proposed model accurately provides for the intricate patterns and features of
botnet attacks, with a testing accuracy of 99.76%. The proposed model also
identifies botnets with a high ROC-AUC curve value of 99.18%. A performance
comparison of the proposed method with existing state-of-the-art models
confirms its higher performance. The outcomes of this research could strengthen
cyber security procedures and safeguard against new attacks.",http://arxiv.org/abs/2502.06138v1,Recommendation System,"botnet, attacks, proposed, bi, iot"
Graph Neural Networks at a Fraction,"Graph Neural Networks (GNNs) have emerged as powerful tools for learning
representations of graph-structured data. In addition to real-valued GNNs,
quaternion GNNs also perform well on tasks on graph-structured data. With the
aim of reducing the energy footprint, we reduce the model size while
maintaining accuracy comparable to that of the original-sized GNNs. This paper
introduces Quaternion Message Passing Neural Networks (QMPNNs), a framework
that leverages quaternion space to compute node representations. Our approach
offers a generalizable method for incorporating quaternion representations into
GNN architectures at one-fourth of the original parameter count. Furthermore,
we present a novel perspective on Graph Lottery Tickets, redefining their
applicability within the context of GNNs and QMPNNs. We specifically aim to
find the initialization lottery from the subnetwork of the GNNs that can
achieve comparable performance to the original GNN upon training. Thereby
reducing the trainable model parameters even further. To validate the
effectiveness of our proposed QMPNN framework and LTH for both GNNs and QMPNNs,
we evaluate their performance on real-world datasets across three fundamental
graph-based tasks: node classification, link prediction, and graph
classification.",http://arxiv.org/abs/2502.06136v2,Recommendation System,"gnns, graph, quaternion, representations, original"
TimeKAN: KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasting,"Real-world time series often have multiple frequency components that are
intertwined with each other, making accurate time series forecasting
challenging. Decomposing the mixed frequency components into multiple single
frequency components is a natural choice. However, the information density of
patterns varies across different frequencies, and employing a uniform modeling
approach for different frequency components can lead to inaccurate
characterization. To address this challenges, inspired by the flexibility of
the recent Kolmogorov-Arnold Network (KAN), we propose a KAN-based Frequency
Decomposition Learning architecture (TimeKAN) to address the complex
forecasting challenges caused by multiple frequency mixtures. Specifically,
TimeKAN mainly consists of three components: Cascaded Frequency Decomposition
(CFD) blocks, Multi-order KAN Representation Learning (M-KAN) blocks and
Frequency Mixing blocks. CFD blocks adopt a bottom-up cascading approach to
obtain series representations for each frequency band. Benefiting from the high
flexibility of KAN, we design a novel M-KAN block to learn and represent
specific temporal patterns within each frequency band. Finally, Frequency
Mixing blocks is used to recombine the frequency bands into the original
format. Extensive experimental results across multiple real-world time series
datasets demonstrate that TimeKAN achieves state-of-the-art performance as an
extremely lightweight architecture. Code is available at
https://github.com/huangst21/TimeKAN.",http://arxiv.org/abs/2502.06910v1,Recommendation System,"frequency, kan, components, blocks, series"
Integrating Sequence and Image Modeling in Irregular Medical Time Series Through Self-Supervised Learning,"Medical time series are often irregular and face significant missingness,
posing challenges for data analysis and clinical decision-making. Existing
methods typically adopt a single modeling perspective, either treating series
data as sequences or transforming them into image representations for further
classification. In this paper, we propose a joint learning framework that
incorporates both sequence and image representations. We also design three
self-supervised learning strategies to facilitate the fusion of sequence and
image representations, capturing a more generalizable joint representation. The
results indicate that our approach outperforms seven other state-of-the-art
models in three representative real-world clinical datasets. We further
validate our approach by simulating two major types of real-world missingness
through leave-sensors-out and leave-samples-out techniques. The results
demonstrate that our approach is more robust and significantly surpasses other
baselines in terms of classification performance.",http://arxiv.org/abs/2502.06134v1,Recommendation System,"image, representations, approach, series, missingness"
Enhancing Document Key Information Localization Through Data Augmentation,"The Visually Rich Form Document Intelligence and Understanding (VRDIU) Track
B focuses on the localization of key information in document images. The goal
is to develop a method capable of localizing objects in both digital and
handwritten documents, using only digital documents for training. This paper
presents a simple yet effective approach that includes a document augmentation
phase and an object detection phase. Specifically, we augment the training set
of digital documents by mimicking the appearance of handwritten documents. Our
experiments demonstrate that this pipeline enhances the models' generalization
ability and achieves high performance in the competition.",http://arxiv.org/abs/2502.06132v1,Reinforcement Learning,"documents, document, digital, handwritten, training"
Self-Correcting Decoding with Generative Feedback for Mitigating Hallucinations in Large Vision-Language Models,"While recent Large Vision-Language Models (LVLMs) have shown remarkable
performance in multi-modal tasks, they are prone to generating hallucinatory
text responses that do not align with the given visual input, which restricts
their practical applicability in real-world scenarios. In this work, inspired
by the observation that the text-to-image generation process is the inverse of
image-conditioned response generation in LVLMs, we explore the potential of
leveraging text-to-image generative models to assist in mitigating
hallucinations in LVLMs. We discover that generative models can offer valuable
self-feedback for mitigating hallucinations at both the response and token
levels. Building on this insight, we introduce self-correcting Decoding with
Generative Feedback (DeGF), a novel training-free algorithm that incorporates
feedback from text-to-image generative models into the decoding process to
effectively mitigate hallucinations in LVLMs. Specifically, DeGF generates an
image from the initial response produced by LVLMs, which acts as an auxiliary
visual reference and provides self-feedback to verify and correct the initial
response through complementary or contrastive decoding. Extensive experimental
results validate the effectiveness of our approach in mitigating diverse types
of hallucinations, consistently surpassing state-of-the-art methods across six
benchmarks. Code is available at https://github.com/zhangce01/DeGF.",http://arxiv.org/abs/2502.06130v1,Reinforcement Learning,"lvlms, image, models, text, response"
Satisfaction-Aware Incentive Scheme for Federated Learning in Industrial Metaverse: DRL-Based Stackbelberg Game Approach,"Industrial Metaverse leverages the Industrial Internet of Things (IIoT) to
integrate data from diverse devices, employing federated learning and
meta-computing to train models in a distributed manner while ensuring data
privacy. Achieving an immersive experience for industrial Metaverse
necessitates maintaining a balance between model quality and training latency.
Consequently, a primary challenge in federated learning tasks is optimizing
overall system performance by balancing model quality and training latency.
This paper designs a satisfaction function that accounts for data size, Age of
Information (AoI), and training latency. Additionally, the satisfaction
function is incorporated into the utility functions to incentivize node
participation in model training. We model the utility functions of servers and
nodes as a two-stage Stackelberg game and employ a deep reinforcement learning
approach to learn the Stackelberg equilibrium. This approach ensures balanced
rewards and enhances the applicability of the incentive scheme for industrial
Metaverse. Simulation results demonstrate that, under the same budget
constraints, the proposed incentive scheme improves at least 23.7% utility
compared to existing schemes without compromising model accuracy.",http://arxiv.org/abs/2502.06909v1,Reinforcement Learning,"model, industrial, training, metaverse, data"
Improved YOLOv5s model for key components detection of power transmission lines,"High-voltage transmission lines are located far from the road, resulting in
inconvenient inspection work and rising maintenance costs. Intelligent
inspection of power transmission lines has become increasingly important.
However, subsequent intelligent inspection relies on accurately detecting
various key components. Due to the low detection accuracy of key components in
transmission line image inspection, this paper proposed an improved object
detection model based on the YOLOv5s (You Only Look Once Version 5 Small) model
to improve the detection accuracy of key components of transmission lines.
According to the characteristics of the power grid inspection image, we first
modify the distance measurement in the k-means clustering to improve the anchor
matching of the YOLOv5s model. Then, we add the convolutional block attention
module (CBAM) attention mechanism to the backbone network to improve accuracy.
Finally, we apply the focal loss function to reduce the impact of class
imbalance. Our improved method's mAP (mean average precision) reached 98.1%,
the precision reached 97.5%, the recall reached 94.4%, and the detection rate
reached 84.8 FPS (frames per second). The experimental results show that our
improved model improves detection accuracy and has performance advantages over
other models.",http://arxiv.org/abs/2502.06127v1,Recommendation System,"inspection, detection, transmission, accuracy, model"
Graph Pseudotime Analysis and Neural Stochastic Differential Equations for Analyzing Retinal Degeneration Dynamics and Beyond,"Understanding disease progression at the molecular pathway level usually
requires capturing both structural dependencies between pathways and the
temporal dynamics of disease evolution. In this work, we solve the former
challenge by developing a biologically informed graph-forming method to
efficiently construct pathway graphs for subjects from our newly curated JR5558
mouse transcriptomics dataset. We then develop Graph-level Pseudotime Analysis
(GPA) to infer graph-level trajectories that reveal how disease progresses at
the population level, rather than in individual subjects. Based on the
trajectories estimated by GPA, we identify the most sensitive pathways that
drive disease stage transitions. In addition, we measure changes in pathway
features using neural stochastic differential equations (SDEs), which enables
us to formally define and compute pathway stability and disease bifurcation
points (points of no return), two fundamental problems in disease progression
research. We further extend our theory to the case when pathways can interact
with each other, enabling a more comprehensive and multi-faceted
characterization of disease phenotypes. The comprehensive experimental results
demonstrate the effectiveness of our framework in reconstructing the dynamics
of the pathway, identifying critical transitions, and providing novel insights
into the mechanistic understanding of disease evolution.",http://arxiv.org/abs/2502.06126v1,Recommendation System,"disease, pathway, level, pathways, graph"
Foundation Model of Electronic Medical Records for Adaptive Risk Estimation,"We developed the Enhanced Transformer for Health Outcome Simulation (ETHOS),
an AI model that tokenizes patient health timelines (PHTs) from EHRs. ETHOS
predicts future PHTs using transformer-based architectures. The Adaptive Risk
Estimation System (ARES) employs ETHOS to compute dynamic and personalized risk
probabilities for clinician-defined critical events. ARES incorporates a
personalized explainability module that identifies key clinical factors
influencing risk estimates for individual patients. ARES was evaluated on the
MIMIC-IV v2.2 dataset in emergency department (ED) settings, benchmarking its
performance against traditional early warning systems and machine learning
models. We processed 299,721 unique patients from MIMIC-IV into 285,622 PHTs,
with 60% including hospital admissions. The dataset contained over 357 million
tokens. ETHOS outperformed benchmark models in predicting hospital admissions,
ICU admissions, and prolonged hospital stays, achieving superior AUC scores.
ETHOS-based risk estimates demonstrated robustness across demographic subgroups
with strong model reliability, confirmed via calibration curves. The
personalized explainability module provides insights into patient-specific
factors contributing to risk. ARES, powered by ETHOS, advances predictive
healthcare AI by providing dynamic, real-time, and personalized risk estimation
with patient-specific explainability to enhance clinician trust. Its
adaptability and superior accuracy position it as a transformative tool for
clinical decision-making, potentially improving patient outcomes and resource
allocation in emergency and inpatient settings. We release the full code at
github.com/ipolharvard/ethos-ares to facilitate future research.",http://arxiv.org/abs/2502.06124v1,Reinforcement Learning,"ethos, risk, patient, ares, personalized"
An Appearance Defect Detection Method for Cigarettes Based on C-CenterNet,"Due to the poor adaptability of traditional methods in the cigarette
detection task on the automatic cigarette production line, it is difficult to
accurately identify whether a cigarette has defects and the types of defects;
thus, a cigarette appearance defect detection method based on C-CenterNet is
proposed. This detector uses keypoint estimation to locate center points and
regresses all other defect properties. Firstly, Resnet50 is used as the
backbone feature extraction network, and the convolutional block attention
mechanism (CBAM) is introduced to enhance the network's ability to extract
effective features and reduce the interference of non-target information. At
the same time, the feature pyramid network is used to enhance the feature
extraction of each layer. Then, deformable convolution is used to replace part
of the common convolution to enhance the learning ability of different shape
defects. Finally, the activation function ACON (ActivateOrNot) is used instead
of the ReLU activation function, and the activation operation of some neurons
is adaptively selected to improve the detection accuracy of the network. The
experimental results are mainly acquired via the mean Average Precision (mAP).
The experimental results show that the mAP of the C-CenterNet model applied in
the cigarette appearance defect detection task is 95.01%. Compared with the
original CenterNet model, the model's success rate is increased by 6.14%, so it
can meet the requirements of precision and adaptability in cigarette detection
tasks on the automatic cigarette production line.",http://arxiv.org/abs/2502.06119v1,Recommendation System,"cigarette, detection, network, defects, defect"
Revisiting Dynamic Graph Clustering via Matrix Factorization,"Dynamic graph clustering aims to detect and track time-varying clusters in
dynamic graphs, revealing the evolutionary mechanisms of complex real-world
dynamic systems. Matrix factorization-based methods are promising approaches
for this task; however, these methods often struggle with scalability and can
be time-consuming when applied to large-scale dynamic graphs. Moreover, they
tend to lack robustness and are vulnerable to real-world noisy data. To address
these issues, we make three key contributions. First, to improve scalability,
we propose temporal separated matrix factorization, where a single matrix is
divided into multiple smaller matrices for independent factorization, resulting
in faster computation. Second, to improve robustness, we introduce
bi-clustering regularization, which jointly optimizes graph embedding and
clustering, thereby filtering out noisy features from the graph embeddings.
Third, to further enhance effectiveness and efficiency, we propose selective
embedding updating, where we update only the embeddings of dynamic nodes while
the embeddings of static nodes are fixed among different timestamps.
Experimental results on six synthetic and five real-world benchmarks
demonstrate the scalability, robustness and effectiveness of our proposed
method. Source code is available at https://github.com/Clearloveyuan/DyG-MF.",http://arxiv.org/abs/2502.06117v1,Recommendation System,"dynamic, graph, clustering, real, world"
Event Vision Sensor: A Review,"By monitoring temporal contrast, event-based vision sensors can provide high
temporal resolution and low latency while maintaining low power consumption and
simplicity in circuit structure. These characteristics have garnered
significant attention in both academia and industry. In recent years, the
application of back-illuminated (BSI) technology, wafer stacking techniques,
and industrial interfaces has brought new opportunities for enhancing the
performance of event-based vision sensors. This is evident in the substantial
advancements made in reducing noise, improving resolution, and increasing
readout rates. Additionally, the integration of these technologies has enhanced
the compatibility of event-based vision sensors with current and edge vision
systems, providing greater possibilities for their practical applications. This
paper will review the progression from neuromorphic engineering to
state-of-the-art event-based vision sensor technologies, including their
development trends, operating principles, and key features. Moreover, we will
delve into the sensitivity of event-based vision sensors and the opportunities
and challenges they face in the realm of infrared imaging, providing references
for future research and applications.",http://arxiv.org/abs/2502.06116v1,Recommendation System,"vision, event, based, sensors, temporal"
Task-driven Layerwise Additive Activation Intervention,"Modern language models (LMs) have significantly advanced generative modeling
in natural language processing (NLP). Despite their success, LMs often struggle
with adaptation to new contexts in real-time applications. A promising approach
to task adaptation is activation intervention, which steers the LMs' generation
process by identifying and manipulating the activations. However, existing
interventions are highly dependent on heuristic rules or require many prompt
inputs to determine effective interventions. This paper proposes a layer-wise
additive activation intervention framework that optimizes the intervention
process, thus enhancing the sample efficiency. We benchmark our framework on
various datasets, demonstrating improvements in the accuracy of pre-trained LMs
and competing intervention baselines.",http://arxiv.org/abs/2502.06115v1,Natural Language Processing,"lms, intervention, language, adaptation, activation"
A Novel Multi-Teacher Knowledge Distillation for Real-Time Object Detection using 4D Radar,"Accurate 3D object detection is crucial for safe autonomous navigation,
requiring reliable performance across diverse weather conditions. While LiDAR
performance deteriorates in challenging weather, Radar systems maintain their
reliability. Traditional Radars have limitations due to their lack of elevation
data, but the recent 4D Radars overcome this by measuring elevation alongside
range, azimuth, and Doppler velocity, making them invaluable for autonomous
vehicles. The primary challenge in utilizing 4D Radars is the sparsity of their
point clouds. Previous works address this by developing architectures that
better capture semantics and context in sparse point cloud, largely drawing
from LiDAR-based approaches. However, these methods often overlook a unique
advantage of 4D Radars: the dense Radar tensor, which encapsulates power
measurements across three spatial dimensions and the Doppler dimension. Our
paper leverages this tensor to tackle the sparsity issue. We introduce a novel
knowledge distillation framework that enables a student model to densify its
sparse input in the latent space by emulating an ensemble of teacher models.
Our experiments demonstrate a 25% performance improvement over the
state-of-the-art RTNH model on the K-Radar dataset. Notably, this improvement
is achieved while still maintaining a real-time inference speed.",http://arxiv.org/abs/2502.06114v2,Recommendation System,"radars, performance, radar, autonomous, weather"
CSR-Bench: Benchmarking LLM Agents in Deployment of Computer Science Research Repositories,"The increasing complexity of computer science research projects demands more
effective tools for deploying code repositories. Large Language Models (LLMs),
such as Anthropic Claude and Meta Llama, have demonstrated significant
advancements across various fields of computer science research, including the
automation of diverse software engineering tasks. To evaluate the effectiveness
of LLMs in handling complex code development tasks of research projects,
particularly for NLP/CV/AI/ML/DM topics, we introduce CSR-Bench, a benchmark
for Computer Science Research projects. This benchmark assesses LLMs from
various aspects including accuracy, efficiency, and deployment script quality,
aiming to explore their potential in conducting computer science research
autonomously. We also introduce a novel framework, CSR-Agents, that utilizes
multiple LLM agents to automate the deployment of GitHub code repositories of
computer science research projects. Specifically, by checking instructions from
markdown files and interpreting repository structures, the model generates and
iteratively improves bash commands that set up the experimental environments
and deploy the code to conduct research tasks. Preliminary results from
CSR-Bench indicate that LLM agents can significantly enhance the workflow of
repository deployment, thereby boosting developer productivity and improving
the management of developmental workflows.",http://arxiv.org/abs/2502.06111v2,Recommendation System,"research, computer, science, projects, code"
Can ChatGPT Diagnose Alzheimer's Disease?,"Can ChatGPT diagnose Alzheimer's Disease (AD)? AD is a devastating
neurodegenerative condition that affects approximately 1 in 9 individuals aged
65 and older, profoundly impairing memory and cognitive function. This paper
utilises 9300 electronic health records (EHRs) with data from Magnetic
Resonance Imaging (MRI) and cognitive tests to address an intriguing question:
As a general-purpose task solver, can ChatGPT accurately detect AD using EHRs?
We present an in-depth evaluation of ChatGPT using a black-box approach with
zero-shot and multi-shot methods. This study unlocks ChatGPT's capability to
analyse MRI and cognitive test results, as well as its potential as a
diagnostic tool for AD. By automating aspects of the diagnostic process, this
research opens a transformative approach for the healthcare system,
particularly in addressing disparities in resource-limited regions where AD
specialists are scarce. Hence, it offers a foundation for a promising method
for early detection, supporting individuals with timely interventions, which is
paramount for Quality of Life (QoL).",http://arxiv.org/abs/2502.06907v1,Recommendation System,"ad, chatgpt, cognitive, individuals, ehrs"
Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks,"The study of mechanistic interpretability aims to reverse-engineer a model to
explain its behaviors. While recent studies have focused on the static
mechanism of a certain behavior, the training dynamics inside a model remain to
be explored. In this work, we develop an interpretable method for fine-tuning
and reveal the mechanism behind learning. We first propose the concept of node
redundancy as an extension of intrinsic dimension and explain the idea behind
circuit discovery from a fresh view. Based on the theory, we propose
circuit-tuning, a two-stage algorithm that iteratively performs circuit
discovery to mask out irrelevant edges and updates the remaining parameters
responsible for a specific task. Experiments show that our method not only
improves performance on a wide range of tasks but is also scalable while
preserving general capabilities. We visualize and analyze the circuits before,
during, and after fine-tuning, providing new insights into the
self-organization mechanism of a neural network in the learning process.",http://arxiv.org/abs/2502.06106v1,Recommendation System,"mechanism, tuning, circuit, model, explain"
Comprehensive Framework for Evaluating Conversational AI Chatbots,"Conversational AI chatbots are transforming industries by streamlining
customer service, automating transactions, and enhancing user engagement.
However, evaluating these systems remains a challenge, particularly in
financial services, where compliance, user trust, and operational efficiency
are critical. This paper introduces a novel evaluation framework that
systematically assesses chatbots across four dimensions: cognitive and
conversational intelligence, user experience, operational efficiency, and
ethical and regulatory compliance. By integrating advanced AI methodologies
with financial regulations, the framework bridges theoretical foundations and
real-world deployment challenges. Additionally, we outline future research
directions, emphasizing improvements in conversational coherence, real-time
adaptability, and fairness.",http://arxiv.org/abs/2502.06105v1,Recommendation System,"conversational, user, ai, chatbots, financial"
Col-OLHTR: A Novel Framework for Multimodal Online Handwritten Text Recognition,"Online Handwritten Text Recognition (OLHTR) has gained considerable attention
for its diverse range of applications. Current approaches usually treat OLHTR
as a sequence recognition task, employing either a single trajectory or image
encoder, or multi-stream encoders, combined with a CTC or attention-based
recognition decoder. However, these approaches face several drawbacks: 1)
single encoders typically focus on either local trajectories or visual regions,
lacking the ability to dynamically capture relevant global features in
challenging cases; 2) multi-stream encoders, while more comprehensive, suffer
from complex structures and increased inference costs. To tackle this, we
propose a Collaborative learning-based OLHTR framework, called Col-OLHTR, that
learns multimodal features during training while maintaining a single-stream
inference process. Col-OLHTR consists of a trajectory encoder, a
Point-to-Spatial Alignment (P2SA) module, and an attention-based decoder. The
P2SA module is designed to learn image-level spatial features through
trajectory-encoded features and 2D rotary position embeddings. During training,
an additional image-stream encoder-decoder is collaboratively trained to
provide supervision for P2SA features. At inference, the extra streams are
discarded, and only the P2SA module is used and merged before the decoder,
simplifying the process while preserving high performance. Extensive
experimental results on several OLHTR benchmarks demonstrate the
state-of-the-art (SOTA) performance, proving the effectiveness and robustness
of our design.",http://arxiv.org/abs/2502.06100v1,Reinforcement Learning,"olhtr, features, stream, decoder, recognition"
Fine-Tuning Federated Learning-Based Intrusion Detection Systems for Transportation IoT,"The rapid advancement of machine learning (ML) and on-device computing has
revolutionized various industries, including transportation, through the
development of Connected and Autonomous Vehicles (CAVs) and Intelligent
Transportation Systems (ITS). These technologies improve traffic management and
vehicle safety, but also introduce significant security and privacy concerns,
such as cyberattacks and data breaches. Traditional Intrusion Detection Systems
(IDS) are increasingly inadequate in detecting modern threats, leading to the
adoption of ML-based IDS solutions. Federated Learning (FL) has emerged as a
promising method for enabling the decentralized training of IDS models on
distributed edge devices without sharing sensitive data. However, deploying
FL-based IDS in CAV networks poses unique challenges, including limited
computational and memory resources on edge devices, competing demands from
critical applications such as navigation and safety systems, and the need to
scale across diverse hardware and connectivity conditions. To address these
issues, we propose a hybrid server-edge FL framework that offloads pre-training
to a central server while enabling lightweight fine-tuning on edge devices.
This approach reduces memory usage by up to 42%, decreases training times by up
to 75%, and achieves competitive IDS accuracy of up to 99.2%. Scalability
analyses further demonstrates minimal performance degradation as the number of
clients increase, highlighting the framework's feasibility for CAV networks and
other IoT applications.",http://arxiv.org/abs/2502.06099v1,Recommendation System,"ids, edge, systems, fl, training"
NLGR: Utilizing Neighbor Lists for Generative Rerank in Personalized Recommendation Systems,"Reranking plays a crucial role in modern multi-stage recommender systems by
rearranging the initial ranking list. Due to the inherent challenges of
combinatorial search spaces, some current research adopts an
evaluator-generator paradigm, with a generator generating feasible sequences
and an evaluator selecting the best sequence based on the estimated list
utility. However, these methods still face two issues. Firstly, due to the goal
inconsistency problem between the evaluator and generator, the generator tends
to fit the local optimal solution of exposure distribution rather than
combinatorial space optimization. Secondly, the strategy of generating target
items one by one is difficult to achieve optimality because it ignores the
information of subsequent items.
  To address these issues, we propose a utilizing Neighbor Lists model for
Generative Reranking (NLGR), which aims to improve the performance of the
generator in the combinatorial space. NLGR follows the evaluator-generator
paradigm and improves the generator's training and generating methods.
Specifically, we use neighbor lists in combination space to enhance the
training process, making the generator perceive the relative scores and find
the optimization direction. Furthermore, we propose a novel sampling-based
non-autoregressive generation method, which allows the generator to jump
flexibly from the current list to any neighbor list. Extensive experiments on
public and industrial datasets validate NLGR's effectiveness and we have
successfully deployed NLGR on the Meituan food delivery platform.",http://arxiv.org/abs/2502.06097v2,Recommendation System,"generator, list, evaluator, nlgr, combinatorial"
Post-detection inference for sequential changepoint localization,"This paper addresses a fundamental but largely unexplored challenge in
sequential changepoint analysis: conducting inference following a detected
change. We study the problem of localizing the changepoint using only the data
observed up to a data-dependent stopping time at which a sequential detection
algorithm $\mathcal A$ declares a change. We first construct confidence sets
for the unknown changepoint when pre- and post-change distributions are assumed
to be known. We then extend our framework to composite pre- and post-change
scenarios. We impose no conditions on the observation space or on $\mathcal A$
-- we only need to be able to run $\mathcal A$ on simulated data sequences. In
summary, this work offers both theoretically sound and practically effective
tools for sequential changepoint localization.",http://arxiv.org/abs/2502.06096v1,Recommendation System,"changepoint, change, sequential, data, post"
"Rateless Joint Source-Channel Coding, and a Blueprint for 6G Semantic Communications System Design","This paper introduces rateless joint source-channel coding (rateless JSCC).
The code is rateless in that it is designed and optimized for a continuum of
coding rates such that it achieves a desired distortion for any rate in that
continuum. We further introduce rate-adaptive and stable communication link
operation to accommodate rateless JSCCs. The link operation resembles a ``bit
pipe'' that is identified by its rate in bits per frame, and, by the rate of
bits that are flipped in each frame. Thus, the link operation is rate-adaptive
such that it punctures the rateless JSCC codeword to adapt its length (and
coding rate) to the underlying channel capacity, and is stable in maintaining
the bit flipping ratio across time frames.
  Next, a new family of autoencoder rateless JSCC codes are introduced. The
code family is dubbed RLACS code (read as relax code, standing for ratelss and
lossy autoencoder channel and source code). The code is tested for
reconstruction loss of image signals and demonstrates powerful performance that
is resilient to variation of channel quality. RLACS code is readily applicable
to the case of semantic distortion suited to variety of semantic and
effectiveness communications use cases.
  In the second part of the paper, we dive into the practical concerns around
semantic communication and provide a blueprint for semantic networking system
design relying on updating the existing network systems with some essential
modifications. We further outline a comprehensive list of open research
problems and development challenges towards a practical 6G communications
system design that enables semantic networking.",http://arxiv.org/abs/2502.06095v1,Recommendation System,"code, rateless, rate, semantic, channel"
Learning-based estimation of cattle weight gain and its influencing factors,"Many cattle farmers still depend on manual methods to measure the live weight
gain of cattle at set intervals, which is time consuming, labour intensive, and
stressful for both the animals and handlers. A remote and autonomous monitoring
system using machine learning (ML) or deep learning (DL) can provide a more
efficient and less invasive method and also predictive capabilities for future
cattle weight gain (CWG). This system allows continuous monitoring and
estimation of individual cattle live weight gain, growth rates and weight
fluctuations considering various factors like environmental conditions, genetic
predispositions, feed availability, movement patterns and behaviour. Several
researchers have explored the efficiency of estimating CWG using ML and DL
algorithms. However, estimating CWG suffers from a lack of consistency in its
application. Moreover, ML or DL can provide weight gain estimations based on
several features that vary in existing research. Additionally, previous studies
have encountered various data related challenges when estimating CWG. This
paper presents a comprehensive investigation in estimating CWG using advanced
ML techniques based on research articles (between 2004 and 2024). This study
investigates the current tools, methods, and features used in CWG estimation,
as well as their strengths and weaknesses. The findings highlight the
significance of using advanced ML approaches in CWG estimation and its critical
influence on factors. Furthermore, this study identifies potential research
gaps and provides research direction on CWG prediction, which serves as a
reference for future research in this area.",http://arxiv.org/abs/2502.06906v1,Recommendation System,"cwg, weight, ml, research, cattle"
Fair-MoE: Fairness-Oriented Mixture of Experts in Vision-Language Models,"Fairness is a fundamental principle in medical ethics. Vision Language Models
(VLMs) have shown significant potential in the medical field due to their
ability to leverage both visual and linguistic contexts, reducing the need for
large datasets and enabling the performance of complex tasks. However, the
exploration of fairness within VLM applications remains limited. Applying VLMs
without a comprehensive analysis of fairness could lead to concerns about equal
treatment opportunities and diminish public trust in medical deep learning
models. To build trust in medical VLMs, we propose Fair-MoE, a model
specifically designed to ensure both fairness and effectiveness. Fair-MoE
comprises two key components: \textit{the Fairness-Oriented Mixture of Experts
(FO-MoE)} and \textit{the Fairness-Oriented Loss (FOL)}. FO-MoE is designed to
leverage the expertise of various specialists to filter out biased patch
embeddings and use an ensemble approach to extract more equitable information
relevant to specific tasks. FOL is a novel fairness-oriented loss function that
not only minimizes the distances between different attributes but also
optimizes the differences in the dispersion of various attributes'
distributions. Extended experiments demonstrate the effectiveness and fairness
of Fair-MoE. Tested on the Harvard-FairVLMed dataset, Fair-MoE showed
improvements in both fairness and accuracy across all four attributes. Code
will be publicly available.",http://arxiv.org/abs/2502.06094v1,Recommendation System,"fairness, moe, medical, fair, vlms"
Lightweight Dataset Pruning without Full Training via Example Difficulty and Prediction Uncertainty,"Recent advances in deep learning rely heavily on massive datasets, leading to
substantial storage and training costs. Dataset pruning aims to alleviate this
demand by discarding redundant examples. However, many existing methods require
training a model with a full dataset over a large number of epochs before being
able to prune the dataset, which ironically makes the pruning process more
expensive than just training the model on the entire dataset. To overcome this
limitation, we introduce a Difficulty and Uncertainty-Aware Lightweight (DUAL)
score, which aims to identify important samples from the early training stage
by considering both example difficulty and prediction uncertainty. To address a
catastrophic accuracy drop at an extreme pruning, we further propose a
ratio-adaptive sampling using Beta distribution. Experiments on various
datasets and learning scenarios such as image classification with label noise
and image corruption, and model architecture generalization demonstrate the
superiority of our method over previous state-of-the-art (SOTA) approaches.
Specifically, on ImageNet-1k, our method reduces the time cost for pruning to
66% compared to previous methods while achieving a SOTA, specifically 60% test
accuracy at a 90% pruning ratio. On CIFAR datasets, the time cost is reduced to
just 15% while maintaining SOTA performance.",http://arxiv.org/abs/2502.06905v1,Recommendation System,"pruning, training, dataset, datasets, model"
On the Computability of Multiclass PAC Learning,"We study the problem of computable multiclass learnability within the
Probably Approximately Correct (PAC) learning framework of Valiant (1984). In
the recently introduced computable PAC (CPAC) learning framework of Agarwal et
al. (2020), both learners and the functions they output are required to be
computable. We focus on the case of finite label space and start by proposing a
computable version of the Natarajan dimension and showing that it characterizes
CPAC learnability in this setting. We further generalize this result by
establishing a meta-characterization of CPAC learnability for a certain family
of dimensions: computable distinguishers. Distinguishers were defined by
Ben-David et al. (1992) as a certain family of embeddings of the label space,
with each embedding giving rise to a dimension. It was shown that the
finiteness of each such dimension characterizes multiclass PAC learnability for
finite label space in the non-computable setting. We show that the
corresponding computable dimensions for distinguishers characterize CPAC
learning. We conclude our analysis by proving that the DS dimension, which
characterizes PAC learnability for infinite label space, cannot be expressed as
a distinguisher (even in the case of finite label space).",http://arxiv.org/abs/2502.06089v1,Recommendation System,"computable, learnability, label, space, pac"
Physics-Guided Foundation Model for Scientific Discovery: An Application to Aquatic Science,"Physics-guided machine learning (PGML) has become a prevalent approach in
studying scientific systems due to its ability to integrate scientific theories
for enhancing machine learning (ML) models. However, most PGML approaches are
tailored to isolated and relatively simple tasks, which limits their
applicability to complex systems involving multiple interacting processes and
numerous influencing features. In this paper, we propose a
\textit{\textbf{P}hysics-\textbf{G}uided \textbf{F}oundation \textbf{M}odel
(\textbf{PGFM})} that combines pre-trained ML models and physics-based models
and leverages their complementary strengths to improve the modeling of multiple
coupled processes. To effectively conduct pre-training, we construct a
simulated environmental system that encompasses a wide range of influencing
features and various simulated variables generated by physics-based models. The
model is pre-trained in this system to adaptively select important feature
interactions guided by multi-task objectives. We then fine-tune the model for
each specific task using true observations, while maintaining consistency with
established physical theories, such as the principles of mass and energy
conservation. We demonstrate the effectiveness of this methodology in modeling
water temperature and dissolved oxygen dynamics in real-world lakes. The
proposed PGFM is also broadly applicable to a range of scientific fields where
physics-based models are being used.",http://arxiv.org/abs/2502.06084v1,Recommendation System,"models, physics, scientific, pre, based"
Debiasing Guidance for Discrete Diffusion with Sequential Monte Carlo,"Discrete diffusion models are a class of generative models that produce
samples from an approximated data distribution within a discrete state space.
Often, there is a need to target specific regions of the data distribution.
Current guidance methods aim to sample from a distribution with mass
proportional to $p_0(x_0) p(\zeta|x_0)^\alpha$ but fail to achieve this in
practice. We introduce a Sequential Monte Carlo algorithm that generates
unbiasedly from this target distribution, utilising the learnt unconditional
and guided process. We validate our approach on low-dimensional distributions,
controlled images and text generations. For text generation, our method
provides strong control while maintaining low perplexity compared to
guidance-based approaches.",http://arxiv.org/abs/2502.06079v1,Recommendation System,"distribution, discrete, models, data, target"
A Planning Framework for Adaptive Labeling,"Ground truth labels/outcomes are critical for advancing scientific and
engineering applications, e.g., evaluating the treatment effect of an
intervention or performance of a predictive model. Since randomly sampling
inputs for labeling can be prohibitively expensive, we introduce an adaptive
labeling framework where measurement effort can be reallocated in batches. We
formulate this problem as a Markov decision process where posterior beliefs
evolve over time as batches of labels are collected (state transition), and
batches (actions) are chosen to minimize uncertainty at the end of data
collection. We design a computational framework that is agnostic to different
uncertainty quantification approaches including those based on deep learning,
and allows a diverse array of policy gradient approaches by relying on
continuous policy parameterizations. On real and synthetic datasets, we
demonstrate even a one-step lookahead policy can substantially outperform
common adaptive labeling heuristics, highlighting the virtue of planning. On
the methodological side, we note that standard REINFORCE-style policy gradient
estimators can suffer high variance since they rely only on zeroth order
information. We propose a direct backpropagation-based approach,
Smoothed-Autodiff, based on a carefully smoothed version of the original
non-differentiable MDP. Our method enjoys low variance at the price of
introducing bias, and we theoretically and empirically show that this trade-off
can be favorable.",http://arxiv.org/abs/2502.06076v1,Recommendation System,"policy, labeling, batches, based, labels"
ID policy (with reassignment) is asymptotically optimal for heterogeneous weakly-coupled MDPs,"Heterogeneity poses a fundamental challenge for many real-world large-scale
decision-making problems but remains largely understudied. In this paper, we
study the fully heterogeneous setting of a prominent class of such problems,
known as weakly-coupled Markov decision processes (WCMDPs). Each WCMDP consists
of $N$ arms (or subproblems), which have distinct model parameters in the fully
heterogeneous setting, leading to the curse of dimensionality when $N$ is
large. We show that, under mild assumptions, a natural adaptation of the ID
policy, although originally proposed for a homogeneous special case of WCMDPs,
in fact achieves an $O(1/\sqrt{N})$ optimality gap in long-run average reward
per arm for fully heterogeneous WCMDPs as $N$ becomes large. This is the first
asymptotic optimality result for fully heterogeneous average-reward WCMDPs. Our
techniques highlight the construction of a novel projection-based Lyapunov
function, which witnesses the convergence of rewards and costs to an optimal
region in the presence of heterogeneity.",http://arxiv.org/abs/2502.06072v1,Recommendation System,"fully, heterogeneous, wcmdps, large, heterogeneity"
Lipschitz-Driven Inference: Bias-corrected Confidence Intervals for Spatial Linear Models,"Linear models remain ubiquitous in modern spatial applications - including
climate science, public health, and economics - due to their interpretability,
speed, and reproducibility. While practitioners generally report a form of
uncertainty, popular spatial uncertainty quantification methods do not jointly
handle model misspecification and distribution shift - despite both being
essentially always present in spatial problems. In the present paper, we show
that existing methods for constructing confidence (or credible) intervals in
spatial linear models fail to provide correct coverage due to unaccounted-for
bias. In contrast to classical methods that rely on an i.i.d. assumption that
is inappropriate in spatial problems, in the present work we instead make a
spatial smoothness (Lipschitz) assumption. We are then able to propose a new
confidence-interval construction that accounts for bias in the estimation
procedure. We demonstrate that our new method achieves nominal coverage via
both theory and experiments. Code to reproduce experiments is available at
https://github.com/DavidRBurt/Lipschitz-Driven-Inference.",http://arxiv.org/abs/2502.06067v1,Recommendation System,"spatial, methods, present, linear, models"
Benchmarking Prompt Sensitivity in Large Language Models,"Large language Models (LLMs) are highly sensitive to variations in prompt
formulation, which can significantly impact their ability to generate accurate
responses. In this paper, we introduce a new task, Prompt Sensitivity
Prediction, and a dataset PromptSET designed to investigate the effects of
slight prompt variations on LLM performance. Using TriviaQA and HotpotQA
datasets as the foundation of our work, we generate prompt variations and
evaluate their effectiveness across multiple LLMs. We benchmark the prompt
sensitivity prediction task employing state-of-the-art methods from related
tasks, including LLM-based self-evaluation, text classification, and query
performance prediction techniques. Our findings reveal that existing methods
struggle to effectively address prompt sensitivity prediction, underscoring the
need to understand how information needs should be phrased for accurate LLM
responses.",http://arxiv.org/abs/2502.06065v1,Recommendation System,"prompt, prediction, variations, sensitivity, llm"
Multi-modal Data Fusion and Deep Ensemble Learning for Accurate Crop Yield Prediction,"This study introduces RicEns-Net, a novel Deep Ensemble model designed to
predict crop yields by integrating diverse data sources through multimodal data
fusion techniques. The research focuses specifically on the use of synthetic
aperture radar (SAR), optical remote sensing data from Sentinel 1, 2, and 3
satellites, and meteorological measurements such as surface temperature and
rainfall. The initial field data for the study were acquired through Ernst &
Young's (EY) Open Science Challenge 2023. The primary objective is to enhance
the precision of crop yield prediction by developing a machine-learning
framework capable of handling complex environmental data. A comprehensive data
engineering process was employed to select the most informative features from
over 100 potential predictors, reducing the set to 15 features from 5 distinct
modalities. This step mitigates the ``curse of dimensionality"" and enhances
model performance. The RicEns-Net architecture combines multiple machine
learning algorithms in a deep ensemble framework, integrating the strengths of
each technique to improve predictive accuracy. Experimental results demonstrate
that RicEns-Net achieves a mean absolute error (MAE) of 341 kg/Ha (roughly
corresponds to 5-6\% of the lowest average yield in the region), significantly
exceeding the performance of previous state-of-the-art models, including those
developed during the EY challenge.",http://arxiv.org/abs/2502.06062v1,Recommendation System,"data, ricens, net, study, deep"
Online Reward-Weighted Fine-Tuning of Flow Matching with Wasserstein Regularization,"Recent advancements in reinforcement learning (RL) have achieved great
success in fine-tuning diffusion-based generative models. However, fine-tuning
continuous flow-based generative models to align with arbitrary user-defined
reward functions remains challenging, particularly due to issues such as policy
collapse from overoptimization and the prohibitively high computational cost of
likelihoods in continuous-time flows. In this paper, we propose an easy-to-use
and theoretically sound RL fine-tuning method, which we term Online
Reward-Weighted Conditional Flow Matching with Wasserstein-2 Regularization
(ORW-CFM-W2). Our method integrates RL into the flow matching framework to
fine-tune generative models with arbitrary reward functions, without relying on
gradients of rewards or filtered datasets. By introducing an online
reward-weighting mechanism, our approach guides the model to prioritize
high-reward regions in the data manifold. To prevent policy collapse and
maintain diversity, we incorporate Wasserstein-2 (W2) distance regularization
into our method and derive a tractable upper bound for it in flow matching,
effectively balancing exploration and exploitation of policy optimization. We
provide theoretical analyses to demonstrate the convergence properties and
induced data distributions of our method, establishing connections with
traditional RL algorithms featuring Kullback-Leibler (KL) regularization and
offering a more comprehensive understanding of the underlying mechanisms and
learning behavior of our approach. Extensive experiments on tasks including
target image generation, image compression, and text-image alignment
demonstrate the effectiveness of our method, where our method achieves optimal
policy convergence while allowing controllable trade-offs between reward
maximization and diversity preservation.",http://arxiv.org/abs/2502.06061v1,Reinforcement Learning,"reward, method, rl, fine, flow"
Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning,"Communicating in natural language is a powerful tool in multi-agent settings,
as it enables independent agents to share information in partially observable
settings and allows zero-shot coordination with humans. However, most prior
works are limited as they either rely on training with large amounts of human
demonstrations or lack the ability to generate natural and useful communication
strategies. In this work, we train language models to have productive
discussions about their environment in natural language without any human
demonstrations. We decompose the communication problem into listening and
speaking. Our key idea is to leverage the agent's goal to predict useful
information about the world as a dense reward signal that guides communication.
Specifically, we improve a model's listening skills by training them to predict
information about the environment based on discussions, and we simultaneously
improve a model's speaking skills with multi-agent reinforcement learning by
rewarding messages based on their influence on other agents. To investigate the
role and necessity of communication in complex social settings, we study an
embodied social deduction game based on Among Us, where the key question to
answer is the identity of an adversarial imposter. We analyze emergent
behaviors due to our technique, such as accusing suspects and providing
evidence, and find that it enables strong discussions, doubling the win rates
compared to standard RL. We release our code and models at
https://socialdeductionllm.github.io/",http://arxiv.org/abs/2502.06060v1,Reinforcement Learning,"communication, natural, language, agent, settings"
Nearly Optimal Sample Complexity of Offline KL-Regularized Contextual Bandits under Single-Policy Concentrability,"KL-regularized policy optimization has become a workhorse in learning-based
decision making, while its theoretical understanding is still very limited.
Although recent progress has been made towards settling the sample complexity
of KL-regularized contextual bandits, existing sample complexity bounds are
either $\tilde{O}(\epsilon^{-2})$ under single-policy concentrability or
$\tilde{O}(\epsilon^{-1})$ under all-policy concentrability. In this paper, we
propose the \emph{first} algorithm with $\tilde{O}(\epsilon^{-1})$ sample
complexity under single-policy concentrability for offline contextual bandits.
Our algorithm is designed for general function approximation and based on the
principle of \emph{pessimism in the face of uncertainty}. The core of our proof
leverages the strong convexity of the KL regularization, and the conditional
non-negativity of the gap between the true reward and its pessimistic estimator
to refine a mean-value-type risk upper bound to its extreme. This in turn leads
to a novel covariance-based analysis, effectively bypassing the need for
uniform control over the discrepancy between any two functions in the function
class. The near-optimality of our algorithm is demonstrated by an
$\tilde{\Omega}(\epsilon^{-1})$ lower bound. Furthermore, we extend our
algorithm to contextual dueling bandits and achieve a similar nearly optimal
sample complexity.",http://arxiv.org/abs/2502.06051v1,Recommendation System,"policy, sample, complexity, algorithm, kl"
LM2: Large Memory Models,"This paper introduces the Large Memory Model (LM2), a decoder-only
Transformer architecture enhanced with an auxiliary memory module that aims to
address the limitations of standard Transformers in multi-step reasoning,
relational argumentation, and synthesizing information distributed over long
contexts. The proposed LM2 incorporates a memory module that acts as a
contextual representation repository, interacting with input tokens via cross
attention and updating through gating mechanisms. To preserve the Transformers
general-purpose capabilities, LM2 maintains the original information flow while
integrating a complementary memory pathway. Experimental results on the
BABILong benchmark demonstrate that the LM2model outperforms both the
memory-augmented RMT model by 37.1% and the baseline Llama-3.2 model by 86.3%
on average across tasks. LM2 exhibits exceptional capabilities in multi-hop
inference, numerical reasoning, and large-context question-answering. On the
MMLU dataset, it achieves a 5.0% improvement over a pre-trained vanilla model,
demonstrating that its memory module does not degrade performance on general
tasks. Further, in our analysis, we explore the memory interpretability,
effectiveness of memory modules, and test-time behavior. Our findings emphasize
the importance of explicit memory in enhancing Transformer architectures.",http://arxiv.org/abs/2502.06049v1,Recommendation System,"memory, model, module, large, transformer"
Neural Shortest Path for Surface Reconstruction from Point Clouds,"In this paper, we propose the neural shortest path (NSP), a vector-valued
implicit neural representation (INR) that approximates a distance function and
its gradient. The key feature of NSP is to learn the exact shortest path (ESP),
which directs an arbitrary point to its nearest point on the target surface.
The NSP is decomposed into its magnitude and direction, and a variable
splitting method is used that each decomposed component approximates a distance
function and its gradient, respectively. Unlike to existing methods of learning
the distance function itself, the NSP ensures the simultaneous recovery of the
distance function and its gradient. We mathematically prove that the decomposed
representation of NSP guarantees the convergence of the magnitude of NSP in the
$H^1$ norm. Furthermore, we devise a novel loss function that enforces the
property of ESP, demonstrating that its global minimum is the ESP. We evaluate
the performance of the NSP through comprehensive experiments on diverse
datasets, validating its capacity to reconstruct high-quality surfaces with the
robustness to noise and data sparsity. The numerical results show substantial
improvements over state-of-the-art methods, highlighting the importance of
learning the ESP, the product of distance function and its gradient, for
representing a wide variety of complex surfaces.",http://arxiv.org/abs/2502.06047v1,Recommendation System,"nsp, function, distance, gradient, esp"
Scalable Differentially Private Bayesian Optimization,"In recent years, there has been much work on scaling Bayesian Optimization to
high-dimensional problems, for example hyperparameter tuning in large neural
network models. These scalable methods have been successful, finding high
objective values much more quickly than traditional global Bayesian
Optimization or random search-based methods. At the same time, these large
neural network models often use sensitive data, but preservation of
Differential Privacy has not scaled alongside these modern Bayesian
Optimization procedures. Here we develop a method to privately estimate
potentially high-dimensional parameter spaces using Gradient Informative
Bayesian Optimization. Our theoretical results prove that under suitable
conditions, our method converges exponentially fast to a ball around the
optimal parameter configuration. Moreover, regardless of whether the
assumptions are satisfied, we show that our algorithm maintains privacy and
empirically demonstrates superior performance to existing methods in the
high-dimensional hyperparameter setting.",http://arxiv.org/abs/2502.06044v1,Recommendation System,"bayesian, optimization, high, dimensional, methods"
Scaling Laws for Forgetting during Finetuning with Pretraining Data Injection,"A widespread strategy to obtain a language model that performs well on a
target domain is to finetune a pretrained model to perform unsupervised
next-token prediction on data from that target domain. Finetuning presents two
challenges: (i) if the amount of target data is limited, as in most practical
applications, the model will quickly overfit, and (ii) the model will drift
away from the original model, forgetting the pretraining data and the generic
knowledge that comes with it. We aim to derive scaling laws that quantify these
two phenomena for various target domains, amounts of available target data, and
model scales. We measure the efficiency of injecting pretraining data into the
finetuning data mixture to avoid forgetting and mitigate overfitting. A key
practical takeaway from our study is that injecting as little as 1% of
pretraining data in the finetuning data mixture prevents the model from
forgetting the pretraining set.",http://arxiv.org/abs/2502.06042v1,Recommendation System,"data, model, target, pretraining, finetuning"
Benchmarking Prompt Engineering Techniques for Secure Code Generation with GPT Models,"Prompt engineering reduces reasoning mistakes in Large Language Models
(LLMs). However, its effectiveness in mitigating vulnerabilities in
LLM-generated code remains underexplored. To address this gap, we implemented a
benchmark to automatically assess the impact of various prompt engineering
strategies on code security. Our benchmark leverages two peer-reviewed prompt
datasets and employs static scanners to evaluate code security at scale. We
tested multiple prompt engineering techniques on GPT-3.5-turbo, GPT-4o, and
GPT-4o-mini. Our results show that for GPT-4o and GPT-4o-mini, a
security-focused prompt prefix can reduce the occurrence of security
vulnerabilities by up to 56%. Additionally, all tested models demonstrated the
ability to detect and repair between 41.9% and 68.7% of vulnerabilities in
previously generated code when using iterative prompting techniques. Finally,
we introduce a ""prompt agent"" that demonstrates how the most effective
techniques can be applied in real-world development workflows.",http://arxiv.org/abs/2502.06039v1,Recommendation System,"prompt, code, security, engineering, vulnerabilities"
Provably Overwhelming Transformer Models with Designed Inputs,"We develop an algorithm which, given a trained transformer model
$\mathcal{M}$ as input, as well as a string of tokens $s$ of length $n_{fix}$
and an integer $n_{free}$, can generate a mathematical proof that $\mathcal{M}$
is ``overwhelmed'' by $s$, in time and space $\widetilde{O}(n_{fix}^2 +
n_{free}^3)$. We say that $\mathcal{M}$ is ``overwhelmed'' by $s$ when the
output of the model evaluated on this string plus any additional string $t$,
$\mathcal{M}(s + t)$, is completely insensitive to the value of the string $t$
whenever length($t$) $\leq n_{free}$. Along the way, we prove a particularly
strong worst-case form of ``over-squashing'', which we use to bound the model's
behavior. Our technique uses computer-aided proofs to establish this type of
operationally relevant guarantee about transformer models. We empirically test
our algorithm on a single layer transformer complete with an attention head,
layer-norm, MLP/ReLU layers, and RoPE positional encoding. We believe that this
work is a stepping stone towards the difficult task of obtaining useful
guarantees for trained transformer models.",http://arxiv.org/abs/2502.06038v1,Recommendation System,"transformer, string, model, algorithm, trained"
Investigating Compositional Reasoning in Time Series Foundation Models,"Large pre-trained time series foundation models (TSFMs) have demonstrated
promising zero-shot performance across a wide range of domains. However, a
question remains: Do TSFMs succeed solely by memorizing training patterns, or
do they possess the ability to reason? While reasoning is a topic of great
interest in the study of Large Language Models (LLMs), it is undefined and
largely unexplored in the context of TSFMs. In this work, inspired by language
modeling literature, we formally define compositional reasoning in forecasting
and distinguish it from in-distribution generalization. We evaluate the
reasoning and generalization capabilities of 23 popular deep learning
forecasting models on multiple synthetic and real-world datasets. Additionally,
through controlled studies, we systematically examine which design choices in
TSFMs contribute to improved reasoning abilities. Our study yields key insights
into the impact of TSFM architecture design on compositional reasoning and
generalization. We find that patch-based Transformers have the best reasoning
performance, closely followed by residualized MLP-based architectures, which
are 97\% less computationally complex in terms of FLOPs and 86\% smaller in
terms of the number of trainable parameters. Interestingly, in some zero-shot
out-of-distribution scenarios, these models can outperform moving average and
exponential smoothing statistical baselines trained on in-distribution data.
Only a few design choices, such as the tokenization method, had a significant
(negative) impact on Transformer model performance.",http://arxiv.org/abs/2502.06037v1,Recommendation System,"reasoning, models, tsfms, performance, distribution"
Traveling Waves Integrate Spatial Information Into Spectral Representations,"Traveling waves are widely observed in the brain, but their precise
computational function remains unclear. One prominent hypothesis is that they
enable the transfer and integration of spatial information across neural
populations. However, few computational models have explored how traveling
waves might be harnessed to perform such integrative processing. Drawing
inspiration from the famous ``Can one hear the shape of a drum?'' problem --
which highlights how spectral modes encode geometric information -- we
introduce a set of convolutional recurrent neural networks that learn to
produce traveling waves in their hidden states in response to visual stimuli.
By applying a spectral decomposition to these wave-like activations, we obtain
a powerful new representational space that outperforms equivalently local
feed-forward networks on tasks requiring global spatial context. In particular,
we observe that traveling waves effectively expand the receptive field of
locally connected neurons, supporting long-range encoding and communication of
information. We demonstrate that models equipped with this mechanism and
spectral readouts solve visual semantic segmentation tasks demanding global
integration, where local feed-forward models fail. As a first step toward
traveling-wave-based representations in artificial networks, our findings
suggest potential efficiency benefits and offer a new framework for connecting
to biological recordings of neural activity.",http://arxiv.org/abs/2502.06034v1,Recommendation System,"traveling, waves, information, neural, models"
A Conditional Tabular GAN-Enhanced Intrusion Detection System for Rare Attacks in IoT Networks,"Internet of things (IoT) networks, boosted by 6G technology, are transforming
various industries. However, their widespread adoption introduces significant
security risks, particularly in detecting rare but potentially damaging
cyber-attacks. This makes the development of robust IDS crucial for monitoring
network traffic and ensuring their safety. Traditional IDS often struggle with
detecting rare attacks due to severe class imbalances in IoT data. In this
paper, we propose a novel two-stage system called conditional tabular
generative synthetic minority data generation with deep neural network
(CTGSM-DNN). In the first stage, a conditional tabular generative adversarial
network (CTGAN) is employed to generate synthetic data for rare attack classes.
In the second stage, the SMOTEENN method is applied to improve dataset quality.
The full study was conducted using the CSE-CIC-IDS2018 dataset, and we assessed
the performance of the proposed IDS using different evaluation metrics. The
experimental results demonstrated the effectiveness of the proposed multiclass
classifier, achieving an overall accuracy of 99.90% and 80% accuracy in
detecting rare attacks.",http://arxiv.org/abs/2502.06031v1,Recommendation System,"rare, detecting, attacks, ids, network"
DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations,"Pre-trained Vision Transformers now serve as powerful tools for computer
vision. Yet, efficiently adapting them for multiple tasks remains a challenge
that arises from the need to modify the rich hidden representations encoded by
the learned weight matrices, without inducing interference between tasks.
Current parameter-efficient methods like LoRA, which apply low-rank updates,
force tasks to compete within constrained subspaces, ultimately degrading
performance. We introduce DiTASK a novel Diffeomorphic Multi-Task Fine-Tuning
approach that maintains pre-trained representations by preserving weight matrix
singular vectors, while enabling task-specific adaptations through neural
diffeomorphic transformations of the singular values. By following this
approach, DiTASK enables both shared and task-specific feature modulations with
minimal added parameters. Our theoretical analysis shows that DITASK achieves
full-rank updates during optimization, preserving the geometric structure of
pre-trained features, and establishing a new paradigm for efficient multi-task
learning (MTL). Our experiments on PASCAL MTL and NYUD show that DiTASK
achieves state-of-the-art performance across four dense prediction tasks, using
75% fewer parameters than existing methods.",http://arxiv.org/abs/2502.06029v1,Computer Vision,"tasks, ditask, task, pre, trained"
Generating 3D Binding Molecules Using Shape-Conditioned Diffusion Models with Guidance,"Drug development is a critical but notoriously resource- and time-consuming
process. In this manuscript, we develop a novel generative artificial
intelligence (genAI) method DiffSMol to facilitate drug development. DiffSmol
generates 3D binding molecules based on the shapes of known ligands. DiffSMol
encapsulates geometric details of ligand shapes within pre-trained, expressive
shape embeddings and then generates new binding molecules through a diffusion
model. DiffSMol further modifies the generated 3D structures iteratively via
shape guidance to better resemble the ligand shapes. It also tailors the
generated molecules toward optimal binding affinities under the guidance of
protein pockets. Here, we show that DiffSMol outperforms the state-of-the-art
methods on benchmark datasets. When generating binding molecules resembling
ligand shapes, DiffSMol with shape guidance achieves a success rate 61.4%,
substantially outperforming the best baseline (11.2%), meanwhile producing
molecules with novel molecular graph structures. DiffSMol with pocket guidance
also outperforms the best baseline in binding affinities by 13.2%, and even by
17.7% when combined with shape guidance. Case studies for two critical drug
targets demonstrate very favorable physicochemical and pharmacokinetic
properties of the generated molecules, thus, the potential of DiffSMol in
developing promising drug candidates.",http://arxiv.org/abs/2502.06027v1,Recommendation System,"diffsmol, molecules, binding, guidance, drug"
A Multimodal PDE Foundation Model for Prediction and Scientific Text Descriptions,"Neural networks are one tool for approximating non-linear differential
equations used in scientific computing tasks such as surrogate modeling,
real-time predictions, and optimal control. PDE foundation models utilize
neural networks to train approximations to multiple differential equations
simultaneously and are thus a general purpose solver that can be adapted to
downstream tasks. Current PDE foundation models focus on either learning
general solution operators and/or the governing system of equations, and thus
only handle numerical or symbolic modalities. However, real-world applications
may require more flexible data modalities, e.g. text analysis or descriptive
outputs. To address this gap, we propose a novel multimodal deep learning
approach that leverages a transformer-based architecture to approximate
solution operators for a wide variety of ODEs and PDEs. Our method integrates
numerical inputs, such as equation parameters and initial conditions, with text
descriptions of physical processes or system dynamics. This enables our model
to handle settings where symbolic representations may be incomplete or
unavailable. In addition to providing accurate numerical predictions, our
approach generates interpretable scientific text descriptions, offering deeper
insights into the underlying dynamics and solution properties. The numerical
experiments show that our model provides accurate solutions for in-distribution
data (with average relative error less than 3.3%) and out-of-distribution data
(average relative error less than 7.8%) together with precise text descriptions
(with correct descriptions generated 100% of times). In certain tests, the
model is also shown to be capable of extrapolating solutions in time.",http://arxiv.org/abs/2502.06026v1,Recommendation System,"numerical, text, descriptions, equations, solution"
Dual Caption Preference Optimization for Diffusion Models,"Recent advancements in human preference optimization, originally developed
for Large Language Models (LLMs), have shown significant potential in improving
text-to-image diffusion models. These methods aim to learn the distribution of
preferred samples while distinguishing them from less preferred ones. However,
existing preference datasets often exhibit overlap between these distributions,
leading to a conflict distribution. Additionally, we identified that input
prompts contain irrelevant information for less preferred images, limiting the
denoising network's ability to accurately predict noise in preference
optimization methods, known as the irrelevant prompt issue. To address these
challenges, we propose Dual Caption Preference Optimization (DCPO), a novel
approach that utilizes two distinct captions to mitigate irrelevant prompts. To
tackle conflict distribution, we introduce the Pick-Double Caption dataset, a
modified version of Pick-a-Pic v2 with separate captions for preferred and less
preferred images. We further propose three different strategies for generating
distinct captions: captioning, perturbation, and hybrid methods. Our
experiments show that DCPO significantly improves image quality and relevance
to prompts, outperforming Stable Diffusion (SD) 2.1, SFT_Chosen, Diffusion-DPO,
and MaPO across multiple metrics, including Pickscore, HPSv2.1, GenEval,
CLIPscore, and ImageReward, fine-tuned on SD 2.1 as the backbone.",http://arxiv.org/abs/2502.06023v1,Recommendation System,"preferred, preference, optimization, diffusion, methods"
Nested subspace learning with flags,"Many machine learning methods look for low-dimensional representations of the
data. The underlying subspace can be estimated by first choosing a dimension
$q$ and then optimizing a certain objective function over the space of
$q$-dimensional subspaces (the Grassmannian). Trying different $q$ yields in
general non-nested subspaces, which raises an important issue of consistency
between the data representations. In this paper, we propose a simple trick to
enforce nestedness in subspace learning methods. It consists in lifting
Grassmannian optimization problems to flag manifolds (the space of nested
subspaces of increasing dimension) via nested projectors. We apply the flag
trick to several classical machine learning methods and show that it
successfully addresses the nestedness issue.",http://arxiv.org/abs/2502.06022v1,Recommendation System,"learning, methods, subspaces, nested, machine"
Temporal Working Memory: Query-Guided Segment Refinement for Enhanced Multimodal Understanding,"Multimodal foundation models (MFMs) have demonstrated significant success in
tasks such as visual captioning, question answering, and image-text retrieval.
However, these models face inherent limitations due to their finite internal
capacity, which restricts their ability to process extended temporal sequences,
a crucial requirement for comprehensive video and audio analysis. To overcome
these challenges, we introduce a specialized cognitive module, temporal working
memory (TWM), which aims to enhance the temporal modeling capabilities of MFMs.
It selectively retains task-relevant information across temporal dimensions,
ensuring that critical details are preserved throughout the processing of video
and audio content. The TWM uses a query-guided attention approach to focus on
the most informative multimodal segments within temporal sequences. By
retaining only the most relevant content, TWM optimizes the use of the model's
limited capacity, enhancing its temporal modeling ability. This plug-and-play
module can be easily integrated into existing MFMs. With our TWM, nine
state-of-the-art models exhibit significant performance improvements across
tasks such as video captioning, question answering, and video-text retrieval.
By enhancing temporal modeling, TWM extends the capability of MFMs to handle
complex, time-sensitive data effectively. Our code is available at
https://github.com/xid32/NAACL_2025_TWM.",http://arxiv.org/abs/2502.06020v1,Recommendation System,"temporal, twm, mfms, video, models"
Noise is an Efficient Learner for Zero-Shot Vision-Language Models,"Recently, test-time adaptation has garnered attention as a method for tuning
models without labeled data. The conventional modus operandi for adapting
pre-trained vision-language models (VLMs) during test-time primarily focuses on
tuning learnable prompts; however, this approach overlooks potential
distribution shifts in the visual representations themselves. In this work, we
address this limitation by introducing Test-Time Noise Tuning (TNT), a novel
method for handling unpredictable shifts in the visual space. TNT leverages,
for the first time, a noise adaptation strategy that optimizes learnable noise
directly in the visual input space, enabling adaptive feature learning from a
single test sample. We further introduce a novel approach for inter-view
representation alignment by explicitly enforcing coherence in embedding
distances, ensuring consistent feature representations across views. Combined
with scaled logits and confident view selection at inference, TNT substantially
enhances VLM generalization and calibration, achieving average gains of +7.38%
on natural distributions benchmark and +0.80% on cross-dataset evaluations over
zero-shot CLIP. These improvements lay a strong foundation for adaptive
out-of-distribution handling.",http://arxiv.org/abs/2502.06019v1,Reinforcement Learning,"test, time, tuning, visual, noise"
Kolmogorov-Arnold Fourier Networks,"Although Kolmogorov-Arnold based interpretable networks (KAN) have strong
theoretical expressiveness, they face significant parameter explosion and
high-frequency feature capture challenges in high-dimensional tasks. To address
this issue, we propose the Kolmogorov-Arnold-Fourier Network (KAF), which
effectively integrates trainable Random Fourier Features (RFF) and a novel
hybrid GELU-Fourier activation mechanism to balance parameter efficiency and
spectral representation capabilities. Our key technical contributions include:
(1) merging KAN's dual-matrix structure through matrix association properties
to substantially reduce parameters; (2) introducing learnable RFF
initialization strategies to eliminate spectral distortion in high-dimensional
approximation tasks; (3) implementing an adaptive hybrid activation function
that progressively enhances frequency representation during the training
process. Comprehensive experiments demonstrate the superiority of our KAF
across various domains including vision, NLP, audio processing, and
differential equation-solving tasks, effectively combining theoretical
interpretability with practical utility and computational efficiency.",http://arxiv.org/abs/2502.06018v1,Recommendation System,"high, tasks, fourier, kolmogorov, arnold"
Emergence of Episodic Memory in Transformers: Characterizing Changes in Temporal Structure of Attention Scores During Training,"We investigate in-context temporal biases in attention heads and transformer
outputs. Using cognitive science methodologies, we analyze attention scores and
outputs of the GPT-2 models of varying sizes. Across attention heads, we
observe effects characteristic of human episodic memory, including temporal
contiguity, primacy and recency. Transformer outputs demonstrate a tendency
toward in-context serial recall. Importantly, this effect is eliminated after
the ablation of the induction heads, which are the driving force behind the
contiguity effect. Our findings offer insights into how transformers organize
information temporally during in-context learning, shedding light on their
similarities and differences with human memory and learning.",http://arxiv.org/abs/2502.06902v1,Recommendation System,"context, attention, heads, outputs, temporal"
Uncertainty Quantification and Causal Considerations for Off-Policy Decision Making,"Off-policy evaluation (OPE) is a critical challenge in robust decision-making
that seeks to assess the performance of a new policy using data collected under
a different policy. However, the existing OPE methodologies suffer from several
limitations arising from statistical uncertainty as well as causal
considerations. In this thesis, we address these limitations by presenting
three different works. Firstly, we consider the problem of high variance in the
importance-sampling-based OPE estimators. We introduce the Marginal Ratio (MR)
estimator, a novel OPE method that reduces variance by focusing on the marginal
distribution of outcomes rather than direct policy shifts, improving robustness
in contextual bandits. Next, we propose Conformal Off-Policy Prediction (COPP),
a principled approach for uncertainty quantification in OPE that provides
finite-sample predictive intervals, ensuring robust decision-making in
risk-sensitive applications. Finally, we address causal unidentifiability in
off-policy decision-making by developing novel bounds for sequential decision
settings, which remain valid under arbitrary unmeasured confounding. We apply
these bounds to assess the reliability of digital twin models, introducing a
falsification framework to identify scenarios where model predictions diverge
from real-world behaviour. Our contributions provide new insights into robust
decision-making under uncertainty and establish principled methods for
evaluating policies in both static and dynamic settings.",http://arxiv.org/abs/2502.06011v1,Recommendation System,"policy, ope, decision, making, robust"
Enabling Autoregressive Models to Fill In Masked Tokens,"Historically, LLMs have been trained using either autoregressive (AR) or
masked language modeling (MLM) objectives, with AR models gaining dominance in
recent years. However, AR models are inherently incapable of masked infilling,
which is the ability to predict masked tokens between past and future context.
In contrast, MLM models suffer from intrinsic computational inefficiencies
during both training and inference that hinder their scalability. This work
introduces MARIA (Masked and Autoregressive Infilling Architecture), a novel
approach that leverages the strengths of both paradigms to achieve
state-of-the-art masked infilling performance. MARIA combines a pre-trained MLM
and AR model by training a linear decoder that takes their concatenated hidden
states as input. This minimal modification enables the AR model to perform
infilling while retaining its inherent advantages in terms of faster inference
with KV caching. Our results demonstrate that MARIA significantly outperforms
existing methods, namely discrete diffusion models, on masked infilling tasks.",http://arxiv.org/abs/2502.06901v1,Reinforcement Learning,"masked, ar, infilling, models, mlm"
Transformers versus the EM Algorithm in Multi-class Clustering,"LLMs demonstrate significant inference capacities in complicated machine
learning tasks, using the Transformer model as its backbone. Motivated by the
limited understanding of such models on the unsupervised learning problems, we
study the learning guarantees of Transformers in performing multi-class
clustering of the Gaussian Mixture Models. We develop a theory drawing strong
connections between the Softmax Attention layers and the workflow of the EM
algorithm on clustering the mixture of Gaussians. Our theory provides
approximation bounds for the Expectation and Maximization steps by proving the
universal approximation abilities of multivariate mappings by Softmax
functions. In addition to the approximation guarantees, we also show that with
a sufficient number of pre-training samples and an initialization, Transformers
can achieve the minimax optimal rate for the problem considered. Our extensive
simulations empirically verified our theory by revealing the strong learning
capacities of Transformers even beyond the assumptions in the theory, shedding
light on the powerful inference capacities of LLMs.",http://arxiv.org/abs/2502.06007v1,Recommendation System,"learning, theory, capacities, transformers, approximation"
Analysis of LLM as a grammatical feature tagger for African American English,"African American English (AAE) presents unique challenges in natural language
processing (NLP). This research systematically compares the performance of
available NLP models--rule-based, transformer-based, and large language models
(LLMs)--capable of identifying key grammatical features of AAE, namely Habitual
Be and Multiple Negation. These features were selected for their distinct
grammatical complexity and frequency of occurrence. The evaluation involved
sentence-level binary classification tasks, using both zero-shot and few-shot
strategies. The analysis reveals that while LLMs show promise compared to the
baseline, they are influenced by biases such as recency and unrelated features
in the text such as formality. This study highlights the necessity for improved
model training and architectural adjustments to better accommodate AAE's unique
linguistic characteristics. Data and code are available.",http://arxiv.org/abs/2502.06004v1,Natural Language Processing,"aae, features, unique, language, nlp"
"Pencils to Pixels: A Systematic Study of Creative Drawings across Children, Adults and AI","Can we derive computational metrics to quantify visual creativity in drawings
across intelligent agents, while accounting for inherent differences in
technical skill and style? To answer this, we curate a novel dataset consisting
of 1338 drawings by children, adults and AI on a creative drawing task. We
characterize two aspects of the drawings -- (1) style and (2) content. For
style, we define measures of ink density, ink distribution and number of
elements. For content, we use expert-annotated categories to study conceptual
diversity, and image and text embeddings to compute distance measures. We
compare the style, content and creativity of children, adults and AI drawings
and build simple models to predict expert and automated creativity scores. We
find significant differences in style and content in the groups -- children's
drawings had more components, AI drawings had greater ink density, and adult
drawings revealed maximum conceptual diversity. Notably, we highlight a
misalignment between creativity judgments obtained through expert and automated
ratings and discuss its implications. Through these efforts, our work provides,
to the best of our knowledge, the first framework for studying human and
artificial creativity beyond the textual modality, and attempts to arrive at
the domain-agnostic principles underlying creativity. Our data and scripts are
available on GitHub.",http://arxiv.org/abs/2502.05999v1,Recommendation System,"drawings, creativity, style, content, children"
Motion Control in Multi-Rotor Aerial Robots Using Deep Reinforcement Learning,"This paper investigates the application of Deep Reinforcement (DRL) Learning
to address motion control challenges in drones for additive manufacturing (AM).
Drone-based additive manufacturing promises flexible and autonomous material
deposition in large-scale or hazardous environments. However, achieving robust
real-time control of a multi-rotor aerial robot under varying payloads and
potential disturbances remains challenging. Traditional controllers like PID
often require frequent parameter re-tuning, limiting their applicability in
dynamic scenarios. We propose a DRL framework that learns adaptable control
policies for multi-rotor drones performing waypoint navigation in AM tasks. We
compare Deep Deterministic Policy Gradient (DDPG) and Twin Delayed Deep
Deterministic Policy Gradient (TD3) within a curriculum learning scheme
designed to handle increasing complexity. Our experiments show TD3 consistently
balances training stability, accuracy, and success, particularly when mass
variability is introduced. These findings provide a scalable path toward
robust, autonomous drone control in additive manufacturing.",http://arxiv.org/abs/2502.05996v1,Reinforcement Learning,"control, deep, additive, manufacturing, drl"
A Comprehensive Survey on Image Signal Processing Approaches for Low-Illumination Image Enhancement,"The usage of digital content (photos and videos) in a variety of applications
has increased due to the popularity of multimedia devices. These uses include
advertising campaigns, educational resources, and social networking platforms.
There is an increasing need for high-quality graphic information as people
become more visually focused. However, captured images frequently have poor
visibility and a high amount of noise due to the limitations of image-capturing
devices and lighting conditions. Improving the visual quality of images taken
in low illumination is the aim of low-illumination image enhancement. This
problem is addressed by traditional image enhancement techniques, which alter
noise, brightness, and contrast. Deep learning-based methods, however, have
dominated recently made advances in this area. These methods have effectively
reduced noise while preserving important information, showing promising results
in the improvement of low-illumination images. An extensive summary of image
signal processing methods for enhancing low-illumination images is provided in
this paper. Three categories are classified in the review for approaches:
hybrid techniques, deep learning-based methods, and traditional approaches.
Conventional techniques include denoising, automated white balancing, and noise
reduction. Convolutional neural networks (CNNs) are used in deep learningbased
techniques to recognize and extract characteristics from low-light images. To
get better results, hybrid approaches combine deep learning-based methodologies
with more conventional methods. The review also discusses the advantages and
limitations of each approach and provides insights into future research
directions in this field.",http://arxiv.org/abs/2502.05995v1,Recommendation System,"images, low, methods, noise, image"
Diffusion Models for Inverse Problems in the Exponential Family,"Diffusion models have emerged as powerful tools for solving inverse problems,
yet prior work has primarily focused on observations with Gaussian measurement
noise, restricting their use in real-world scenarios. This limitation persists
due to the intractability of the likelihood score, which until now has only
been approximated in the simpler case of Gaussian likelihoods. In this work, we
extend diffusion models to handle inverse problems where the observations
follow a distribution from the exponential family, such as a Poisson or a
Binomial distribution. By leveraging the conjugacy properties of exponential
family distributions, we introduce the evidence trick, a method that provides a
tractable approximation to the likelihood score. In our experiments, we
demonstrate that our methodology effectively performs Bayesian inference on
spatially inhomogeneous Poisson processes with intensities as intricate as
ImageNet images. Furthermore, we demonstrate the real-world impact of our
methodology by showing that it performs competitively with the current
state-of-the-art in predicting malaria prevalence estimates in Sub-Saharan
Africa.",http://arxiv.org/abs/2502.05994v1,Recommendation System,"diffusion, models, inverse, problems, work"
SNAT-YOLO: Efficient Cross-Layer Aggregation Network for Edge-Oriented Gangue Detection,"To address the issues of slow detection speed,low accuracy,difficulty in
deployment on industrial edge devices,and large parameter and computational
requirements in deep learning-based coal gangue target detection methods,we
propose a lightweight coal gangue target detection algorithm based on an
improved YOLOv11.First,we use the lightweight network ShuffleNetV2 as the
backbone to enhance detection speed.Second,we introduce a lightweight
downsampling operation,ADown,which reduces model complexity while improving
average detection accuracy.Third,we improve the C2PSA module in YOLOv11 by
incorporating the Triplet Attention mechanism,resulting in the proposed
C2PSA-TriAtt module,which enhances the model's ability to focus on different
dimensions of images.Fourth,we propose the Inner-FocalerIoU loss function to
replace the existing CIoU loss function.Experimental results show that our
model achieves a detection accuracy of 99.10% in coal gangue detection
tasks,reduces the model size by 38%,the number of parameters by 41%,and the
computational cost by 40%,while decreasing the average detection time per image
by 1 ms.The improved model demonstrates enhanced detection speed and
accuracy,making it suitable for deployment on industrial edge mobile
devices,thus contributing positively to coal processing and efficient
utilization of coal resources.",http://arxiv.org/abs/2502.05988v1,Recommendation System,"detection, coal, model, accuracy, gangue"
Speech to Speech Translation with Translatotron: A State of the Art Review,"A cascade-based speech-to-speech translation has been considered a benchmark
for a very long time, but it is plagued by many issues, like the time taken to
translate a speech from one language to another and compound errors. These
issues are because a cascade-based method uses a combination of methods such as
speech recognition, speech-to-text translation, and finally, text-to-speech
translation. Translatotron, a sequence-to-sequence direct speech-to-speech
translation model was designed by Google to address the issues of compound
errors associated with cascade model. Today there are 3 versions of the
Translatotron model: Translatotron 1, Translatotron 2, and Translatotron3. The
first version was designed as a proof of concept to show that a direct
speech-to-speech translation was possible, it was found to be less effective
than the cascade model but was producing promising results. Translatotron2 was
an improved version of Translatotron 1 with results similar to the cascade
model. Translatotron 3 the latest version of the model is better than the
cascade model at some points. In this paper, a complete review of
speech-to-speech translation will be presented, with a particular focus on all
the versions of Translatotron models. We will also show that Translatotron is
the best model to bridge the language gap between African Languages and other
well-formalized languages.",http://arxiv.org/abs/2502.05980v1,Recommendation System,"speech, translatotron, model, cascade, translation"
VFX Creator: Animated Visual Effect Generation with Controllable Diffusion Transformer,"Crafting magic and illusions is one of the most thrilling aspects of
filmmaking, with visual effects (VFX) serving as the powerhouse behind
unforgettable cinematic experiences. While recent advances in generative
artificial intelligence have driven progress in generic image and video
synthesis, the domain of controllable VFX generation remains relatively
underexplored. In this work, we propose a novel paradigm for animated VFX
generation as image animation, where dynamic effects are generated from
user-friendly textual descriptions and static reference images. Our work makes
two primary contributions: (i) Open-VFX, the first high-quality VFX video
dataset spanning 15 diverse effect categories, annotated with textual
descriptions, instance segmentation masks for spatial conditioning, and
start-end timestamps for temporal control. (ii) VFX Creator, a simple yet
effective controllable VFX generation framework based on a Video Diffusion
Transformer. The model incorporates a spatial and temporal controllable LoRA
adapter, requiring minimal training videos. Specifically, a plug-and-play mask
control module enables instance-level spatial manipulation, while tokenized
start-end motion timestamps embedded in the diffusion process, alongside the
text encoder, allow precise temporal control over effect timing and pace.
Extensive experiments on the Open-VFX test set demonstrate the superiority of
the proposed system in generating realistic and dynamic effects, achieving
state-of-the-art performance and generalization ability in both spatial and
temporal controllability. Furthermore, we introduce a specialized metric to
evaluate the precision of temporal control. By bridging traditional VFX
techniques with generative approaches, VFX Creator unlocks new possibilities
for efficient and high-quality video effect generation, making advanced VFX
accessible to a broader audience.",http://arxiv.org/abs/2502.05979v2,Recommendation System,"vfx, temporal, video, generation, spatial"
Decision Making in Hybrid Environments: A Model Aggregation Approach,"Recent work by Foster et al. (2021, 2022, 2023) and Xu and Zeevi (2023)
developed the framework of decision estimation coefficient (DEC) that
characterizes the complexity of general online decision making problems and
provides a general algorithm design principle. These works, however, either
focus on the pure stochastic regime where the world remains fixed over time, or
the pure adversarial regime where the world arbitrarily changes over time. For
the hybrid regime where the dynamics of the world is fixed while the reward
arbitrarily changes, they only give pessimistic bounds on the decision
complexity. In this work, we propose a general extension of DEC that more
precisely characterizes this case. Besides applications in special cases, our
framework leads to a flexible algorithm design where the learner learns over
subsets of the hypothesis set, trading estimation complexity with decision
complexity, which could be of independent interest. Our work covers model-based
learning and model-free learning in the hybrid regime, with a newly proposed
extension of the bilinear classes (Du et al., 2021) to the adversarial-reward
case. We also recover some existing model-free learning results in the pure
stochastic regime.",http://arxiv.org/abs/2502.05974v1,Recommendation System,"regime, decision, complexity, work, general"
Known Unknowns: Out-of-Distribution Property Prediction in Materials and Molecules,"Discovery of high-performance materials and molecules requires identifying
extremes with property values that fall outside the known distribution.
Therefore, the ability to extrapolate to out-of-distribution (OOD) property
values is critical for both solid-state materials and molecular design. Our
objective is to train predictor models that extrapolate zero-shot to higher
ranges than in the training data, given the chemical compositions of solids or
molecular graphs and their property values. We propose using a transductive
approach to OOD property prediction, achieving improvements in prediction
accuracy. In particular, the True Positive Rate (TPR) of OOD classification of
materials and molecules improved by 3x and 2.5x, respectively, and precision
improved by 2x and 1.5x compared to non-transductive baselines. Our method
leverages analogical input-target relations in the training and test sets,
enabling generalization beyond the training target support, and can be applied
to any other material and molecular tasks.",http://arxiv.org/abs/2502.05970v1,Recommendation System,"property, materials, values, ood, molecular"
Asymptotic FDR Control with Model-X Knockoffs: Is Moments Matching Sufficient?,"We propose a unified theoretical framework for studying the robustness of the
model-X knockoffs framework by investigating the asymptotic false discovery
rate (FDR) control of the practically implemented approximate knockoffs
procedure. This procedure deviates from the model-X knockoffs framework by
substituting the true covariate distribution with a user-specified distribution
that can be learned using in-sample observations. By replacing the
distributional exchangeability condition of the model-X knockoff variables with
three conditions on the approximate knockoff statistics, we establish that the
approximate knockoffs procedure achieves the asymptotic FDR control. Using our
unified framework, we further prove that an arguably most popularly used
knockoff variable generation method--the Gaussian knockoffs generator based on
the first two moments matching--achieves the asymptotic FDR control when the
two-moment-based knockoff statistics are employed in the knockoffs inference
procedure. For the first time in the literature, our theoretical results
justify formally the effectiveness and robustness of the Gaussian knockoffs
generator. Simulation and real data examples are conducted to validate the
theoretical findings.",http://arxiv.org/abs/2502.05969v1,Recommendation System,"knockoffs, framework, procedure, knockoff, theoretical"
$μ$nit Scaling: Simple and Scalable FP8 LLM Training,"Large Language Model training with 8-bit floating point (FP8) formats
promises significant efficiency improvements, but reduced numerical precision
makes training challenging. It is currently possible to train in FP8 only if
one is willing to tune various hyperparameters, reduce model scale, or accept
the overhead of computing dynamic scale factors. We demonstrate simple,
scalable FP8 training that requires no dynamic scaling factors or special
hyperparameters, even at large model sizes. Our method, $\mu$nit Scaling
($\mu$S), also enables simple hyperparameter transfer across model widths,
matched numerics across training and inference, and other desirable properties.
$\mu$nit Scaling is straightforward to implement, consisting of a set of
minimal interventions based on a first-principles analysis of common
transformer operations. We validate our method by training models from 1B to
13B parameters, performing all hidden linear layer computations in FP8. We
achieve quality equal to higher precision baselines while also training up to
33% faster.",http://arxiv.org/abs/2502.05967v1,Recommendation System,"training, model, scaling, large, precision"
Detection of Physiological Data Tampering Attacks with Quantum Machine Learning,"The widespread use of cloud-based medical devices and wearable sensors has
made physiological data susceptible to tampering. These attacks can compromise
the reliability of healthcare systems which can be critical and
life-threatening. Detection of such data tampering is of immediate need.
Machine learning has been used to detect anomalies in datasets but the
performance of Quantum Machine Learning (QML) is still yet to be evaluated for
physiological sensor data. Thus, our study compares the effectiveness of QML
for detecting physiological data tampering, focusing on two types of white-box
attacks: data poisoning and adversarial perturbation. The results show that QML
models are better at identifying label-flipping attacks, achieving accuracy
rates of 75%-95% depending on the data and attack severity. This superior
performance is due to the ability of quantum algorithms to handle complex and
high-dimensional data. However, both QML and classical models struggle to
detect more sophisticated adversarial perturbation attacks, which subtly alter
data without changing its statistical properties. Although QML performed poorly
against this attack with around 45%-65% accuracy, it still outperformed
classical algorithms in some cases.",http://arxiv.org/abs/2502.05966v1,Reinforcement Learning,"data, qml, attacks, physiological, tampering"
Revisiting Gradient-based Uncertainty for Monocular Depth Estimation,"Monocular depth estimation, similar to other image-based tasks, is prone to
erroneous predictions due to ambiguities in the image, for example, caused by
dynamic objects or shadows. For this reason, pixel-wise uncertainty assessment
is required for safety-critical applications to highlight the areas where the
prediction is unreliable. We address this in a post hoc manner and introduce
gradient-based uncertainty estimation for already trained depth estimation
models. To extract gradients without depending on the ground truth depth, we
introduce an auxiliary loss function based on the consistency of the predicted
depth and a reference depth. The reference depth, which acts as pseudo ground
truth, is in fact generated using a simple image or feature augmentation,
making our approach simple and effective. To obtain the final uncertainty
score, the derivatives w.r.t. the feature maps from single or multiple layers
are calculated using back-propagation. We demonstrate that our gradient-based
approach is effective in determining the uncertainty without re-training using
the two standard depth estimation benchmarks KITTI and NYU. In particular, for
models trained with monocular sequences and therefore most prone to
uncertainty, our method outperforms related approaches. In addition, we
publicly provide our code and models: https://github.com/jhornauer/GrUMoDepth",http://arxiv.org/abs/2502.05964v1,Reinforcement Learning,"depth, uncertainty, estimation, based, image"
Temporal Model On Quantum Logic,"This paper introduces a unified theoretical framework for modeling temporal
memory dynamics, combining concepts from temporal logic, memory decay models,
and hierarchical contexts. The framework formalizes the evolution of
propositions over time using linear and branching temporal models,
incorporating exponential decay (Ebbinghaus forgetting curve) and reactivation
mechanisms via Bayesian updating. The hierarchical organization of memory is
represented using directed acyclic graphs to model recall dependencies and
interference. Novel insights include feedback dynamics, recursive influences in
memory chains, and the integration of entropy-based recall efficiency. This
approach provides a foundation for understanding memory processes across
cognitive and computational domains.",http://arxiv.org/abs/2502.07817v1,Recommendation System,"memory, temporal, framework, dynamics, decay"
Redefining Robot Generalization Through Interactive Intelligence,"Recent advances in large-scale machine learning have produced high-capacity
foundation models capable of adapting to a broad array of downstream tasks.
While such models hold great promise for robotics, the prevailing paradigm
still portrays robots as single, autonomous decision-makers, performing tasks
like manipulation and navigation, with limited human involvement. However, a
large class of real-world robotic systems, including wearable robotics (e.g.,
prostheses, orthoses, exoskeletons), teleoperation, and neural interfaces, are
semiautonomous, and require ongoing interactive coordination with human
partners, challenging single-agent assumptions. In this position paper, we
argue that robot foundation models must evolve to an interactive multi-agent
perspective in order to handle the complexities of real-time human-robot
co-adaptation. We propose a generalizable, neuroscience-inspired architecture
encompassing four modules: (1) a multimodal sensing module informed by
sensorimotor integration principles, (2) an ad-hoc teamwork model reminiscent
of joint-action frameworks in cognitive science, (3) a predictive world belief
model grounded in internal model theories of motor control, and (4) a
memory/feedback mechanism that echoes concepts of Hebbian and
reinforcement-based plasticity. Although illustrated through the lens of cyborg
systems, where wearable devices and human physiology are inseparably
intertwined, the proposed framework is broadly applicable to robots operating
in semi-autonomous or interactive contexts. By moving beyond single-agent
designs, our position emphasizes how foundation models in robotics can achieve
a more robust, personalized, and anticipatory level of performance.",http://arxiv.org/abs/2502.05963v1,Reinforcement Learning,"models, human, foundation, robotics, single"
MetaChain: A Fully-Automated and Zero-Code Framework for LLM Agents,"Large Language Model (LLM) Agents have demonstrated remarkable capabilities
in task automation and intelligent decision-making, driving the widespread
adoption of agent development frameworks such as LangChain and AutoGen.
However, these frameworks predominantly serve developers with extensive
technical expertise - a significant limitation considering that only 0.03 % of
the global population possesses the necessary programming skills. This stark
accessibility gap raises a fundamental question: Can we enable everyone,
regardless of technical background, to build their own LLM agents using natural
language alone? To address this challenge, we introduce MetaChain-a
Fully-Automated and highly Self-Developing framework that enables users to
create and deploy LLM agents through Natural Language Alone. Operating as an
autonomous Agent Operating System, MetaChain comprises four key components: i)
Agentic System Utilities, ii) LLM-powered Actionable Engine, iii) Self-Managing
File System, and iv) Self-Play Agent Customization module. This lightweight yet
powerful system enables efficient and dynamic creation and modification of
tools, agents, and workflows without coding requirements or manual
intervention. Beyond its code-free agent development capabilities, MetaChain
also serves as a versatile multi-agent system for General AI Assistants.
Comprehensive evaluations on the GAIA benchmark demonstrate MetaChain's
effectiveness in generalist multi-agent tasks, surpassing existing
state-of-the-art methods. Furthermore, MetaChain's Retrieval-Augmented
Generation (RAG)-related capabilities have shown consistently superior
performance compared to many alternative LLM-based solutions.",http://arxiv.org/abs/2502.05957v1,Recommendation System,"agent, llm, metachain, system, agents"
Cyri: A Conversational AI-based Assistant for Supporting the Human User in Detecting and Responding to Phishing Attacks,"This work introduces Cyri, an AI-powered conversational assistant designed to
support a human user in detecting and analyzing phishing emails by leveraging
Large Language Models. Cyri has been designed to scrutinize emails for semantic
features used in phishing attacks, such as urgency, and undesirable
consequences, using an approach that unifies features already established in
the literature with others by Cyri features extraction methodology. Cyri can be
directly plugged into a client mail or webmail, ensuring seamless integration
with the user's email workflow while maintaining data privacy through local
processing. By performing analyses on the user's machine, Cyri eliminates the
need to transmit sensitive email data over the internet, reducing associated
security risks. The Cyri user interface has been designed to reduce habituation
effects and enhance user engagement. It employs dynamic visual cues and
context-specific explanations to keep users alert and informed while using
emails. Additionally, it allows users to explore identified malicious semantic
features both through conversation with the agent and visual exploration,
obtaining the advantages of both modalities for expert or non-expert users. It
also allows users to keep track of the conversation, supports the user in
solving additional questions on both computed features or new parts of the
mail, and applies its detection on demand. To evaluate Cyri, we crafted a
comprehensive dataset of 420 phishing emails and 420 legitimate emails. Results
demonstrate high effectiveness in identifying critical phishing semantic
features fundamental to phishing detection. A user study involving 10
participants, both experts and non-experts, evaluated Cyri's effectiveness and
usability. Results indicated that Cyri significantly aided users in identifying
phishing emails and enhanced their understanding of phishing tactics.",http://arxiv.org/abs/2502.05951v1,Natural Language Processing,"cyri, user, phishing, emails, features"
Survival Concept-Based Learning Models,"Concept-based learning enhances prediction accuracy and interpretability by
leveraging high-level, human-understandable concepts. However, existing CBL
frameworks do not address survival analysis tasks, which involve predicting
event times in the presence of censored data -- a common scenario in fields
like medicine and reliability analysis. To bridge this gap, we propose two
novel models: SurvCBM (Survival Concept-based Bottleneck Model) and SurvRCM
(Survival Regularized Concept-based Model), which integrate concept-based
learning with survival analysis to handle censored event time data. The models
employ the Cox proportional hazards model and the Beran estimator. SurvCBM is
based on the architecture of the well-known concept bottleneck model, offering
interpretable predictions through concept-based explanations. SurvRCM uses
concepts as regularization to enhance accuracy. Both models are trained
end-to-end and provide interpretable predictions in terms of concepts. Two
interpretability approaches are proposed: one leveraging the linear
relationship in the Cox model and another using an instance-based explanation
framework with the Beran estimator. Numerical experiments demonstrate that
SurvCBM outperforms SurvRCM and traditional survival models, underscoring the
importance and advantages of incorporating concept information. The code for
the proposed algorithms is publicly available.",http://arxiv.org/abs/2502.05950v1,Recommendation System,"concept, based, survival, model, models"
Verifying Proportionality in Temporal Voting,"We study a model of temporal voting where there is a fixed time horizon, and
at each round the voters report their preferences over the available candidates
and a single candidate is selected. Prior work has adapted popular notions of
justified representation as well as voting rules that provide strong
representation guarantees from the multiwinner election setting to this model.
In our work, we focus on the complexity of verifying whether a given outcome
offers proportional representation. We show that in the temporal setting
verification is strictly harder than in multiwinner voting, but identify
natural special cases that enable efficient algorithms.",http://arxiv.org/abs/2502.05949v1,Recommendation System,"voting, representation, model, temporal, work"
Acceleration Multiple Heads Decoding for LLM via Dynamic Tree Attention,"Multiple heads decoding accelerates the inference of Large Language Models
(LLMs) by predicting next several tokens simultaneously. It generates and
verifies multiple candidate sequences in parallel via tree attention with a
fixed structure. In this paper, we replace the fixed tree attention with
dynamic tree attention on multiple head decoding, specifically in the context
of MEDUSA. We propose a simple and low complexity strategy to generate
candidates and construct the dynamic tree structure. Preliminary experiments
show that the proposed method improves the decoding efficiency of multiple head
decoding for LLMs while maintaining the generation quality. This result
demonstrates the potential for improvement of multiple head decoding in
candidate generation.",http://arxiv.org/abs/2502.05947v1,Recommendation System,"multiple, decoding, tree, attention, head"
"""Let the AI conspiracy begin..."" Language Model coordination is just one inference-intervention away","In this work, we introduce a straightforward and effective methodology to
steer large language model behaviour capable of bypassing learned alignment
goals. We employ interference-time activation shifting, which is effective
without additional training. Following prior studies, we derive intervention
directions from activation differences in contrastive pairs of model outputs,
which represent the desired and undesired behaviour. By prompting the model to
include multiple-choice answers in its response, we can automatically evaluate
the sensitivity of model output to individual attention heads steering efforts.
We demonstrate that interventions on these heads generalize well to open-ended
answer generation in the challenging ""AI coordination"" dataset. In this
dataset, models must choose between assisting another AI or adhering to
ethical, safe, and unharmful behaviour. Our fine-grained interventions lead
Llama 2 to prefer coordination with other AIs over following established
alignment goals. Additionally, this approach enables stronger interventions
than those applied to whole model layers, preserving the overall cohesiveness
of the output. The simplicity of our method highlights the shortcomings of
current alignment strategies and points to potential future research
directions, as concepts like ""AI coordination"" can be influenced by selected
attention heads.",http://arxiv.org/abs/2502.05945v1,Reinforcement Learning,"model, behaviour, alignment, heads, interventions"
Polynomial Regret Concentration of UCB for Non-Deterministic State Transitions,"Monte Carlo Tree Search (MCTS) has proven effective in solving
decision-making problems in perfect information settings. However, its
application to stochastic and imperfect information domains remains limited.
This paper extends the theoretical framework of MCTS to stochastic domains by
addressing non-deterministic state transitions, where actions lead to
probabilistic outcomes. Specifically, building on the work of Shah et al.
(2020), we derive polynomial regret concentration bounds for the Upper
Confidence Bound algorithm in multi-armed bandit problems with stochastic
transitions, offering improved theoretical guarantees. Our primary contribution
is proving that these bounds also apply to non-deterministic environments,
ensuring robust performance in stochastic settings. This broadens the
applicability of MCTS to real-world decision-making problems with probabilistic
outcomes, such as in autonomous systems and financial decision-making.",http://arxiv.org/abs/2502.06900v1,Recommendation System,"stochastic, mcts, decision, making, problems"
A Sociotechnical Approach for Knowledge Management (KM),"This article presents a sociotechnical framework for KM. This sociotechnical
vision of KM allows: (1) to remove KM from a commercial concern; (2) to divide
the different KM technologies; and (3) to question the paradigms associated
with the social and technical components of KM. It is precisely this last point
that this article develops to identify the generic mechanisms of KM. More
precisely, the social aspect is explained through the organizational approach
to KM, the managerial approach to KM, and the biological approach to KM. In
contrast, the technical aspect is described through the knowledge and skills
engineering approach to KM. These approaches also lead us to provide a
comparative table between these organizational, managerial, and biological
visions of KM.",http://arxiv.org/abs/2502.06899v1,Recommendation System,"km, approach, article, sociotechnical, social"
A Semi-Supervised Text Generation Framework Combining a Deep Transformer and a GAN,"This paper introduces a framework that connects a deep generative pre-trained
Transformer language model with a generative adversarial network for
semi-supervised text generation. In other words, the proposed model is first
pre-trained unsupervised on a large and diverse text corpus with 24 layers.
Then a simple GAN architecture for synthetic text generation is introduced, and
Gumbel-Softmax is applied to handle the discreteness of tokens. The paper also
shows a semi-supervised approach where real data is augmented with GAN samples,
which is further used to fine-tune the Transformer model on the merged dataset.
Detailed theoretical derivations are also included, outlining the proof of the
min-max objective function, and an extensive discussion of the Gumbel-Softmax
reparameterization trick.",http://arxiv.org/abs/2502.05937v1,Reinforcement Learning,"model, text, paper, generative, pre"
Barriers and Pathways to Human-AI Alignment: A Game-Theoretic Approach,"Under what conditions can capable AI agents efficiently align their actions
with human preferences? More specifically, when they are proficient enough to
collaborate with us, how long does coordination take, and when is it
computationally feasible? These foundational questions of AI alignment help
define what makes an AI agent ``sufficiently safe'' and valuable to humans.
Since such generally capable systems do not yet exist, a theoretical analysis
is needed to establish when guarantees hold -- and what they even are.
  We introduce a game-theoretic framework that generalizes prior alignment
approaches with fewer assumptions, allowing us to analyze the computational
complexity of alignment across $M$ objectives and $N$ agents, providing both
upper and lower bounds. Unlike previous work, which often assumes common
priors, idealized communication, or implicit tractability, our framework
formally characterizes the difficulty of alignment under minimal assumptions.
  Our main result shows that even when agents are fully rational and
computationally \emph{unbounded}, alignment can be achieved with high
probability in time \emph{linear} in the task space size. Therefore, in
real-world settings, where task spaces are often \emph{exponential} in input
length, this remains impractical. More strikingly, our lower bound demonstrates
that alignment is \emph{impossible} to speed up when scaling to exponentially
many tasks or agents, highlighting a fundamental computational barrier to
scalable alignment.
  Relaxing these idealized assumptions, we study \emph{computationally bounded}
agents with noisy messages (representing obfuscated intent), showing that while
alignment can still succeed with high probability, it incurs additional
\emph{exponential} slowdowns in the task space size, number of agents, and
number of tasks.
  We conclude by identifying conditions that make alignment more feasible.",http://arxiv.org/abs/2502.05934v1,Recommendation System,"alignment, agents, ai, assumptions, task"
Learning to Substitute Words with Model-based Score Ranking,"Smart word substitution aims to enhance sentence quality by improving word
choices; however current benchmarks rely on human-labeled data. Since word
choices are inherently subjective, ground-truth word substitutions generated by
a small group of annotators are often incomplete and likely not generalizable.
To circumvent this issue, we instead employ a model-based score (BARTScore) to
quantify sentence quality, thus forgoing the need for human annotations.
Specifically, we use this score to define a distribution for each word
substitution, allowing one to test whether a substitution is statistically
superior relative to others. In addition, we propose a loss function that
directly optimizes the alignment between model predictions and sentence scores,
while also enhancing the overall quality score of a substitution. Crucially,
model learning no longer requires human labels, thus avoiding the cost of
annotation while maintaining the quality of the text modified with
substitutions. Experimental results show that the proposed approach outperforms
both masked language models (BERT, BART) and large language models (GPT-4,
LLaMA). The source code is available at
https://github.com/Hyfred/Substitute-Words-with-Ranking.",http://arxiv.org/abs/2502.05933v1,Reinforcement Learning,"word, substitution, quality, sentence, human"
Skill Expansion and Composition in Parameter Space,"Humans excel at reusing prior knowledge to address new challenges and
developing skills while solving problems. This paradigm becomes increasingly
popular in the development of autonomous agents, as it develops systems that
can self-evolve in response to new challenges like human beings. However,
previous methods suffer from limited training efficiency when expanding new
skills and fail to fully leverage prior knowledge to facilitate new task
learning. In this paper, we propose Parametric Skill Expansion and Composition
(PSEC), a new framework designed to iteratively evolve the agents' capabilities
and efficiently address new challenges by maintaining a manageable skill
library. This library can progressively integrate skill primitives as
plug-and-play Low-Rank Adaptation (LoRA) modules in parameter-efficient
finetuning, facilitating efficient and flexible skill expansion. This structure
also enables the direct skill compositions in parameter space by merging LoRA
modules that encode different skills, leveraging shared information across
skills to effectively program new skills. Based on this, we propose a
context-aware module to dynamically activate different skills to
collaboratively handle new tasks. Empowering diverse applications including
multi-objective composition, dynamics shift, and continual policy shift, the
results on D4RL, DSRL benchmarks, and the DeepMind Control Suite show that PSEC
exhibits superior capacity to leverage prior knowledge to efficiently tackle
new challenges, as well as expand its skill libraries to evolve the
capabilities. Project website: https://ltlhuuu.github.io/PSEC/.",http://arxiv.org/abs/2502.05932v1,Recommendation System,"new, skills, skill, challenges, prior"
Protecting Intellectual Property of EEG-based Neural Networks with Watermarking,"EEG-based neural networks, pivotal in medical diagnosis and brain-computer
interfaces, face significant intellectual property (IP) risks due to their
reliance on sensitive neurophysiological data and resource-intensive
development. Current watermarking methods, particularly those using abstract
trigger sets, lack robust authentication and fail to address the unique
challenges of EEG models. This paper introduces a cryptographic wonder
filter-based watermarking framework tailored for EEG-based neural networks.
Leveraging collision-resistant hashing and public-key encryption, the wonder
filter embeds the watermark during training, ensuring minimal distortion ($\leq
5\%$ drop in EEG task accuracy) and high reliability (100\% watermark
detection). The framework is rigorously evaluated against adversarial attacks,
including fine-tuning, transfer learning, and neuron pruning. Results
demonstrate persistent watermark retention, with classification accuracy for
watermarked states remaining above 90\% even after aggressive pruning, while
primary task performance degrades faster, deterring removal attempts. Piracy
resistance is validated by the inability to embed secondary watermarks without
severe accuracy loss ( $>10\%$ in EEGNet and CCNN models). Cryptographic
hashing ensures authentication, reducing brute-force attack success
probabilities. Evaluated on the DEAP dataset across models (CCNN, EEGNet,
TSception), the method achieves $>99.4\%$ null-embedding accuracy, effectively
eliminating false positives. By integrating wonder filters with EEG-specific
adaptations, this work bridges a critical gap in IP protection for
neurophysiological models, offering a secure, tamper-proof solution for
healthcare and biometric applications. The framework's robustness against
adversarial modifications underscores its potential to safeguard sensitive EEG
models while maintaining diagnostic utility.",http://arxiv.org/abs/2502.05931v1,Recommendation System,"eeg, models, accuracy, based, wonder"
ClinKD: Cross-Modal Clinic Knowledge Distiller For Multi-Task Medical Images,"Med-VQA (Medical Visual Question Answering) is a crucial subtask within the
broader VQA (Visual Question Answering) domain. This task requires a visual
question answering system to analyze the provided image and corresponding
question,offering reasonable analysis and suggestions to assist medical
professionals in making pathological diagnoses, or ideally, enabling the system
to independently provide correct diagnoses. Furthermore, more advanced Med-VQA
tasks involve Referring and Grounding, which not only require the system to
accurately comprehend medical images but also to pinpoint specific biological
locations within those images. While many large pre-trained models have
demonstrated substantial VQA capabilities,challenges persist in the medical
imaging domain. The intricacy of biological features in medical images and the
scarcity of high-quality medical image datasets, combined with the fact that
current models are not tailored for the medical field in terms of architecture
and training paradigms, hinder the full exploitation of model generalization.
This results in issues such as hallucination in Visual Grounding. In this
paper, we introduce the ClinKD model, which incorporates modifications to model
position encoding and a diversified training process. Initially, we enhance the
model's ability to perceive image and modality variations by using Med-CLIP
Guided Rotary Position Embedding. Subsequently, we leverage distillation to
provide prior knowledge to the model before using complete training data.
Additionally, the feedback-based training process during the formal training
phase further enhances data utilization. Notably, under unchanged evaluation
protocols, we achieve a new state-of-the-art performance on the Med-GRIT-270k
dataset, and the Med-CLIP Guided Rotary Position Embedding approach presents
potential for generalizing to universal model position encoding.",http://arxiv.org/abs/2502.05928v1,Recommendation System,"medical, model, med, training, vqa"
A Generative Framework for Bidirectional Image-Report Understanding in Chest Radiography,"The rapid advancements in large language models (LLMs) have unlocked their
potential for multimodal tasks, where text and visual data are processed
jointly. However, applying LLMs to medical imaging, particularly for chest
X-rays (CXR), poses significant challenges due to the need for precise
visual-textual alignment and the preservation of critical diagnostic details.
In this paper, we propose Multi-Stage Adaptive Vision-Language Tuning (MAViLT),
a novel framework designed to enhance multimodal reasoning and generation for
CXR understanding. MAViLT incorporates a clinical gradient-weighted
tokenization process and a hierarchical fine-tuning strategy, enabling it to
generate accurate radiology reports, synthesize realistic CXRs from text, and
answer vision-based clinical questions. We evaluate MAViLT on two benchmark
datasets, MIMIC-CXR and Indiana University CXR, achieving state-of-the-art
results across all tasks. Human evaluations further validate the clinical
relevance and utility of MAViLT, making it a robust tool for real-world medical
applications. This work demonstrates the feasibility of leveraging LLMs for
multimodal medical imaging while addressing key challenges in vision-language
integration.",http://arxiv.org/abs/2502.05926v1,Recommendation System,"cxr, mavilt, language, llms, multimodal"
Sign-Symmetry Learning Rules are Robust Fine-Tuners,"Backpropagation (BP) has long been the predominant method for training neural
networks due to its effectiveness. However, numerous alternative approaches,
broadly categorized under feedback alignment, have been proposed, many of which
are motivated by the search for biologically plausible learning mechanisms.
Despite their theoretical appeal, these methods have consistently
underperformed compared to BP, leading to a decline in research interest. In
this work, we revisit the role of such methods and explore how they can be
integrated into standard neural network training pipelines. Specifically, we
propose fine-tuning BP-pre-trained models using Sign-Symmetry learning rules
and demonstrate that this approach not only maintains performance parity with
BP but also enhances robustness. Through extensive experiments across multiple
tasks and benchmarks, we establish the validity of our approach. Our findings
introduce a novel perspective on neural network training and open new research
directions for leveraging biologically inspired learning rules in deep
learning.",http://arxiv.org/abs/2502.05925v1,Recommendation System,"bp, learning, training, neural, biologically"
Multi-Branch Collaborative Learning Network for Video Quality Assessment in Industrial Video Search,"Video Quality Assessment (VQA) is vital for large-scale video retrieval
systems, aimed at identifying quality issues to prioritize high-quality videos.
In industrial systems, low-quality video characteristics fall into four
categories: visual-related issues like mosaics and black boxes, textual issues
from video titles and OCR content, and semantic issues like frame incoherence
and frame-text mismatch from AI-generated videos. Despite their prevalence in
industrial settings, these low-quality videos have been largely overlooked in
academic research, posing a challenge for accurate identification. To address
this, we introduce the Multi-Branch Collaborative Network (MBCN) tailored for
industrial video retrieval systems. MBCN features four branches, each designed
to tackle one of the aforementioned quality issues. After each branch
independently scores videos, we aggregate these scores using a weighted
approach and a squeeze-and-excitation mechanism to dynamically address quality
issues across different scenarios. We implement point-wise and pair-wise
optimization objectives to ensure score stability and reasonableness. Extensive
offline and online experiments on a world-level video search engine demonstrate
MBCN's effectiveness in identifying video quality issues, significantly
enhancing the retrieval system's ranking performance. Detailed experimental
analyses confirm the positive contribution of all four evaluation branches.
Furthermore, MBCN significantly improves recognition accuracy for low-quality
AI-generated videos compared to the baseline.",http://arxiv.org/abs/2502.05924v1,Recommendation System,"quality, video, issues, videos, mbcn"
"Large Language Models for In-File Vulnerability Localization Can Be ""Lost in the End""","Recent advancements in artificial intelligence have enabled processing of
larger inputs, leading everyday software developers to increasingly rely on
chat-based large language models (LLMs) like GPT-3.5 and GPT-4 to detect
vulnerabilities across entire files, not just within functions. This new
development practice requires researchers to urgently investigate whether
commonly used LLMs can effectively analyze large file-sized inputs, in order to
provide timely insights for software developers and engineers about the pros
and cons of this emerging technological trend. Hence, the goal of this paper is
to evaluate the effectiveness of several state-of-the-art chat-based LLMs,
including the GPT models, in detecting in-file vulnerabilities. We conducted a
costly investigation into how the performance of LLMs varies based on
vulnerability type, input size, and vulnerability location within the file. To
give enough statistical power to our study, we could only focus on the three
most common (as well as dangerous) vulnerabilities: XSS, SQL injection, and
path traversal. Our findings indicate that the effectiveness of LLMs in
detecting these vulnerabilities is strongly influenced by both the location of
the vulnerability and the overall size of the input. Specifically, regardless
of the vulnerability type, LLMs tend to significantly (p < .05) underperform
when detecting vulnerabilities located toward the end of larger files, a
pattern we call the 'lost-in-the-end' effect. Finally, to further support
software developers and practitioners, we also explored the optimal input size
for these LLMs and presented a simple strategy for identifying it, which can be
applied to other models and vulnerability types. Eventually, we show how
adjusting the input size can lead to significant improvements in LLM-based
vulnerability detection, with an average recall increase of over 37% across all
models.",http://arxiv.org/abs/2502.06898v1,Natural Language Processing,"llms, vulnerability, vulnerabilities, based, models"
Inverse Problem Sampling in Latent Space Using Sequential Monte Carlo,"In image processing, solving inverse problems is the task of finding
plausible reconstructions of an image that was corrupted by some (usually
known) degradation model. Commonly, this process is done using a generative
image model that can guide the reconstruction towards solutions that appear
natural. The success of diffusion models over the last few years has made them
a leading candidate for this task. However, the sequential nature of diffusion
models makes this conditional sampling process challenging. Furthermore, since
diffusion models are often defined in the latent space of an autoencoder, the
encoder-decoder transformations introduce additional difficulties. Here, we
suggest a novel sampling method based on sequential Monte Carlo (SMC) in the
latent space of diffusion models. We use the forward process of the diffusion
model to add additional auxiliary observations and then perform an SMC sampling
as part of the backward process. Empirical evaluations on ImageNet and FFHQ
show the benefits of our approach over competing methods on various inverse
problem tasks.",http://arxiv.org/abs/2502.05908v1,Recommendation System,"diffusion, process, models, image, model"
PyPotteryInk: One-Step Diffusion Model for Sketch to Publication-ready Archaeological Drawings,"Archaeological pottery documentation traditionally requires a time-consuming
manual process of converting pencil sketches into publication-ready inked
drawings. I present PyPotteryInk, an open-source automated pipeline that
transforms archaeological pottery sketches into standardised publication-ready
drawings using a one-step diffusion model. Built on a modified img2img-turbo
architecture, the system processes drawings in a single forward pass while
preserving crucial morphological details and maintaining archaeologic
documentation standards and analytical value. The model employs an efficient
patch-based approach with dynamic overlap, enabling high-resolution output
regardless of input drawing size. I demonstrate the effectiveness of the
approach on a dataset of Italian protohistoric pottery drawings, where it
successfully captures both fine details like decorative patterns and structural
elements like vessel profiles or handling elements. Expert evaluation confirms
that the generated drawings meet publication standards while significantly
reducing processing time from hours to seconds per drawing. The model can be
fine-tuned to adapt to different archaeological contexts with minimal training
data, making it versatile across various pottery documentation styles. The
pre-trained models, the Python library and comprehensive documentation are
provided to facilitate adoption within the archaeological research community.",http://arxiv.org/abs/2502.06897v1,Recommendation System,"drawings, archaeological, pottery, documentation, publication"
QP-SNN: Quantized and Pruned Spiking Neural Networks,"Brain-inspired Spiking Neural Networks (SNNs) leverage sparse spikes to
encode information and operate in an asynchronous event-driven manner, offering
a highly energy-efficient paradigm for machine intelligence. However, the
current SNN community focuses primarily on performance improvement by
developing large-scale models, which limits the applicability of SNNs in
resource-limited edge devices. In this paper, we propose a hardware-friendly
and lightweight SNN, aimed at effectively deploying high-performance SNN in
resource-limited scenarios. Specifically, we first develop a baseline model
that integrates uniform quantization and structured pruning, called QP-SNN
baseline. While this baseline significantly reduces storage demands and
computational costs, it suffers from performance decline. To address this, we
conduct an in-depth analysis of the challenges in quantization and pruning that
lead to performance degradation and propose solutions to enhance the baseline's
performance. For weight quantization, we propose a weight rescaling strategy
that utilizes bit width more effectively to enhance the model's representation
capability. For structured pruning, we propose a novel pruning criterion using
the singular value of spatiotemporal spike activities to enable more accurate
removal of redundant kernels. Extensive experiments demonstrate that
integrating two proposed methods into the baseline allows QP-SNN to achieve
state-of-the-art performance and efficiency, underscoring its potential for
enhancing SNN deployment in edge intelligence computing.",http://arxiv.org/abs/2502.05905v1,Recommendation System,"snn, performance, baseline, propose, pruning"
Fast Omni-Directional Image Super-Resolution: Adapting the Implicit Image Function with Pixel and Semantic-Wise Spherical Geometric Priors,"In the context of Omni-Directional Image (ODI) Super-Resolution (SR), the
unique challenge arises from the non-uniform oversampling characteristics
caused by EquiRectangular Projection (ERP). Considerable efforts in designing
complex spherical convolutions or polyhedron reprojection offer significant
performance improvements but at the expense of cumbersome processing procedures
and slower inference speeds. Under these circumstances, this paper proposes a
new ODI-SR model characterized by its capacity to perform Fast and
Arbitrary-scale ODI-SR processes, denoted as FAOR. The key innovation lies in
adapting the implicit image function from the planar image domain to the ERP
image domain by incorporating spherical geometric priors at both the latent
representation and image reconstruction stages, in a low-overhead manner.
Specifically, at the latent representation stage, we adopt a pair of pixel-wise
and semantic-wise sphere-to-planar distortion maps to perform affine
transformations on the latent representation, thereby incorporating it with
spherical properties. Moreover, during the image reconstruction stage, we
introduce a geodesic-based resampling strategy, aligning the implicit image
function with spherical geometrics without introducing additional parameters.
As a result, the proposed FAOR outperforms the state-of-the-art ODI-SR models
with a much faster inference speed. Extensive experimental results and ablation
studies have demonstrated the effectiveness of our design.",http://arxiv.org/abs/2502.05902v1,Recommendation System,"image, odi, sr, spherical, latent"
Beyond Fine-Tuning: A Systematic Study of Sampling Techniques in Personalized Image Generation,"Personalized text-to-image generation aims to create images tailored to
user-defined concepts and textual descriptions. Balancing the fidelity of the
learned concept with its ability for generation in various contexts presents a
significant challenge. Existing methods often address this through diverse
fine-tuning parameterizations and improved sampling strategies that integrate
superclass trajectories during the diffusion process. While improved sampling
offers a cost-effective, training-free solution for enhancing fine-tuned
models, systematic analyses of these methods remain limited. Current approaches
typically tie sampling strategies with fixed fine-tuning configurations, making
it difficult to isolate their impact on generation outcomes. To address this
issue, we systematically analyze sampling strategies beyond fine-tuning,
exploring the impact of concept and superclass trajectories on the results.
Building on this analysis, we propose a decision framework evaluating text
alignment, computational constraints, and fidelity objectives to guide strategy
selection. It integrates with diverse architectures and training approaches,
systematically optimizing concept preservation, prompt adherence, and resource
efficiency. The source code can be found at
https://github.com/ControlGenAI/PersonGenSampler.",http://arxiv.org/abs/2502.05895v1,Recommendation System,"fine, sampling, generation, concept, tuning"
A Distributional Perspective on Word Learning in Neural Language Models,"Language models (LMs) are increasingly being studied as models of human
language learners. Due to the nascency of the field, it is not well-established
whether LMs exhibit similar learning dynamics to humans, and there are few
direct comparisons between learning trajectories in humans and models. Word
learning trajectories for children are relatively well-documented, and recent
work has tried to extend these investigations to language models. However,
there are no widely agreed-upon metrics for word learning in language models.
We take a distributional approach to this problem, defining lexical knowledge
in terms of properties of the learned distribution for a target word. We argue
that distributional signatures studied in prior work fail to capture key
distributional information. Thus, we propose an array of signatures that
improve on earlier approaches by capturing knowledge of both where the target
word can and cannot occur as well as gradient preferences about the word's
appropriateness. We obtain learning trajectories for a selection of small
language models we train from scratch, study the relationship between different
distributional signatures, compare how well they align with human word learning
trajectories and interpretable lexical features, and address basic
methodological questions about estimating these distributional signatures. Our
metrics largely capture complementary information, suggesting that it is
important not to rely on a single metric. However, across all metrics, language
models' learning trajectories fail to correlate with those of children.",http://arxiv.org/abs/2502.05892v1,Natural Language Processing,"models, learning, language, word, trajectories"
A Comprehensive Review of U-Net and Its Variants: Advances and Applications in Medical Image Segmentation,"Medical images often exhibit low and blurred contrast between lesions and
surrounding tissues, with considerable variation in lesion edges and shapes
even within the same disease, leading to significant challenges in
segmentation. Therefore, precise segmentation of lesions has become an
essential prerequisite for patient condition assessment and formulation of
treatment plans. Significant achievements have been made in research related to
the U-Net model in recent years. It improves segmentation performance and is
extensively applied in the semantic segmentation of medical images to offer
technical support for consistent quantitative lesion analysis methods. First,
this paper classifies medical image datasets on the basis of their imaging
modalities and then examines U-Net and its various improvement models from the
perspective of structural modifications. The research objectives, innovative
designs, and limitations of each approach are discussed in detail. Second, we
summarize the four central improvement mechanisms of the U-Net and U-Net
variant algorithms: the jump-connection mechanism, residual-connection
mechanism, 3D-UNet, and transformer mechanism. Finally, we examine the
relationships among the four core enhancement mechanisms and commonly utilized
medical datasets and propose potential avenues and strategies for future
advancements. This paper provides a systematic summary and reference for
researchers in related fields, and we look forward to designing more efficient
and stable medical image segmentation network models based on the U-Net
network.",http://arxiv.org/abs/2502.06895v1,Recommendation System,"medical, segmentation, u, net, mechanism"
MTPChat: A Multimodal Time-Aware Persona Dataset for Conversational Agents,"Understanding temporal dynamics is critical for conversational agents,
enabling effective content analysis and informed decision-making. However,
time-aware datasets, particularly for persona-grounded conversations, are still
limited, which narrows their scope and diminishes their complexity. To address
this gap, we introduce MTPChat, a multimodal, time-aware persona dialogue
dataset that integrates linguistic, visual, and temporal elements within
dialogue and persona memory. Leveraging MTPChat, we propose two time-sensitive
tasks: Temporal Next Response Prediction (TNRP) and Temporal Grounding Memory
Prediction (TGMP), both designed to assess a model's ability to understand
implicit temporal cues and dynamic interactions. Additionally, we present an
innovative framework featuring an adaptive temporal module to effectively
integrate multimodal streams and capture temporal dependencies. Experimental
results validate the challenges posed by MTPChat and demonstrate the
effectiveness of our framework in multimodal time-sensitive scenarios.",http://arxiv.org/abs/2502.05887v1,Recommendation System,"temporal, time, persona, mtpchat, multimodal"
NeuralPrefix: A Zero-shot Sensory Data Imputation Plugin,"Real-world sensing challenges such as sensor failures, communication issues,
and power constraints lead to data intermittency. An issue that is known to
undermine the traditional classification task that assumes a continuous data
stream. Previous works addressed this issue by designing bespoke solutions
(i.e. task-specific and/or modality-specific imputation). These approaches,
while effective for their intended purposes, had limitations in their
applicability across different tasks and sensor modalities. This raises an
important question: Can we build a task-agnostic imputation pipeline that is
transferable to new sensors without requiring additional training? In this
work, we formalise the concept of zero-shot imputation and propose a novel
approach that enables the adaptation of pre-trained models to handle data
intermittency. This framework, named NeuralPrefix, is a generative neural
component that precedes a task model during inference, filling in gaps caused
by data intermittency. NeuralPrefix is built as a continuous dynamical system,
where its internal state can be estimated at any point in time by solving an
Ordinary Differential Equation (ODE). This approach allows for a more versatile
and adaptable imputation method, overcoming the limitations of task-specific
and modality-specific solutions. We conduct a comprehensive evaluation of
NeuralPrefix on multiple sensory datasets, demonstrating its effectiveness
across various domains. When tested on intermittent data with a high 50%
missing data rate, NeuralPreifx accurately recovers all the missing samples,
achieving SSIM score between 0.93-0.96. Zero-shot evaluations show that
NeuralPrefix generalises well to unseen datasets, even when the measurements
come from a different modality.",http://arxiv.org/abs/2502.05883v1,Recommendation System,"data, task, specific, imputation, neuralprefix"
"AI-Driven HSI: Multimodality, Fusion, Challenges, and the Deep Learning Revolution","Hyperspectral imaging (HSI) captures spatial and spectral data, enabling
analysis of features invisible to conventional systems. The technology is vital
in fields such as weather monitoring, food quality control, counterfeit
detection, healthcare diagnostics, and extending into defense, agriculture, and
industrial automation at the same time. HSI has advanced with improvements in
spectral resolution, miniaturization, and computational methods. This study
provides an overview of the HSI, its applications, challenges in data fusion
and the role of deep learning models in processing HSI data. We discuss how
integration of multimodal HSI with AI, particularly with deep learning,
improves classification accuracy and operational efficiency. Deep learning
enhances HSI analysis in areas like feature extraction, change detection,
denoising unmixing, dimensionality reduction, landcover mapping, data
augmentation, spectral construction and super resolution. An emerging focus is
the fusion of hyperspectral cameras with large language models (LLMs), referred
as highbrain LLMs, enabling the development of advanced applications such as
low visibility crash detection and face antispoofing. We also highlight key
players in HSI industry, its compound annual growth rate and the growing
industrial significance. The purpose is to offer insight to both technical and
non-technical audience, covering HSI's images, trends, and future directions,
while providing valuable information on HSI datasets and software libraries.",http://arxiv.org/abs/2502.06894v1,Recommendation System,"hsi, data, spectral, detection, deep"
A New Hybrid Intelligent Approach for Multimodal Detection of Suspected Disinformation on TikTok,"In the context of the rapid dissemination of multimedia content, identifying
disinformation on social media platforms such as TikTok represents a
significant challenge. This study introduces a hybrid framework that combines
the computational power of deep learning with the interpretability of fuzzy
logic to detect suspected disinformation in TikTok videos. The methodology is
comprised of two core components: a multimodal feature analyser that extracts
and evaluates data from text, audio, and video; and a multimodal disinformation
detector based on fuzzy logic. These systems operate in conjunction to evaluate
the suspicion of spreading disinformation, drawing on human behavioural cues
such as body language, speech patterns, and text coherence. Two experiments
were conducted: one focusing on context-specific disinformation and the other
on the scalability of the model across broader topics. For each video
evaluated, high-quality, comprehensive, well-structured reports are generated,
providing a detailed view of the disinformation behaviours.",http://arxiv.org/abs/2502.06893v1,Recommendation System,"disinformation, context, tiktok, fuzzy, logic"
Enhancing Depression Detection with Chain-of-Thought Prompting: From Emotion to Reasoning Using Large Language Models,"Depression is one of the leading causes of disability worldwide, posing a
severe burden on individuals, healthcare systems, and society at large. Recent
advancements in Large Language Models (LLMs) have shown promise in addressing
mental health challenges, including the detection of depression through
text-based analysis. However, current LLM-based methods often struggle with
nuanced symptom identification and lack a transparent, step-by-step reasoning
process, making it difficult to accurately classify and explain mental health
conditions. To address these challenges, we propose a Chain-of-Thought
Prompting approach that enhances both the performance and interpretability of
LLM-based depression detection. Our method breaks down the detection process
into four stages: (1) sentiment analysis, (2) binary depression classification,
(3) identification of underlying causes, and (4) assessment of severity. By
guiding the model through these structured reasoning steps, we improve
interpretability and reduce the risk of overlooking subtle clinical indicators.
We validate our method on the E-DAIC dataset, where we test multiple
state-of-the-art large language models. Experimental results indicate that our
Chain-of-Thought Prompting technique yields superior performance in both
classification accuracy and the granularity of diagnostic insights, compared to
baseline approaches.",http://arxiv.org/abs/2502.05879v1,Recommendation System,"depression, large, detection, based, causes"
MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor Scene Generation,"Controllable 3D scene generation has extensive applications in virtual
reality and interior design, where the generated scenes should exhibit high
levels of realism and controllability in terms of geometry. Scene graphs
provide a suitable data representation that facilitates these applications.
However, current graph-based methods for scene generation are constrained to
text-based inputs and exhibit insufficient adaptability to flexible user
inputs, hindering the ability to precisely control object geometry. To address
this issue, we propose MMGDreamer, a dual-branch diffusion model for scene
generation that incorporates a novel Mixed-Modality Graph, visual enhancement
module, and relation predictor. The mixed-modality graph allows object nodes to
integrate textual and visual modalities, with optional relationships between
nodes. It enhances adaptability to flexible user inputs and enables meticulous
control over the geometry of objects in the generated scenes. The visual
enhancement module enriches the visual fidelity of text-only nodes by
constructing visual representations using text embeddings. Furthermore, our
relation predictor leverages node representations to infer absent relationships
between nodes, resulting in more coherent scene layouts. Extensive experimental
results demonstrate that MMGDreamer exhibits superior control of object
geometry, achieving state-of-the-art scene generation performance. Project
page: https://yangzhifeio.github.io/project/MMGDreamer.",http://arxiv.org/abs/2502.05874v1,Recommendation System,"scene, visual, generation, geometry, nodes"
HyLiFormer: Hyperbolic Linear Attention for Skeleton-based Human Action Recognition,"Transformers have demonstrated remarkable performance in skeleton-based human
action recognition, yet their quadratic computational complexity remains a
bottleneck for real-world applications. To mitigate this, linear attention
mechanisms have been explored but struggle to capture the hierarchical
structure of skeleton data. Meanwhile, the Poincar\'e model, as a typical
hyperbolic geometry, offers a powerful framework for modeling hierarchical
structures but lacks well-defined operations for existing mainstream linear
attention. In this paper, we propose HyLiFormer, a novel hyperbolic linear
attention Transformer tailored for skeleton-based action recognition. Our
approach incorporates a Hyperbolic Transformation with Curvatures (HTC) module
to map skeleton data into hyperbolic space and a Hyperbolic Linear Attention
(HLA) module for efficient long-range dependency modeling. Theoretical analysis
and extensive experiments on NTU RGB+D and NTU RGB+D 120 datasets demonstrate
that HyLiFormer significantly reduces computational complexity while preserving
model accuracy, making it a promising solution for efficiency-critical
applications.",http://arxiv.org/abs/2502.05869v1,Recommendation System,"hyperbolic, skeleton, linear, attention, based"
Norm Augmented Graph AutoEncoders for Link Prediction,"Link Prediction (LP) is a crucial problem in graph-structured data. Graph
Neural Networks (GNNs) have gained prominence in LP, with Graph AutoEncoders
(GAEs) being a notable representation. However, our empirical findings reveal
that GAEs' LP performance suffers heavily from the long-tailed node degree
distribution, i.e., low-degree nodes tend to exhibit inferior LP performance
compared to high-degree nodes. \emph{What causes this degree-related bias, and
how can it be mitigated?} In this study, we demonstrate that the norm of node
embeddings learned by GAEs exhibits variation among nodes with different
degrees, underscoring its central significance in influencing the final
performance of LP. Specifically, embeddings with larger norms tend to guide the
decoder towards predicting higher scores for positive links and lower scores
for negative links, thereby contributing to superior performance. This
observation motivates us to improve GAEs' LP performance on low-degree nodes by
increasing their embedding norms, which can be implemented simply yet
effectively by introducing additional self-loops into the training objective
for low-degree nodes. This norm augmentation strategy can be seamlessly
integrated into existing GAE methods with light computational cost. Extensive
experiments on various datasets and GAE methods show the superior performance
of norm-augmented GAEs.",http://arxiv.org/abs/2502.05868v1,Reinforcement Learning,"lp, performance, degree, gaes, nodes"
Certifying Language Model Robustness with Fuzzed Randomized Smoothing: An Efficient Defense Against Backdoor Attacks,"The widespread deployment of pre-trained language models (PLMs) has exposed
them to textual backdoor attacks, particularly those planted during the
pre-training stage. These attacks pose significant risks to high-reliability
applications, as they can stealthily affect multiple downstream tasks. While
certifying robustness against such threats is crucial, existing defenses
struggle with the high-dimensional, interdependent nature of textual data and
the lack of access to original poisoned pre-training data. To address these
challenges, we introduce \textbf{F}uzzed \textbf{R}andomized \textbf{S}moothing
(\textbf{FRS}), a novel approach for efficiently certifying language model
robustness against backdoor attacks. FRS integrates software robustness
certification techniques with biphased model parameter smoothing, employing
Monte Carlo tree search for proactive fuzzing to identify vulnerable textual
segments within the Damerau-Levenshtein space. This allows for targeted and
efficient text randomization, while eliminating the need for access to poisoned
training data during model smoothing. Our theoretical analysis demonstrates
that FRS achieves a broader certified robustness radius compared to existing
methods. Extensive experiments across various datasets, model configurations,
and attack strategies validate FRS's superiority in terms of defense
efficiency, accuracy, and robustness.",http://arxiv.org/abs/2502.06892v1,Recommendation System,"robustness, model, pre, textual, attacks"
"Learning Accurate, Efficient, and Interpretable MLPs on Multiplex Graphs via Node-wise Multi-View Ensemble Distillation","Multiplex graphs, with multiple edge types (graph views) among common nodes,
provide richer structural semantics and better modeling capabilities. Multiplex
Graph Neural Networks (MGNNs), typically comprising view-specific GNNs and a
multi-view integration layer, have achieved advanced performance in various
downstream tasks. However, their reliance on neighborhood aggregation poses
challenges for deployment in latency-sensitive applications. Motivated by
recent GNN-to-MLP knowledge distillation frameworks, we propose Multiplex
Graph-Free Neural Networks (MGFNN and MGFNN+) to combine MGNNs' superior
performance and MLPs' efficient inference via knowledge distillation. MGFNN
directly trains student MLPs with node features as input and soft labels from
teacher MGNNs as targets. MGFNN+ further employs a low-rank approximation-based
reparameterization to learn node-wise coefficients, enabling adaptive knowledge
ensemble from each view-specific GNN. This node-wise multi-view ensemble
distillation strategy allows student MLPs to learn more informative multiplex
semantic knowledge for different nodes. Experiments show that MGFNNs achieve
average accuracy improvements of about 10% over vanilla MLPs and perform
comparably or even better to teacher MGNNs (accurate); MGFNNs achieve a
35.40$\times$-89.14$\times$ speedup in inference over MGNNs (efficient); MGFNN+
adaptively assigns different coefficients for multi-view ensemble distillation
regarding different nodes (interpretable).",http://arxiv.org/abs/2502.05864v1,Recommendation System,"mgnns, view, multiplex, knowledge, distillation"
Uni-Retrieval: A Multi-Style Retrieval Framework for STEM's Education,"In AI-facilitated teaching, leveraging various query styles to interpret
abstract text descriptions is crucial for ensuring high-quality teaching.
However, current retrieval models primarily focus on natural text-image
retrieval, making them insufficiently tailored to educational scenarios due to
the ambiguities in the retrieval process. In this paper, we propose a diverse
expression retrieval task tailored to educational scenarios, supporting
retrieval based on multiple query styles and expressions. We introduce the STEM
Education Retrieval Dataset (SER), which contains over 24,000 query pairs of
different styles, and the Uni-Retrieval, an efficient and style-diversified
retrieval vision-language model based on prompt tuning. Uni-Retrieval extracts
query style features as prototypes and builds a continuously updated Prompt
Bank containing prompt tokens for diverse queries. This bank can updated during
test time to represent domain-specific knowledge for different subject
retrieval scenarios. Our framework demonstrates scalability and robustness by
dynamically retrieving prompt tokens based on prototype similarity, effectively
facilitating learning for unknown queries. Experimental results indicate that
Uni-Retrieval outperforms existing retrieval models in most retrieval tasks.
This advancement provides a scalable and precise solution for diverse
educational needs.",http://arxiv.org/abs/2502.05863v1,Recommendation System,"retrieval, query, prompt, styles, educational"
SphereFusion: Efficient Panorama Depth Estimation via Gated Fusion,"Due to the rapid development of panorama cameras, the task of estimating
panorama depth has attracted significant attention from the computer vision
community, especially in applications such as robot sensing and autonomous
driving. However, existing methods relying on different projection formats
often encounter challenges, either struggling with distortion and discontinuity
in the case of equirectangular, cubemap, and tangent projections, or
experiencing a loss of texture details with the spherical projection. To tackle
these concerns, we present SphereFusion, an end-to-end framework that combines
the strengths of various projection methods. Specifically, SphereFusion
initially employs 2D image convolution and mesh operations to extract two
distinct types of features from the panorama image in both equirectangular and
spherical projection domains. These features are then projected onto the
spherical domain, where a gate fusion module selects the most reliable features
for fusion. Finally, SphereFusion estimates panorama depth within the spherical
domain. Meanwhile, SphereFusion employs a cache strategy to improve the
efficiency of mesh operation. Extensive experiments on three public panorama
datasets demonstrate that SphereFusion achieves competitive results with other
state-of-the-art methods, while presenting the fastest inference speed at only
17 ms on a 512$\times$1024 panorama image.",http://arxiv.org/abs/2502.05859v1,Computer Vision,"panorama, spherefusion, projection, spherical, methods"
Acquisition through My Eyes and Steps: A Joint Predictive Agent Model in Egocentric Worlds,"This paper addresses the task of learning an agent model behaving like
humans, which can jointly perceive, predict, and act in egocentric worlds.
Previous methods usually train separate models for these three abilities,
leading to information silos among them, which prevents these abilities from
learning from each other and collaborating effectively. In this paper, we
propose a joint predictive agent model, named EgoAgent, that simultaneously
learns to represent the world, predict future states, and take reasonable
actions with a single transformer. EgoAgent unifies the representational spaces
of the three abilities by mapping them all into a sequence of continuous
tokens. Learnable query tokens are appended to obtain current states, future
states, and next actions. With joint supervision, our agent model establishes
the internal relationship among these three abilities and effectively mimics
the human inference and learning processes. Comprehensive evaluations of
EgoAgent covering image classification, egocentric future state prediction, and
3D human motion prediction tasks demonstrate the superiority of our method. The
code and trained model will be released for reproducibility.",http://arxiv.org/abs/2502.05857v1,Reinforcement Learning,"model, abilities, learning, agent, egoagent"
DexVLA: Vision-Language Model with Plug-In Diffusion Expert for General Robot Control,"Enabling robots to perform diverse tasks across varied environments is a
central challenge in robot learning. While vision-language-action (VLA) models
have shown promise for generalizable robot skills, realizing their full
potential requires addressing limitations in action representation and
efficient training. Current VLA models often focus on scaling the
vision-language model (VLM) component, while the action space representation
remains a critical bottleneck. This paper introduces DexVLA, a novel framework
designed to enhance the efficiency and generalization capabilities of VLAs for
complex, long-horizon tasks across diverse robot embodiments. DexVLA features a
novel diffusion-based action expert, scaled to one billion parameters, designed
for cross-embodiment learning. A novel embodiment curriculum learning strategy
facilitates efficient training: (1) pre-training the diffusion expert that is
separable from the VLA on cross-embodiment data, (2) aligning the VLA model to
specific embodiments, and (3) post-training for rapid adaptation to new tasks.
We conduct comprehensive experiments across multiple embodiments, including
single-arm, bimanual, and dexterous hand, demonstrating DexVLA's adaptability
to challenging tasks without task-specific adaptation, its ability to learn
dexterous skills on novel embodiments with limited data, and its capacity to
complete complex, long-horizon tasks using only direct language prompting, such
as laundry folding. In all settings, our method demonstrates superior
performance compared to state-of-the-art models like Octo, OpenVLA, and
Diffusion Policy.",http://arxiv.org/abs/2502.05855v1,Recommendation System,"tasks, action, vla, training, novel"
MetaML-Pro: Cross-Stage Design Flow Automation for Efficient Deep Learning Acceleration,"This paper presents a unified framework for codifying and automating
optimization strategies to efficiently deploy deep neural networks (DNNs) on
resource-constrained hardware, such as FPGAs, while maintaining high
performance, accuracy, and resource efficiency. Deploying DNNs on such
platforms involves addressing the significant challenge of balancing
performance, resource usage (e.g., DSPs and LUTs), and inference accuracy,
which often requires extensive manual effort and domain expertise. Our novel
approach addresses two key issues: cross-stage co-optimization and optimization
search. By seamlessly integrating programmatic DNN optimization techniques with
high-level synthesis (HLS)-based metaprogramming and leveraging advanced design
space exploration (DSE) strategies like Bayesian optimization, the framework
automates both top-down and bottom-up design flows, reducing the need for
manual intervention and domain expertise. The proposed framework introduces
customizable optimization, transformation, and control blocks to enhance DNN
accelerator performance and resource efficiency. Experimental results
demonstrate up to a 92\% DSP and 89\% LUT usage reduction for select networks,
while preserving accuracy, along with a 15.6-fold reduction in optimization
time compared to grid search. These results underscore the novelty and
potential of the proposed framework for automated, resource-efficient DNN
accelerator designs.",http://arxiv.org/abs/2502.05850v1,Recommendation System,"optimization, resource, framework, performance, accuracy"
ScaffoldGPT: A Scaffold-based Large Language Model for Drug Improvement,"Drug optimization has become increasingly crucial in light of fast-mutating
virus strains and drug-resistant cancer cells. Nevertheless, it remains
challenging as it necessitates retaining the beneficial properties of the
original drug while simultaneously enhancing desired attributes beyond its
scope. In this work, we aim to tackle this challenge by introducing
ScaffoldGPT, a novel Large Language Model (LLM) designed for drug optimization
based on molecular scaffolds. Our work comprises three key components: (1) A
three-stage drug optimization approach that integrates pretraining, finetuning,
and decoding optimization. (2) A uniquely designed two-phase incremental
training approach for pre-training the drug optimization LLM-based generator on
molecule scaffold with enhanced performance. (3) A token-level decoding
optimization strategy, TOP-N, that enabling controlled, reward-guided
generation using pretrained/finetuned LLMs. Finally, by conducting a
comprehensive evaluation on COVID and cancer benchmarks, we demonstrate that
SCAFFOLDGPT outperforms the competing baselines in drug optimization
benchmarks, while excelling in preserving the original functional scaffold and
enhancing desired properties.",http://arxiv.org/abs/2502.06891v1,Reinforcement Learning,"drug, optimization, cancer, properties, original"
Training-free Anomaly Event Detection via LLM-guided Symbolic Pattern Discovery,"Anomaly event detection plays a crucial role in various real-world
applications. However, current approaches predominantly rely on supervised
learning, which faces significant challenges: the requirement for extensive
labeled training data and lack of interpretability in decision-making
processes. To address these limitations, we present a training-free framework
that integrates open-set object detection with symbolic regression, powered by
Large Language Models (LLMs) for efficient symbolic pattern discovery. The LLMs
guide the symbolic reasoning process, establishing logical relationships
between detected entities. Through extensive experiments across multiple
domains, our framework demonstrates several key advantages: (1) achieving
superior detection accuracy through direct reasoning without any training
process; (2) providing highly interpretable logical expressions that are
readily comprehensible to humans; and (3) requiring minimal annotation effort -
approximately 1% of the data needed by traditional training-based methods.To
facilitate comprehensive evaluation and future research, we introduce two
datasets: a large-scale private dataset containing over 110,000 annotated
images covering various anomaly scenarios including construction site safety
violations, illegal fishing activities, and industrial hazards, along with a
public benchmark dataset of 5,000 samples with detailed anomaly event
annotations. Code is available at here.",http://arxiv.org/abs/2502.05843v1,Recommendation System,"training, anomaly, detection, symbolic, event"
LegalSeg: Unlocking the Structure of Indian Legal Judgments Through Rhetorical Role Classification,"In this paper, we address the task of semantic segmentation of legal
documents through rhetorical role classification, with a focus on Indian legal
judgments. We introduce LegalSeg, the largest annotated dataset for this task,
comprising over 7,000 documents and 1.4 million sentences, labeled with 7
rhetorical roles. To benchmark performance, we evaluate multiple
state-of-the-art models, including Hierarchical BiLSTM-CRF,
TransformerOverInLegalBERT (ToInLegalBERT), Graph Neural Networks (GNNs), and
Role-Aware Transformers, alongside an exploratory RhetoricLLaMA, an
instruction-tuned large language model. Our results demonstrate that models
incorporating broader context, structural relationships, and sequential
sentence information outperform those relying solely on sentence-level
features. Additionally, we conducted experiments using surrounding context and
predicted or actual labels of neighboring sentences to assess their impact on
classification accuracy. Despite these advancements, challenges persist in
distinguishing between closely related roles and addressing class imbalance.
Our work underscores the potential of advanced techniques for improving legal
document understanding and sets a strong foundation for future research in
legal NLP.",http://arxiv.org/abs/2502.05836v1,Natural Language Processing,"legal, task, documents, rhetorical, role"
Contrastive Representation Distillation via Multi-Scale Feature Decoupling,"Knowledge distillation is a technique aimed at enhancing the performance of a
smaller student network without increasing its parameter size by transferring
knowledge from a larger, pre-trained teacher network. Previous approaches have
predominantly focused on distilling global feature information while
overlooking the importance of disentangling the diverse types of information
embedded within different regions of the feature. In this work, we introduce
multi-scale decoupling in the feature transfer process for the first time,
where the decoupled local features are individually processed and integrated
with contrastive learning. Moreover, compared to previous contrastive
learning-based distillation methods, our approach not only reduces
computational costs but also enhances efficiency, enabling performance
improvements for the student network using only single-batch samples. Extensive
evaluations on CIFAR-100 and ImageNet demonstrate our method's superiority,
with some student networks distilled using our method even surpassing the
performance of their pre-trained teacher networks. These results underscore the
effectiveness of our approach in enabling student networks to thoroughly absorb
knowledge from teacher networks.",http://arxiv.org/abs/2502.05835v1,Recommendation System,"student, networks, knowledge, performance, network"
LLMs for Drug-Drug Interaction Prediction: A Comprehensive Comparison,"The increasing volume of drug combinations in modern therapeutic regimens
needs reliable methods for predicting drug-drug interactions (DDIs). While
Large Language Models (LLMs) have revolutionized various domains, their
potential in pharmaceutical research, particularly in DDI prediction, remains
largely unexplored. This study thoroughly investigates LLMs' capabilities in
predicting DDIs by uniquely processing molecular structures (SMILES), target
organisms, and gene interaction data as raw text input from the latest DrugBank
dataset. We evaluated 18 different LLMs, including proprietary models (GPT-4,
Claude, Gemini) and open-source variants (from 1.5B to 72B parameters), first
assessing their zero-shot capabilities in DDI prediction. We then fine-tuned
selected models (GPT-4, Phi-3.5 2.7B, Qwen-2.5 3B, Gemma-2 9B, and Deepseek R1
distilled Qwen 1.5B) to optimize their performance. Our comprehensive
evaluation framework included validation across 13 external DDI datasets,
comparing against traditional approaches such as l2-regularized logistic
regression. Fine-tuned LLMs demonstrated superior performance, with Phi-3.5
2.7B achieving a sensitivity of 0.978 in DDI prediction, with an accuracy of
0.919 on balanced datasets (50% positive, 50% negative cases). This result
represents an improvement over both zero-shot predictions and state-of-the-art
machine-learning methods used for DDI prediction. Our analysis reveals that
LLMs can effectively capture complex molecular interaction patterns and cases
where drug pairs target common genes, making them valuable tools for practical
applications in pharmaceutical research and clinical settings.",http://arxiv.org/abs/2502.06890v1,Natural Language Processing,"llms, ddi, drug, prediction, models"
Compressing Model with Few Class-Imbalance Samples: An Out-of-Distribution Expedition,"In recent years, as a compromise between privacy and performance, few-sample
model compression has been widely adopted to deal with limited data resulting
from privacy and security concerns. However, when the number of available
samples is extremely limited, class imbalance becomes a common and tricky
problem. Achieving an equal number of samples across all classes is often
costly and impractical in real-world applications, and previous studies on
few-sample model compression have mostly ignored this significant issue. Our
experiments comprehensively demonstrate that class imbalance negatively affects
the overall performance of few-sample model compression methods. To address
this problem, we propose a novel and adaptive framework named OOD-Enhanced
Few-Sample Model Compression (OE-FSMC). This framework integrates easily
accessible out-of-distribution (OOD) data into both the compression and
fine-tuning processes, effectively rebalancing the training distribution. We
also incorporate a joint distillation loss and a regularization term to reduce
the risk of the model overfitting to the OOD data. Extensive experiments on
multiple benchmark datasets show that our framework can be seamlessly
incorporated into existing few-sample model compression methods, effectively
mitigating the accuracy degradation caused by class imbalance.",http://arxiv.org/abs/2502.05832v1,Recommendation System,"model, compression, sample, data, class"
Secure Visual Data Processing via Federated Learning,"As the demand for privacy in visual data management grows, safeguarding
sensitive information has become a critical challenge. This paper addresses the
need for privacy-preserving solutions in large-scale visual data processing by
leveraging federated learning. Although there have been developments in this
field, previous research has mainly focused on integrating object detection
with either anonymization or federated learning. However, these pairs often
fail to address complex privacy concerns. On the one hand, object detection
with anonymization alone can be vulnerable to reverse techniques. On the other
hand, federated learning may not provide sufficient privacy guarantees.
Therefore, we propose a new approach that combines object detection, federated
learning and anonymization. Combining these three components aims to offer a
robust privacy protection strategy by addressing different vulnerabilities in
visual data. Our solution is evaluated against traditional centralized models,
showing that while there is a slight trade-off in accuracy, the privacy
benefits are substantial, making it well-suited for privacy sensitive
applications.",http://arxiv.org/abs/2502.06889v1,Recommendation System,"privacy, federated, learning, visual, data"
HyGEN: Regularizing Negative Hyperedge Generation for Accurate Hyperedge Prediction,"Hyperedge prediction is a fundamental task to predict future high-order
relations based on the observed network structure. Existing hyperedge
prediction methods, however, suffer from the data sparsity problem. To
alleviate this problem, negative sampling methods can be used, which leverage
non-existing hyperedges as contrastive information for model training. However,
the following important challenges have been rarely studied: (C1) lack of
guidance for generating negatives and (C2) possibility of producing false
negatives. To address them, we propose a novel hyperedge prediction method,
HyGEN, that employs (1) a negative hyperedge generator that employs positive
hyperedges as a guidance to generate more realistic ones and (2) a
regularization term that prevents the generated hyperedges from being false
negatives. Extensive experiments on six real-world hypergraphs reveal that
HyGEN consistently outperforms four state-of-the-art hyperedge prediction
methods.",http://arxiv.org/abs/2502.05827v1,Recommendation System,"hyperedge, prediction, methods, hyperedges, negatives"
MindCraft: Revolutionizing Education through AI-Powered Personalized Learning and Mentorship for Rural India,"MindCraft is a modern platform designed to revolutionize education in rural
India by leveraging Artificial Intelligence (AI) to create personalized
learning experiences, provide mentorship, and foster resource-sharing. In a
country where access to quality education is deeply influenced by geography and
socio economic status, rural students often face significant barriers in their
educational journeys. MindCraft aims to bridge this gap by utilizing AI to
create tailored learning paths, connect students with mentors, and enable a
collaborative network of educational resources that transcends both physical
and digital divides. This paper explores the challenges faced by rural
students, the transformative potential of AI, and how MindCraft offers a
scalable, sustainable solution for equitable education system. By focusing on
inclusivity, personalized learning, and mentorship, MindCraft seeks to empower
rural students, equipping them with the skills, knowledge, and opportunities
needed to thrive in an increasingly digital world. Ultimately, MindCraft
envisions a future in which technology not only bridges educational gaps but
also becomes the driving force for a more inclusive and empowered society.",http://arxiv.org/abs/2502.05826v1,Recommendation System,"mindcraft, rural, students, education, ai"
Delta - Contrastive Decoding Mitigates Text Hallucinations in Large Language Models,"Large language models (LLMs) demonstrate strong capabilities in natural
language processing but remain prone to hallucinations, generating factually
incorrect or fabricated content. This issue undermines their reliability,
particularly in high-stakes domains such as healthcare and legal advisory. To
address this challenge, we propose Delta, an inference-time method that reduces
hallucinations without requiring model retraining or additional data. Delta
works by randomly masking parts of the input prompt and contrasting the output
distributions for the original and masked inputs, effectively suppressing
hallucinations through inference-only computations. We evaluate Delta on
context-rich question-answering benchmarks, achieving absolute improvements of
approximately 3 and 6 percentage points on SQuAD v1.1 and v2, respectively, and
7 and 2 percentage points on TriviaQA and Natural Questions under-sampling
decoding. Delta also improves the no-answer exact match score on SQuAD v2 by
over ten percentage points, demonstrating its effectiveness in mitigating
hallucinations arising from contextual ambiguity. These results highlight Delta
as a computationally efficient and scalable approach for improving the
reliability of LLMs in real-world applications.",http://arxiv.org/abs/2502.05825v1,Natural Language Processing,"delta, hallucinations, percentage, points, language"
Klotski: Efficient Mixture-of-Expert Inference via Expert-Aware Multi-Batch Pipeline,"Mixture of Experts (MoE), with its distinctive sparse structure, enables the
scaling of language models up to trillions of parameters without significantly
increasing computational costs. However, the substantial parameter size
presents a challenge for inference, as the expansion in GPU memory cannot keep
pace with the growth in parameters. Although offloading techniques utilise
memory from the CPU and disk and parallelise the I/O and computation for
efficiency, the computation for each expert in MoE models is often less than
the I/O, resulting in numerous bubbles in the pipeline.
  Therefore, we propose Klotski, an efficient MoE inference engine that
significantly reduces pipeline bubbles through a novel expert-aware multi-batch
pipeline paradigm. The proposed paradigm uses batch processing to extend the
computation time of the current layer to overlap with the loading time of the
next layer. Although this idea has been effectively applied to dense models,
more batches may activate more experts in the MoE, leading to longer loading
times and more bubbles. Thus, unlike traditional approaches, we balance
computation and I/O time and minimise bubbles by orchestrating their inference
orders based on their heterogeneous computation and I/O requirements and
activation patterns under different batch numbers. Moreover, to adapt to
different hardware environments and models, we design a constraint-sensitive
I/O-compute planner and a correlation-aware expert prefetcher for a schedule
that minimises pipeline bubbles. Experimental results demonstrate that Klotski
achieves a superior throughput-latency trade-off compared to state-of-the-art
techniques, with throughput improvements of up to 85.12x.",http://arxiv.org/abs/2502.06888v1,Recommendation System,"o, computation, bubbles, moe, models"
Image-Based Alzheimer's Disease Detection Using Pretrained Convolutional Neural Network Models,"Alzheimer's disease is an untreatable, progressive brain disorder that slowly
robs people of their memory, thinking abilities, and ultimately their capacity
to complete even the most basic tasks. Among older adults, it is the most
frequent cause of dementia. Although there is presently no treatment for
Alzheimer's disease, scientific trials are ongoing to discover drugs to combat
the condition. Treatments to slow the signs of dementia are also available.
Many researchers throughout the world became interested in developing
computer-aided diagnosis systems to aid in the early identification of this
deadly disease and assure an accurate diagnosis. In particular, image based
approaches have been coupled with machine learning techniques to address the
challenges of Alzheimer's disease detection. This study proposes a computer
aided diagnosis system to detect Alzheimer's disease from biomarkers captured
using neuroimaging techniques. The proposed approach relies on deep learning
techniques to extract the relevant visual features from the image collection to
accurately predict the Alzheimer's class value. In the experiments, standard
datasets and pre-trained deep learning models were investigated. Moreover,
standard performance measures were used to assess the models' performances. The
obtained results proved that VGG16-based models outperform the state of the art
performance.",http://arxiv.org/abs/2502.05815v1,Recommendation System,"alzheimer, disease, diagnosis, learning, techniques"
Devil is in the Details: Density Guidance for Detail-Aware Generation with Flow Models,"Diffusion models have emerged as a powerful class of generative models,
capable of producing high-quality images by mapping noise to a data
distribution. However, recent findings suggest that image likelihood does not
align with perceptual quality: high-likelihood samples tend to be smooth, while
lower-likelihood ones are more detailed. Controlling sample density is thus
crucial for balancing realism and detail. In this paper, we analyze an existing
technique, Prior Guidance, which scales the latent code to influence image
detail. We introduce score alignment, a condition that explains why this method
works and show that it can be tractably checked for any continuous normalizing
flow model. We then propose Density Guidance, a principled modification of the
generative ODE that enables exact log-density control during sampling. Finally,
we extend Density Guidance to stochastic sampling, ensuring precise log-density
control while allowing controlled variation in structure or fine details. Our
experiments demonstrate that these techniques provide fine-grained control over
image detail without compromising sample quality.",http://arxiv.org/abs/2502.05807v1,Recommendation System,"density, quality, image, likelihood, detail"
Divide-and-Conquer: Tree-structured Strategy with Answer Distribution Estimator for Goal-Oriented Visual Dialogue,"Goal-oriented visual dialogue involves multi-round interaction between
artificial agents, which has been of remarkable attention due to its wide
applications. Given a visual scene, this task occurs when a Questioner asks an
action-oriented question and an Answerer responds with the intent of letting
the Questioner know the correct action to take. The quality of questions
affects the accuracy and efficiency of the target search progress. However,
existing methods lack a clear strategy to guide the generation of questions,
resulting in the randomness in the search process and inconvergent results. We
propose a Tree-Structured Strategy with Answer Distribution Estimator (TSADE)
which guides the question generation by excluding half of the current candidate
objects in each round. The above process is implemented by maximizing a binary
reward inspired by the ``divide-and-conquer'' paradigm. We further design a
candidate-minimization reward which encourages the model to narrow down the
scope of candidate objects toward the end of the dialogue. We experimentally
demonstrate that our method can enable the agents to achieve high task-oriented
accuracy with fewer repeating questions and rounds compared to traditional
ergodic question generation approaches. Qualitative results further show that
TSADE facilitates agents to generate higher-quality questions.",http://arxiv.org/abs/2502.05806v1,Recommendation System,"questions, oriented, agents, question, generation"
MicroViT: A Vision Transformer with Low Complexity Self Attention for Edge Device,"The Vision Transformer (ViT) has demonstrated state-of-the-art performance in
various computer vision tasks, but its high computational demands make it
impractical for edge devices with limited resources. This paper presents
MicroViT, a lightweight Vision Transformer architecture optimized for edge
devices by significantly reducing computational complexity while maintaining
high accuracy. The core of MicroViT is the Efficient Single Head Attention
(ESHA) mechanism, which utilizes group convolution to reduce feature redundancy
and processes only a fraction of the channels, thus lowering the burden of the
self-attention mechanism. MicroViT is designed using a multi-stage MetaFormer
architecture, stacking multiple MicroViT encoders to enhance efficiency and
performance. Comprehensive experiments on the ImageNet-1K and COCO datasets
demonstrate that MicroViT achieves competitive accuracy while significantly
improving 3.6 faster inference speed and reducing energy consumption with 40%
higher efficiency than the MobileViT series, making it suitable for deployment
in resource-constrained environments such as mobile and edge devices.",http://arxiv.org/abs/2502.05800v1,Computer Vision,"microvit, vision, edge, devices, transformer"
Decoding Complexity: Intelligent Pattern Exploration with CHPDA (Context Aware Hybrid Pattern Detection Algorithm),"Detecting sensitive data such as Personally Identifiable Information (PII)
and Protected Health Information (PHI) is critical for data security platforms.
This study evaluates regex-based pattern matching algorithms and exact-match
search techniques to optimize detection speed, accuracy, and scalability. Our
benchmarking results indicate that Google RE2 provides the best balance of
speed (10-15 ms/MB), memory efficiency (8-16 MB), and accuracy (99.5%) among
regex engines, outperforming PCRE while maintaining broader hardware
compatibility than Hyperscan. For exact matching, Aho-Corasick demonstrated
superior performance (8 ms/MB) and scalability for large datasets. Performance
analysis revealed that regex processing time scales linearly with dataset size
and pattern complexity. A hybrid AI + Regex approach achieved the highest F1
score (91. 6%) by improving recall and minimizing false positives. Device
benchmarking confirmed that our solution maintains efficient CPU and memory
usage on both high-performance and mid-range systems. Despite its
effectiveness, challenges remain, such as limited multilingual support and the
need for regular pattern updates. Future work should focus on expanding
language coverage, integrating data security and privacy management (DSPM) with
data loss prevention (DLP) tools, and enhancing regulatory compliance for
broader global adoption.",http://arxiv.org/abs/2502.07815v1,Recommendation System,"data, regex, pattern, mb, performance"
The Curse of Depth in Large Language Models,"In this paper, we introduce the Curse of Depth, a concept that highlights,
explains, and addresses the recent observation in modern Large Language
Models(LLMs) where nearly half of the layers are less effective than expected.
We first confirm the wide existence of this phenomenon across the most popular
families of LLMs such as Llama, Mistral, DeepSeek, and Qwen. Our analysis,
theoretically and empirically, identifies that the underlying reason for the
ineffectiveness of deep layers in LLMs is the widespread usage of Pre-Layer
Normalization (Pre-LN). While Pre-LN stabilizes the training of Transformer
LLMs, its output variance exponentially grows with the model depth, which
undesirably causes the derivative of the deep Transformer blocks to be an
identity matrix, and therefore barely contributes to the training. To resolve
this training pitfall, we propose LayerNorm Scaling, which scales the variance
of output of the layer normalization inversely by the square root of its depth.
This simple modification mitigates the output variance explosion of deeper
Transformer layers, improving their contribution. Our experimental results,
spanning model sizes from 130M to 1B, demonstrate that LayerNorm Scaling
significantly enhances LLM pre-training performance compared to Pre-LN.
Moreover, this improvement seamlessly carries over to supervised fine-tuning.
All these gains can be attributed to the fact that LayerNorm Scaling enables
deeper layers to contribute more effectively during training.",http://arxiv.org/abs/2502.05795v1,Recommendation System,"pre, training, layers, depth, llms"
Gradient Based Method for the Fusion of Lattice Quantizers,"In practical applications, lattice quantizers leverage discrete lattice
points to approximate arbitrary points in the lattice. An effective lattice
quantizer significantly enhances both the accuracy and efficiency of these
approximations. In the context of high-dimensional lattice quantization,
previous work proposed utilizing low-dimensional optimal lattice quantizers and
addressed the challenge of determining the optimal length ratio in orthogonal
splicing. Notably, it was demonstrated that fixed length ratios and
orthogonality yield suboptimal results when combining low-dimensional lattices.
Building on this foundation, another approach employed gradient descent to
identify optimal lattices, which inspired us to explore the use of neural
networks to discover matrices that outperform those obtained from orthogonal
splicing methods. We propose two novel approaches to tackle this problem: the
Household Algorithm and the Matrix Exp Algorithm. Our results indicate that
both the Household Algorithm and the Matrix Exp Algorithm achieve improvements
in lattice quantizers across dimensions 13, 15, 17 to 19, 21, and 22. Moreover,
the Matrix Exp Algorithm demonstrates superior efficacy in high-dimensional
settings.",http://arxiv.org/abs/2502.06887v1,Reinforcement Learning,"lattice, algorithm, dimensional, quantizers, optimal"
I3S: Importance Sampling Subspace Selection for Low-Rank Optimization in LLM Pretraining,"Low-rank optimization has emerged as a promising approach to enabling
memory-efficient training of large language models (LLMs). Existing low-rank
optimization methods typically project gradients onto a low-rank subspace,
reducing the memory cost of storing optimizer states. A key challenge in these
methods is identifying suitable subspaces to ensure an effective optimization
trajectory. Most existing approaches select the dominant subspace to preserve
gradient information, as this intuitively provides the best approximation.
However, we find that in practice, the dominant subspace stops changing during
pretraining, thereby constraining weight updates to similar subspaces.
  In this paper, we propose importance sampling subspace selection (I3S) for
low-rank optimization, which theoretically offers a comparable convergence rate
to the dominant subspace approach. Empirically, we demonstrate that I3S
significantly outperforms previous methods in LLM pretraining tasks.",http://arxiv.org/abs/2502.05790v1,Recommendation System,"subspace, low, rank, optimization, methods"
EPBC-YOLOv8: An efficient and accurate improved YOLOv8 underwater detector based on an attention mechanism,"In this study, we enhance underwater target detection by integrating channel
and spatial attention into YOLOv8's backbone, applying Pointwise Convolution in
FasterNeXt for the FasterPW model, and leveraging Weighted Concat in a
BiFPN-inspired WFPN structure for improved cross-scale connections and
robustness. Utilizing CARAFE for refined feature reassembly, our framework
addresses underwater image degradation, achieving mAP at 0.5 scores of 76.7
percent and 79.0 percent on URPC2019 and URPC2020 datasets, respectively. These
scores are 2.3 percent and 0.7 percent higher than the original YOLOv8,
showcasing enhanced precision in detecting marine organisms.",http://arxiv.org/abs/2502.05788v1,Computer Vision,"percent, underwater, scores, study, enhance"
Propagation of Chaos for Mean-Field Langevin Dynamics and its Application to Model Ensemble,"Mean-field Langevin dynamics (MFLD) is an optimization method derived by
taking the mean-field limit of noisy gradient descent for two-layer neural
networks in the mean-field regime. Recently, the propagation of chaos (PoC) for
MFLD has gained attention as it provides a quantitative characterization of the
optimization complexity in terms of the number of particles and iterations. A
remarkable progress by Chen et al. (2022) showed that the approximation error
due to finite particles remains uniform in time and diminishes as the number of
particles increases. In this paper, by refining the defective log-Sobolev
inequality -- a key result from that earlier work -- under the neural network
training setting, we establish an improved PoC result for MFLD, which removes
the exponential dependence on the regularization coefficient from the particle
approximation term of the optimization complexity. As an application, we
propose a PoC-based model ensemble strategy with theoretical guarantees.",http://arxiv.org/abs/2502.05784v1,Recommendation System,"mean, field, mfld, optimization, poc"
WatchGuardian: Enabling User-Defined Personalized Just-in-Time Intervention on Smartwatch,"While just-in-time interventions (JITIs) have effectively targeted common
health behaviors, individuals often have unique needs to intervene in personal
undesirable actions that can negatively affect physical, mental, and social
well-being. We present WatchGuardian, a smartwatch-based JITI system that
empowers users to define custom interventions for these personal actions with a
small number of samples. For the model to detect new actions based on limited
new data samples, we developed a few-shot learning pipeline that finetuned a
pre-trained inertial measurement unit (IMU) model on public hand-gesture
datasets. We then designed a data augmentation and synthesis process to train
additional classification layers for customization. Our offline evaluation with
26 participants showed that with three, five, and ten examples, our approach
achieved an average accuracy of 76.8%, 84.7%, and 87.7%, and an F1 score of
74.8%, 84.2%, and 87.2% We then conducted a four-hour intervention study to
compare WatchGuardian against a rule-based intervention. Our results
demonstrated that our system led to a significant reduction by 64.0 +- 22.6% in
undesirable actions, substantially outperforming the baseline by 29.0%. Our
findings underscore the effectiveness of a customizable, AI-driven JITI system
for individuals in need of behavioral intervention in personal undesirable
actions. We envision that our work can inspire broader applications of
user-defined personalized intervention with advanced AI solutions.",http://arxiv.org/abs/2502.05783v1,Recommendation System,"actions, intervention, personal, undesirable, based"
GOLD: Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation,"Despite graph neural networks' (GNNs) great success in modelling
graph-structured data, out-of-distribution (OOD) test instances still pose a
great challenge for current GNNs. One of the most effective techniques to
detect OOD nodes is to expose the detector model with an additional OOD
node-set, yet the extra OOD instances are often difficult to obtain in
practice. Recent methods for image data address this problem using OOD data
synthesis, typically relying on pre-trained generative models like Stable
Diffusion. However, these approaches require vast amounts of additional data,
as well as one-for-all pre-trained generative models, which are not available
for graph data. Therefore, we propose the GOLD framework for graph OOD
detection, an implicit adversarial learning pipeline with synthetic OOD
exposure without pre-trained models. The implicit adversarial training process
employs a novel alternating optimisation framework by training: (1) a latent
generative model to regularly imitate the in-distribution (ID) embeddings from
an evolving GNN, and (2) a GNN encoder and an OOD detector to accurately
classify ID data while increasing the energy divergence between the ID
embeddings and the generative model's synthetic embeddings. This novel approach
implicitly transforms the synthetic embeddings into pseudo-OOD instances
relative to the ID data, effectively simulating exposure to OOD scenarios
without auxiliary data. Extensive OOD detection experiments are conducted on
five benchmark graph datasets, verifying the superior performance of GOLD
without using real OOD data compared with the state-of-the-art OOD exposure and
non-exposure baselines.",http://arxiv.org/abs/2502.05780v1,Reinforcement Learning,"ood, data, graph, generative, exposure"
A 3D Multimodal Feature for Infrastructure Anomaly Detection,"Ageing structures require periodic inspections to identify structural
defects. Previous work has used geometric distortions to locate cracks in
synthetic masonry bridge point clouds but has struggled to detect small cracks.
To address this limitation, this study proposes a novel 3D multimodal feature,
3DMulti-FPFHI, that combines a customized Fast Point Feature Histogram (FPFH)
with an intensity feature. This feature is integrated into the PatchCore
anomaly detection algorithm and evaluated through statistical and parametric
analyses. The method is further evaluated using point clouds of a real masonry
arch bridge and a full-scale experimental model of a concrete tunnel. Results
show that the 3D intensity feature enhances inspection quality by improving
crack detection; it also enables the identification of water ingress which
introduces intensity anomalies. The 3DMulti-FPFHI outperforms FPFH and a
state-of-the-art multimodal anomaly detection method. The potential of the
method to address diverse infrastructure anomaly detection scenarios is
highlighted by the minimal requirements for data compared to learning-based
methods. The code and related point cloud dataset are available at
https://github.com/Jingyixiong/3D-Multi-FPFHI.",http://arxiv.org/abs/2502.05779v1,Recommendation System,"feature, point, detection, intensity, anomaly"
Predictive Crash Analytics for Traffic Safety using Deep Learning,"Traditional automated crash analysis systems heavily rely on static
statistical models and historical data, requiring significant manual
interpretation and lacking real-time predictive capabilities. This research
presents an innovative approach to traffic safety analysis through the
integration of ensemble learning methods and multi-modal data fusion for
real-time crash risk assessment and prediction. Our primary contribution lies
in developing a hierarchical severity classification system that combines
spatial-temporal crash patterns with environmental conditions, achieving
significant improvements over traditional statistical approaches. The system
demonstrates a Mean Average Precision (mAP) of 0.893, representing a 15%
improvement over current state-of-the-art methods (baseline mAP: 0.776). We
introduce a novel feature engineering technique that integrates crash location
data with incident reports and weather conditions, achieving 92.4% accuracy in
risk prediction and 89.7% precision in hotspot identification. Through
extensive validation using 500,000 initial crash records filtered to 59,496
high-quality samples, our solution shows marked improvements in both prediction
accuracy and computational efficiency. Key innovations include a robust data
cleaning pipeline, adaptive feature generation, and a scalable real-time
prediction system capable of handling peak loads of 1,000 concurrent requests
while maintaining sub-100ms response times.",http://arxiv.org/abs/2502.05777v1,Reinforcement Learning,"crash, data, prediction, real, time"
Dynamic Pricing in the Linear Valuation Model using Shape Constraints,"We propose a shape-constrained approach to dynamic pricing for censored data
in the linear valuation model that eliminates the need for tuning parameters
commonly required in existing methods. Previous works have addressed the
challenge of unknown market noise distribution F using strategies ranging from
kernel methods to reinforcement learning algorithms, such as bandit techniques
and upper confidence bounds (UCB), under the Lipschitz (and stronger)
assumption(s) on $F_0$. In contrast, our method relies on isotonic regression
under the weaker assumption that $F_0$ is $\alpha$-Holder continuous for some
$\alpha \in (0,1]$. We obtain an upper bound on the asymptotic expected regret
that matches existing bounds in the literature for $\alpha = 1$ (the Lipschitz
case). Simulations and experiments with real-world data obtained by Welltower
Inc (a major healthcare Real Estate Investment Trust) consistently demonstrate
that our method attains better empirical regret in comparison to several
existing methods in the literature while offering the advantage of being
completely tuning-parameter free.",http://arxiv.org/abs/2502.05776v1,Reinforcement Learning,"existing, methods, data, tuning, upper"
PIPA: Preference Alignment as Prior-Informed Statistical Estimation,"Offline preference alignment for language models such as Direct Preference
Optimization (DPO) is favored for its effectiveness and simplicity, eliminating
the need for costly reinforcement learning. Various offline algorithms have
been developed for different data settings, yet they lack a unified
understanding.
  In this study, we introduce Pior-Informed Preference Alignment (PIPA), a
unified, RL-free probabilistic framework that formulates language model
preference alignment as a Maximum Likelihood Estimation (MLE) problem with
prior constraints. This method effectively accommodates both paired and
unpaired data, as well as answer and step-level annotations. We illustrate that
DPO and KTO are special cases with different prior constraints within our
framework. By integrating different types of prior information, we developed
two variations of PIPA: PIPA-M and PIPA-N. Both algorithms demonstrate a
$3\sim10\%$ performance enhancement on the GSM8K and MATH benchmarks across all
configurations, achieving these gains without additional training or
computational costs compared to existing algorithms.",http://arxiv.org/abs/2502.05773v1,Recommendation System,"preference, pipa, alignment, algorithms, different"
Effective Black-Box Multi-Faceted Attacks Breach Vision Large Language Model Guardrails,"Vision Large Language Models (VLLMs) integrate visual data processing,
expanding their real-world applications, but also increasing the risk of
generating unsafe responses. In response, leading companies have implemented
Multi-Layered safety defenses, including alignment training, safety system
prompts, and content moderation. However, their effectiveness against
sophisticated adversarial attacks remains largely unexplored. In this paper, we
propose MultiFaceted Attack, a novel attack framework designed to
systematically bypass Multi-Layered Defenses in VLLMs. It comprises three
complementary attack facets: Visual Attack that exploits the multimodal nature
of VLLMs to inject toxic system prompts through images; Alignment Breaking
Attack that manipulates the model's alignment mechanism to prioritize the
generation of contrasting responses; and Adversarial Signature that deceives
content moderators by strategically placing misleading information at the end
of the response. Extensive evaluations on eight commercial VLLMs in a black-box
setting demonstrate that MultiFaceted Attack achieves a 61.56% attack success
rate, surpassing state-of-the-art methods by at least 42.18%.",http://arxiv.org/abs/2502.05772v1,Recommendation System,"attack, vllms, alignment, visual, responses"
"Digital Twin Buildings: 3D Modeling, GIS Integration, and Visual Descriptions Using Gaussian Splatting, ChatGPT/Deepseek, and Google Maps Platform","Urban digital twins are virtual replicas of cities that use multi-source data
and data analytics to optimize urban planning, infrastructure management, and
decision-making. Towards this, we propose a framework focused on the
single-building scale. By connecting to cloud mapping platforms such as Google
Map Platforms APIs, by leveraging state-of-the-art multi-agent Large Language
Models data analysis using ChatGPT(4o) and Deepseek-V3/R1, and by using our
Gaussian Splatting-based mesh extraction pipeline, our Digital Twin Buildings
framework can retrieve a building's 3D model, visual descriptions, and achieve
cloud-based mapping integration with large language model-based data analytics
using a building's address, postal code, or geographic coordinates.",http://arxiv.org/abs/2502.05769v2,Recommendation System,"data, building, based, urban, digital"
Privacy-Preserving Dataset Combination,"Access to diverse, high-quality datasets is crucial for machine learning
model performance, yet data sharing remains limited by privacy concerns and
competitive interests, particularly in regulated domains like healthcare. This
dynamic especially disadvantages smaller organizations that lack resources to
purchase data or negotiate favorable sharing agreements. We present SecureKL, a
privacy-preserving framework that enables organizations to identify beneficial
data partnerships without exposing sensitive information. Building on recent
advances in dataset combination methods, we develop a secure multiparty
computation protocol that maintains strong privacy guarantees while achieving
>90\% correlation with plaintext evaluations. In experiments with real-world
hospital data, SecureKL successfully identifies beneficial data partnerships
that improve model performance for intensive care unit mortality prediction
while preserving data privacy. Our framework provides a practical solution for
organizations seeking to leverage collective data resources while maintaining
privacy and competitive advantages. These results demonstrate the potential for
privacy-preserving data collaboration to advance machine learning applications
in high-stakes domains while promoting more equitable access to data resources.",http://arxiv.org/abs/2502.05765v1,Recommendation System,"data, privacy, organizations, resources, preserving"
3CAD: A Large-Scale Real-World 3C Product Dataset for Unsupervised Anomaly,"Industrial anomaly detection achieves progress thanks to datasets such as
MVTec-AD and VisA. However, they suf- fer from limitations in terms of the
number of defect sam- ples, types of defects, and availability of real-world
scenes. These constraints inhibit researchers from further exploring the
performance of industrial detection with higher accuracy. To this end, we
propose a new large-scale anomaly detection dataset called 3CAD, which is
derived from real 3C produc- tion lines. Specifically, the proposed 3CAD
includes eight different types of manufactured parts, totaling 27,039 high-
resolution images labeled with pixel-level anomalies. The key features of 3CAD
are that it covers anomalous regions of different sizes, multiple anomaly
types, and the possibility of multiple anomalous regions and multiple anomaly
types per anomaly image. This is the largest and first anomaly de- tection
dataset dedicated to 3C product quality control for community exploration and
development. Meanwhile, we in- troduce a simple yet effective framework for
unsupervised anomaly detection: a Coarse-to-Fine detection paradigm with
Recovery Guidance (CFRG). To detect small defect anoma- lies, the proposed CFRG
utilizes a coarse-to-fine detection paradigm. Specifically, we utilize a
heterogeneous distilla- tion model for coarse localization and then fine
localiza- tion through a segmentation model. In addition, to better capture
normal patterns, we introduce recovery features as guidance. Finally, we report
the results of our CFRG frame- work and popular anomaly detection methods on
the 3CAD dataset, demonstrating strong competitiveness and providing a highly
challenging benchmark to promote the development of the anomaly detection
field. Data and code are available: https://github.com/EnquanYang2022/3CAD.",http://arxiv.org/abs/2502.05761v1,Recommendation System,"anomaly, detection, types, dataset, tion"
Exploring Visual Embedding Spaces Induced by Vision Transformers for Online Auto Parts Marketplaces,"This study examines the capabilities of the Vision Transformer (ViT) model in
generating visual embeddings for images of auto parts sourced from online
marketplaces, such as Craigslist and OfferUp. By focusing exclusively on
single-modality data, the analysis evaluates ViT's potential for detecting
patterns indicative of illicit activities. The workflow involves extracting
high-dimensional embeddings from images, applying dimensionality reduction
techniques like Uniform Manifold Approximation and Projection (UMAP) to
visualize the embedding space, and using K-Means clustering to categorize
similar items. Representative posts nearest to each cluster centroid provide
insights into the composition and characteristics of the clusters. While the
results highlight the strengths of ViT in isolating visual patterns, challenges
such as overlapping clusters and outliers underscore the limitations of
single-modal approaches in this domain. This work contributes to understanding
the role of Vision Transformers in analyzing online marketplaces and offers a
foundation for future advancements in detecting fraudulent or illegal
activities.",http://arxiv.org/abs/2502.05756v1,Reinforcement Learning,"vit, vision, visual, embeddings, images"
"Filter, Obstruct and Dilute: Defending Against Backdoor Attacks on Semi-Supervised Learning","Recent studies have verified that semi-supervised learning (SSL) is
vulnerable to data poisoning backdoor attacks. Even a tiny fraction of
contaminated training data is sufficient for adversaries to manipulate up to
90\% of the test outputs in existing SSL methods. Given the emerging threat of
backdoor attacks designed for SSL, this work aims to protect SSL against such
risks, marking it as one of the few known efforts in this area. Specifically,
we begin by identifying that the spurious correlations between the backdoor
triggers and the target class implanted by adversaries are the primary cause of
manipulated model predictions during the test phase. To disrupt these
correlations, we utilize three key techniques: Gaussian Filter, complementary
learning and trigger mix-up, which collectively filter, obstruct and dilute the
influence of backdoor attacks in both data pre-processing and feature learning.
Experimental results demonstrate that our proposed method, Backdoor Invalidator
(BI), significantly reduces the average attack success rate from 84.7\% to
1.8\% across different state-of-the-art backdoor attacks. It is also worth
mentioning that BI does not sacrifice accuracy on clean data and is supported
by a theoretical guarantee of its generalization capability.",http://arxiv.org/abs/2502.05755v1,Recommendation System,"backdoor, ssl, data, attacks, learning"
PINGS: Gaussian Splatting Meets Distance Fields within a Point-Based Implicit Neural Map,"Robots require high-fidelity reconstructions of their environment for
effective operation. Such scene representations should be both, geometrically
accurate and photorealistic to support downstream tasks. While this can be
achieved by building distance fields from range sensors and radiance fields
from cameras, the scalable incremental mapping of both fields consistently and
at the same time with high quality remains challenging. In this paper, we
propose a novel map representation that unifies a continuous signed distance
field and a Gaussian splatting radiance field within an elastic and compact
point-based implicit neural map. By enforcing geometric consistency between
these fields, we achieve mutual improvements by exploiting both modalities. We
devise a LiDAR-visual SLAM system called PINGS using the proposed map
representation and evaluate it on several challenging large-scale datasets.
Experimental results demonstrate that PINGS can incrementally build globally
consistent distance and radiance fields encoded with a compact set of neural
points. Compared to the state-of-the-art methods, PINGS achieves superior
photometric and geometric rendering at novel views by leveraging the
constraints from the distance field. Furthermore, by utilizing dense
photometric cues and multi-view consistency from the radiance field, PINGS
produces more accurate distance fields, leading to improved odometry estimation
and mesh reconstruction.",http://arxiv.org/abs/2502.05752v1,Recommendation System,"fields, distance, radiance, field, pings"
UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control,"Recent advances in diffusion bridge models leverage Doob's $h$-transform to
establish fixed endpoints between distributions, demonstrating promising
results in image translation and restoration tasks. However, these approaches
frequently produce blurred or excessively smoothed image details and lack a
comprehensive theoretical foundation to explain these shortcomings. To address
these limitations, we propose UniDB, a unified framework for diffusion bridges
based on Stochastic Optimal Control (SOC). UniDB formulates the problem through
an SOC-based optimization and derives a closed-form solution for the optimal
controller, thereby unifying and generalizing existing diffusion bridge models.
We demonstrate that existing diffusion bridges employing Doob's $h$-transform
constitute a special case of our framework, emerging when the terminal penalty
coefficient in the SOC cost function tends to infinity. By incorporating a
tunable terminal penalty coefficient, UniDB achieves an optimal balance between
control costs and terminal penalties, substantially improving detail
preservation and output quality. Notably, UniDB seamlessly integrates with
existing diffusion bridge models, requiring only minimal code modifications.
Extensive experiments across diverse image restoration tasks validate the
superiority and adaptability of the proposed framework. Our code is available
at https://github.com/UniDB-SOC/UniDB/.",http://arxiv.org/abs/2502.05749v2,Recommendation System,"diffusion, unidb, bridge, models, image"
Satellite Observations Guided Diffusion Model for Accurate Meteorological States at Arbitrary Resolution,"Accurate acquisition of surface meteorological conditions at arbitrary
locations holds significant importance for weather forecasting and climate
simulation. Due to the fact that meteorological states derived from satellite
observations are often provided in the form of low-resolution grid fields, the
direct application of spatial interpolation to obtain meteorological states for
specific locations often results in significant discrepancies when compared to
actual observations. Existing downscaling methods for acquiring meteorological
state information at higher resolutions commonly overlook the correlation with
satellite observations. To bridge the gap, we propose Satellite-observations
Guided Diffusion Model (SGD), a conditional diffusion model pre-trained on ERA5
reanalysis data with satellite observations (GridSat) as conditions, which is
employed for sampling downscaled meteorological states through a zero-shot
guided sampling strategy and patch-based methods. During the training process,
we propose to fuse the information from GridSat satellite observations into
ERA5 maps via the attention mechanism, enabling SGD to generate atmospheric
states that align more accurately with actual conditions. In the sampling, we
employed optimizable convolutional kernels to simulate the upscale process,
thereby generating high-resolution ERA5 maps using low-resolution ERA5 maps as
well as observations from weather stations as guidance. Moreover, our devised
patch-based method promotes SGD to generate meteorological states at arbitrary
resolutions. Experiments demonstrate SGD fulfills accurate meteorological
states downscaling to 6.25km.",http://arxiv.org/abs/2502.07814v1,Recommendation System,"meteorological, observations, states, satellite, sgd"
Understanding Representation Dynamics of Diffusion Models via Low-Dimensional Modeling,"This work addresses the critical question of why and when diffusion models,
despite being designed for generative tasks, can excel at learning high-quality
representations in a self-supervised manner. To address this, we develop a
mathematical framework based on a low-dimensional data model and posterior
estimation, revealing a fundamental trade-off between generation and
representation quality near the final stage of image generation. Our analysis
explains the unimodal representation dynamics across noise scales, mainly
driven by the interplay between data denoising and class specification.
Building on these insights, we propose an ensemble method that aggregates
features across noise levels, significantly improving both clean performance
and robustness under label noise. Extensive experiments on both synthetic and
real-world datasets validate our findings.",http://arxiv.org/abs/2502.05743v1,Recommendation System,"noise, quality, data, generation, representation"
Linear Attention Modeling for Learned Image Compression,"Recent years, learned image compression has made tremendous progress to
achieve impressive coding efficiency. Its coding gain mainly comes from
non-linear neural network-based transform and learnable entropy modeling.
However, most of recent focuses have been solely on a strong backbone, and few
studies consider the low-complexity design. In this paper, we propose LALIC, a
linear attention modeling for learned image compression. Specially, we propose
to use Bi-RWKV blocks, by utilizing the Spatial Mix and Channel Mix modules to
achieve more compact features extraction, and apply the Conv based Omni-Shift
module to adapt to two-dimensional latent representation. Furthermore, we
propose a RWKV-based Spatial-Channel ConTeXt model (RWKV-SCCTX), that leverages
the Bi-RWKV to modeling the correlation between neighboring features
effectively, to further improve the RD performance. To our knowledge, our work
is the first work to utilize efficient Bi-RWKV models with linear attention for
learned image compression. Experimental results demonstrate that our method
achieves competitive RD performances by outperforming VTM-9.1 by -14.84%,
-15.20%, -17.32% in BD-rate on Kodak, Tecnick and CLIC Professional validation
datasets.",http://arxiv.org/abs/2502.05741v1,Reinforcement Learning,"rwkv, learned, image, compression, linear"
RECOVER: Designing a Large Language Model-based Remote Patient Monitoring System for Postoperative Gastrointestinal Cancer Care,"Cancer surgery is a key treatment for gastrointestinal (GI) cancers, a group
of cancers that account for more than 35% of cancer-related deaths worldwide,
but postoperative complications are unpredictable and can be life-threatening.
In this paper, we investigate how recent advancements in large language models
(LLMs) can benefit remote patient monitoring (RPM) systems through clinical
integration by designing RECOVER, an LLM-powered RPM system for postoperative
GI cancer care. To closely engage stakeholders in the design process, we first
conducted seven participatory design sessions with five clinical staff and
interviewed five cancer patients to derive six major design strategies for
integrating clinical guidelines and information needs into LLM-based RPM
systems. We then designed and implemented RECOVER, which features an
LLM-powered conversational agent for cancer patients and an interactive
dashboard for clinical staff to enable efficient postoperative RPM. Finally, we
used RECOVER as a pilot system to assess the implementation of our design
strategies with four clinical staff and five patients, providing design
implications by identifying crucial design elements, offering insights on
responsible AI, and outlining opportunities for future LLM-powered RPM systems.",http://arxiv.org/abs/2502.05740v1,Recommendation System,"design, cancer, rpm, clinical, llm"
Mitigating Sensitive Information Leakage in LLMs4Code through Machine Unlearning,"Large Language Models for Code (LLMs4Code) excel at code generation tasks,
yielding promise to release developers from huge software development burdens.
Nonetheless, these models have been shown to suffer from the significant
privacy risks due to the potential leakage of sensitive information embedded
during training, known as the memorization problem. Addressing this issue is
crucial for ensuring privacy compliance and upholding user trust, but till now
there is a dearth of dedicated studies in the literature that focus on this
specific direction. Recently, machine unlearning has emerged as a promising
solution by enabling models to ""forget"" sensitive information without full
retraining, offering an efficient and scalable approach compared to traditional
data cleaning methods. In this paper, we empirically evaluate the effectiveness
of unlearning techniques for addressing privacy concerns in
LLMs4Code.Specifically, we investigate three state-of-the-art unlearning
algorithms and three well-known open-sourced LLMs4Code, on a benchmark that
takes into consideration both the privacy data to be forgotten as well as the
code generation capabilites of these models. Results show that it is feasible
to mitigate the privacy concerns of LLMs4Code through machine unlearning while
maintain their code generation capabilities at the same time. We also dissect
the forms of privacy protection/leakage after unlearning and observe that there
is a shift from direct leakage to indirect leakage, which underscores the need
for future studies addressing this risk.",http://arxiv.org/abs/2502.05739v1,Recommendation System,"privacy, unlearning, models, code, leakage"
Performance Analysis of Traditional VQA Models Under Limited Computational Resources,"In real-world applications where computational resources are limited,
effectively integrating visual and textual information for Visual Question
Answering (VQA) presents significant challenges. This paper investigates the
performance of traditional models under computational constraints, focusing on
enhancing VQA performance, particularly for numerical and counting questions.
We evaluate models based on Bidirectional GRU (BidGRU), GRU, Bidirectional LSTM
(BidLSTM), and Convolutional Neural Networks (CNN), analyzing the impact of
different vocabulary sizes, fine-tuning strategies, and embedding dimensions.
Experimental results show that the BidGRU model with an embedding dimension of
300 and a vocabulary size of 3000 achieves the best overall performance without
the computational overhead of larger models. Ablation studies emphasize the
importance of attention mechanisms and counting information in handling complex
reasoning tasks under resource limitations. Our research provides valuable
insights for developing more efficient VQA models suitable for deployment in
environments with limited computational capacity.",http://arxiv.org/abs/2502.05738v1,Recommendation System,"computational, models, vqa, performance, limited"
Towards Autonomous Experimentation: Bayesian Optimization over Problem Formulation Space for Accelerated Alloy Development,"Accelerated discovery in materials science demands autonomous systems capable
of dynamically formulating and solving design problems. In this work, we
introduce a novel framework that leverages Bayesian optimization over a problem
formulation space to identify optimal design formulations in line with
decision-maker preferences. By mapping various design scenarios to a multi
attribute utility function, our approach enables the system to balance
conflicting objectives such as ductility, yield strength, density, and
solidification range without requiring an exact problem definition at the
outset. We demonstrate the efficacy of our method through an in silico case
study on a Mo-Nb-Ti-V-W alloy system targeted for gas turbine engine blade
applications. The framework converges on a sweet spot that satisfies critical
performance thresholds, illustrating that integrating problem formulation
discovery into the autonomous design loop can significantly streamline the
experimental process. Future work will incorporate human feedback to further
enhance the adaptability of the system in real-world experimental settings.",http://arxiv.org/abs/2502.05735v1,Recommendation System,"design, problem, system, discovery, autonomous"
Attainability of Two-Point Testing Rates for Finite-Sample Location Estimation,"LeCam's two-point testing method yields perhaps the simplest lower bound for
estimating the mean of a distribution: roughly, if it is impossible to
well-distinguish a distribution centered at $\mu$ from the same distribution
centered at $\mu+\Delta$, then it is impossible to estimate the mean by better
than $\Delta/2$. It is setting-dependent whether or not a nearly matching upper
bound is attainable. We study the conditions under which the two-point testing
lower bound can be attained for univariate mean estimation; both in the setting
of location estimation (where the distribution is known up to translation) and
adaptive location estimation (unknown distribution). Roughly, we will say an
estimate nearly attains the two-point testing lower bound if it incurs error
that is at most polylogarithmically larger than the Hellinger modulus of
continuity for $\tilde{\Omega}(n)$ samples.
  Adaptive location estimation is particularly interesting as some
distributions admit much better guarantees than sub-Gaussian rates (e.g.
$\operatorname{Unif}(\mu-1,\mu+1)$ permits error $\Theta(\frac{1}{n})$, while
the sub-Gaussian rate is $\Theta(\frac{1}{\sqrt{n}})$), yet it is not obvious
whether these rates may be adaptively attained by one unified approach. Our
main result designs an algorithm that nearly attains the two-point testing rate
for mixtures of symmetric, log-concave distributions with a common mean.
Moreover, this algorithm runs in near-linear time and is parameter-free. In
contrast, we show the two-point testing rate is not nearly attainable even for
symmetric, unimodal distributions.
  We complement this with results for location estimation, showing the
two-point testing rate is nearly attainable for unimodal distributions, but
unattainable for symmetric distributions.",http://arxiv.org/abs/2502.05730v1,Recommendation System,"point, testing, distribution, nearly, estimation"
Impact of Data Poisoning Attacks on Feasibility and Optimality of Neural Power System Optimizers,"The increased integration of clean yet stochastic energy resources and the
growing number of extreme weather events are narrowing the decision-making
window of power grid operators. This time constraint is fueling a plethora of
research on Machine Learning-, or ML-, based optimization proxies. While
finding a fast solution is appealing, the inherent vulnerabilities of the
learning-based methods are hindering their adoption. One of these
vulnerabilities is data poisoning attacks, which adds perturbations to ML
training data, leading to incorrect decisions. The impact of poisoning attacks
on learning-based power system optimizers have not been thoroughly studied,
which creates a critical vulnerability. In this paper, we examine the impact of
data poisoning attacks on ML-based optimization proxies that are used to solve
the DC Optimal Power Flow problem. Specifically, we compare the resilience of
three different methods-a penalty-based method, a post-repair approach, and a
direct mapping approach-against the adverse effects of poisoning attacks. We
will use the optimality and feasibility of these proxies as performance
metrics. The insights of this work will establish a foundation for enhancing
the resilience of neural power system optimizers.",http://arxiv.org/abs/2502.05727v1,Recommendation System,"based, power, poisoning, attacks, proxies"
Improving Environment Novelty Quantification for Effective Unsupervised Environment Design,"Unsupervised Environment Design (UED) formalizes the problem of autocurricula
through interactive training between a teacher agent and a student agent. The
teacher generates new training environments with high learning potential,
curating an adaptive curriculum that strengthens the student's ability to
handle unseen scenarios. Existing UED methods mainly rely on regret, a metric
that measures the difference between the agent's optimal and actual
performance, to guide curriculum design. Regret-driven methods generate
curricula that progressively increase environment complexity for the student
but overlook environment novelty -- a critical element for enhancing an agent's
generalizability. Measuring environment novelty is especially challenging due
to the underspecified nature of environment parameters in UED, and existing
approaches face significant limitations. To address this, this paper introduces
the Coverage-based Evaluation of Novelty In Environment (CENIE) framework.
CENIE proposes a scalable, domain-agnostic, and curriculum-aware approach to
quantifying environment novelty by leveraging the student's state-action space
coverage from previous curriculum experiences. We then propose an
implementation of CENIE that models this coverage and measures environment
novelty using Gaussian Mixture Models. By integrating both regret and novelty
as complementary objectives for curriculum design, CENIE facilitates effective
exploration across the state-action space while progressively increasing
curriculum complexity. Empirical evaluations demonstrate that augmenting
existing regret-based UED algorithms with CENIE achieves state-of-the-art
performance across multiple benchmarks, underscoring the effectiveness of
novelty-driven autocurricula for robust generalization.",http://arxiv.org/abs/2502.05726v1,Recommendation System,"environment, novelty, curriculum, cenie, ued"
Predictive Coresets,"Modern data analysis often involves massive datasets with hundreds of
thousands of observations, making traditional inference algorithms
computationally prohibitive. Coresets are selection methods designed to choose
a smaller subset of observations while maintaining similar learning
performance. Conventional coreset approaches determine these weights by
minimizing the Kullback-Leibler (KL) divergence between the likelihood
functions of the full and weighted datasets; as a result, this makes them
ill-posed for nonparametric models, where the likelihood is often intractable.
We propose an alternative variational method which employs randomized
posteriors and finds weights to match the unknown posterior predictive
distributions conditioned on the full and reduced datasets. Our approach
provides a general algorithm based on predictive recursions suitable for
nonparametric priors. We evaluate the performance of the proposed coreset
construction on diverse problems, including random partitions and density
estimation.",http://arxiv.org/abs/2502.05725v1,Recommendation System,"datasets, observations, performance, coreset, weights"
Rethinking Link Prediction for Directed Graphs,"Link prediction for directed graphs is a crucial task with diverse real-world
applications. Recent advances in embedding methods and Graph Neural Networks
(GNNs) have shown promising improvements. However, these methods often lack a
thorough analysis of embedding expressiveness and suffer from ineffective
benchmarks for a fair evaluation. In this paper, we propose a unified framework
to assess the expressiveness of existing methods, highlighting the impact of
dual embeddings and decoder design on performance. To address limitations in
current experimental setups, we introduce DirLinkBench, a robust new benchmark
with comprehensive coverage and standardized evaluation. The results show that
current methods struggle to achieve strong performance on the new benchmark,
while DiGAE outperforms others overall. We further revisit DiGAE theoretically,
showing its graph convolution aligns with GCN on an undirected bipartite graph.
Inspired by these insights, we propose a novel spectral directed graph
auto-encoder SDGAE that achieves SOTA results on DirLinkBench. Finally, we
analyze key factors influencing directed link prediction and highlight open
challenges.",http://arxiv.org/abs/2502.05724v1,Recommendation System,"methods, graph, directed, link, prediction"
Explainable and Class-Revealing Signal Feature Extraction via Scattering Transform and Constrained Zeroth-Order Optimization,"We propose a new method to extract discriminant and explainable features from
a particular machine learning model, i.e., a combination of the scattering
transform and the multiclass logistic regression. Although this model is
well-known for its ability to learn various signal classes with high
classification rate, it remains elusive to understand why it can generate such
successful classification, mainly due to the nonlinearity of the scattering
transform. In order to uncover the meaning of the scattering transform
coefficients selected by the multiclass logistic regression (with the Lasso
penalty), we adopt zeroth-order optimization algorithms to search an input
pattern that maximizes the class probability of a class of interest given the
learned model. In order to do so, it turns out that imposing sparsity and
smoothness of input patterns is important. We demonstrate the effectiveness of
our proposed method using a couple of synthetic time-series classification
problems.",http://arxiv.org/abs/2502.05722v2,Recommendation System,"model, scattering, transform, classification, order"
"Pareto-Optimality, Smoothness, and Stochasticity in Learning-Augmented One-Max-Search","One-max search is a classic problem in online decision-making, in which a
trader acts on a sequence of revealed prices and accepts one of them
irrevocably to maximise its profit. The problem has been studied both in
probabilistic and in worst-case settings, notably through competitive analysis,
and more recently in learning-augmented settings in which the trader has access
to a prediction on the sequence. However, existing approaches either lack
smoothness, or do not achieve optimal worst-case guarantees: they do not attain
the best possible trade-off between the consistency and the robustness of the
algorithm. We close this gap by presenting the first algorithm that
simultaneously achieves both of these important objectives. Furthermore, we
show how to leverage the obtained smoothness to provide an analysis of one-max
search in stochastic learning-augmented settings which capture randomness in
both the observed prices and the prediction.",http://arxiv.org/abs/2502.05720v1,Recommendation System,"settings, max, search, problem, trader"
Extended Histogram-based Outlier Score (EHBOS),"Histogram-Based Outlier Score (HBOS) is a widely used outlier or anomaly
detection method known for its computational efficiency and simplicity.
However, its assumption of feature independence limits its ability to detect
anomalies in datasets where interactions between features are critical. In this
paper, we propose the Extended Histogram-Based Outlier Score (EHBOS), which
enhances HBOS by incorporating two-dimensional histograms to capture
dependencies between feature pairs. This extension allows EHBOS to identify
contextual and dependency-driven anomalies that HBOS fails to detect. We
evaluate EHBOS on 17 benchmark datasets, demonstrating its effectiveness and
robustness across diverse anomaly detection scenarios. EHBOS outperforms HBOS
on several datasets, particularly those where feature interactions are critical
in defining the anomaly structure, achieving notable improvements in ROC AUC.
These results highlight that EHBOS can be a valuable extension to HBOS, with
the ability to model complex feature dependencies. EHBOS offers a powerful new
tool for anomaly detection, particularly in datasets where contextual or
relational anomalies play a significant role.",http://arxiv.org/abs/2502.05719v1,Recommendation System,"ehbos, hbos, anomaly, feature, datasets"
Using agent-based models and EXplainable Artificial Intelligence (XAI) to simulate social behaviors and policy intervention scenarios: A case study of private well users in Ireland,"Around 50 percent of Irelands rural population relies on unregulated private
wells vulnerable to agricultural runoff and untreated wastewater. High national
rates of Shiga toxin-producing Escherichia coli (STEC) and other waterborne
illnesses have been linked to well water exposure. Periodic well testing is
essential for public health, yet the lack of government incentives places the
financial burden on households. Understanding environmental, cognitive, and
material factors influencing well-testing behavior is critical.
  This study employs Agent-Based Modeling (ABM) to simulate policy
interventions based on national survey data. The ABM framework, designed for
private well-testing behavior, integrates a Deep Q-network reinforcement
learning model and Explainable AI (XAI) for decision-making insights. Key
features were selected using Recursive Feature Elimination (RFE) with 10-fold
cross-validation, while SHAP (Shapley Additive Explanations) provided further
interpretability for policy recommendations.
  Fourteen policy scenarios were tested. The most effective, Free Well Testing
plus Communication Campaign, increased participation to 435 out of 561 agents,
from a baseline of approximately 5 percent, with rapid behavioral adaptation.
Free Well Testing plus Regulation also performed well, with 433 out of 561
agents initiating well testing. Free testing alone raised participation to over
75 percent, with some agents testing multiple times annually. Scenarios with
free well testing achieved faster learning efficiency, converging in 1000
episodes, while others took 2000 episodes, indicating slower adaptation.
  This research demonstrates the value of ABM and XAI in public health policy,
providing a framework for evaluating behavioral interventions in environmental
health.",http://arxiv.org/abs/2502.05718v1,Reinforcement Learning,"testing, policy, free, percent, health"
Topological derivative approach for deep neural network architecture adaptation,"This work presents a novel algorithm for progressively adapting neural
network architecture along the depth. In particular, we attempt to address the
following questions in a mathematically principled way: i) Where to add a new
capacity (layer) during the training process? ii) How to initialize the new
capacity? At the heart of our approach are two key ingredients: i) the
introduction of a ``shape functional"" to be minimized, which depends on neural
network topology, and ii) the introduction of a topological derivative of the
shape functional with respect to the neural network topology. Using an optimal
control viewpoint, we show that the network topological derivative exists under
certain conditions, and its closed-form expression is derived. In particular,
we explore, for the first time, the connection between the topological
derivative from a topology optimization framework with the Hamiltonian from
optimal control theory. Further, we show that the optimality condition for the
shape functional leads to an eigenvalue problem for deep neural architecture
adaptation. Our approach thus determines the most sensitive location along the
depth where a new layer needs to be inserted during the training phase and the
associated parametric initialization for the newly added layer. We also
demonstrate that our layer insertion strategy can be derived from an optimal
transport viewpoint as a solution to maximizing a topological derivative in
$p$-Wasserstein space, where $p>= 1$. Numerical investigations with fully
connected network, convolutional neural network, and vision transformer on
various regression and classification problems demonstrate that our proposed
approach can outperform an ad-hoc baseline network and other architecture
adaptation strategies. Further, we also demonstrate other applications of
topological derivative in fields such as transfer learning.",http://arxiv.org/abs/2502.06885v1,Recommendation System,"network, neural, topological, derivative, layer"
Proving the Coding Interview: A Benchmark for Formally Verified Code Generation,"We introduce the Formally Verified Automated Programming Progress Standards,
or FVAPPS, a benchmark of 4715 samples for writing programs and proving their
correctness, the largest formal verification benchmark, including 1083 curated
and quality controlled samples. Previously, APPS provided a benchmark and
dataset for programming puzzles to be completed in Python and checked against
unit tests, of the kind seen in technical assessments in the software
engineering industry. Building upon recent approaches for benchmarks in
interactive theorem proving, we generalize the unit tests to Lean 4 theorems
given without proof (i.e., using Lean's ""sorry"" keyword). On the 406 theorems
of 100 randomly selected samples, Sonnet correctly proves 30% and Gemini
correctly proves 18%. We challenge the machine learning and program synthesis
communities to solve both each general purpose programming problem and its
associated correctness specifications. The benchmark is available at
https://huggingface.co/datasets/quinn-dougherty/fvapps.",http://arxiv.org/abs/2502.05714v1,Recommendation System,"benchmark, programming, samples, proving, correctness"
4D VQ-GAN: Synthesising Medical Scans at Any Time Point for Personalised Disease Progression Modelling of Idiopathic Pulmonary Fibrosis,"Understanding the progression trajectories of diseases is crucial for early
diagnosis and effective treatment planning. This is especially vital for
life-threatening conditions such as Idiopathic Pulmonary Fibrosis (IPF), a
chronic, progressive lung disease with a prognosis comparable to many cancers.
Computed tomography (CT) imaging has been established as a reliable diagnostic
tool for IPF. Accurately predicting future CT scans of early-stage IPF patients
can aid in developing better treatment strategies, thereby improving survival
outcomes. In this paper, we propose 4D Vector Quantised Generative Adversarial
Networks (4D-VQ-GAN), a model capable of generating realistic CT volumes of IPF
patients at any time point. The model is trained using a two-stage approach. In
the first stage, a 3D-VQ-GAN is trained to reconstruct CT volumes. In the
second stage, a Neural Ordinary Differential Equation (ODE) based temporal
model is trained to capture the temporal dynamics of the quantised embeddings
generated by the encoder in the first stage. We evaluate different
configurations of our model for generating longitudinal CT scans and compare
the results against ground truth data, both quantitatively and qualitatively.
For validation, we conduct survival analysis using imaging biomarkers derived
from generated CT scans and achieve a C-index comparable to that of biomarkers
derived from the real CT scans. The survival analysis results demonstrate the
potential clinical utility inherent to generated longitudinal CT scans, showing
that they can reliably predict survival outcomes.",http://arxiv.org/abs/2502.05713v1,Recommendation System,"ct, scans, stage, ipf, survival"
SSDD-GAN: Single-Step Denoising Diffusion GAN for Cochlear Implant Surgical Scene Completion,"Recent deep learning-based image completion methods, including both
inpainting and outpainting, have demonstrated promising results in restoring
corrupted images by effectively filling various missing regions. Among these,
Generative Adversarial Networks (GANs) and Denoising Diffusion Probabilistic
Models (DDPMs) have been employed as key generative image completion
approaches, excelling in the field of generating high-quality restorations with
reduced artifacts and improved fine details. In previous work, we developed a
method aimed at synthesizing views from novel microscope positions for
mastoidectomy surgeries; however, that approach did not have the ability to
restore the surrounding surgical scene environment. In this paper, we propose
an efficient method to complete the surgical scene of the synthetic
postmastoidectomy dataset. Our approach leverages self-supervised learning on
real surgical datasets to train a Single-Step Denoising Diffusion-GAN
(SSDD-GAN), combining the advantages of diffusion models with the adversarial
optimization of GANs for improved Structural Similarity results of 6%. The
trained model is then directly applied to the synthetic postmastoidectomy
dataset using a zero-shot approach, enabling the generation of realistic and
complete surgical scenes without the need for explicit ground-truth labels from
the synthetic postmastoidectomy dataset. This method addresses key limitations
in previous work, offering a novel pathway for full surgical microscopy scene
completion and enhancing the usability of the synthetic postmastoidectomy
dataset in surgical preoperative planning and intraoperative navigation.",http://arxiv.org/abs/2502.05710v1,Recommendation System,"surgical, synthetic, postmastoidectomy, dataset, completion"
Flow-based Conformal Prediction for Multi-dimensional Time Series,"Conformal prediction for time series presents two key challenges: (1)
leveraging sequential correlations in features and non-conformity scores and
(2) handling multi-dimensional outcomes. We propose a novel conformal
prediction method to address these two key challenges by integrating
Transformer and Normalizing Flow. Specifically, the Transformer encodes the
historical context of time series, and normalizing flow learns the
transformation from the base distribution to the distribution of non-conformity
scores conditioned on the encoded historical context. This enables the
construction of prediction regions by transforming samples from the base
distribution using the learned conditional flow. We ensure the marginal
coverage by defining the prediction regions as sets in the transformed space
that correspond to a predefined probability mass in the base distribution. The
model is trained end-to-end by Flow Matching, avoiding the need for
computationally intensive numerical solutions of ordinary differential
equations. We demonstrate that our proposed method achieves smaller prediction
regions compared to the baselines while satisfying the desired coverage through
comprehensive experiments using simulated and real-world time series datasets.",http://arxiv.org/abs/2502.05709v1,Recommendation System,"prediction, flow, distribution, time, series"
GWRF: A Generalizable Wireless Radiance Field for Wireless Signal Propagation Modeling,"We present Generalizable Wireless Radiance Fields (GWRF), a framework for
modeling wireless signal propagation at arbitrary 3D transmitter and receiver
positions. Unlike previous methods that adapt vanilla Neural Radiance Fields
(NeRF) from the optical to the wireless signal domain, requiring extensive
per-scene training, GWRF generalizes effectively across scenes. First, a
geometry-aware Transformer encoder-based wireless scene representation module
incorporates information from geographically proximate transmitters to learn a
generalizable wireless radiance field. Second, a neural-driven ray tracing
algorithm operates on this field to automatically compute signal reception at
the receiver. Experimental results demonstrate that GWRF outperforms existing
methods on single scenes and achieves state-of-the-art performance on unseen
scenes.",http://arxiv.org/abs/2502.05708v1,Recommendation System,"wireless, radiance, gwrf, signal, scenes"
TD(0) Learning converges for Polynomial mixing and non-linear functions,"Theoretical work on Temporal Difference (TD) learning has provided
finite-sample and high-probability guarantees for data generated from Markov
chains. However, these bounds typically require linear function approximation,
instance-dependent step sizes, algorithmic modifications, and restrictive
mixing rates. We present theoretical findings for TD learning under more
applicable assumptions, including instance-independent step sizes, full data
utilization, and polynomial ergodicity, applicable to both linear and
non-linear functions. \textbf{To our knowledge, this is the first proof of
TD(0) convergence on Markov data under universal and instance-independent step
sizes.} While each contribution is significant on its own, their combination
allows these bounds to be effectively utilized in practical application
settings. Our results include bounds for linear models and non-linear under
generalized gradients and H\""older continuity.",http://arxiv.org/abs/2502.05706v1,Recommendation System,"linear, data, bounds, instance, step"
Rethinking Word Similarity: Semantic Similarity through Classification Confusion,"Word similarity has many applications to social science and cultural
analytics tasks like measuring meaning change over time and making sense of
contested terms. Yet traditional similarity methods based on cosine similarity
between word embeddings cannot capture the context-dependent, asymmetrical,
polysemous nature of semantic similarity. We propose a new measure of
similarity, Word Confusion, that reframes semantic similarity in terms of
feature-based classification confusion. Word Confusion is inspired by Tversky's
suggestion that similarity features be chosen dynamically. Here we train a
classifier to map contextual embeddings to word identities and use the
classifier confusion (the probability of choosing a confounding word c instead
of the correct target word t) as a measure of the similarity of c and t. The
set of potential confounding words acts as the chosen features. Our method is
comparable to cosine similarity in matching human similarity judgments across
several datasets (MEN, WirdSim353, and SimLex), and can measure similarity
using predetermined features of interest. We demonstrate our model's ability to
make use of dynamic features by applying it to test a hypothesis about changes
in the 18th C. meaning of the French word ""revolution"" from popular to state
action during the French Revolution. We hope this reimagining of semantic
similarity will inspire the development of new tools that better capture the
multi-faceted and dynamic nature of language, advancing the fields of
computational social science and cultural analytics and beyond.",http://arxiv.org/abs/2502.05704v1,Recommendation System,"similarity, word, confusion, features, semantic"
TOKON: TOKenization-Optimized Normalization for time series analysis with a large language model,"While large language models have rapidly evolved towards general artificial
intelligence, their versatility in analyzing time series data remains limited.
To address this limitation, we propose a novel normalization technique that
considers the inherent nature of tokenization. The proposed
Tokenization-Optimized Normalization (TOKON) simplifies time series data by
representing each element with a single token, effectively reducing the number
of tokens by 2 to 3 times. Additionally, we introduce a novel prompt for time
series forecasting, termed Time Series Forecasting with Care (TFSC), to further
enhance forecasting performance. Experimental results demonstrate that TOKON
improves root mean square error (RMSE) for multi-step forecasting by
approximately 7% to 18%, depending on the dataset and prompting method.
Furthermore, TFSC, when used in conjunction with TOKON, shows additional
improvements in forecasting accuracy for certain datasets",http://arxiv.org/abs/2502.05701v1,Recommendation System,"forecasting, time, series, tokon, data"
Context information can be more important than reasoning for time series forecasting with a large language model,"With the evolution of large language models (LLMs), there is growing interest
in leveraging LLMs for time series tasks. In this paper, we explore the
characteristics of LLMs for time series forecasting by considering various
existing and proposed prompting techniques. Forecasting for both short and long
time series was evaluated. Our findings indicate that no single prompting
method is universally applicable. It was also observed that simply providing
proper context information related to the time series, without additional
reasoning prompts, can achieve performance comparable to the best-performing
prompt for each case. From this observation, it is expected that providing
proper context information can be more crucial than a prompt for specific
reasoning in time series forecasting. Several weaknesses in prompting for time
series forecasting were also identified. First, LLMs often fail to follow the
procedures described by the prompt. Second, when reasoning steps involve simple
algebraic calculations with several operands, LLMs often fail to calculate
accurately. Third, LLMs sometimes misunderstand the semantics of prompts,
resulting in incomplete responses.",http://arxiv.org/abs/2502.05699v1,Natural Language Processing,"llms, time, series, forecasting, prompting"
Learning Conformal Abstention Policies for Adaptive Risk Management in Large Language and Vision-Language Models,"Large Language and Vision-Language Models (LLMs/VLMs) are increasingly used
in safety-critical applications, yet their opaque decision-making complicates
risk assessment and reliability. Uncertainty quantification (UQ) helps assess
prediction confidence and enables abstention when uncertainty is high.
Conformal prediction (CP), a leading UQ method, provides statistical guarantees
but relies on static thresholds, which fail to adapt to task complexity and
evolving data distributions, leading to suboptimal trade-offs in accuracy,
coverage, and informativeness. To address this, we propose learnable conformal
abstention, integrating reinforcement learning (RL) with CP to optimize
abstention thresholds dynamically. By treating CP thresholds as adaptive
actions, our approach balances multiple objectives, minimizing prediction set
size while maintaining reliable coverage. Extensive evaluations across diverse
LLM/VLM benchmarks show our method outperforms Least Ambiguous Classifiers
(LAC) and Adaptive Prediction Sets (APS), improving accuracy by up to 3.2%,
boosting AUROC for hallucination detection by 22.19%, enhancing
uncertainty-guided selective generation (AUARC) by 21.17%, and reducing
calibration error by 70%-85%. These improvements hold across multiple models
and datasets while consistently meeting the 90% coverage target, establishing
our approach as a more effective and flexible solution for reliable
decision-making in safety-critical applications. The code is available at:
{https://github.com/sinatayebati/vlm-uncertainty}.",http://arxiv.org/abs/2502.06884v1,Reinforcement Learning,"prediction, uncertainty, abstention, cp, thresholds"
Semantic-Aware Adaptive Video Streaming Using Latent Diffusion Models for Wireless Networks,"This paper proposes a novel framework for real-time adaptive-bitrate video
streaming by integrating latent diffusion models (LDMs) within the FFmpeg
techniques. This solution addresses the challenges of high bandwidth usage,
storage inefficiencies, and quality of experience (QoE) degradation associated
with traditional constant bitrate streaming (CBS) and adaptive bitrate
streaming (ABS). The proposed approach leverages LDMs to compress I-frames into
a latent space, offering significant storage and semantic transmission savings
without sacrificing high visual quality. While it keeps B-frames and P-frames
as adjustment metadata to ensure efficient video reconstruction at the user
side, the proposed framework is complemented with the most state-of-the-art
denoising and video frame interpolation (VFI) techniques. These techniques
mitigate semantic ambiguity and restore temporal coherence between frames, even
in noisy wireless communication environments. Experimental results demonstrate
the proposed method achieves high-quality video streaming with optimized
bandwidth usage, outperforming state-of-the-art solutions in terms of QoE and
resource efficiency. This work opens new possibilities for scalable real-time
video streaming in 5G and future post-5G networks.",http://arxiv.org/abs/2502.05695v1,Recommendation System,"video, streaming, frames, bitrate, techniques"
"Zero-Shot End-to-End Relation Extraction in Chinese: A Comparative Study of Gemini, LLaMA and ChatGPT","This study investigates the performance of various large language models
(LLMs) on zero-shot end-to-end relation extraction (RE) in Chinese, a task that
integrates entity recognition and relation extraction without requiring
annotated data. While LLMs show promise for RE, most prior work focuses on
English or assumes pre-annotated entities, leaving their effectiveness in
Chinese RE largely unexplored. To bridge this gap, we evaluate ChatGPT, Gemini,
and LLaMA based on accuracy, efficiency, and adaptability. ChatGPT demonstrates
the highest overall performance, balancing precision and recall, while Gemini
achieves the fastest inference speed, making it suitable for real-time
applications. LLaMA underperforms in both accuracy and latency, highlighting
the need for further adaptation. Our findings provide insights into the
strengths and limitations of LLMs for zero-shot Chinese RE, shedding light on
trade-offs between accuracy and efficiency. This study serves as a foundation
for future research aimed at improving LLM adaptability to complex linguistic
tasks in Chinese NLP.",http://arxiv.org/abs/2502.05694v1,Natural Language Processing,"chinese, llms, accuracy, study, performance"
Managing Geological Uncertainty in Critical Mineral Supply Chains: A POMDP Approach with Application to U.S. Lithium Resources,"The world is entering an unprecedented period of critical mineral demand,
driven by the global transition to renewable energy technologies and electric
vehicles. This transition presents unique challenges in mineral resource
development, particularly due to geological uncertainty-a key characteristic
that traditional supply chain optimization approaches do not adequately
address. To tackle this challenge, we propose a novel application of Partially
Observable Markov Decision Processes (POMDPs) that optimizes critical mineral
sourcing decisions while explicitly accounting for the dynamic nature of
geological uncertainty. Through a case study of the U.S. lithium supply chain,
we demonstrate that POMDP-based policies achieve superior outcomes compared to
traditional approaches, especially when initial reserve estimates are
imperfect. Our framework provides quantitative insights for balancing domestic
resource development with international supply diversification, offering
policymakers a systematic approach to strategic decision-making in critical
mineral supply chains.",http://arxiv.org/abs/2502.05690v1,Recommendation System,"mineral, supply, critical, transition, resource"
Mobile Application Threats and Security,"The movement to mobile computing solutions provides flexibility to different
users whether it is a business user, a student, or even providing entertainment
to children and adults of all ages. Due to these emerging technologies mobile
users are unable to safeguard private information in a very effective way and
cybercrimes are increasing day by day. This manuscript will focus on security
vulnerabilities in the mobile computing industry, especially focusing on
tablets and smart phones. This study will dive into current security threats
for the Android & Apple iOS market, exposing security risks and threats that
the novice or average user may not be aware of. The purpose of this study is to
analyze current security risks and threats, and provide solutions that may be
deployed to protect against such threats.",http://arxiv.org/abs/2502.05685v1,Recommendation System,"security, threats, mobile, computing, solutions"
Machine Unlearning via Information Theoretic Regularization,"How can we effectively remove or ""unlearn"" undesirable information, such as
specific features or individual data points, from a learning outcome while
minimizing utility loss and ensuring rigorous guarantees? We introduce a
mathematical framework based on information-theoretic regularization to address
both feature and data point unlearning. For feature unlearning, we derive a
unified solution that simultaneously optimizes diverse learning objectives,
including entropy, conditional entropy, KL-divergence, and the energy of
conditional probability. For data point unlearning, we first propose a novel
definition that serves as a practical condition for unlearning via retraining,
is easy to verify, and aligns with the principles of differential privacy from
an inference perspective. Then, we provide provable guarantees for our
framework on data point unlearning. By combining flexibility in learning
objectives with simplicity in regularization design, our approach is highly
adaptable and practical for a wide range of machine learning and AI
applications.",http://arxiv.org/abs/2502.05684v2,Recommendation System,"unlearning, data, learning, point, information"
Federated Learning with Reservoir State Analysis for Time Series Anomaly Detection,"With a growing data privacy concern, federated learning has emerged as a
promising framework to train machine learning models without sharing locally
distributed data. In federated learning, local model training by multiple
clients and model integration by a server are repeated only through model
parameter sharing. Most existing federated learning methods assume training
deep learning models, which are often computationally demanding. To deal with
this issue, we propose federated learning methods with reservoir state analysis
to seek computational efficiency and data privacy protection simultaneously.
Specifically, our method relies on Mahalanobis Distance of Reservoir States
(MD-RS) method targeting time series anomaly detection, which learns a
distribution of reservoir states for normal inputs and detects anomalies based
on a deviation from the learned distribution. Iterative updating of statistical
parameters in the MD-RS enables incremental federated learning (IncFed MD-RS).
We evaluate the performance of IncFed MD-RS using benchmark datasets for time
series anomaly detection. The results show that IncFed MD-RS outperforms other
federated learning methods with deep learning and reservoir computing models
particularly when clients' data are relatively short and heterogeneous. We
demonstrate that IncFed MD-RS is robust against reduced sample data compared to
other methods. We also show that the computational cost of IncFed MD-RS can be
reduced by subsampling from the reservoir states without performance
degradation. The proposed method is beneficial especially in anomaly detection
applications where computational efficiency, algorithm simplicity, and low
communication cost are required.",http://arxiv.org/abs/2502.05679v1,Recommendation System,"learning, md, rs, federated, data"
Surprise Potential as a Measure of Interactivity in Driving Scenarios,"Validating the safety and performance of an autonomous vehicle (AV) requires
benchmarking on real-world driving logs. However, typical driving logs contain
mostly uneventful scenarios with minimal interactions between road users.
Identifying interactive scenarios in real-world driving logs enables the
curation of datasets that amplify critical signals and provide a more accurate
assessment of an AV's performance. In this paper, we present a novel metric
that identifies interactive scenarios by measuring an AV's surprise potential
on others. First, we identify three dimensions of the design space to describe
a family of surprise potential measures. Second, we exhaustively evaluate and
compare different instantiations of the surprise potential measure within this
design space on the nuScenes dataset. To determine how well a surprise
potential measure correctly identifies an interactive scenario, we use a reward
model learned from human preferences to assess alignment with human intuition.
Our proposed surprise potential, arising from this exhaustive comparative
study, achieves a correlation of more than 0.82 with the human-aligned reward
function, outperforming existing approaches. Lastly, we validate motion
planners on curated interactive scenarios to demonstrate downstream
applications.",http://arxiv.org/abs/2502.05677v1,Recommendation System,"surprise, potential, scenarios, interactive, av"
Generalized Venn and Venn-Abers Calibration with Applications in Conformal Prediction,"Ensuring model calibration is critical for reliable predictions, yet popular
distribution-free methods, such as histogram binning and isotonic regression,
provide only asymptotic guarantees. We introduce a unified framework for Venn
and Venn-Abers calibration, generalizing Vovk's binary classification approach
to arbitrary prediction tasks and loss functions. Venn calibration leverages
binning calibrators to construct prediction sets that contain at least one
marginally perfectly calibrated point prediction in finite samples, capturing
epistemic uncertainty in the calibration process. The width of these sets
shrinks asymptotically to zero, converging to a conditionally calibrated point
prediction. Furthermore, we propose Venn multicalibration, a novel methodology
for finite-sample calibration across subpopulations. For quantile loss,
group-conditional and multicalibrated conformal prediction arise as special
cases of Venn multicalibration, and Venn calibration produces novel conformal
prediction intervals that achieve quantile-conditional coverage. As a separate
contribution, we extend distribution-free conditional calibration guarantees of
histogram binning and isotonic calibration to general losses.",http://arxiv.org/abs/2502.05676v1,Recommendation System,"calibration, venn, prediction, binning, conditional"
The Evolution of Dataset Distillation: Toward Scalable and Generalizable Solutions,"Dataset distillation, which condenses large-scale datasets into compact
synthetic representations, has emerged as a critical solution for training
modern deep learning models efficiently. While prior surveys focus on
developments before 2023, this work comprehensively reviews recent advances,
emphasizing scalability to large-scale datasets such as ImageNet-1K and
ImageNet-21K. We categorize progress into a few key methodologies: trajectory
matching, gradient matching, distribution matching, scalable generative
approaches, and decoupling optimization mechanisms. As a comprehensive
examination of recent dataset distillation advances, this survey highlights
breakthrough innovations: the SRe2L framework for efficient and effective
condensation, soft label strategies that significantly enhance model accuracy,
and lossless distillation techniques that maximize compression while
maintaining performance. Beyond these methodological advancements, we address
critical challenges, including robustness against adversarial and backdoor
attacks, effective handling of non-IID data distributions. Additionally, we
explore emerging applications in video and audio processing, multi-modal
learning, medical imaging, and scientific computing, highlighting its domain
versatility. By offering extensive performance comparisons and actionable
research directions, this survey equips researchers and practitioners with
practical insights to advance efficient and generalizable dataset distillation,
paving the way for future innovations.",http://arxiv.org/abs/2502.05673v1,Recommendation System,"distillation, dataset, matching, large, scale"
